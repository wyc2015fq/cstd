# 4个小例子告诉你，如何成为一名数据极客 - 文章 - 伯乐在线
原文出处： [GavinZhang（ @GavinBuildSomething ）](http://guoze.me/2015/12/12/data-geek/)
对于数据岗位的员工，互联网公司颇有些不同的称谓，像统计工程师、大数据工程师、数据分析师、算法工程师、数据科学家等，每一种之间的技能差距简直是风马牛不相及。
但我觉得，数据岗位的需求千变万化，真正能通过数据解决问题的人，不仅要通晓两到三种岗位的技能，而且要深刻理解数据方法论，能将数据玩弄于鼓掌之中，这种人我称之为`数据极客`。好比武侠小说中的绝顶高手，杀人已不需要用剑，剑意就能杀人于无形。
数据极客都需要具备哪些能力？懂数据的人会怎么去思考和解决问题？我想举我自身遇到的4个小例子来说明。
# 懂得创造数据
在大部分人的常识里，数据是客观存在的，既不会递增，也不会消减。所有当他们绘制报表、展开分析、构建模型时，很容易遭遇的瓶颈是`没有数据`，俗话说，巧妇难为无米之炊。真实的状况却是：数据是无穷无尽的，哪怕有时我们与数据之间的距离很远，就像远在天边的繁星，「手可摘星辰」只是一个传说，但经过大气层的折射我们却能时刻感受到它们的光辉。不仅光会折射，数据同样也会折射。举一个小例子：
> 
实习生Q跑来问我：「Boss赶着要大厅发言的数据去对付投资人，但是后台碍于发言的数据量级太大，一直都没有保存，无论数据库还是日志系统都没有记录。」
我想了一下，问：「客户端进入大厅页面的事件一直都有监控，可以用那个数据替代吗？」
「但是这个数据并不精确，因为进入大厅的并不完全转化为发言。」
「是的，虽然不十分精确，但可以暂时用这个数据近似。然后，好友添加的数据一定程度也能反映大厅发言的热度，因为之前的统计显示，70%的好友关系产生来自于大厅。哦，对了，你有没有关注大厅界面的发送按钮的事件统计？这会是一个更为精确的替代数据。」
这就是一个数据有无到有被创造出来的例子。虽然原始数据没有保存，但是数据极客的任务就是通过其他可能被获取的数据逼近原始数据，从而还原一个较为真实的状况。如果没有数据能够成为一个罢工的借口，那么我相信恐怕90%的数据极客都得失业了。但反过来，如果不是对业务对数据的采集都了如指掌，同样没办法快速实现这种变数据的戏法。
# 数据是立体的
20世纪初，毕加索兴起了立体主义的绘画潮流，追求以许多组合的碎片形态去描写对象物，并将其置于同一个画面之中，物体的各个角度交错叠放创造出了一个多维的迷人空间。这和理想的数据展示多么相似：客观存在的问题经过多维度的数据解读，被展现在一个二维的平面上，让读者即便只站在一个角度，也能看到这个问题在所有角度上的表现。再举一个小例子（是的，这个例子完全与数据岗位无关，是一个来自客户端工程师的困扰）：
> 
W是U公司负责海外业务的安卓工程师，最近盯的是视频播放的项目，有次闲聊的时候说起，最近做了好几个底层库的性能优化，但从指标上看却没有明显提升，每次向老大汇报的时候总是心虚。
「性能优化的指标是怎么统计的？」
「海外业务的网络状况普遍不好，所以我们最关注的是视频页面的加载时间，统计的是从页面打开到视频完全加载的时间差，取所有用户的均值。」
「这个指标似乎不那么全面，如果一个用户等待的时间过长，他有可能提前关闭页面，是否有统计过关闭页面的数据？还有，看过这个时间差的分布状况么？如果性能优化有针对一些特殊的客户端（比如型号、CPU、内存），有没有看过特殊客户端下的指标有没有提升？」
我默想W的下次汇报一定会大肆耀武扬威一番，嘿嘿。
这就是数据的魔力所在。通过层层剖析，始终能找到与问题相关的有区分度的数据，再通过数据的变化去定位到问题的发生原因或者发展趋势，给出不容置疑的结论。所以，在解决任何问题之前（也不限于数据岗位），你都必须先构建起一套立体化的数据监控体系，来强有力的印证你的方案是有效的。
# 厌恶抽样
无论是做推荐系统、精准营销还是反欺诈，都会遇到一个现实的问题：如何检测一个模型的实际效果？在观察指标之余，抽取一小部分的标记用户，观察他们的行为模式，人为去验证这个模型的准确率，是一个必要的环节。但是抽样如果用得泛滥了，就不是补药而是毒药了。再举个小例子：
> 
G是团队的新人，有阵子我看他没日没夜的加班，忍不住过问了几句，看是不是最近业务上碰到了什么瓶颈。一问下来有点啼笑皆非：原来G正在负责一个反欺诈模型的建设，需要一些黑标签，他从所有用户中抽取了好几个特征用户群，然后从每个用户群中再抽样一批用户，通过日志观察是否有欺诈行为，这么一来就耗掉了两天的时间。
抽样是一种从局部看整体的方法，在抽样之上，你还要有对整体的把控。比如像G的做法就不符合数据极客的行为指南，既然可以通过日志观察到用户的行为特征，你就应该先把这种行为特征转化为可用的统计指标（比如识别欺诈，完全可以用收益相关的指标），再计算这几个用户群的均值特征，这样对比下来一目了然，而且省时省力。
# 善用工具
感谢谷歌创造了这个时代最廉价的`数据核武器` – Hadoop（当然，如果Spark的bug再少一些，我会考虑把AMPLab放到谷歌的前面），数据的规模对大部分企业而言已经是一个无需顾虑的问题。但是数据极客不会满足于会用工具的层次，理解工具的原理，灵活的使用工具，使工具变得更加顺手，才能真正达到「善」用工具的境界。再举一个小例子：
> 
Z博士刚毕业不久，一腔热血要把高大上的机器学习算法用到我们的推荐系统上，但是第一次的运算结果居然要8个小时才能跑完，远远达不到产品团队的更新要求。于是老大鼓动我去协助Z提升整个环节的效率，我们一起在白板上梳理了整个计算的流程，我发现有好几处都是浪费资源降低效率的做法：原始数据由单机做一次处理再上传到Hadoop、多个MapReduce其实可以合并为一个、甚至Hadoop的参数也可以根据机器的性能稍做调整：加大节点数、加大Map和Reduce环节的可用内存、添加压缩以减少节点间传输的时间。稍作改造，运算时间便只剩下了原来的四分之一。
说到这里，你也许会觉得数据极客也没什么巧妙，他们的方法论，和一切工作的方法论没什么不同，都会要多用脑子、多用工具、多种角度看待问题。既然如此，我可要恭喜你，你已经完全懂得了数据的妙用，而我一直以为，懂点数据，会对人的工作和生活大有助益。
