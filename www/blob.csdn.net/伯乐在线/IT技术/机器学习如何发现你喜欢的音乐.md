# 机器学习如何发现你喜欢的音乐 - 文章 - 伯乐在线
本文由 [伯乐在线](http://blog.jobbole.com) - [XiaofengYue_DXY](http://www.jobbole.com/members/1789912317) 翻译，[艾凌风](http://www.jobbole.com/members/hanxiaomax) 校稿。未经许可，禁止转载！
英文出处：[Sophia Ciocca](https://hackernoon.com/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe)。欢迎加入[翻译组](https://github.com/jobbole/translation-project)。
## 机器学习如何发现你喜欢的音乐：音乐个性化推荐背后的科学原理
本周一，正如其它每个周一，一亿多 Spotify 用户每人都收到了一个崭新的歌单。这个叫做每周发现的歌单内混合了用户从未听过但是可能会喜欢的 30首歌曲。效果堪称神奇。
我自己是 Spotify 的超级粉丝，对每周发现尤其喜爱。为什么呢？因为我觉得它懂我。它比我生命中的任何人都更清楚我的音乐品味。我很高兴每周它都能满足我的需求，一如既往地推荐一些我自己永远都不会找到或知道会喜欢的歌曲。
对于那些两耳不闻窗外事的人们，请允许我介绍一下我的虚拟好友：
![](http://wx2.sinaimg.cn/large/7cc829d3gy1fq7l3ts6p3j20ps0ocq78.jpg)
[图片说明: 我的 Spotify 每周发现歌单]
没想到，在这方面我不是一个人，不光是我对每周发现如此着迷 – 整个用户群体都趋之若鹜。这股热潮使得 Spotify 重新调整了它的重心，并在基于算法的歌单上投入了更多的资源。
![](http://wx4.sinaimg.cn/mw690/7cc829d3gy1fq7l3uppwxj20dy0bwabh.jpg)
> 
Dave Howitz: @Spotfiy 每周发现的歌单对我的了解程度简直毛骨悚然，熟悉到就像一个曾经与我有过一起濒死体验的前女友一样。
Amanda Whitbred: 现在 @Spotify 的每周发现对我已经了解到如果它现在求婚，我也会说同意的地步了。
自「每周发现」在 2015 年第一次上线以来，我就迫切想知道它是怎么运作的（而且由于我是 Spotify 公司的迷妹，我喜欢假装在那里工作并研究他们的产品）。 经过三周的疯狂Google，我终于满怀感恩地获取了一些幕后的知识。
所以 Spotify 到底是如何成功做到给每人每周挑选 30 首歌曲的？我们先来仔细看下其它的音乐服务是如何做音乐推荐，以及 Spotify 是如何更胜一筹的。
### 在线音乐甄选服务简史
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l3vdopfj20iu07n756.jpg)
早在千禧年之初，Songza 就开始使用手动甄选为用户提供歌单。手动甄选的意思就是所谓的音乐专家或者其他编辑会手动挑选一些他们自己认为不错的音乐做成歌单，然后听众可以直接拿来听。（稍后，Beats 音乐也采取了同样的策略）。手动甄选效果尚可，但是由于这种方法只是纯手工挑选，方式方法也比较简单，它并不能照顾到每个听众音乐品味的微妙差异。
跟 Songza 一样， Pandora 也是音乐甄选服务领域的早期玩家之一。它使用了一个略为更高级的方法来代替给歌曲属性手工打标签。即大众在听音乐的时候，对每首歌曲挑选一些描述性的词语来作为标签。进而，Pandora 的程序可以直接过滤特定的标签来生成包含相似歌曲的歌单。
差不多同一时间，一个隶属于麻省理工学院媒体实验室的名叫 The Echo Nest 的音乐信息机构，采用了一个完全不同的高级策略来定制音乐。The Echo Nest 使用算法来分析音频和音乐的文本内容，以完成音乐识别，个性化推荐，歌单创建和分析等。
最后，是 Last.fm 另辟蹊径，采取了另一个沿用至今的策略。那就是利用协同过滤来识别用户可能喜欢的音乐。稍后本文会展开讨论更多这方面的内容。
所以说既然其他的音乐甄选服务都实现了推荐功能，Spotify 究竟是怎么操作自己的神奇引擎，来实现甩出竞争对手几条街的用户品味默契度的呢？
### Spotify 的三种推荐模型
事实上 Spotify 并没有使用什么单一的革命性推荐模型，而是**混合了一些其他公司使用的最好的策略来创建他们自己独一无二的强大发现引擎。**
Spotify 使用三种主要的推荐模型来创建每周发现：
- **协同过滤模型**（即 Last.fm 最早使用的那些模型）。工作原理为分析你和**其他**用户的行为。
- **自然语言处理（NLP）**模型 。工作原理为分析文本。
- **音频**模型。工作原理为分析**原始音频声道本身**。
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l3vwrx4j20mv0dgjw0.jpg)
我们来具体看下这些推荐模型是怎么工作的！
### 推荐模型之一：协同过滤
![](http://wx4.sinaimg.cn/mw690/7cc829d3gy1fq7l3wmkvhj218g094tah.jpg)
首先介绍下背景：当很多人听到协同过滤这几个词的时候，他们会立刻联想到 **Netflix**，因为它是第一个利用协同过滤来实现推荐模型的公司之一。其做法主要是使用用户提交的电影星级来计算推荐那些电影给其他**类似的**用户。
自 **Netflix **将其成功应用以来，协同过滤开始快速流传开来。现在无论是谁想实现一个推荐模型的话，一般都会拿它作为初次尝试。
与**Netflix**不同的是，Spotify 并没有用户对他们音乐的星级评价数据。Spotify 所用的数据是**隐形反馈**的，具体来说就是我们在线听歌的**歌曲次数**，以及其他额外信息，诸如用户是否保存歌曲到个人歌单，或者听完歌曲后是否接着访问艺术家主页等。
但什么是协同过滤，到底它是如何工作的呢？下面用一段简短对话来做一个大致的介绍。
![](http://wx4.sinaimg.cn/large/7cc829d3gy1fq7l3x7gfyj20go0cytht.jpg)
啥情况? 原来这俩人里面每人都有自己的一些歌曲偏好 – 左边的人喜欢歌曲 P, Q, R 和 S; 右边的人喜欢 Q, R, S 和 T。
协同过滤系统进而利用这些数据得出结论，
> 
*“**嗯。既然你俩都喜欢相同的歌曲 – Q**，R **和 S – **那么你们可能是类似的用户。所以你们应该会喜欢另一个人听过但是你还没有听过的歌曲。”*
系统然后建议右边的人去体验下歌曲 P，以及左边的人去体验下歌曲 T。听起来够简单吧？
但是 Spotify 具体是怎么具体应用这个概念，来计算**基于百万级**的用户偏好从而得出**数以百万计**的用户歌曲推荐呢？
### …矩阵运算，用 Python 库即可实现
![](http://wx3.sinaimg.cn/mw690/7cc829d3gy1fq7l3xy4boj20ay071t9u.jpg)
现实中，此处提及的矩阵是极其庞大的。**每行都代表了**** Spotify ****的一亿四千万用户中的一员**（如果你也用 Spotify，那么你也是这个矩阵中的一行），而每一列则代表了 Spotify 数据库中**三亿首歌曲**中的一首。
然后，Python 库就开始跑这个漫长而复杂的矩阵分解公式：
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l3yp06ej20oy01v3zg.jpg)
计算完成后，系统会生成两种类型的向量，在此分别命名为 X 和 Y。X 为用户向量，代表单个用户的音乐品味。Y 则为歌曲向量，代表单支歌曲的特征。
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l3zb0mxj20mn0a8di9.jpg)
现在我们得到了一亿四千万个用户向量，每人一个，还有三亿歌曲向量。这些向量的具体内容只是一些单独拎出来自身并无意义的数字，但是在后面进行比较时会非常有用。
为了找到那些跟我相似品味的用户，协同过滤系统会拿我的向量跟其他用户的向量作比较，最终会找到那些跟我最相似的用户。对于 Y 向量，也是同样的流程 – 你可以拿一首歌的向量与其他的歌曲向量做比较，进而找出哪些歌曲是跟你现在正在看的歌曲最相似。
协同过滤确实效果不错，但是 Spotify 深知再添加另外一个引擎的话效果会更出色。这就到了自然语言处理出场的时候了。
### 推荐模型之二：自然语言处理
Spotify 采用的第二个推荐模型就是**自然语言处理**。这些模型的源数据，正如名字所示，就是一些普通的**语言文字** – 例如歌曲的元数据，新闻文章，博客，和互联网上的其它文本等。
![](http://wx4.sinaimg.cn/mw690/7cc829d3gy1fq7l40111lj20dr09h41u.jpg)
自然语言处理 – 计算机理解人类语言的能力 – 本身就是一个巨大的领域，通常通过情感分析应用编程接口（API）来进行操作处理。
自然语言处理背后的具体原理超出了本文的讨论范畴，但是在此本文可以提供一些粗略的描述：Spotify 会在网上不断爬取博客帖子以及其它音乐相关的文本，并找出人们对特定的艺术家和歌曲的评论 – 比如说人们对这些歌曲经常使用哪些形容词和语言, 以及哪些其他艺术家和歌曲也会和它们放在一起讨论。
虽然我不知道 Spotify 如何处理他们抓取的数据，但是我可以介绍下 The Echo Nest 是如何使用它们的。他们会把数据分类成“文化向量”和“最佳评语集”。每个艺术家和歌曲都有数以千计的每日更新的最佳评语集。每个评语都有一个相关的权重，来表示其描述的重要性（简单说就是某人可能会用该评语描述某个音乐的概率）。
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l40o7dnj20jm07qaej.jpg)
[ “Cultural vectors”, or “top terms”, as used by the Echo Nest. Table from Brian Whitman]
然后，与协同过滤类似，自然语言处理模型用这些评语和权重来创建一个歌曲的表达向量，可以用来确定两首音乐是否相似。很酷吧？
### 推荐模型之三：原始音频模型
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l41ibqgj20pn09btap.jpg)
首先，你可能会问这个问题：
> 
*但是，Sophia**，我们已经从前两种模型中获取了这么多数据！为什么还要继续分析音频本身呢？*
额，首先要说的是，引入第三个模型会进一步提高这个已经很优秀的推荐服务的准确性。但实际上，采用这个模型还有另外一个次要目的：**原始音频模型会把新歌考虑进来。**
比如说，你的创作歌手朋友在 Spotify 上刚放上了一首新歌。可能它只有 50 次听歌记录，所以很少能有其他听众来一起协同过滤它。与此同时，它也在网上也没有留下多少痕迹，所以自然语言处理模型也不会注意到它。幸运的是，原始音频模型并不区分新歌曲和热门歌曲。所以有了它的帮忙，你朋友的歌曲也可以和流行歌曲一道出现在每周发现的歌单里面。
好了，到了“如何”的部分了。我们如何才能分析这些看起来如此抽象的**原始音频数据**呢？
…用**卷积神经网络！**
卷积神经网络同样也是支撑面部识别的技术。只不过在 Spotify 的案例中，他们被稍作修改以基于音频数据处理而不是像素点。下面是一个神经网络架构的例子：
![](http://wx2.sinaimg.cn/mw690/7cc829d3gy1fq7l426503j20sg0gl423.jpg)
[*Image credit: Sander Dieleman*]
这个特定的神经网络有四个**卷积层**，具体为图中左侧的宽柱，和右边的稍微窄些的三根柱。输入是音频帧的时频表示，进而连接起来形成频谱图。
音频帧会穿过这些卷积层，经过最后一个卷积层，你可以看到一个“全局临时池”层。该层在整个时间轴上汇集数据，并有效计算和统计歌曲时长内的学习特征。
处理完之后，神经网络会得出其对歌曲的理解，包括估计的**时间签名，音调，调式，拍子及音量**等特征。下面就是 Draft Punk 的 “Around the World” 30 秒片段的数据图。
![](http://wx1.sinaimg.cn/mw690/7cc829d3gy1fq7l43abdwj20fq0hkdk4.jpg)
[Image Credit: [Tristan Jehan & David DesRoches (The Echo Nest)](http://docs.echonest.com.s3-website-us-east-1.amazonaws.com/_static/AnalyzeDocumentation.pdf)]
最终，对这些对歌曲关键特征的理解可以让 Spotify 来决定歌曲之间的相似度，以及根据用户听歌历史来判断哪些用户可能会喜欢它们。
这些基本涵盖了为每周发现提供支持的推荐作业流程所依赖的三种主要模型。
![](http://wx2.sinaimg.cn/large/7cc829d3gy1fq7l4426xrj20q70ec7ad.jpg)
[ Cassandra instances]
当然了，这些推荐模型也和 Spotify 其它更大的生态系统连接在一起，其中包括利用海量的数据存储以及**非常多**的 Hadoop 集群来做推荐服务的扩展，使得引擎得以计算巨型矩阵，无穷无尽的互联网音乐文章和大量的音频文件。
我希望本文可以对你有所启发，并且像当时它对我一样能够激起你的好奇。怀着对幕后的机器学习技术的了解和感激之情，现在我将通过我自己的每周发现来寻找我喜欢的音乐。
文章结束。
