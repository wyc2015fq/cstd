# 从做蛋糕到多重共线性(Multicollinearity) - 简书

# 从做蛋糕到多重共线性(Multicollinearity)

如果你不要看文章，只要订蛋糕，那就加wechat： wyywenyi。（限湾区，限湾区。我最喜欢你这种人了??）

#### 01 什么是Multicollinearity（多重共线性）？

这是回归方程：Y  =?0 + ?1X1 + ?2X2 + ?3X3 + ?4X4 + …... + ?pXp + E

这是我卖的蛋糕??：

![](https://upload-images.jianshu.io/upload_images/6342708-e9c15e47edd06e54.jpeg)

Micasa's Cake ～我就知道你不会读完文章，所以我先告诉你，欢迎加wechat：wyywenyi 欢迎订购呀。

**放蛋糕，是因为我要解释什么是Multicollinearity，顺便做个植入广告。嘿嘿。**

比如方程里的Y是面包的烘培时间(分钟)，X1是面粉的重量(g)，X2是面粉里面筋的重量(g)。我突然发现通过面粉里头面筋的重量，就可以推出面粉的重量，或者即使推不出来，也有很强的关系。或者又多出来一个X3，和面粉里的面筋量可以合起来，共同推出面粉的重量。

**这种变量之间的相关性就叫做多重共线性。**

#### 02 如果一个回归方程有了Multicollinearity，会怎么样?

回到做蛋糕，一般我们解释回归的时候，都是说，如果其他材料重量保持不变，面粉增加1g，那么烘烤时间会增加1分钟。但是有了Multicollinearity，就不能这么说了。因为我面粉增加了，面粉里的面筋也会增加的。

另外，如果有Multicollinearity，这些变量系数的正负号，也可能会和想象的想反。比如明明面粉越多，烘烤时间越长，但是有Multicollinearity的话，会变成面粉越多，烘烤时间越少了。这个你说可能伐？

#### 03 如何发现是不是有multicollinearity呢？

**1 用经验法：**
- 像前面说过的，如果面粉越多，烘培时间越少（即面粉变量的系数是负的），那肯定要怀疑是不是有multicollinearity；
- 面粉增加1g，烘培时间增加1000分钟（即面粉变量的系数是正的1000），也要怀疑，怎么可能才增加1g，就增加那么长时间。

**2 用尝试法：**
- 比如有6几个变量，来预测蛋糕烘烤时间。去除一个变量后，再做一下回归模型，观察是不是和原本系数方向相反。如果有很大不同，可能存在multicollinearity。
- 比如原来有300个数据点，我去除30个数据点，再做一下回归模型，观察是不是和原本系数方向相反。

**3 用统计方法：**
- 看每个变量的VIF。

看每个变量VIF就是把Y去除，把每个变量当作Y，轮流预测。举个例子就是：如果要计算X1的VIF，那么就是把X1当作Y，用X2，X3..来预测X1，看预测模型出来的R2是多少，然后用VIF公式 = 1/ （1- R2）。具体例子看下面。

X1 =?0 + ?2X2 + ?3X3 + ?4X4 + …... + ?pXp + E   ->  X1： VIF  21.4

X2 =?0 + ?1X1 + ?3X3 + ?4X4 + …... + ?pXp + E   ->  X2： VIF  20.3

X3 =?0 + ?2X2 + ?3X3 + ?4X4 + …... + ?pXp + E   ->  X3： VIF  1.3

一般来说如果一个变量的VIF大于5的话，那么这个变量是可能造成multicollinearity的原因。
- 看变量与变量之间的相关性。有些人喜欢写表格，有些人喜欢画heatmap。

![](https://upload-images.jianshu.io/upload_images/6342708-e2a3b2b3d6a12a45.png)

**这里要指出，这种图是描述变量两两之间的相关性。有一种情况是，两两之间没有较强的相关性，但是多个变量在一起时，就会产生很强的相关性。如果有这种情况的话，VIF可以观察到。**

### 04 如果multicollinearity真的有得话，我要怎么办：

**如果multicollinearity很严重，不能忽略的话，应该：**

1）根据VIF的值，去除某些变量。比如前面VIF，X1 是21.4  X2是20.3，X3是1.3；发现X1和X2相关性高，那么可以去除VIF最大的X1。

2）用stepwise的方法挑选变量。

3）把几个相关性高变量成一个变量。可以把他们组合。比如在用汉堡销量和薯条销量等，预测营业额，那么可以用套餐数量代替汉堡和薯条的数量。另外，还有比较常用的是用ratio，就是把两个变量相除。比如预测这个人是否会买SUV，我们可以这个人浏览SUV的总次数除以浏览汽车的总次数，而不是单独列在那里当作2个变量。

4）PCA

5）Ridge Regression

**有些情况， Multicollinearity存在也不会产生很大的负面影响，是可以忽略。比如：**
- 
有些变量是高阶变量。

Y  =?0 + ?1X1 + ?2X1^2 + ?3X1^3 + ?pXp^p + E

这种情况，一定是有Multicollinearity的。并且VIF一定都大于阀值5。

这时候可以保留这些变量，但是为了具有说服力，会将这些变量都标准化，这样VIF就会小于5。

- 
另外，还有一种情况，引用一下minitab一篇文章来说明。

用一个人的体脂率，体重，运动量，体脂率＊体重。这4个变量预测脖子的骨密度。因为有一个衍生变量（Interaction terms）即体脂率*体重存在，我们的模型有3个变量VIF大于5，而且体脂率的系数是+0.0055，说明越胖，骨密度越大，和常识相反。

另外从P值看，虽然体重是0.000 小于0.005，但是体重的VIF达到了33。

那如果我们把这4个变量都标准化，看看会是怎么样的情况。所有变量的VIF都小于5，而且P也有显著性。另外体脂率从正系数，变成了负的系数，和常识一致了。

为了方便我把前后的结果一起比较，可以看到R2 都是56.23%，没有变化。也就是他们预测出来的结果Y，不会因为变量标准化了，结果发生变化。所以这种情况试用于只关心预测结果多过关心变量的情况。

![](https://upload-images.jianshu.io/upload_images/6342708-cf68c8c8c6971b4c.png)

**最后要说的是，如果采用忽略multicollinearity的做法，我们就不能说，如果其他变量不变，只变化其中某变量的一个单位，结果会变化多少。在日常分析工作中，如果要向其他人或者客户解释模型变量发现的话，这种忽略的做法就不可取了。**

**最后总结一下**


![](https://upload-images.jianshu.io/upload_images/6342708-200e71ecb83eb7e7.png)


**再做一下广告，欢迎订购**


![](https://upload-images.jianshu.io/upload_images/6342708-7a2166b8b56fb145.jpeg)


**如果你还想看我的其他文章，请戳**
[消费者、用户和产品的关系思考](https://www.jianshu.com/p/9a4006a20961)
[我喜欢的10个可视化](https://www.jianshu.com/p/8562dbe14513)
[一步一步教你分析消费者大数据](https://www.jianshu.com/p/aa1b28f1813d)
[从优惠券的投放人群，教你看分类模型的评判标准](https://www.jianshu.com/p/85ba33ec85e7)
[数据分析师，少一点套路，多一点思路](https://www.jianshu.com/p/fecf339585ca)
[关于数据建模变量标准化，你想知道的都在这里了](https://www.jianshu.com/p/1e63cd2afedc)
[运营经理，你真的知道模型里的R平方吗？](https://www.jianshu.com/p/ce3f861de580)
[从可视化角度浅谈如何做一份优秀的咨询PPT(一)](https://www.jianshu.com/p/5444a1663b93)
[用可视化思维解读统计自由度](https://www.jianshu.com/p/0032087b9dbb)
[孰好孰坏？第一方数据与第三方数据](https://www.jianshu.com/p/e29537ba020e)
[读完这篇，连小学生都看的懂什么是机器学习里的boosting](https://www.jianshu.com/p/742bb490ed2c)
[教你炼就火眼金睛，识别会说谎的数据分析](https://www.jianshu.com/p/ca701e07bb3f)


