# 数值分析学习笔记（八） - 知乎
# 

在这一章中，我们介绍非线性方程组的数值解法。

非线性方程组的数值求解方法一方面可以从函数零点求解方法出发进行推广得到（不动点法，Newton方法）。另一方面，也有一些广泛而又有启发性的新方法的引入。

我们加下来讨论的问题限定于 ![n](https://www.zhihu.com/equation?tex=n) 个未知数 ![n](https://www.zhihu.com/equation?tex=n) 个方程的情况，且假设方程所涉及到的函数有足够好的性质，方程有解。

 即具有形式![\begin{cases} f_1(x_1,...,x_n)=0\\ \ \ \ \ \ \ \ \ \ \ ...\\ f_n(x_1,...,x_n)=0 \end{cases}](https://www.zhihu.com/equation?tex=%5Cbegin%7Bcases%7D+f_1%28x_1%2C...%2Cx_n%29%3D0%5C%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+...%5C%5C+f_n%28x_1%2C...%2Cx_n%29%3D0+%5Cend%7Bcases%7D)

**1、不动点法**

我们在求解线性方程的方法一章中将不动点迭代进行了推广得到了Jacobi方法。

其实，不动点迭代方法也能够很容易推广至非线性方程的求解。

为了能够清晰地看出不动点函数，我们先对于方程组进行形式改写。

假设向量函数 ![\vec{F}:\mathbb{R}^n\rightarrow\mathbb{R}^n](https://www.zhihu.com/equation?tex=%5Cvec%7BF%7D%3A%5Cmathbb%7BR%7D%5En%5Crightarrow%5Cmathbb%7BR%7D%5En) 使得

![\vec{F}(x_1,...,x_n)=(f_1(x_1,...,x_n),...,f_n(x_1,...,x_n))](https://www.zhihu.com/equation?tex=%5Cvec%7BF%7D%28x_1%2C...%2Cx_n%29%3D%28f_1%28x_1%2C...%2Cx_n%29%2C...%2Cf_n%28x_1%2C...%2Cx_n%29%29)

并且假设 ![\vec{x}=(x_1,...,x_n)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%3D%28x_1%2C...%2Cx_n%29)

则非线性方程组可以统一地表示成 ![\vec{F}(\vec{x})=\vec{0}](https://www.zhihu.com/equation?tex=%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%29%3D%5Cvec%7B0%7D) 。

我们成功地将非线性方程组写成了函数零点求解的形式。

接下来，很自然地，我们可以进行类似于一元情形的不动点迭代重构非线性方程不动点迭代的求解理论。

![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 的**不动点**![\vec{p}](https://www.zhihu.com/equation?tex=%5Cvec%7Bp%7D) 为使得 ![\vec{G}(\vec{p})=\vec{p}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%28%5Cvec%7Bp%7D%29%3D%5Cvec%7Bp%7D) 成立的点（实际是向量）。

类似地，我们将一元的压缩映照定理进行推广。

**定理（压缩映照定理的向量函数形式）**

**![D](https://www.zhihu.com/equation?tex=D) 为 ![\mathbb{R}^n](https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En) 的一个区域，满足 ![\exists a_i,b_i,\ \forall i,\ a_i\leq x_i\leq b_i](https://www.zhihu.com/equation?tex=%5Cexists+a_i%2Cb_i%2C%5C+%5Cforall+i%2C%5C+a_i%5Cleq+x_i%5Cleq+b_i) 。假设 ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 为 ![D](https://www.zhihu.com/equation?tex=D) 上连续函数，将 ![D](https://www.zhihu.com/equation?tex=D) 映射到 ![\mathbb{R}^n](https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En) 。且 ![\forall \vec{x}\in D,\vec{G}(\vec{x})\in D](https://www.zhihu.com/equation?tex=%5Cforall+%5Cvec%7Bx%7D%5Cin+D%2C%5Cvec%7BG%7D%28%5Cvec%7Bx%7D%29%5Cin+D) （自身映射性质）。则 ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 在 ![D](https://www.zhihu.com/equation?tex=D) 中的不动点存在。**

**进一步地，如果 ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 的各个分量 ![g_i(x_1,...,x_n)](https://www.zhihu.com/equation?tex=g_i%28x_1%2C...%2Cx_n%29) 均有连续偏导，且 ![\exists K<1,\forall \vec{x}\in D,|\frac{\partial g_i}{\partial x_j}|\leq \frac{K}{n}](https://www.zhihu.com/equation?tex=%5Cexists+K%3C1%2C%5Cforall+%5Cvec%7Bx%7D%5Cin+D%2C%7C%5Cfrac%7B%5Cpartial+g_i%7D%7B%5Cpartial+x_j%7D%7C%5Cleq+%5Cfrac%7BK%7D%7Bn%7D) 对于 ![j=1,2,...,n](https://www.zhihu.com/equation?tex=j%3D1%2C2%2C...%2Cn) 成立，（偏导有界）则不动点存在唯一。**

**值得注意的是：压缩映照条件中偏导数的上界不是 ![1](https://www.zhihu.com/equation?tex=1) 而是 ![\frac{1}{n}](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bn%7D) 。**

那么，自然地，我们对于向量函数的不动点迭代有如下形式。

取定初值 ![\vec{x}_0](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D_0) ，定义向量列 ![\vec{x}_k=\vec{G}(\vec{x}_{k-1})](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D_k%3D%5Cvec%7BG%7D%28%5Cvec%7Bx%7D_%7Bk-1%7D%29) 。则 ![\lim_{k\rightarrow \infty}\vec{x}_k=\vec{p}](https://www.zhihu.com/equation?tex=%5Clim_%7Bk%5Crightarrow+%5Cinfty%7D%5Cvec%7Bx%7D_k%3D%5Cvec%7Bp%7D)  。（假设收敛）

一元情况下对于不动点迭代收敛情况的讨论也可以为我们所用。

**定理（不动点迭代收敛性）**

**只需要满足压缩映照条件，则对于任意初值，不动点迭代必定收敛到不动点。**

我们直接在例子中体会即可。

例：

![3x_1-cos(x_2x_3)-\frac{1}{2}=0](https://www.zhihu.com/equation?tex=3x_1-cos%28x_2x_3%29-%5Cfrac%7B1%7D%7B2%7D%3D0)

![x_1^2-81(x_2+0.1)^2+sinx_3+1.06=0](https://www.zhihu.com/equation?tex=x_1%5E2-81%28x_2%2B0.1%29%5E2%2Bsinx_3%2B1.06%3D0)

![e^{-x_1x_2}+20x_3+\frac{10\pi-3}{3}=0](https://www.zhihu.com/equation?tex=e%5E%7B-x_1x_2%7D%2B20x_3%2B%5Cfrac%7B10%5Cpi-3%7D%7B3%7D%3D0)

在区域 ![D=[-1,1]\times[-1,1]\times[-1,1]](https://www.zhihu.com/equation?tex=D%3D%5B-1%2C1%5D%5Ctimes%5B-1%2C1%5D%5Ctimes%5B-1%2C1%5D) 上求解。

解：

先构造向量函数（显式地将 ![x_1,x_2,x_3](https://www.zhihu.com/equation?tex=x_1%2Cx_2%2Cx_3) 分别解出后化为不动点迭代函数）。

![g_1=\frac{2cosx_2x_3+1}{6}](https://www.zhihu.com/equation?tex=g_1%3D%5Cfrac%7B2cosx_2x_3%2B1%7D%7B6%7D)

![g_2=\frac{\sqrt{x_1^2+sinx_3+1.06}}{9}-0.1](https://www.zhihu.com/equation?tex=g_2%3D%5Cfrac%7B%5Csqrt%7Bx_1%5E2%2Bsinx_3%2B1.06%7D%7D%7B9%7D-0.1)

![g_3=-\frac{e^{-x_1x_2}}{20}-\frac{10\pi-3}{60}](https://www.zhihu.com/equation?tex=g_3%3D-%5Cfrac%7Be%5E%7B-x_1x_2%7D%7D%7B20%7D-%5Cfrac%7B10%5Cpi-3%7D%7B60%7D)

容易发现 ![\vec{G}=(g_1,g_2,g_3)=(x_1,x_2,x_3)](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%3D%28g_1%2Cg_2%2Cg_3%29%3D%28x_1%2Cx_2%2Cx_3%29) 即为我们所求非线性方程组。

容易验证其满足自身映射性质。即 ![\vec{x}\in D,g_1,g_2,g_3\in[-1,1]](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5Cin+D%2Cg_1%2Cg_2%2Cg_3%5Cin%5B-1%2C1%5D) 。

接着再考虑其各个分量函数关于 ![x_1,x_2,x_3](https://www.zhihu.com/equation?tex=x_1%2Cx_2%2Cx_3) 的偏导数。

容易验证： ![\forall i,j,\ |\frac{\partial g_i}{\partial x_j}|< \frac{1}{3}](https://www.zhihu.com/equation?tex=%5Cforall+i%2Cj%2C%5C+%7C%5Cfrac%7B%5Cpartial+g_i%7D%7B%5Cpartial+x_j%7D%7C%3C+%5Cfrac%7B1%7D%7B3%7D) 。故满足压缩映射条件。

说明 ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 的不动点在 ![D](https://www.zhihu.com/equation?tex=D) 上存在唯一，且不动点迭代对于任何初值收敛。

![x_1^{(k)}=g_1(x_1^{(k-1)},x_2^{(k-1)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_1%5E%7B%28k%29%7D%3Dg_1%28x_1%5E%7B%28k-1%29%7D%2Cx_2%5E%7B%28k-1%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)

![x_2^{(k)}=g_2(x_1^{(k-1)},x_2^{(k-1)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_2%5E%7B%28k%29%7D%3Dg_2%28x_1%5E%7B%28k-1%29%7D%2Cx_2%5E%7B%28k-1%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)

![x_3^{(k)}=g_3(x_1^{(k-1)},x_2^{(k-1)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_3%5E%7B%28k%29%7D%3Dg_3%28x_1%5E%7B%28k-1%29%7D%2Cx_2%5E%7B%28k-1%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)

若我们取 ![\vec{x}_0=(0.1,0.1,-0.1)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D_0%3D%280.1%2C0.1%2C-0.1%29) ，则5次迭代后即可收敛到 ![10^{-5}](https://www.zhihu.com/equation?tex=10%5E%7B-5%7D) 以下的绝对误差。（向量无穷范数标准下）


到此为止，一些敏锐的读者可能已经发现了：我们可以略施技巧**加速不动点迭代的收敛**。

回忆Gauss-Seidel方法对于Jacobi方法进行的改进：当最新的估计已经可用时，我们使用最新的估计值，而非上一次的估计值。

这里其实是一样的。注意到在估计 ![x_2^{(k)}](https://www.zhihu.com/equation?tex=x_2%5E%7B%28k%29%7D) 时， ![x_1^{(k)}](https://www.zhihu.com/equation?tex=x_1%5E%7B%28k%29%7D) 已经被求出了。对于 ![x_3^{(k)}](https://www.zhihu.com/equation?tex=x_3%5E%7B%28k%29%7D) 也是同样的。

故在进行这个小小的优化后，估计式为：

![x_1^{(k)}=g_1(x_1^{(k-1)},x_2^{(k-1)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_1%5E%7B%28k%29%7D%3Dg_1%28x_1%5E%7B%28k-1%29%7D%2Cx_2%5E%7B%28k-1%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)

![x_2^{(k)}=g_2(x_1^{(k)},x_2^{(k-1)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_2%5E%7B%28k%29%7D%3Dg_2%28x_1%5E%7B%28k%29%7D%2Cx_2%5E%7B%28k-1%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)

![x_3^{(k)}=g_3(x_1^{(k)},x_2^{(k)},x_3^{(k-1)})](https://www.zhihu.com/equation?tex=x_3%5E%7B%28k%29%7D%3Dg_3%28x_1%5E%7B%28k%29%7D%2Cx_2%5E%7B%28k%29%7D%2Cx_3%5E%7B%28k-1%29%7D%29)


额外需要注意的一些地方是： ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 在 ![D](https://www.zhihu.com/equation?tex=D) 上不动点存在唯一并**不意味**着原方程组在 ![D](https://www.zhihu.com/equation?tex=D) 上解唯一。（一元情况也是类似）且类似Gauss-Seidel方法，利用最新估计并**不总是**能保证收敛的加速。


**2、Newton方法**

在我们推广了不动点迭代后，读者自然地能想到对于Newton法的推广形式。

我们下面将再一次说明：**二阶收敛选择了Newton方法**。

我们的目标是：找到一个函数具有形式 ![\vec{G}(\vec{x})=\vec{x}-A^{-1}(\vec{x})\vec{F}(\vec{x})](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%28%5Cvec%7Bx%7D%29%3D%5Cvec%7Bx%7D-A%5E%7B-1%7D%28%5Cvec%7Bx%7D%29%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%29) ，使得方法具有二阶收敛的性质。

回忆一元情况，二阶收敛的条件是不动点迭代函数在不动点 ![p](https://www.zhihu.com/equation?tex=p) 处的一阶导数为 ![0](https://www.zhihu.com/equation?tex=0) 。在向量函数情况中，二阶收敛的条件变为 ![\forall i,j\ \frac{\partial g_i(\vec{p})}{\partial x_j}=0](https://www.zhihu.com/equation?tex=%5Cforall+i%2Cj%5C+%5Cfrac%7B%5Cpartial+g_i%28%5Cvec%7Bp%7D%29%7D%7B%5Cpartial+x_j%7D%3D0) 。

不妨假设矩阵 ![A^{-1}(\vec{x})](https://www.zhihu.com/equation?tex=A%5E%7B-1%7D%28%5Cvec%7Bx%7D%29) 中第 ![i](https://www.zhihu.com/equation?tex=i) 行 ![j](https://www.zhihu.com/equation?tex=j) 列的元素为 ![a_{ij}](https://www.zhihu.com/equation?tex=a_%7Bij%7D) 。

则 ![g_i=x_i-\sum_{j=1}^na_{ij}f_j](https://www.zhihu.com/equation?tex=g_i%3Dx_i-%5Csum_%7Bj%3D1%7D%5Ena_%7Bij%7Df_j)

则当 ![i\neq k](https://www.zhihu.com/equation?tex=i%5Cneq+k) 时，![\frac{\partial g_i(\vec{x})}{\partial x_k}=-\sum_{j=1}^n(a_{ij}\frac{\partial f_j(\vec{x})}{\partial x_k}+\frac{\partial a_{ij}(\vec{x})}{\partial x_k}f_j)](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+g_i%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7D%3D-%5Csum_%7Bj%3D1%7D%5En%28a_%7Bij%7D%5Cfrac%7B%5Cpartial+f_j%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7D%2B%5Cfrac%7B%5Cpartial+a_%7Bij%7D%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7Df_j%29) 。

当 ![i=k](https://www.zhihu.com/equation?tex=i%3Dk) 时， ![\frac{\partial g_i(\vec{x})}{\partial x_k}=1-\sum_{j=1}^n(a_{ij}\frac{\partial f_j(\vec{x})}{\partial x_k}+\frac{\partial a_{ij}(\vec{x})}{\partial x_k}f_j)](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+g_i%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7D%3D1-%5Csum_%7Bj%3D1%7D%5En%28a_%7Bij%7D%5Cfrac%7B%5Cpartial+f_j%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7D%2B%5Cfrac%7B%5Cpartial+a_%7Bij%7D%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_k%7Df_j%29)

由二阶收敛的条件，当![i\neq k](https://www.zhihu.com/equation?tex=i%5Cneq+k) 时，![0=\sum_{j=1}^n a_{ij}(\vec{p})\frac{\partial f_j(\vec{p})}{\partial x_k}](https://www.zhihu.com/equation?tex=0%3D%5Csum_%7Bj%3D1%7D%5En+a_%7Bij%7D%28%5Cvec%7Bp%7D%29%5Cfrac%7B%5Cpartial+f_j%28%5Cvec%7Bp%7D%29%7D%7B%5Cpartial+x_k%7D) 。

当 ![i=k](https://www.zhihu.com/equation?tex=i%3Dk) 时， ![1=\sum_{j=1}^n a_{ij}(\vec{p})\frac{\partial f_j(\vec{p})}{\partial x_k}](https://www.zhihu.com/equation?tex=1%3D%5Csum_%7Bj%3D1%7D%5En+a_%7Bij%7D%28%5Cvec%7Bp%7D%29%5Cfrac%7B%5Cpartial+f_j%28%5Cvec%7Bp%7D%29%7D%7B%5Cpartial+x_k%7D)

写成矩阵乘法形式，得到 ![A^{-1}J=I](https://www.zhihu.com/equation?tex=A%5E%7B-1%7DJ%3DI) 。

其中 ![J](https://www.zhihu.com/equation?tex=J) 为Jacobi矩阵，满足 ![J_{ij}(\vec{x})=\frac{\partial f_i(\vec{x})}{\partial x_j}](https://www.zhihu.com/equation?tex=J_%7Bij%7D%28%5Cvec%7Bx%7D%29%3D%5Cfrac%7B%5Cpartial+f_i%28%5Cvec%7Bx%7D%29%7D%7B%5Cpartial+x_j%7D)

故得到： ![A(\vec{x})=J(\vec{x})](https://www.zhihu.com/equation?tex=A%28%5Cvec%7Bx%7D%29%3DJ%28%5Cvec%7Bx%7D%29) 。

这说明了一个简单的事实：**在向量函数情况下，Jacobi矩阵代替了导数在Newton方法中的作用。**

我们得到了Newton方法的估计式：

![\vec{x}^{(k)}=\vec{x}^{(k-1)}-J^{-1}(\vec{x}^{(k-1)})\vec{F}(\vec{x}^{(k-1)})](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5E%7B%28k%29%7D%3D%5Cvec%7Bx%7D%5E%7B%28k-1%29%7D-J%5E%7B-1%7D%28%5Cvec%7Bx%7D%5E%7B%28k-1%29%7D%29%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%5E%7B%28k-1%29%7D%29)

在具体实现中，求逆通常用解线性方程组来代替。

牛顿法的**优点是非常快的收敛速度，但是其收敛性是初值依赖的，需要初值足够靠近真实解的前提下才能保证收敛。此外，计算Jacobi矩阵中各个元素的值需要利用数值微分，计算代价十分巨大。**

为此，一些近似Newton方法被引入。如Broyden方法，可以看作是割线法在向量函数情况下的推广。类似地，其不再需要每次迭代都计算Jacobi矩阵的值，大大减少了计算代价。但是其不再是二阶收敛，而仅仅是超线性收敛，且其失去了对于舍入误差的自修正性。Broyden的具体实现就不在此赘述了。


**3、最速下降法**

牛顿方法与Broyden方法收敛的前提条件都是：迭代的初值足够靠近方程零点。

那么是否有一种方法能保证在一般情况下的收敛性呢？

最速下降法便具有这样的优良性质，其在一般情况下对于任意迭代初值均能保证收敛。

我们在共轭梯度法处已经提及：**梯度方向是函数的值增加得最快的方向**。很自然地，我们联想到当在估计一个函数的最小值时，在每一点处均沿着负梯度方向前进一定使得函数值下降得最快。

而对于一个非线性方程组，我们不难将零点求解问题转化为一个辅助函数 ![g](https://www.zhihu.com/equation?tex=g) 的最小值求解问题。

考虑 ![g(x_1,...,x_n)=\sum_{i=1}^n f_i^2(x_1,...,x_n)](https://www.zhihu.com/equation?tex=g%28x_1%2C...%2Cx_n%29%3D%5Csum_%7Bi%3D1%7D%5En+f_i%5E2%28x_1%2C...%2Cx_n%29)

显然，**![g(\vec{x})](https://www.zhihu.com/equation?tex=g%28%5Cvec%7Bx%7D%29) 取最小值 ![0](https://www.zhihu.com/equation?tex=0) 当且仅当 ![\vec{x}](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D) 为非线性方程的零点**。

现在，我们清晰地知道了最速下降法的原理；我们也知道了在每一步迭代中我们应该向哪个方向前进。剩下的唯一问题便是：在具体实现中，每一步前进的距离长度为多少？

我们总是希望每一步的函数值能够尽可能多得下降。即对于给定的 ![\vec{x}^{(k)}](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5E%7B%28k%29%7D) ， ![\vec{x}^{(k+1)}=\vec{x}^{(k)}+\alpha\  \nabla g(\vec{x}^{(k)})](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5E%7B%28k%2B1%29%7D%3D%5Cvec%7Bx%7D%5E%7B%28k%29%7D%2B%5Calpha%5C++%5Cnabla+g%28%5Cvec%7Bx%7D%5E%7B%28k%29%7D%29) ，我们希望取得的 ![\alpha](https://www.zhihu.com/equation?tex=%5Calpha) 使得 ![h(\alpha)=g(\vec{x}^{(k)}+\alpha\  \nabla g(\vec{x}^{(k)}))](https://www.zhihu.com/equation?tex=h%28%5Calpha%29%3Dg%28%5Cvec%7Bx%7D%5E%7B%28k%29%7D%2B%5Calpha%5C++%5Cnabla+g%28%5Cvec%7Bx%7D%5E%7B%28k%29%7D%29%29)  尽可能地小。

**具体做法是：**

**对于给定的 ![\vec{x}^{(k)}](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5E%7B%28k%29%7D) ，先求得 ![\nabla g(\vec{x}^{(k)})](https://www.zhihu.com/equation?tex=%5Cnabla+g%28%5Cvec%7Bx%7D%5E%7B%28k%29%7D%29) 并单位化后得到向量 ![\vec{y}](https://www.zhihu.com/equation?tex=%5Cvec%7By%7D) 。**

**接下来，取 ![\alpha_1=0](https://www.zhihu.com/equation?tex=%5Calpha_1%3D0) ，取 ![\alpha_3](https://www.zhihu.com/equation?tex=%5Calpha_3) 为使得 ![h(\alpha_3)<h(\alpha_1)](https://www.zhihu.com/equation?tex=h%28%5Calpha_3%29%3Ch%28%5Calpha_1%29) 的最大的具有 ![2^{-k}](https://www.zhihu.com/equation?tex=2%5E%7B-k%7D) 形式的数。（ ![0<\alpha_3\leq 1](https://www.zhihu.com/equation?tex=0%3C%5Calpha_3%5Cleq+1) ），取 ![\alpha_2=\frac{\alpha_3}{2}](https://www.zhihu.com/equation?tex=%5Calpha_2%3D%5Cfrac%7B%5Calpha_3%7D%7B2%7D) 。**

**我们的目的是：求出 ![\alpha](https://www.zhihu.com/equation?tex=%5Calpha) 使得 ![h(\alpha)](https://www.zhihu.com/equation?tex=h%28%5Calpha%29) 在 ![[\alpha_1,\alpha_3]](https://www.zhihu.com/equation?tex=%5B%5Calpha_1%2C%5Calpha_3%5D) 取值最小。**

**由于 ![h(\alpha)](https://www.zhihu.com/equation?tex=h%28%5Calpha%29) 的形式通常过于复杂，我们进行大致估算：**

**利用 ![\alpha_1,\alpha_2,\alpha_3](https://www.zhihu.com/equation?tex=%5Calpha_1%2C%5Calpha_2%2C%5Calpha_3) 三点处的函数值进行插值多项式拟合（得到二次插值多项式），再考虑此二次函数在区间上的最小值点作为 ![\alpha](https://www.zhihu.com/equation?tex=%5Calpha) 的取值**。

最速下降法的完整步骤到此为止就介绍完了。

值得注意的是：最速下降法一般而言收敛，但是却未必收敛到理想结果。由于**辅助函数 ![g](https://www.zhihu.com/equation?tex=g) 的凸性**无法保证，导致最速下降法可能陷入局部最小值中“无法自拔”，而错失全局最小值。由此，我们得以理解为何通常在方程组求解时取 ![g(x_1,...,x_n)=\sum_{i=1}^n f_i^2(x_1,...,x_n)](https://www.zhihu.com/equation?tex=g%28x_1%2C...%2Cx_n%29%3D%5Csum_%7Bi%3D1%7D%5En+f_i%5E2%28x_1%2C...%2Cx_n%29) 。这是因为函数 ![y=x_1^2+...+x_n^2](https://www.zhihu.com/equation?tex=y%3Dx_1%5E2%2B...%2Bx_n%5E2) 为 ![\mathbb{R}^n](https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5En) 上的凸函数。

另外，最速下降法仅仅是**线性收敛**的。故其在实际中常常作为**为牛顿方法或Broyden方法寻找良好迭代初值的方法**。


**四、同伦延展法**

在第一次学习到同伦延展法时，我一直很疑惑：同伦作为拓扑中的概念，要如何与方程组的求解问题联系起来呢？

我们先进行一些简单的定义：

**假定 ![\vec{G}:[0,1]\times \mathbb{R}^n\rightarrow\mathbb{R}^n](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%3A%5B0%2C1%5D%5Ctimes+%5Cmathbb%7BR%7D%5En%5Crightarrow%5Cmathbb%7BR%7D%5En)**

**即对于任意一个固定的![\lambda\in[0,1]](https://www.zhihu.com/equation?tex=%5Clambda%5Cin%5B0%2C1%5D) ， ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 都是一个向量函数**。

这意味着随着 ![\lambda](https://www.zhihu.com/equation?tex=%5Clambda) 的连续变化， ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D) 作为 ![n](https://www.zhihu.com/equation?tex=n) 维向量之间的映射也会相应连续地改变。

**假定 ![\vec{x}(\lambda)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%28%5Clambda%29) 表示方程 ![\vec{G}(\lambda,\vec{x})=\vec{0}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%28%5Clambda%2C%5Cvec%7Bx%7D%29%3D%5Cvec%7B0%7D) 的解**。

**我们的意图是将非线性方程组的求解问题转化为 ![\vec{x}(\lambda)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%28%5Clambda%29) 随着 ![\lambda\in[0,1]](https://www.zhihu.com/equation?tex=%5Clambda%5Cin%5B0%2C1%5D) 连续地变化的过程。**

**则我们不妨假设 ![\vec{x}(0)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%280%29) 为给定的迭代初值，**则我们的想法就是**将 ![\vec{x}(1)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%281%29) 构造为原方程 ![\vec{F}(\vec{x})=\vec{0}](https://www.zhihu.com/equation?tex=%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%29%3D%5Cvec%7B0%7D) 的解**，通过寻找 ![\vec{x}(\lambda)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%28%5Clambda%29) 在 ![[0,1]](https://www.zhihu.com/equation?tex=%5B0%2C1%5D) 上连续地变化的规律对于 ![\vec{x}(1)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%281%29) 进行估计。

基于上述意图，我们可以如下地简单地**构造出 ![\vec{G}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D)**

![\vec{G}(\lambda,\vec{x})=\lambda\vec{F}(\vec{x})+(1-\lambda)[\vec{F}(\vec{x})-\vec{F}(\vec{x}(0))]](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%28%5Clambda%2C%5Cvec%7Bx%7D%29%3D%5Clambda%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%29%2B%281-%5Clambda%29%5B%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%29-%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%280%29%29%5D) 。

我们接下来的工作是：寻找到![\vec{x}(\lambda)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%28%5Clambda%29) 在 ![[0,1]](https://www.zhihu.com/equation?tex=%5B0%2C1%5D) 上连续地变化的规律，从而得到估计 ![\vec{x}(1)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%281%29) 作为原方程组的解。

要得到规律，直接的想法就是对于 ![\vec{G}(\lambda,\vec{x})=\vec{0}](https://www.zhihu.com/equation?tex=%5Cvec%7BG%7D%28%5Clambda%2C%5Cvec%7Bx%7D%29%3D%5Cvec%7B0%7D) 等式两边对 ![\lambda](https://www.zhihu.com/equation?tex=%5Clambda) 求偏导。

得到： ![\frac{\partial \vec{G}}{\partial \lambda}+\frac{\partial \vec{G}}{\partial \vec{x}}\vec{x}^{'}(\lambda)=0](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cvec%7BG%7D%7D%7B%5Cpartial+%5Clambda%7D%2B%5Cfrac%7B%5Cpartial+%5Cvec%7BG%7D%7D%7B%5Cpartial+%5Cvec%7Bx%7D%7D%5Cvec%7Bx%7D%5E%7B%27%7D%28%5Clambda%29%3D0)

**化简得到矩阵形式： **![\vec{x}^{'}(\lambda)=-J^{-1}(\vec{x}(\lambda))\vec{F}(\vec{x}(0)),\ \lambda\in[0,1]](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%5E%7B%27%7D%28%5Clambda%29%3D-J%5E%7B-1%7D%28%5Cvec%7Bx%7D%28%5Clambda%29%29%5Cvec%7BF%7D%28%5Cvec%7Bx%7D%280%29%29%2C%5C+%5Clambda%5Cin%5B0%2C1%5D)

我们惊奇地发现：**这是 ![\vec{x}(\lambda)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%28%5Clambda%29) 关于 ![\lambda](https://www.zhihu.com/equation?tex=%5Clambda) 的ODE初值问题。初值 ![\vec{x}(0)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%280%29) 已经给定**。

这表示：我们成功地利用同伦的性质将一个方程组求解问题转化为了一个ODE的初值问题。

接下来的步骤中，我们只需要数值地估计常微分方程组即可，Runge-Kutta的推广方法可以被使用来产生出 ![\vec{x}(1)](https://www.zhihu.com/equation?tex=%5Cvec%7Bx%7D%281%29) 的估计，即为原方程的解。

同伦延展方法将**函数抽象为函数族**，以使得曲线能够随参数的连续变化而连续变化，从而将方程组求解问题转化为了连续变化的ODE初值问题。如此一来，各种先前提及的ODE数值方法就可以被应用来产生估计。

值得一提的是：**同伦延展法本身可以作为一个完整方法来使用，且对于初值的选取无要求，但是计算代价往往很大**。

关于非线性方程组求解方法的叙述，到此为止就告一段落了。

事实上，原本我还想阐述一些数值求解特征值的方法，但是后来发现诸如幂法及其推广、Householder变换、Q-R方法、SVD等等均在高代课程中有了比较完备的概述，读者若有兴趣可以自行查找资料学习。

那么，**数值分析这个系列的学习笔记就到此为止了**。个人感觉，数值分析是一门很应用也很有趣的数学课。学习数值分析，最应该把握的是某种特定方法为何会出现、具有什么优缺点、能够进行哪些改进等等问题，而非一味地追求实践。只有对于各种方法有了宏观层面的把握，才能够对每一个方法的适用场合与实现细节了如指掌。

最后，谢谢各位对于数值分析系列学习笔记的阅读！

