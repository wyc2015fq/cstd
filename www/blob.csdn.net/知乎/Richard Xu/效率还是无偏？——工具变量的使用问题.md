# 效率还是无偏？——工具变量的使用问题 - 知乎
# 

**这是本专栏的第*****54*****篇日记**

今天Alwyn Young来我校CESR做讲座，他最近的这篇Working Paper搞了个大新闻：

"Consistency without Inference: Instrumental Variables in Practical Application"

论文地址：[http://personal.lse.ac.uk/YoungA/ConsistencyWithoutInference.pdf](https://link.zhihu.com/?target=http%3A//personal.lse.ac.uk/YoungA/ConsistencyWithoutInference.pdf)

作者从AEA（美国经济学会）旗下的期刊（包括**经济学顶刊AER**）中，根据“标题或摘要中出现Instrument字样”的标准，在最近十年发表的论文中找出了32篇共1400个使用工具变量（IV）进行的2SLS回归。对这些回归结果的研究表明：

1） 大部分（甚至可以高达80%）回归的**残差不满足正态分布，存在聚类固定效应，不满足同方差假设**。（而经济学家关于使用IV的结论大多数是在这些条件下得到的）

2）如果我们**有选择性地去掉一个观察(observation)或一个聚类(cluster)，有45%在0.01水平显著的系数可以“修正”为不显著，而有21%在0.01水平不显著的可以“修正”为显著**；如果允许去掉两个观察或聚类，则相应的比例上升为63%和39%。而如果我们进行的是OLS而不是2SLS，这四个比例分别是15%，25%，26%，39%。

对于t值和IV第一阶段回归的F值，上述delete-one或delete-two的操作同样能造成非常显著的波动，甚至能够将F值提高到三倍以上或三分之一以下。由于第一阶段回归的F值常用于判定工具变量是否有效，这一结果意味着**有可能从并不有效的工具变量中“制造”出合理的F值**。

3）弃用OLS转用IV和2SLS的原因之一是当理论显示存在内生性时，OLS估计的系数将会有偏（Biased）；但是IV的缺点是效率不如OLS，换言之IV得到的置信区间更大。结果是，如果我们将上述2SLS回归的数据**直接用OLS回归得到系数估计，有很高比例（超过70%）落在2SLS得到的置信区间当中，甚至OLS的置信区间可以整个落在2SLS得到的置信区间当中（超过50%）**。

4）另外，OLS是否真的有偏呢？使用DWH test的结论是，在0.05水平也**只有40%的OLS能判定是有偏的**（假设2SLS的结果是正确的），而利用Bootstrap的结论则更低，只有27%的OLS能判定是有偏的。

这里列举的是我今天听讲座的时候印象特别深的，原文还有一些其它的检验结果，不再赘述。

作者的解释是这样的：

一方面是所谓的“leverage effect”，简单地说，leverage就是单个观察的解释变量X在将被解释变量y线性投影成其预测值y-hat时所占的“比重”。上述文章中，问题更“严重”的回归，其所有观察中最大的leverage也往往更大，甚至可以达到0.3以上，结果就是**其系数估计严重依赖这些outlier**。作者认为，通过Bootstrap和Jackknife等手段，可以有效地解决这个问题。

另一方面，如上所说，**经济学家对于使用IV的结论，都是在一些理想化的条件下得到的，比如说误差项是独立同分布的正态分布**，而对于其它一些分布，经济学家在使用IV时缺乏理论上的支持。作者通过Monte-Carlo模拟各种不同的分布并进行回归发现IV在这些“奇葩”分布下表现得并不如OLS。

（还有一些关于如何改善的建议，比如使用OLS与2SLS结果的加权平均，或者通过随机实验获取数据，对实证感兴趣的同学可以去原文了解）

现场有教授提出了Publication Bias的问题：在进行回归时，往往更倾向于报告显著的结果而不报告不显著的结果（或者说结果不显著的论文发表不出来），但是Alwyn Young表示他这篇文章并不能给出相应的结论。

但是我的想法是这样的：是否可能存在另一种形式的Publication Bias? 尽管Alwyn Young强调他在寻找文章时并未进行刻意筛选，但是其选择标准其实未必“公平”：能够发表的论文，特别是将IV当作关键词写入标题和摘要的论文，往往是因为**其利用IV得到了反传统或反常识的结果，这类结果更有可能正好处在门槛上**，使得IV得到这些“反转”结果的与其说是因为有什么新的理论解释，更有可能是因为**误差项呈现出系统性的偏差或者有严重的outlier**导致结果倒向了显著，也就是说，即使ex-ante误差项可能确实是i.i.d.正态的，被研究的数据中所实现的误差项，ex-post的看，其经验分布(empirical distribution)可能是skewed，恰恰违背了IV的使用要求。而且由于这种偏差的“系统性”，**很多Robustness Check的手段，除非是“另选一组数据”，本质上将会是无效的。**

举个类比的例子，我抛一枚标准硬币二十次，因为运气好，抛出了十八个正面，在这种情况下你很难拒绝“我是抛正面高手”的假设——一个显然有效的Robustness Check是让我再抛二十次，但是大多数实证研究的自然实验并不允许他们“再来一次”。

*(Photo Credit: Photo on [Visual Hunt](https://link.zhihu.com/?target=https%3A//visualhunt.com/re/334251))*

