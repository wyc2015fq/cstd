# 通过空间上下文特征进行阴影检测 - 知乎
# 

本文及其它机器学习、深度学习算法的全面系统讲解可以阅读《机器学习与应用》，清华大学出版社，雷明著，由SIGAI公众号作者倾力打造，自2019年1月出版以来已重印3次。
- [书的购买链接](https://link.zhihu.com/?target=https%3A//item.jd.com/12504554.html)
- [书的勘误，优化，源代码资源](https://link.zhihu.com/?target=http%3A//www.tensorinfinity.com/paper_78.html)

**PDF全文链接：**[通过空间上下文特征进行阴影检测](https://link.zhihu.com/?target=http%3A//www.tensorinfinity.com/paper_142.html)

![](https://pic1.zhimg.com/v2-c8af31c9ecdda1dc193341f3b55f8fd4_b.png)

## **简介**

阴影检测是计算机视觉中基础且具有挑战性的问题——对于一张输入图像，我们通过生成二进制图像来标记阴影区域，阴影区域的检测为进一步获取图像中的光照情况、物体的形状与位置，以及摄像机的参数提供了可能。与此同时，阴影的存在也为计算机视觉中进一步理解图像的算法，例如物体的检测与跟踪，带来了障碍。阴影检测需要对整张图片进行一个全局的语意信息的理解，从而才能够正确的提取出阴影的位置。 本文通过DSC(direction-aware spatial context) 信息，从而提取到更为全局的特征，并且能更好的判断出阴影的位置。

## **正文**

阴影检测问题和二分类的语义分割问题十分相似，本质上是对图中的每一个像素点，判断出该像素点属于阴影还是属于非阴影。但是，阴影检测的难点在于，图中很多黑色区域容易被当做阴影，事实上，从全局的角度看，并不是阴影。比如一块黑色的布放在地上，如果没有丰富的全局上下文信息作为指导，网络很有可能无法区分该区域是不是阴影。

 ICCV2017 的scGAN 与ECCV2016 的stacked-CNN，主要是通过深度神经网络从大量的数据样本中自动学习特征，用于检测阴影区域。

如下图所示，从全局看是右边的人在追杀左边的人，但是从电视中这个局部的视角，是左边的人在杀右边的人。因此，通过这个例子，可以看出全局语义信息对于阴影检测的指导意义。

![](https://pic3.zhimg.com/v2-94212f72bdbb3aa7c77af0a97fcb4d46_b.png)

在下图中，可以看到从C-->A并不能简单判断是不是阴影，因为C和A都是黑色区域。然而，从B-->A的方向上，可以很容易判断出A区域是阴影，因为B-->A有很明显的光照变化。因此本文基于这个思想提出了通过提取不同方向的上下文信息去分析阴影区域。

![](https://pic2.zhimg.com/v2-4629d4676c28b4a4b6127519cfc72199_b.png)
再比如这张图，黄色车道线区域虽然是阴影，但是由于颜色差距较大，之前的方法检测效果较差，很容易当做非阴影区域处理。但是如果通过黄色区域的四个方向的信息可以判断出黄色区域也是阴影。
![](https://pic4.zhimg.com/v2-5e5dda221254d1c309e4a7fef911732f_b.png)
## **整体流程**

## **网络结构如下**

![](https://pic3.zhimg.com/v2-5d4051a05a52df24386d3a434c6a57fe_b.png)

首先通过主干网络提取不同层次的特征(蓝色区域)，其次通过作者设计的DSC模块得到具有四个方向的信息的特征，然后通过1x1的卷积进行降维并将所有尺度的特征upsample到统一尺度预测结果，最后对结果求平均值得到最终结果。

下图是作者提出的DSC模块，通过spatial RNN建模四个方向的信息，

第一轮通过对输入的feature map通过RNN进行四个方向的卷积，这样，feature map中的任何一个像素都会得到来自他所在的行和列的像素的信息。

第二轮再重复上述操作，经过两轮RNN，feature map中的每一个像素都会得到来自所有像素的信息，这样的feature map中是包含丰富的global context的，对于阴影的定位不会受局部特征的影响。

![](https://pic2.zhimg.com/v2-7d46913d59e349980a5aba2b6050f989_b.png)

具体的说，就是将一个卷积神经网络中的 2D 特征图作为输入，首先经过一个 1 乘 1 的卷积操作，之后是四个方向的 recurrent translation。接着我们将四个结果综合起来作为中间的特征图，然后重复上述过程，最终得到全局的空间上下文特征。

为了进一步方向性的分析空间上下文特征，我们采用的是 attention 机制，来生成一组权值，并且将他们分成四张权值图，分别通过点对点的方式，乘上四个方向的空间上下文特征。

这些权值会在两次 recurrent translation 中共享（且可以跟整个深度学习网络一起进行训练），因此，我们可以通过在不同方向上选择性的使用空间上下文特征来得到 direction-aware spatial context feature，这个结果我们叫做 DSC 特征。

至于获取该特征的过程被称作 DSC 模块。如下图所示。

![](https://pic4.zhimg.com/v2-3e5eb8322463b3b02fe3c370a7ba34bb_b.png)

## **实验细节**

作者采用weighted cross entropy loss, L_total = L1 + L2


![\begin{aligned} L_{1}=-(\frac{N_{n}}{N_{p}+N_{n}})y\log(p)-(\frac{N_{p}}{N_{p}+N_{n}})(1-y)\log(1-p), \\(3) \\  and\\L_{2} =-(1-\frac{TP}{N_{p}})y\log(p)-(1-\frac{TN}{N_{n}})(1-y)\log(1-p),\\(4)  \end{aligned}](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+L_%7B1%7D%3D-%28%5Cfrac%7BN_%7Bn%7D%7D%7BN_%7Bp%7D%2BN_%7Bn%7D%7D%29y%5Clog%28p%29-%28%5Cfrac%7BN_%7Bp%7D%7D%7BN_%7Bp%7D%2BN_%7Bn%7D%7D%29%281-y%29%5Clog%281-p%29%2C+%5C%5C%283%29+%5C%5C++and%5C%5CL_%7B2%7D+%3D-%281-%5Cfrac%7BTP%7D%7BN_%7Bp%7D%7D%29y%5Clog%28p%29-%281-%5Cfrac%7BTN%7D%7BN_%7Bn%7D%7D%29%281-y%29%5Clog%281-p%29%2C%5C%5C%284%29++%5Cend%7Baligned%7D)


L1 用来平衡阴影区域与非阴影区域的比重，如果阴影区域的面积小于非阴影区域，会惩罚误检的阴影区域多一些。

L2 帮助网络去学习不容易识别的类型（这里主要指阴影或非阴影）。如果正确识别的阴影区域较小，那么他的损失函数的权值就会变大，反之亦然。

在测试过程中，作者使用 MLIF 层以及 fusion 层的均值作为最后的结果。并且使用 CRF 作为后处理，用来改进检测到的阴影区域的边界。

## **数据集简介**

作者在SBU数据集上进行训练，SBU是最大的阴影检测数据集，其中包括4089张训练数据和638张测试数据。 作者并在UCF数据集上进行测试，UCF包括76张测试图片上。


## **可视化结果分析**

作者对比了一系列阴影检测算法，其中甚至对比了知名的语义分割算法PSPNet。

可视化结果如下:

![](https://pic2.zhimg.com/v2-5abeaf56780fdc8fb0a5ceae3766fb81_b.png)

可以看到别的算法或多或少都把一些非阴影区域当做阴影，或者说没有检测出阴影区域，而作者的算法可以准确检测阴影，并排除非阴影区域。

## **定量结果分析**

如下表所示，作者的算法在两个数据集上都取得了最好的结果。

![](https://pic2.zhimg.com/v2-ab424d00fcd8ba9abe3140330d997b7d_b.png)

## **总结**

这篇文章主要的亮点在于引入了DSC模块，从而可以提取全局的语义信息，这个思想和后续kaiming 大神的 的non-local有异曲同工之妙，不知道non-local是不是借鉴了这个idea呢？个人觉得这个idea可以借鉴到目标检测和语义分割之中，从而缓解错误样本的检测和分割的问题。

参考文献：

H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR, pages 2881–2890, 2017.

V. Nguyen, T. F. Y. Vicente, M. Zhao, M. Hoai, and D. Samaras.Shadow detection with conditional generative adversarial networks. In ICCV, pages 4510–4518, 2017

T. F. Y. Vicente, L. Hou, C.-P. Yu, M. Hoai, and D. Samaras. Large-scale training of shadow detectors with noisilyannotated shadow examples. In ECCV, pages 816–832, 2016.

K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.

