# 人体骨骼关键点检测综述 - 知乎
# 

`原创声明：本文为 SIGAI 原创文章，仅供个人学习使用，未经允许，不得转载，不能用于商业目的。 `

本文及其它机器学习、深度学习算法的全面系统讲解可以阅读《机器学习与应用》，清华大学出版社，雷明著，由SIGAI公众号作者倾力打造，自2019年1月出版以来已重印3次。
- [书的购买链接](https://link.zhihu.com/?target=https%3A//item.jd.com/12504554.html)
- [书的勘误，优化，源代码资源](https://link.zhihu.com/?target=http%3A//www.tensorinfinity.com/paper_78.html)

> ***邀稿声明***
各位SIGAIer，之前不少小伙伴要求写一篇Human Pose Estimation的综述，SIGAI有幸邀请了来自北大的东尼大佬为我们解析有关人体骨骼关键点检测技术的发展脉络。小编在这里表示感谢。同时SIGAI也欢迎其他业内专家来平台投稿，大家一起共建专业的人工智能知识分享平台。投稿一旦接收，SIGAI将会赠送雷明老师的《机器学习与应用》签名书，并根据实际情况提供相应的报酬和福利。
投稿请联系：SIGAI_admin

> 导言
人体骨骼关键点对于描述人体姿态，预测人体行为至关重要。因此人体骨骼关键点检测是诸多计算机视觉任务的基础，例如动作分类，异常行为检测，以及自动驾驶等等。近年来，随着深度学习技术的发展，人体骨骼关键点检测效果不断提升，已经开始广泛应用于计算机视觉的相关领域。本文主要介绍2D人体骨骼关键点的基本概念和相关算法，其中算法部分着重介绍基于深度学习的人体骨骼关键点检测算法的两个方向，即自上而下（Top-Down）的检测方法和自下而上（Bottom-Up）的检测方法。

## **相关介绍**

> **什么是人体骨骼关键点检测**

人体骨骼关键点检测，即Pose Estimation，主要检测人体的一些关键点，如关节，五官等，通过关键点描述人体骨骼信息；
![](https://pic3.zhimg.com/v2-6c9829bff31a82bd4df2dd56bc0e681a_b.jpg)
> **应用与挑战**

人体骨骼关键点检测是计算机视觉的基础性算法之一，在计算机视觉的其他相关领域的研究中都起到了基础性的作用，如行为识别、人物跟踪、步态识别等相关领域。具体应用主要集中在智能视频监控，病人监护系统，人机交互，虚拟现实，人体动画，智能家居，智能安防，运动员辅助训练等等。

由于人体具有相当的柔性，会出现各种姿态和形状，人体任何一个部位的微小变化都会产生一种新的姿态，同时其关键点的可见性受穿着、姿态、视角等影响非常大，而且还面临着遮挡、光照、雾等环境的影响，除此之外，2D人体关键点和3D人体关键点在视觉上会有明显的差异，身体不同部位都会有视觉上缩短的效果（foreshortening），使得人体骨骼关键点检测成为计算机视觉领域中一个极具挑战性的课题。

> **相关数据集**

LSP（Leeds Sports Pose Dataset）：单人人体关键点检测数据集，关键点个数为14，样本数2K，在目前的研究中基本上被弃用；

FLIC（Frames Labeled In Cinema）：单人人体关键点检测数据集，关键点个数为9，样本数2W，在目前的研究中基本上被弃用；

MPII（MPII Human Pose Dataset）：单人/多人人体关键点检测数据集，关键点个数为16，样本数25K；

MSCOCO：多人人体关键点检测数据集，关键点个数为17，样本数多于30W，目前的相关研究基本上还需要在该数据集上进行验证；

AI Challenger：多人人体关键点检测数据集，关键点个数为14，样本数约38W，竞赛数据集；

PoseTrack：最新的关于人体骨骼关键点的数据集，多人人体关键点跟踪数据集，包含单帧关键点检测、多帧关键点检测、多人关键点跟踪三个人物，多于500个视频序列，帧数超过20K，关键点个数为15。

> **传统算法概述**

传统的人体骨骼关键点检测算法基本上都是在几何先验的基础上基于模版匹配的思路来进行，那么核心就在于如何去用模版表示整个人体结构，包括关键点的表示，肢体结构的表示以及不同肢体结构之间的关系的表示。一个好的模版匹配的思路，可以模拟更多的姿态范围，以至于能够更好的匹配并检测出对应的人体姿态。

Pictorial Structure是其中一个较为经典的算法思路，主要包含两个部分，其一是单元模版（Unary Templates），其二是模版关系（Pairwise Springs），对于模版关系，提出了著名的弹簧形变模型，弹簧形变模型，即对部件模型与整体模型的相对空间位置关系进行建模，利用了物体的一些空间先验知识，既合理约束了整体模型和部件模型的空间相对位置，又保持了一定的灵活性。
![](https://pic3.zhimg.com/v2-a4d3ae15a26e3562c1e5727d8a3e1ad2_b.jpg)
在接下来的研究中，为了匹配更大的姿态范围，Yang & Ramanan提出了“mini parts”的概念，即将每个肢体结构（part）切分成更小的parts以能够模拟更多的姿态变化，从而提高模版匹配的效果，具体示意图如下图（摘自论文[7]对应slides）所示。
![](https://pic3.zhimg.com/v2-1d57cc7a2b11b206b26b9a7830e5e48e_b.jpg)
## **人体骨骼关键点检测**

> **算法概述**

多人人体骨骼关键点检测主要有两个方向，一种是自上而下，一种是自下而上，其中自上而上的人体骨骼关键点定位算法主要包含两个部分，人体检测和单人人体关键点检测，即首先通过目标检测算法将每一个人检测出来，然后在检测框的基础上针对单个人做人体骨骼关键点检测，其中代表性算法有G-RMI, CFN, RMPE, Mask R-CNN, and CPN，目前在MSCOCO数据集上最好的效果是72.6%；自下而上的方法也包含两个部分，关键点检测和关键点聚类，即首先需要将图片中所有的关键点都检测出来，然后通过相关策略将所有的关键点聚类成不同的个体，其中对关键点之间关系进行建模的代表性算法有PAF, Associative Embedding, Part Segmentation, Mid-Range offsets，目前在MSCOCO数据集上最好的效果是68.7%。

> **Coordinate、Heatmap和Heatmap + Offsets**

在介绍多人人体骨骼关键点检测算法之间，首先介绍一下关键点回归的Ground Truth的构建问题，主要有两种思路，Coordinate和Heatmap，Coordinate即直接将关键点坐标作为最后网络需要回归的目标，这种情况下可以直接得到每个坐标点的直接位置信息；Heatmap即将每一类坐标用一个概率图来表示，对图片中的每个像素位置都给一个概率，表示该点属于对应类别关键点的概率，比较自然的是，距离关键点位置越近的像素点的概率越接近1，距离关键点越远的像素点的概率越接近0，具体可以通过相应函数进行模拟，如Gaussian等，如果同一个像素位置距离不同关键点的距离大小不同，即相对于不同关键点该位置的概率不一样，这时可以取Max或Average，如下图（摘自论文[16]）所示。
![](https://pic1.zhimg.com/v2-e437f6d1430ec2a2bba2d81eaae44644_b.jpg)
对于两种Ground Truth的差别，Coordinate网络在本质上来说，需要回归的是每个关键点的一个相对于图片的offset，而长距离offset在实际学习过程中是很难回归的，误差较大，同时在训练中的过程，提供的监督信息较少，整个网络的收敛速度较慢；Heatmap网络直接回归出每一类关键点的概率，在一定程度上每一个点都提供了监督信息，网络能够较快的收敛，同时对每一个像素位置进行预测能够提高关键点的定位精度，在可视化方面，Heatmap也要优于Coordinate，除此之外，实践证明，Heatmap确实要远优于Coordinate，具体结构如下图所示。
![](https://pic3.zhimg.com/v2-bd7bdcf87feab28253b4a28c1eaa92fa_b.jpg)
最后，对于Heatmap + Offsets的Ground Truth构建思路主要是Google在CVPR 2017上提出的，与单纯的Heatmap不同的是，Google的Heatmap指的是在距离目标关键点一定范围内的所有点的概率值都为1，在Heatmap之外，使用Offsets，即偏移量来表示距离目标关键点一定范围内的像素位置与目标关键点之间的关系。目前还没有在公开的论文看到有人比较过这两种Ground Truth构建思路的效果差异，但是个人认为Heatmap + Offsets不仅构建了与目标关键点之间的位置关系，同时Offsets也表示了对应像素位置与目标关键点之间的方向信息，应该要优于单纯的Heatmap构建思路。如下图所示（摘自论文[9]）。
![](https://pic1.zhimg.com/v2-29bffd4e930d5f3b91c96104834a4e9c_b.jpg)
> **自上而下的人体关键点检测算法**

自上而下（Top-Down）的人体骨骼关键点检测算法主要包含两个部分，目标检测和单人人体骨骼关键点检测，对于目标检测算法，这里不再进行描述，而对于关键点检测算法，首先需要注意的是关键点局部信息的区分性很弱，即背景中很容易会出现同样的局部区域造成混淆，所以需要考虑较大的感受野区域；其次人体不同关键点的检测的难易程度是不一样的，对于腰部、腿部这类关键点的检测要明显难于头部附近关键点的检测，所以不同的关键点可能需要区别对待；最后自上而下的人体关键点定位依赖于检测算法的提出的Proposals，会出现检测不准和重复检测等现象，大部分相关论文都是基于这三个特征去进行相关改进，接下来我将简要介绍其中几种经典的算法思路。
![](https://pic3.zhimg.com/v2-a636caa41a91e3bc26f3bc6cba55fe32_b.jpg)
Convolutional Pose Machines：本论文将深度学习应用于人体姿态分析，同时用卷积图层表达纹理信息和空间信息。主要网络结构分为多个stage，其中第一个stage会产生初步的关键点的检测效果，接下来的几个stage均以前一个stage的预测输出和从原图提取的特征作为输入，进一步提高关键点的检测效果。具体的流程图如下图（摘自论文[12]）所示。
![](https://pic2.zhimg.com/v2-71853492402f13ff006c1307f804e251_b.jpg)
用各部件响应图来表达各部件之间的空间约束，响应图和特征图一起作为数据在网络中传递。人体关键点在空间上的先验分布会指导网络的学习，假如stage 1的预测结果中右肩关键点的预测结果是正确的，而右肘关键点的预测是错误的，那么在接下来的stage中肩和肘在空间上的先验分布会指导网络的学习。如下图（摘自论文[12]）所示。
![](https://pic3.zhimg.com/v2-43cd019e6cc6b3be9c5f5425f55a42d2_b.jpg)
除此之外，使用多阶段监督，对于各个阶段的预测输出都有监督训练，避免过深网络难以优化的问题，而且感受野随着stage的增多而逐渐增大，最后值得一提的是第一阶段对原图提取特征的网络区别于stage > 1的特征提取网络，因为第一个阶段网络的作用是预测初步的结果，而后几个阶段的作用是结合关键点空间先验知识和对原图提取的特征对上一个stage预测的结果做进一步精化。

Cascaded Pyramid Network：本论文主要关注的是不同类别关键点的检测难度是不一样的，整个结构的思路是先检测比较简单的关键点、然后检测较难的关键点、最后检测更难的或不可见的关键点。具体Pipeline如下图（摘自论文[13]对应slides）所示。
![](https://pic1.zhimg.com/v2-ec2520d69d15664a2970ec06b386b99c_b.jpg)
具体实现时，分为两个stage，GlobalNet和RefineNet。其中GlobalNet主要负责检测容易检测和较难检测的关键点，对于较难关键点的检测，主要体现在网络的较深层，通过进一步更高层的语义信息来解决较难检测的关键点问题；RefineNet主要解决更难或者不可见关键点的检测，这里对关键点进行难易程度进行界定主要体现在关键点的训练损失上，使用了常见的Hard Negative Mining策略，在训练时取损失较大的top-K个关键点计算损失，然后进行梯度更新，不考虑损失较小的关键点。网络结果如下图（摘自论文[13]对应slides）所示。
![](https://pic4.zhimg.com/v2-857caea100c364f4010e5225064381af_b.jpg)
RMPE：本论文主要考虑的是自上而下的关键点检测算法在目标检测产生Proposals的过程中，可能会出现检测框定位误差、对同一个物体重复检测等问题。检测框定位误差，会出现裁剪出来的区域没有包含整个人活着目标人体在框内的比例较小，造成接下来的单人人体骨骼关键点检测错误；对同一个物体重复检测，虽然目标人体是一样的，但是由于裁剪区域的差异可能会造成对同一个人会生成不同的关键点定位结果。本文提出了一种方法来解决目标检测产生的Proposals所存在的问题，即通过空间变换网络将同一个人体的产生的不同裁剪区域（Proposals）都变换到一个较好的结果，如人体在裁剪区域的正中央，这样就不会产生对于一个人体的产生的不同Proposals有不同关键点检测效果。具体Pipeline如下图（摘自论文[14]）所示。
![](https://pic2.zhimg.com/v2-dd5ed12101376e90dd24c518e6518389_b.jpg)
> **自下而上的人体关键点检测算法**

自下而上（Bottom-Up）的人体骨骼关键点检测算法主要包含两个部分，关键点检测和关键点聚类，其中关键点检测和单人的关键点检测方法上是差不多的，区别在于这里的关键点检测需要将图片中所有类别的所有关键点全部检测出来，然后对这些关键点进行聚类处理，将不同人的不同关键点连接在一块，从而聚类产生不同的个体。而这方面的论文主要侧重于对关键点聚类方法的探索，即如何去构建不同关键点之间的关系，接下来我将介绍几种经典的方法。

Part Segmentation：即对人体进行不同部位分割，而关键点都落在分割区域的特定位置，通过部位分割对关键点之间的关系进行建模，既可以显式的提供人体关键点的空间先验知识，指导网络的学习，同时在最后对不同人体关键点进行聚类时也能起到相应的连接关键点的作用。如下图（摘自论文[15]）所示。
![](https://pic3.zhimg.com/v2-28df6d702dc5e414179cefbf9ee946ba_b.jpg)
﻿Part Affinity Fields：该方法通过对人体的不同肢体结构进行建模，使用向量场来模拟不同肢体结构，解决了单纯使用中间点是否在肢干上造成的错连问题。
![](https://pic2.zhimg.com/v2-b239ae21c472312ee4739a4fd4210535_b.jpg)
如上图（摘自论文[16]对应slides）所示，如果只使用中间点对肢干进行建模，如果中间点都在对应的肢干上，则判断两个关键点处在该肢干的两端，这样就会出现如上图所示的错连情况。而PAFs则不仅使用中间点来建模肢干，而且在中间的位置之外还给每个中间点加上了方向的信息，这样就能解决出现的错连问题。具体如下图（摘自论文[16]对应slides）所示。
![](https://pic1.zhimg.com/v2-c0e4752f7069149e63fb4a5a630ca5f4_b.jpg)
Associative Embedding：该方法通过使用高维空间的向量来编码不同人体的不同关键点之间的关系，即同一个人的不同关键点在空间上是尽可能接近的，不同人的不同关键点在空间上是尽可能远离的，最后可以通过两个关键点在高维空间上的距离来判断两个关键点是否属于同一个人，从而达到聚类的目的。如下图（摘自论文[17]）所示。
![](https://pic2.zhimg.com/v2-a3cdb7ba32d9a1d258d9ae569e5fd59d_b.jpg)
Mid-Range Offsets：该方法通过直接回归一个关键点到另一个关键点之间的offset来建模两个关键点之间的关系，这种较长距离的offsets是较难学习的，在回归具体数值时会有较大误差，这里可以用关键点周围的Short-Range Offsets去进一步Refine对应的offsets。具体如下图（摘自论文[18]）所示。
![](https://pic1.zhimg.com/v2-30880a9874f6c7ec86c5a429aa90d570_b.jpg)
## 小结

人体骨骼关键点定位至今仍然是计算机视觉领域较为活跃的一个研究方向，人体骨骼关键点检测算法还没有达到比较完美的效果，在较为复杂的场景下仍然会出现很多错误的检测结果。自上而下的关键点检测算法在效果上要明显好于自下而上的关键点检测算法，因为自上而下的检测方法加入了整个人体的一个空间先验。个人认为，自下而上的关键点定位算法没有显示的去建模整个人体的空间关系，而只是建模了局部的空间关系，以至于在效果上目前还远低于自上而上的关键点检测方法。

参考文献

[1] Iqbal U, Milan A, Gall J. PoseTrack: Joint Multi-person Pose Estimation and Tracking[C]// Computer Vision and Pattern Recognition. IEEE, 2017:4654-4663.

[2] ﻿S. Johnson and M. Everingham. Learning effective human pose estimation from inaccurate annotation. In CVPR, pages 1465–1472. IEEE, 2011.

[3] ﻿T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra- manan, P. Dollar, and C. L. Zitnick. Microsoft coco: Com- mon objects in context. In ECCV, 2014.

[4] ﻿Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and Bernt Schiele. 2d human pose estimation: New benchmark and state of the art analysis. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 3686– 3693. IEEE, 2014.

[5] Fischler M A, Elschlager R A. The Representation and Matching of Pictorial Structures[J]. IEEE Trans Computers C, 1973, 22(1):67-92.

[6] Pedro F. Felzenszwalb, Daniel P. Huttenlocher. Pictorial Structures for Object Recognition[J]. International Journal of Computer Vision, 2005, 61(1):55-79.

[7] Yang Y, Ramanan D. Articulated pose estimation with flexible mixtures-of-parts[J]. 2011, 32(14):1385-1392.

[8] Toshev A, Szegedy C. DeepPose: Human Pose Estimation via Deep Neural Networks[C]// Computer Vision and Pattern Recognition. IEEE, 2014:1653-1660.

[9] Papandreou G, Zhu T, Kanazawa N, et al. Towards Accurate Multi-person Pose Estimation in the Wild[J]. 2017:3711-3719.

[10] Huang S, Gong M, Tao D. A Coarse-Fine Network for Keypoint Localization[C]// IEEE International Conference on Computer Vision. IEEE, 2017:3047-3056.

[11] He K, Gkioxari G, Dollár P, et al. Mask R-CNN[J]. 2017.

[12] Wei S E, Ramakrishna V, Kanade T, et al. Convolutional Pose Machines[J]. 2016:4724-4732.

[13] Chen Y, Wang Z, Peng Y, et al. Cascaded Pyramid Network for Multi-Person Pose Estimation[J]. 2017.

[14] Fang H S, Xie S, Tai Y W, et al. RMPE: Regional Multi-person Pose Estimation[J]. 2016:2353-2362.

[15] Xia F, Wang P, Chen X, et al. Joint Multi-person Pose Estimation and Semantic Part Segmentation[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, 2017:6080-6089.

[16] Cao Z, Simon T, Wei S E, et al. Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields[J]. 2016:1302-1310.

[17] Newell A, Huang Z, Deng J. Associative Embedding: End-to-End Learning for Joint Detection and Grouping[J]. 2016.

[18] Papandreou G, Zhu T, Chen L C, et al. PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model[J]. 2018.

原创声明：本文为 [SIGAI](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/G9gW2ghTII57jGmXSIaf7w) 原创文章，仅供个人学习使用，未经允许，不得转载，不能用于商业目的。

推荐阅读

[1]  [机器学习-波澜壮阔40年](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483705%26idx%3D1%26sn%3Dc6e7c4a2e14a2469308b41eb60f155ac%26chksm%3Dfdb69caecac115b8712653600e526e99a3f6976fdaa2f6b6a09388fa6f9677ccb57b40c40ae3%26scene%3D21%23wechat_redirect) SIGAI 2018.4.13.

[2]  [学好机器学习需要哪些数学知识？](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483713%26idx%3D1%26sn%3D1e7c81381d16806ac73e15691fe17aec%26chksm%3Dfdb69cd6cac115c05f1f90b0407e3f8ae9be8719e454f908074ac0d079885b5c134e2d60fd64%26scene%3D21%23wechat_redirect)SIGAI 2018.4.17.

[3]  [人脸识别算法演化史](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483726%26idx%3D1%26sn%3D9fef4cc1766ea4258749f8d40cc71a6e%26chksm%3Dfdb69cd9cac115cf4eba16081780c3b64c75e1e55a40bf2782783d5c28f00c6f143426e6f0aa%26scene%3D21%23wechat_redirect) SIGAI 2018.4.20.

[4]  [基于深度学习的目标检测算法综述](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483731%26idx%3D1%26sn%3D237c52bc9ddfe65779b73ef8b5507f3c%26chksm%3Dfdb69cc4cac115d2ca505e0deb975960a792a0106a5314ffe3052f8e02a75c9fef458fd3aca2%26scene%3D21%23wechat_redirect) SIGAI 2018.4.24.

[5]  [卷积神经网络为什么能够称霸计算机视觉领域？](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483816%26idx%3D1%26sn%3Dfc52765b012771d4736c9be4109f910e%26chksm%3Dfdb69c3fcac115290020c3dd0d677d987086a031c1bde3429339bb3b5bbc0aa154e76325c225%26scene%3D21%23wechat_redirect) SIGAI 2018.4.26.

[6] [用一张图理解SVM的脉络](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483937%26idx%3D1%26sn%3D84a5acf12e96727b13fd7d456c414c12%26chksm%3Dfdb69fb6cac116a02dc68d948958ee731a4ae2b6c3d81196822b665224d9dab21d0f2fccb329%26scene%3D21%23wechat_redirect)SIGAI 2018.4.28.

[7] [人脸检测算法综述](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483950%26idx%3D1%26sn%3Da3a5b7907b2552c233f654a529931776%26chksm%3Dfdb69fb9cac116af5dd237cf987e56d12b0d2e54c5c565aab752f3e366c0c45bfefa76f5ed16%26scene%3D21%23wechat_redirect) SIGAI 2018.5.3.

[8] [理解神经网络的激活函数](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247483977%26idx%3D1%26sn%3D401b211bf72bc70f733d6ac90f7352cc%26chksm%3Dfdb69fdecac116c81aad9e5adae42142d67f50258106f501af07dc651d2c1473c52fad8678c3%26scene%3D21%23wechat_redirect) SIGAI 2018.5.5.

[9] [深度卷积神经网络演化历史及结构改进脉络-40页长文全面解读](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484037%26idx%3D1%26sn%3D13ad0d521b6a3578ff031e14950b41f4%26chksm%3Dfdb69f12cac11604a42ccb37913c56001a11c65a8d1125c4a9aeba1aed570a751cb400d276b6%26scene%3D21%23wechat_redirect) SIGAI        2018.5.8.

[10] [理解梯度下降法](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484111%26idx%3D1%26sn%3D4ed4480e849298a0aff828611e18f1a8%26chksm%3Dfdb69f58cac1164e844726bd429862eb7b38d22509eb4d1826eb851036460cb7ca5a8de7b9bb%26scene%3D21%23wechat_redirect) SIGAI 2018.5.11

[11] [循环神经网络综述—语音识别与自然语言处理的利器](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484310%26idx%3D1%26sn%3D0fc55a2784a894100a1ae64d7dbfa23d%26chksm%3Dfdb69e01cac1171758cb021fc8779952e55de41032a66ee5417bd3e826bf703247e243654bd0%26scene%3D21%23wechat_redirect) SIGAI 2018.5.15

[12] [理解凸优化](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484439%26idx%3D1%26sn%3D4fa8c71ae9cb777d6e97ebd0dd8672e7%26chksm%3Dfdb69980cac110960e08c63061e0719a8dc7945606eeef460404dc2eb21b4f5bdb434fb56f92%26scene%3D21%23wechat_redirect)  SIGAI 2018.5.18

[13][【实验】理解SVM的核函数和参数](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484495%26idx%3D1%26sn%3D4f3a6ce21cdd1a048e402ed05c9ead91%26chksm%3Dfdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9%26scene%3D21%23wechat_redirect) SIGAI 2018.5.22

[14][【SIGAI综述】 行人检测算法](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484523%26idx%3D1%26sn%3Dddaa70c4b92f6005d9bbd6b3a3fe4571%26chksm%3Dfdb699fccac110ea14e6adeb873a00d6ee86dd4145ddf8e90c9b878b908ac7b7655cfa51dab6%26scene%3D21%23wechat_redirect) SIGAI 2018.5.25

[15] [机器学习在自动驾驶中的应用—以百度阿波罗平台为例](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484540%26idx%3D1%26sn%3D733332042c31e1e18ad800f7f527893b%26chksm%3Dfdb699ebcac110fd6607c1c99bc7ebed1594a8d00bc454b63d7f518191bd72274f7e61ca5187%23rd)（上） SIGAI 2018.5.29 

[16] [理解牛顿法](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484651%26idx%3D1%26sn%3Da0e4ca5edb868fe3eae9101b71dd7103%26chksm%3Dfdb6997ccac1106a61f51fe9f8fd532045cc5d13f6c75c2cbbf1a7c94c58bcdf5f2a6661facd%26scene%3D21%23wechat_redirect) SIGAI 2018.5.31

[17] [【群话题精华】5月集锦—机器学习和深度学习中一些值得思考的问题](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484658%26idx%3D1%26sn%3Df5c9f92c272c75883bf8e6f532559f11%26chksm%3Dfdb69965cac11073f49048caef5d7b9129614090a363d9ef7f3d1b9bc59948d2217d2bca7b7b%26scene%3D21%23wechat_redirect)SIGAI 2018.6.1

[18] [大话Adaboost算法](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484692%26idx%3D1%26sn%3D9b389aa65208c778dddf17c601afbee1%26chksm%3Dfdb69883cac1119593934734e94c3b71aa68de67bda8a946c1f9f9e1209c3b6f0bf18fed99b8%23rd) SIGAI 2018.6.1

[19] [FlowNet到FlowNet2.0：基于卷积神经网络的光流预测算法](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484711%26idx%3D1%26sn%3Dbb7644e101b5924f54d6800b952dc3aa%26chksm%3Dfdb698b0cac111a6605f5b9b6f0478bf21a8527cfad2342dbaaf624b4e9dcc43c0d85ae06deb%26scene%3D21%23wechat_redirect) SIGAI 2018.6.4

[20][理解主成分分析(PCA)](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484754%26idx%3D1%26sn%3Db2c0d6798f44e13956bb42373e51d18c%26chksm%3Dfdb698c5cac111d3e3dca24c50aafbfb61e5b05c5df5b603067bb7edec8db049370b73046b24%23rd) SIGAI 2018.6.9

原创声明
本文为 [SIGAI](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4MjQ3MDkwNA%3D%3D%26mid%3D2247484439%26idx%3D2%26sn%3Dd2fb3a3062d6d6abe4fef8ca8495bcbf%26chksm%3Dfdb69980cac11096dea7276ee62ce2fac42cd7a0e088256c5e2f5aec5aacacb0dcaea0575d67%23rd) 原创文章，仅供个人学习使用，未经允许，不得转载，不能用于商业目的。

![](https://pic2.zhimg.com/v2-6209626d2165f95155f3cfafa6cc544d_b.jpg)
更多干货请搜索关注 VX公众号：SIGAI


