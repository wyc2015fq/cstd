# AI算法通过照片识别同性恋准确率超过人类，斯坦福大学研究惹争议 - 知乎
# 



> 2016 年，上海交通大学的一篇论文《基于面部图像的自动犯罪概率推断》引起了极大的争议，被贴上了「歧视」的标签。近日，斯坦福大学在《Journal of Personality and Social Psychology》上公布了一篇论文《Deep neural networks are more accurate than humans at detecting sexual orientation from facial images》，同样引发了极大的争议。




据《卫报》报道，该研究发现计算机算法能够准确地区分直男与同性恋，准确率高达 81%，对女性的性取向判别的准确率为 74%。这一研究引发了对隐私、道德问题的争议。




人脸识别正随着技术的发展不断进步。在美国，人脸识别正被教会用于跟踪礼拜者；在英国，零售商店用它来识别偷窃者。今年，威尔士警方使用人脸识别技术在体育场外逮捕了一名嫌犯。而在中国，人脸识别技术可以确认司机身份，让游客进入景点，并已成为付款方式的一种。苹果今年 9 月即将推出的新一代 iPhone 也几乎确定会使用人脸识别技术来解锁屏幕。




这种技术的应用场景显然还在不断增多。科技的发展，就像飞机和互联网，显著地改变了人类生活的面貌，而人脸识别技术正在编码人类的生活。虽然人的面孔属于个体，但也是公开的，技术从一开始就绕过了隐私权的争议。现在，面对人脸图像数据的记录、存储与分析，我们对于隐私、公平和信任的观念正在面临挑战。




人脸不仅是名字的标签，它也显示了很多其他的信息——而它们也是机器可读的。这意味着我们可以利用它来造福人类，一些科技公司正在开发自动人脸识别系统，用于罕见遗传病的诊断，例如 Hajdu-Cheney 综合征——人工智能的方法比其他已有方法能够更快提供诊断；测量情绪系统也可以让人们掌握自闭症患者难以捉摸的情绪信号。然而，技术也会引发困扰，来自斯坦福大学的研究者们最近的研究已经证明，当看到同性恋或异性恋的照片时，算法可以准确识别出照片中人物的性取向（准确率可达 81%，而人类只有 61%）。在同性恋违法的国家里，这种软件识别的方法显然具有可怕的前景。




这项研究已经发表在了《Personality and Social Psychology》上，并被最新一期《经济学人》等媒体报道。它基于超过 35,000 张美国交友网站上男女的头像图片训练。论文作者 Michal Kosinski 与 Yilun Wang 利用深度神经网络从图像中提取特征，利用大量数据让计算机学会识别人们的性取向。




研究发现，同性恋男女倾向于具有「性别非典型」特征、表情和「打扮风格」。理论上，男同性恋趋向于女性化，而女同反之。在研究中，人们还找到了一些其他的趋势，如同性恋男人有比直男更窄的下巴，更长的鼻子以及更大的前额；而同性恋女性相比「直女」趋向于有更大的下巴、更小的前额。




在「识别同性恋」任务中，人类的判断表现要低于算法，其准确率为在男性中 61%，在女性中 54%。当软件识别被测试者的图片（每人五张图片）时，准确率则显著不同：男性 91% 准确率，女性 83% 准确率。研究人员在论文中写道，广义上，这意味着「人类面孔包含了比人类大脑可以感知和解释的更多的性取向信息」。




论文指出，研究提供了有关性取向源于出生前暴露于某些激素的「强烈支持」，这意味着同性恋并不是一个可以被自己控制的选择。而机器对于女性性取向识别成功率较低的现象则支持了女性对于性取向更加灵活的观点。




虽然研究结果局限于性别——和性还有一些区别，有色人种没有被纳入研究，而变性者和双性恋也没有纳入考量——但这项研究对于人工智能的影响敲响了警钟。研究人员认为，数十亿存储在社交网络和政府数据库中的公共数据都可以被用来进行性取向识别，而无需本人的同意。




可想而知，一旦这种技术推广开来，夫妻一方会使用这种技术来调查自己是否被欺骗，青少年使用这种算法来识别自己的同龄人，在 LGBT 非法的国家里会发生什么则更加难以想象。这意味着构建一种具有争议的软件，并鼓励人们利用它做出危害他人的事。




但该论文的作者表示，这些技术已经存在，公开以便政府和公司对其慎重考虑，并制定法规加以约束非常重要。




「这当然是令人不安的，它就像任何新工具一样，如果被错误地使用，就会造成危险，」多伦多大学心理学教授 Nick Rule 表示。「如果我们开始以外表来判定人的好坏，那么结果将会是灾难性的。」




不过，Rule 认为开发和测试这项技术的重要性不言而喻：「研究者们证明了这种方法非常强大……现在我们明白了我们需要做点什么了。」




Kosinski 目前拒绝接受采访，斯坦福大学表示，这位教授以在剑桥大学时期进行的心理学研究而闻名，其中包括使用 Facebook 数据识别人格。有趣的是，在 2016 年美国大选，以及英国脱欧投票时期，数据分析机构也使用了类似的分析方法来试图影响投票者，这种技术引发了人们的担忧。




在斯坦福大学的研究中，作者同时指出，人工智能可以被用于探索面部特征与其他很多特性之间的联系，如政治观点、心理状况和个性。




这一类型的研究进一步引起了人们对于类似电影《少数派报告》中危险的担忧，在电影中，警察可以预测犯罪的发生，并对其进行阻止。




「如果有了足够的数据，人工智能可以告诉你任何人的任何事，」人脸识别科技公司 Kairos 首席执行官 Brian Brackeen 说道。「问题是对于社会来说，我们需要知道吗？」




Brackeen 表示，斯坦福大学研究人员有关性取向的研究「非常正确」，人们需要对于隐私和机器学习新技术持有更加慎重的态度，这样才能阻止危险发生。




Rule 对于人工智能，特别是人脸识别的未来也表示担忧：「我们都需要对此保持关注。」




论文：[Deep neural networks are more accurate than humans at detecting sexual orientation from facial images](https://link.zhihu.com/?target=https%3A//osf.io/zn79k/).




摘要：我们展示了人脸包含很多有关性取向的信息，可被人类大脑感知并解读。我们使用深度神经网络从 35326 张面部图像中提取特征。这些特征被输入到一个 logistic 回归算法中，来分类性取向。给定一张面部图像，分类器能够准确的区分同性恋与直男，准确率高达 81%，女性准确率为 74%。而人类在这方面的准确率更低：男、女性准确率分别为 61% 与 54%。如果给定某个人的 5 张面部图像，算法判定是否为同性恋的准确率增长到 91% 与 83%。分类器采用的面部特征包括固定的（例如鼻子形状）与暂时的面部特征（如装饰风格）。与性取向产前激素理论一致，同性恋倾向于拥有性别非典型面部形态、表达与装饰风格。针对单性别的预测模型检测男性同性恋的准确率为 57%，女性同性恋的准确率为 58%。这些发现推进了我们对性取向以及人类认知缺陷的理解。此外，在公司与政府越来越多地使用计算机视觉算法探测人的私密特征，我们的研究暴露出男、女性同性恋的隐私与安全问题。



![](https://pic1.zhimg.com/v2-5526c53d86a2f396f081938be699fae0_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1782' height='1100'></svg>)



图 4：通过把普通人脸分类为最可能是同性恋与最不可能是同性恋而建立的合成人脸与普通人脸标志

**机器之心报道**




