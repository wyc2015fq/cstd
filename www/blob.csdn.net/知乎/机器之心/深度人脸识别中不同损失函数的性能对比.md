# 深度人脸识别中不同损失函数的性能对比 - 知乎
# 



选自arXiv，作者：Y Srivastava、V Murali、S R Dubey，机器之心编译，参与：路、淑婷**。**

> 人脸识别是当前手机设备中使用最广泛的生物识别特征之一。而损失函数在训练用于人脸识别的 CNN 过程中有重要作用。因此，本文对用于人脸识别的多种损失函数进行了性能对比。

无约束人脸识别是计算机视觉领域中最难的问题之一。人脸识别在罪犯识别、考勤系统、人脸解锁系统中得到了大量应用，因此已经成为人们日常生活的一部分。这些识别工具的简洁性是其在工业和行政方面得到广泛应用的主要原因之一。但是同时，这种易用性掩盖了工具设计背后的复杂度和难度。很多科学家和研究人员仍然在研究多种技术以获得准确、稳健的人脸识别机制，未来其应用范围仍然会以指数级增加。2012 年，Krizhevsky 等人 [1] 提出 AlexNet，这一变革性研究是人脸识别领域的一项重大突破，AlexNet 赢得了 ImageNet 挑战赛 2012 的冠军。之后，基于 CNN 的方法在大部分计算机视觉问题中如鱼得水，如图像识别、目标检测、语义分割和生物医疗图像分析等。过去几年研究者提出了多种基于 CNN 的方法，其中大部分方法处理问题所需的复杂度和非线性，从而得到更一般的特征，然后在 LFW [12]、Megaface [13] 等主要人脸数据集上达到当前最优准确率。2012 年之后，出现了很多基于深度学习的人脸识别框架，如 DeepFace [14]、DeepID [15]、FaceNet [16] 等，轻松超越了手工方法的性能。

图像识别性能的提升伴随着 CNN 深度的增加，如 GoogLeNet [17] 和 ResNet [4]。然而，研究发现，在深度到达一定程度后，性能趋向于饱和，即深度的增加几乎不会再带来性能的提升。同时，人脸识别的大规模应用成本高昂，因为其深度架构所需的计算成本很高。因此，近年来研究者也在研究 CNN 模型的其它方面，如损失函数、非线性、优化器等。其中一个重要研究是开发适合人脸识别的损失函数。关于损失函数的早期研究包括 Center Loss 和 Triplet Loss，主要用于减少当前样本和正样本之间的距离、增加当前样本和负样本之间的距离，从而更紧密地与人脸识别产生关联。近期的损失函数（如 Soft-Margin Softmax Loss [19]、Congenerous Cosine Loss [20]、Minimum Margin Loss [21]、Range Loss [22]、L2-Softmax Loss [23]、Large-Margin Softmax Loss [24] 和 A-Softmax Loss [25]）在更轻量级的 CNN 模型上展示出了强大性能，有些结果甚至优于大型 CNN 模型。

本论文对近期提出的用于深度人脸识别的损失函数进行了综合性能对比。该研究实施了大量实验，从不同方面（比如架构的影响（如深度和重量）、训练数据集的影响）来判断不同损失函数的性能。然后使用训练准确率、测试准确率和收敛速率评估标准对结果进行分析。

**论文：A Performance Comparison of Loss Functions for Deep Face Recognition**
![](https://pic2.zhimg.com/v2-a590de8fe7e959c537e066a8d96bbc9d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='843' height='185'></svg>)
论文链接：[https://arxiv.org/pdf/1901.05903.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1901.05903.pdf)

摘要：生物识别工具的出现及其在日常设备中日渐增加的应用使得用户验证过程更加简单，尤其是与之前使用的密码和图案解锁相比。生物识别工具的易用性减少了人类手工劳作，促进更快、更自动的验证过程。在不同的生物识别特征中，人脸是无需用户配合即可获取的。此外，人脸识别是目前设备中最广泛应用的特征之一，因此也应该是最需要优先解决的重要问题。按照近期趋势，基于 CNN 的方法在多个计算机视觉任务中获得了高度成功，包括人脸识别。其中损失函数被用于判断网络的性能，损失函数在 CNN 训练过程中发挥重要作用。如果网络在当前参数设置下无法获得优秀性能的话，它就会生成大的损失。本文对用于人脸识别的不同损失函数进行了性能对比，如交叉熵损失、Angular Softmax、Additive-Margin Softmax、ArcFace 和 Marginal Loss。实验所用 CNN 架构是 ResNet 和 MobileNet，训练数据集为 CASIA-Webface 和 MS-Celeb-1M，测试数据集为 LFW 人脸数据集。

**损失函数**

本文对比了五种损失函数：交叉熵损失、Angular Softmax Loss、Additive-Margin Softmax Loss、ArcFace Loss 和 Marginal Loss。其中 Angular Softmax Loss 和 Additive-Margin Softmax Loss 等损失函数是专为人脸识别任务提出的。

交叉熵损失
![](https://pic1.zhimg.com/v2-51a815d29ec7a19986f0d86dfe8a88b8_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='351' height='63'></svg>)
Angular-Softmax Loss
![](https://pic2.zhimg.com/v2-da7d05aeb16c55f60c42036503cd5739_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='427' height='68'></svg>)
Additive Margin Softmax Loss
![](https://pic3.zhimg.com/v2-9d524fc6c145194fbd52ac252b913082_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='411' height='68'></svg>)
ArcFace Loss
![](https://pic1.zhimg.com/v2-c0bb190415d5fd03646e13300553c744_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='421' height='62'></svg>)
Marginal Loss
![](https://pic4.zhimg.com/v2-ad1bef7911e84c1594927580705ebca7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='423' height='68'></svg>)![](https://pic4.zhimg.com/v2-ee97f33d643c201a96bff38c9fd958c7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='279' height='35'></svg>)
## **网络架构**

**ResNet 模型**
![](https://pic3.zhimg.com/v2-258b60697a2f6d7bff3e18f9b2e09896_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='813' height='295'></svg>)
图 1a：ResNet 所用基础残差块。b：MobileNet 使用两个不同的卷积来减少计算量。D_k 表示滤波器大小，M 表示输入维度。
![](https://pic1.zhimg.com/v2-832b52b2ed8ec7d822dc770321232464_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='344' height='246'></svg>)
表 1：ResNet50 架构的表格表示。第一二三列分别表示层命名、输出大小和滤波器大小。

**MobileNet**
![](https://pic3.zhimg.com/v2-6115b2f5cbb52646518cdac66306cdf2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='440' height='388'></svg>)
表 2：MobileNet 架构概览。

**性能评估和观测**

研究者使用 ResNet50 和 MobileNetv1 架构和上述损失函数，在 MS-Celeb-1M 和 CASIA-Webface 数据集上执行训练，在 LFW 数据集上执行测试。作者提供了基于测试准确率、收敛速率和测试结果的对比。
![](https://pic2.zhimg.com/v2-b2c4107a55b9a531089a0b73f0d39481_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='892' height='329'></svg>)
图 2：损失函数性能评估的训练和测试框架。
![](https://pic3.zhimg.com/v2-87a8d9725fd1c2ea3f9d7b788ee39e3e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='374'></svg>)
图 3：该研究中不同模型在 LFW 数据集上获得的最高测试准确率。
![](https://pic3.zhimg.com/v2-a2c9562e48b28f2755a7ccefddd27312_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='352'></svg>)
图 4：给定损失函数获得最佳模型性能所需的最少 epoch 数量。
![](https://pic2.zhimg.com/v2-cdcf56eeb3a07db27f8974f7cc49aaa9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='495'></svg>)
表 3：ResNet50 和 MobileNetv1 这两个架构在 MS-Celeb-1M 和 CASIA-Webface 数据集上获得的训练准确率对比，和在 LFW 数据集上获得的测试准确率对比。
![](https://pic1.zhimg.com/v2-18cc987d5f379a82f1208b6d90722318_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='73' height='24'></svg>)





