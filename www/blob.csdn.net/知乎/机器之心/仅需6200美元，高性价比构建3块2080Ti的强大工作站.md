# 仅需6200美元，高性价比构建3块2080Ti的强大工作站 - 知乎
# 



> 如果想要进行[深度学习](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650758471%26idx%3D1%26sn%3D406a31c432579973186e9c5d2872d948%26chksm%3D871a9939b06d102fa57b2b9d7f3b95686a4964b5fab60da7e1998bd7a731d32167e83c6a7060%26token%3D631808646%26lang%3Dzh_CN)训练，在英伟达的新一代 GPU 中，RTX 2080Ti 是性价比最高的显卡（参见：[首个 Titan RTX 深度学习评测结果出炉：2019 年你该选择哪款 GPU？](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650754819%26idx%3D3%26sn%3D8cab0836e667fb6d6abeb65c2a0d631d%26chksm%3D871a8b7db06d026b46699f668105463b496f1b8f7dd7a4e1cf27133a8cca4bf28a62f00e2f5b%26scene%3D21%23wechat_redirect)）。但即使不上泰坦，9000 元一块的 GPU 也是很贵的。在本文中，来自 MIT 的 Curtis Northcutt 为我们找到了组建一台三 2080Ti 深度学习工作站的最简方式。

**选自L7，作者：Curtis Northcutt，机器之心编译。**

在他的配置下，整个系统需花费 6200 美元（约合 41700 元人民币），相比 AI 硬件供应商 Lambda Labs 提供的整机要便宜一半。如何为实验室组装一台最强大的计算机，让我们来看看他是怎么做到的。

我在 MIT 量子计算实验室和数字学习实验室构建了一台多 GPU 深度学习工作站。在网络中搜索时我发现，并没有一篇文章详细介绍了所有装机细节。

不过我还是发现了像 Lambda GPU 工作站这样的整机供应商。唯一的问题是：一台这样的机器需要花费 12,500 美元。这是进行顶级前沿深度学习研究的最佳配置，但如果买不起的话什么都无从谈起了。在这篇文章中，我将介绍一个自己版本的装机配置——使用相同或更好的配置，而且节省一半以上资金：只需 6200 美元。为了能让所有研究者获得帮助，在这篇文章中我会分享所有配置细节。

如果你正在构建一台较小的深度学习机器，你会发现本文同样有用。在正文中，我加入了可进一步降低成本的一些示例。

在文章最后，我给出了自组建机器与谷歌计算引擎（GCE）深度学习 VM 的时间/成本对比。我使用 PyTorch ImageNet/ResNet50 训练作为基准。

**完美配置？**

完美配置是不存在的，因为每个人的需求都不尽相同。即使过去曾经出现过，最佳配置也会随着新硬件的不断推出而改变。所以，本文试图给出尽可能好的配置。

**深度学习工作站的所有组件**

以下就是清单的全部了。

我订购的所有组件都是在 Newegg 上在线购买的，不过对于我们来说，亚马逊等其他途径都是可以的。如果你想去电子城找更便宜的，也可以尝试。
![](https://pic3.zhimg.com/v2-64eb5aec111d7c9fb864c28aeba11f0a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='810'></svg>)深度学习工作站的所有组件
在 2019 年 1 月 31 日，每个组件及其价格如下：
- 3 块 EVGA 英伟达 RTX 2080 Ti GPU
- EVGA GeForce 2080 Ti，3570 美元（每块 1190 美元）



- 20 线程 CPU（中央处理器）
- 英特尔 Core i9 9820X Skylake X 10 核 3.3Ghz，850 美元



- X299 主板（所有其他组件都要连接主板）
- ASUS WS X299 SAGE LGA 2066 英特尔 X299，492 美元



- 机箱
- 海盗船 Carbide 系列 Air 540，130 美元



- 2TB M.2 SSD 固态硬盘
- 英特尔 660p 系列 M.2 2280 2TB PCI-Express，280 美元



- 3TB 机械硬盘（用于速度不敏感文件的存储）
- 希捷 BarraCuda ST3000DM008 3TB 7200 转，85 美元



- 128G 内存
- 4 个海盗船 Vengeance LPX 32GB，740 美元（每个 185 美元）



- 1600W PSU 电源
- EVGA SuperNOVA 1600W P2，347 美元（1300W 的电源在 ImageNet/ResNet50 基准测试时会出现断电重启）



- 散热器
- 海盗船 Hydro 系列 H100i PRO 低噪音版，110 美元

在 Newegg 上使用会员账户购买的话，不算消费税所有组件的总价为 6200 美元（升级后的电源另有 107 美元）。
![](https://pic4.zhimg.com/v2-061acb5cb1f9dc6b8611f1ec19446003_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='894'></svg>)深度学习工作站视图
**每一个组件的考虑事项**

在选择 GPU、RAM、CPU 和主板等组件时，需要牢记以下三个目标：
- 速度和容量最大化
- 避免组件间出现瓶颈
- 花费少

我列举了构建工作站所需的所有组件以及每一组件的考虑事项。各组件以其对深度学习模型训练的性能影响为序排列。

**GPU**
- 经基准测试，RTX 2080 Ti 是 2500 美元价位下最好的 GPU。
- 请购买 after-market GPU（如 EVGA 或 MSI），而不是英伟达 Founders Edition。
- 注意 RTX 2080 Ti 的过热问题。
- 该工作站并未使用涡轮风扇式（blower-style）GPU（更便宜），但涡轮风扇式 GPU 的性能可能更好。

GPU 是深度学习机器中最为重要的组件，同时也是最昂贵的。你通常应该首先考虑使用哪种 GPU：装配中的其他所有组件选择将基于此。很多博客都有介绍如何选择满足你需要的 GPU。

如果你想要一款高性能 GPU，我建议不要受市场营销的干扰，直接购买 RTX 2080 Ti。如果你想自己做研究，并想要选择一款性价比高的 GPU，则可以通过 [http://videocardbenchmark.net](https://link.zhihu.com/?target=http%3A//videocardbenchmark.net) 检索，并在你的价格区间内选择性能最佳的 GPU。除非你的预算在 2,500 美元以上，RTX 2080 Ti 是最佳选择。如果性能降低 30%，你可以选择购买更便宜的 RTX 2080 或者旧版 GTX 1080 Ti。为实现最佳的深度学习，我建议你购买至少 11GB 内存的 GPU，而这正是 RTX 2080 Ti 的内存容量。

在购买 RTX 2080 Ti 时，你会注意到市场上有大量相关品牌：EVGA、技嘉、华硕、微星等。这些都是所谓的 after-market GPU（非公版）。你也可以选择直接购买英伟达的 Founders Edition。一般而言，如果你想追求最佳性能，不要购买 founders edition。为优化性能，EVGA 等公司会对 GPU 进行定制设计，有时会进行 GPU 超频处理。Founders edition 是首次尝试而非最佳尝试。非公版 GPU 通常设计有一至三个风扇，大概风扇越多，性能越好。其中一些只是营销噱头罢了，两个风扇通常就够了。这里的主要建议是：购买 EVGA、技嘉、华硕或微星的非公版 GPU。

请注意，after-market GPU 品牌众多，价格不一。超频 GPU 往往更贵，但通常会作出一些折中，因而实际上并不能提升性能。你通常只需购买最便宜的即可。

一些顾客已经抱怨过 RTX 2080 TI 的过热问题。我在构建工作站时仅使用三个 GPU 就是为了增加冷却气流。如果没有出现问题，我会另加第四个 RTX 2080 TI GPU。

我在构建工作站中使用了开放式风扇 GPU（风扇在每个 GPU 的底部），因为它们成本更低。涡轮风扇式 GPU 将气流从机箱一侧排出，使性能更佳。就我们使用的主板而言，GPU 被压缩得很紧，阻止开放式 GPU 风扇排出气流。如果你购买了涡轮风扇式 GPU，风扇可直接将气流从机箱一侧排出。

**固态硬盘 SSD**
- SSD <> GPU 数据迁移是深度学习训练和预测的主要瓶颈。
- m.2 SSD 比标准 SSD 快了 6 倍。
- 如果预算足够，请购买 m.2 SSD。你需要与 m.2 兼容的主板。

从硬盘到 GPU 的数据迁移是深度学习的主要瓶颈，会极大降低训练和测试时速。m.2 SSD 可以解决这个问题。最贵的 SSD 写入速度为 3500 mb/s，而标准 SSD 写入速度为 500 mb/s。

我购买了一个较便宜的 m.2 SSD 来构建工作站，其写入速度约为 1800 mb/s，但容量较大，为 2 TB。你可能会觉得购买更小的 256MB m.2 SSD 更有用，因为它写入速度更快且成本更低。这的确是以更少的成本获得更好性能的好办法。唯一需要注意的是，你要确保所有训练数据都可以放在 m.2 SSD 上。

**主板**
- 为了支持多 GPU，你需要足够的 PCI-E 通道。
- 这意味着你需要 x299（英特尔 CPU）或 x399（AMD CPU）主板。
- 你可以选择便宜一点的，但如果预算足够，可以考虑工作站（workstation）主板。

主板很难购买，因为选择太多，很多人不清楚为什么有的主板会比其它主板贵很多。对于深度学习来说，主板最重要的方面是 PCI-E 通道的数量。在我构建的工作站中，主板有 44 个 PCI-E 通道。这意味着如果有 3 个 GPU（每个需要 16 个通道），我可以在 32 个通道上运行两个 GPU（每个 GPU16 个通道），在 8 个通道上运行 1 个 GPU（总共需要 40 个通道）。大多数基准测试表明，在 8 个通道和 16 个通道上运行 GPU 的性能差异可以忽略不计，但未来差别可能会大一些。至少，确保你的主板有足够的 PCI-E 通道，能够满足每个 GPU 所需的最少数量。所以对 3 块 RTX 2080 TI GPU 来说，最少需要 24 个 PCI-E 通道。

另一个考量是选择 x299（英特尔 CPU）还是 x399（AMD CPU）主板。对每个处理线程来说，英特尔 CPU 更快，但对于相同数量的处理线程来说，AMD CPU 通常比英特尔 CPU 更便宜。我选择用英特尔处理器（20 个线程和较快的处理速度），因此需要 x299 主板。

更可靠（也更昂贵）的主板通常被称为工作站主板。可靠性的提高是否值得如此高价仍有待商榷。我在自己的构建过程中选择了工作站主板，但如果你想选择更便宜的，可以考虑 SUPERMICRO x299 主板。它满足了我的所有需求，但便宜了 100 美元。

**CPU**
- 选择英特尔 X 系列（x299 主板）或 AMD ThreadRipper（x399）。
- 对每个线程来说，英特尔 CPU 更快，但 AMD CPU 在相同的花费下支持更多线程。

通过考虑以下问题，基于你的计算需求选择 CPU：
- 你是否需要运行大量多线程工作？
- 你需要每个线程运行很快吗？

如果（1）回答「是」，而（2）回答（不需要），那么你可以用更少的成本选择支持 32 个线程的 AMD Ryzen Threadripper 2950X。如果第二个问题的答案是「需要」，那你可能想要选择英特尔 CPU。

对于英特尔 CPU，你需要选择核心的英特尔 X 系列 CPU 用于多 GPU 深度学习。只有 X 系列的 CPU 支持 x299 主板，而只有 x299 主板才具有足够的 PCI-E 通道来支持多 GPU。如果你仅使用 2 个 GPU，那么你可以减少主板+CPU 的成本，选择较便宜的 300 系列英特尔 CPU 和 LGA 1151 主板（而非 x299）。这样你就可以在 16 个 PCI-E 通道上运行一个 GPU，然后在另外 8 个通道上运行另一个 GPU（大部分 LGA 1151 主板有 24 个 PCI-E 通道，但购买的时候请仔细确认）。

**机箱**
- 选择适合自己主板的机箱（ATX 是标准尺寸，mini-ATX 较小）。
- 选择具备气流流通空间的机箱，以保持 GPU 低温。
- Carbide Series™ Air 540 High Airflow ATX Cube Case 比较适合深度学习工作站。

对于多 GPU 工作站，气流和散热是重中之重。选择适合主板的机箱。大部分使用多 GPU 的主板是 ATX，因此你可以选择一个适合 ATX 主板的机箱。如果你不确定要买哪种机箱，Carbide Series™ Air 540 High Airflow ATX Cube Case 是不错的选择。

**硬盘驱动器**

如果 m.2 SSD 无法满足存储需求，购买 7200 RPM 的机械硬盘。

如果 m.2 SSD 太小，无法满足你的存储需求，你可以购买一个机械硬盘驱动器。它比较便宜，有两种速度：5400 RPM（较慢）和 7200 RPM（较快）。RPM 表示每分钟转速，这些磁盘会在计算机内进行物理旋转，所以会有噪音。不过机械硬盘驱动器比较便宜，你可以买一个 7200 RPM 的。

**内存**
- 购买低间隙内存（RAM），确保它适合你的机箱。
- 避免购买没听说过的牌子。

关于 RAM，你需要考虑它的容量、物理体积和延迟。我构建的工作站使用的是 128GB RAM，不过你可以根据数据集大小将容量减到 64GB 或 32GB。如果资金充足，我建议购买 128GB RAM，这样在训练深度学习模型时，你可以将整个数据集加载到内存中，避免每个 epoch 中出现 hard-drive <> RAM 瓶颈。

对于多 GPU 工作站，确保购买低间隙 RAM（较小机箱），间隙即 RAM 的高度。主板上要安装大量东西，有时候大机箱 RAM 会阻塞其他组件。海盗船 Vengeance 是一款不错的低间隙 RAM。

如果你不使用全部 RAM 插槽的话，记得查看主板文档。将 RAM 放进合适的插槽中很重要！主板和主板文档通常会写明放置 RAM 的位置。

**PSU（电源供应器）**
- 确保你的 PSU 可以提供充足的电量。参考 PSU 计算器：[https://outervision.com/power-supply-calculator](https://link.zhihu.com/?target=https%3A//outervision.com/power-supply-calculator)
- 每个 RTX 2080 Ti 需要大约 300W 能耗。
- 选择全模组，因为电缆越少就意味着气流越多。
- 我的 1300W PSU 导致最大负载时工作站会重启，1600W 比较适合该工作站。

你可能会看到 gold PSU vs. platinum PSU。这指的是 PSU 所用的金属，platinum > gold > silver > bronze > basic，它和 PSU 的效能有关。例如，同样的计算量，bronze PSU 要比 platinum PSU 消耗更多电。如果你需要考虑省电的问题（同时也环保），可以考虑购买 platinum 或 gold PSU。

至于本文介绍的工作站，我原本买的是 Seasonic PRIME 1300W PSU，但是当我进行分布式 PyTorch ImageNet/ResNet50 训练且最大化利用所有 GPU 时，工作站濒临重启状态。于是我换成了 EVGA SuperNOVA 1600 P2，这些问题解决了。注意，我使用 sudo nvidia-smi -pl 180 将 GPU 电量从 250W 降到 180W 时，1300W PSU 是可以使用的。不过我仍然推荐 1600W PSU，不然会限制 GPU 速度。

**散热系统**
- 通常，不错的气流和适当的电缆管理对于 GPU 散热来说足够了。
- 高性能（i9 X-Series）CPU 散热用海盗船 h100i 就可以了。
- 即使如此，如果可以请将机器放在阴凉、装有空调的房间里。

从散热风扇到全系统水冷却，你有很多选择。通常，如果机箱很大且电缆管理合适，那么你不用要太多华丽的东西。我构建的工作站中，CPU 没有配备散热器，我使用的是深度学习工作站中的标准配置海盗船 h100i。更低价的选择是 Noctua NH-U9S CPU Cooler Fan。我没买它的原因是它太大了，可能会阻塞部分 RAM 插槽。如果你只需要 32 GB RAM，你可以选择这款散热风扇。

**基准测试 VS 谷歌计算引擎**

我对这台机器和谷歌计算引擎（GCE）深度学习虚拟机进行了基准测试对比。这些虚拟机据称是专门为优化深度学习而预构建的。GCE 深度学习虚拟机使用 CUDA 版本和基于源代码构建的驱动程序，这些程序转为其硬件架构而优化。GCE 虚拟机没有英伟达 RTX 2080 Ti GPU，所以我用 Tesla K40 来代替。根据不同的基准任务，英伟达 RTX 2080 Ti 的性能是 GPU Tesla K40 的 2 倍至 4 倍。所以为了公平起见，我将这台设备上的一个 RTX 2080 Ti 与 GCE 虚拟机上的 4 个 Tesla K40 进行了对比。

为了做基准测试，我使用了 PyTorch 的 ImageNet 分布式案例。我下载了 ImageNet 2012 训练和验证集，并在我的个人机器和 GCE 深度学习虚拟机上运行了以下代码：

`python examples/imagenet/main.py -a resnet18 --lr 0.1 --dist-url 'tcp://127.0.0.1:FREEPORT' --dist-backend 'nccl' --multiprocessing-distributed --world-size 1 --rank 0 "/location/where/I/stored/imagenet/"`

**GCE 深度学习虚拟机规格**

我创建的虚拟机规格如下：
- 架构：64 位，x86_64
- K40 GPU 数量：8
- 内存：394 GB
- RAM：172 GB
- CPU 线程数量：24

**ImageNet 训练时间基准**

训练 1 个 epoch 所需时间对比：
- 我构建的工作站上 1 个 RTX 2080 TI 训练 1 个 epoch 耗时：37.5 分钟
- GCE 虚拟机上 4 个 Tesla K40 GPU 训练 1 个 epoch 耗时：86.3 分钟

这些值是经过 50 个 epoch 训练后平均得到的。运行的代码和上面相同，没有在任何一台机器上展开其它进程。

**训练每个 epoch GCE 所需的花费**

我使用的 GCE 架构并不是最具成本效应的设置，训练花费为：

4 个 Tesla K40 GPU 训练 1 个 epoch 所需花费为 12.77 美元

所以用 Tesla K40 GPU 对 ImageNet 进行 100 个 epoch 训练将花费约 1277 美元。而对于整个虚拟机来说，将花费约 21 美元/小时。

**与 Lambda 的 4-GPU 工作站进行对比**

我所构建的工作站旨在优化成本／性能权衡。如果你想构建与 Lambda 4-GPU 更加匹配的工作站，那么可以看一下 Lambda CEO Stephen Balaban 在 reddit 上分享的几条建议：
- 添加一块额外的涡轮风扇式 GPU（1349 美元）
- 加 159 美元，将另外 3 块 GPU 都升级成涡轮风扇式 GPU（共 477 美元）
- 加一个热插拔式驱动器托架（50 美元）
- 加 1600W PSU（107 美元）
- 将 CPU 从 10 核升级到 12 核（189 美元）
- 上述原本工作站需花费 6200 美元

进行以上调整后，整个工作站的总花费大约是 8372 美元，比 Lambda 工作站少大概 4000 美元。

**其他**

我使用的操作系统是 Ubuntu Server 18.04 LTS，我使用 TensorFlow Cuda 10.1（从源代码安装）和 PyTorch。当我长时间以最大容量使用这三块 GPU 时，我发现最上面的 GPU 出现过热降频，造成性能出现 5%-20% 的下降。这可能是双风扇 GPU 设计的缘故。如果你担心这个问题的话，推荐使用涡轮风扇式 GPU，以避免过热降频。
*![](https://pic1.zhimg.com/v2-18cc987d5f379a82f1208b6d90722318_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='73' height='24'></svg>)*
*原文链接：*[http://l7.curtisnorthcutt.com/build-pro-deep-learning-workstation](https://link.zhihu.com/?target=http%3A//l7.curtisnorthcutt.com/build-pro-deep-learning-workstation)




