# ECCV 2018奖项公布：德国团队获最佳论文，吴育昕、何恺明上榜 - 知乎
# 



**机器之心报道，机器之心编辑部。**

> 今日，ECCV 2018 获奖论文公布，来自德国航空航天中心、慕尼黑工业大学的研究者获得最佳论文奖项；吴育昕与何恺明合作的《Group Normalization》、Albert Pumarola 等人合作的《GANimation: Anatomically-aware Facial Animation from a Single Image》获得了最佳论文荣誉提名奖。

当前，在人工智能大浪潮下，学术会议成为产业界甚至公众密切关注的事件。

前有[NIPS 门票开放注册 11 分钟后被抢光](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650748057%26idx%3D1%26sn%3D055d227136f71e8626c42ed4340adc67%26scene%3D21%23wechat_redirect)，而正在火热进行的 ECCV 官网也提前发布通知表示，大会已经满额，不要自发来参与此大会。
![](https://pic4.zhimg.com/v2-0d5fce9b3a72726f1b8cff34464f9573_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1024' height='768'></svg>)
作为计算机视觉领域的三大顶会之一，ECCV 今年的火爆程度超乎寻常。据数据显示，今年大会参会人数近 3200 人，是上届（2016）的两倍。
![](https://pic2.zhimg.com/v2-92311cf574a31e92cd0e609233a4f579_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1024' height='768'></svg>)
论文接收方面，本届大会收到论文投稿 2439 篇，接收 776 篇（31.8%），59 篇 oral 论文，717 篇 poster 论文。在活动方面，ECCV 2018 共有 43 场 Workshop 和 11 场 Tutorial。

除了介绍本届大会的参会与论文接收情况，会议主办方在周三的晚宴中还公布了今年的获奖论文：




**最佳论文**

最佳论文奖由来自德国航空航天中心、慕尼黑工业大学的团队获得。值得一提的是港中文大学教授、商汤科技联合创始人汤晓鸥是颁奖委员会成员之一。
![](https://pic3.zhimg.com/v2-70f8371a0b6f9c349d3395b8fca61342_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='620'></svg>)



**论文：Implicit 3D Orientation Learning for 6D Object Detection from RGB Images**
- 作者：Martin Sundermeyer、En Yen Puang、Zoltan-Csaba Marton、Maximilian Durner、Rudolph Triebel
- 机构：德国航空航天中心、慕尼黑工业大学
- 论文链接：[http://openaccess.thecvf.com/content_ECCV_2018/papers/Martin_Sundermeyer_Implicit_3D_Orientation_ECCV_2018_paper.pdf](https://link.zhihu.com/?target=http%3A//openaccess.thecvf.com/content_ECCV_2018/papers/Martin_Sundermeyer_Implicit_3D_Orientation_ECCV_2018_paper.pdf)

**摘要**：我们提出了一个基于 RGB 的实时目标检测和 6D 姿势估计流程。我们的新型 3D 目标朝向估计方法基于去噪自编码器（Denoising Autoencoder）的一种变体，其使用域随机化（Domain Randomization）在 3D 模型的模拟视图上进行训练。我们称之为「增强自编码器」（Augmented Autoencoder，AAE），它和现有方法相比具备多项优势：无需真实的姿势标注训练数据，可泛化至多种测试传感器，且内在地能够处理目标和视图对称性。该方法不学习从输入图像到目标姿势的显性映射，而是提供样本在潜在空间中定义的目标朝向隐性表征。在 T-LESS 和 LineMOD 数据集上的实验表明，我们的方法优于基于模型的类似方法，可以媲美需要真实姿态标注图像的当前最优方法。

具体而言，我们的方法在单张 RGB 图像上运行，由于不需要深度信息，其可用性大大提高。尽管我们注意到深度图可以被选择性地合并以改进估计。第一步，我们应用一个单次多框检测器（Single Shot Multibox Detector，SSD）来提供物体边界框和标识符。在生成的场景裁剪图上，我们采用了新的 3D 朝向估计算法，该算法基于先前预训练的深度网络架构。虽然深度网络也在现有方法中使用，但我们的方法不同之处在于，我们在训练期间没有从 3D 姿态标注数据中显式地学习。相反，我们从渲染的 3D 模型视图中隐式地学习表征。

本论文提出方法的原理图如下所示：
![](https://pic3.zhimg.com/v2-e9fef8343d0b14394184b6dbe77e3b12_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='825' height='506'></svg>)图 1：具有同质转化 H_cam2obj ∈ R^(4x4)（右上）和深度精制结果 H^（refined）_cam2obj（右下）的 6D 目标检测管道![](https://pic4.zhimg.com/v2-433d233f4cf86ebe85f3cb58cfb3be93_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='863' height='459'></svg>)图 4：AAE（增强自编码器）的训练过程![](https://pic3.zhimg.com/v2-a25b5bd51c32dee252d37c23d4de54ba_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1069' height='412'></svg>)图 5：具有遮挡测试输入的自编码器 CNN 架构![](https://pic3.zhimg.com/v2-79974a3b968e19c756e90b22ad407f06_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1052' height='461'></svg>)表 5：LineMOD：使用不同训练和测试数据的目标召回（ADD 标准），结果来自 [35]![](https://pic3.zhimg.com/v2-f9065642b62e572eb08905ccd811bd8a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='576'></svg>)最佳论文获奖团队接受颁奖
**荣誉提名论文**
![](https://pic2.zhimg.com/v2-e6e898947e289ff0e362f25b54de3be9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='575'></svg>)



**论文：Group Normalization**
- 作者：吴育昕、何恺明
- 机构：Facebook AI Research (FAIR)
- 论文链接：[https://arxiv.org/abs/1803.08494](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1803.08494)

**摘要**：批归一化（BN）是深度学习发展史中的一项里程碑技术，使得大量神经网络得以训练。但是，批量维度上的归一化也衍生出一些问题——当批量统计估算不准确导致批量越来越小时，BN 的误差快速增大，从而限制了 BN 用于更大模型的训练，也妨碍了将特征迁移至检测、分割、视频等计算机视觉任务之中，因为它们受限于内存消耗，只能使用小批量。在本论文中，我们提出了作为批归一化（BN）简单替代的组归一化（GN）。GN 把通道分为组，并计算每一组之内的均值和方差，以进行归一化。GN 的计算与批量大小无关，其精度也在各种批量大小下保持稳定。在 ImageNet 上训练的 ResNet-50 上，当批量大小为 2 时，GN 的误差比 BN 低 10.6%。当使用经典的批量大小时，GN 与 BN 相当，但优于其他归一化变体。此外，GN 可以自然地从预训练阶段迁移到微调阶段。在 COCO 的目标检测和分割任务以及 Kinetics 的视频分类任务中，GN 的性能优于或与 BN 变体相当，这表明 GN 可以在一系列不同任务中有效替代强大的 BN；在现代的深度学习库中，GN 通过若干行代码即可轻松实现。
![](https://pic1.zhimg.com/v2-305af7d4a8be1b46c93409cb2efbdb08_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='614' height='431'></svg>)
图 1：ImageNet 分类误差 vs. 批大小。这是在 ImageNet 训练集上用 8 个工作站（GPU）训练、在验证集上进行评估的 ResNet-50 模型。

具体内容参见：[FAIR 何恺明等人提出组归一化：替代批归一化，不受批量大小限制](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650739772%26idx%3D1%26sn%3D47d7c43c04f9074fb9d08ae630c8bf0a%26scene%3D21%23wechat_redirect)




**论文：GANimation: Anatomically-aware Facial Animation from a Single Image**
- 作者：Albert Pumarola、Antonio Agudo、Aleix M. Martinez、Alberto Sanfeliu、Francesc Moreno-Noguer
- 机构：西班牙机器人与工业信息研究所、俄亥俄州立大学
- 论文链接：[https://arxiv.org/abs/1807.09251](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.09251)

**摘要**：近期生成对抗网络（GAN）在人脸表情合成任务中取得了惊人的表现。其中最成功的架构是 StarGAN，它使用特定域的图像来调整 GAN 生成过程，即一系列相同表情的人脸图像。尽管该方法很有效，但它只能生成不连续的表情，而这是由数据集决定的。为了解决这个局限，本文提出了一种基于动作单元（AU）标注的新型 GAN 条件化方法，该方法在连续流形中描述了定义人脸表情解剖结构的运动。我们的方法允许控制每个 AU 的激活值大小，并将其组合。此外，我们还提出了一个完全无监督的策略来训练该模型，仅需要用激活 AU 标注的图像，并利用注意力机制使我们的网络对背景和光照条件变化具备鲁棒性。扩展评估结果表明，我们的方法在合成更多样表情（按解剖结构的肌肉运动），以及处理自然图像的能力上都超越了对比的条件生成模型。
![](https://pic2.zhimg.com/v2-782f4e4cd0d200c627739345ddab9ac9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1036' height='728'></svg>)
图 1：从单张图像生成的人脸动画。研究者提出了一种解剖结构上连贯的方法，该方法不局限于离散数量的表情，可以对给定的图像进行动画化处理, 并在一些连续的图像域中生成新的表情。在这些例子中，只给出最左边的图像输入 I_yr（由绿色方框圈出）, 参数α控制微笑表情中包含的目标动作单元的激活程度。此外, 该系统可以处理非自然光照条件下的图像, 如最下面一行的例子。




以下是部分动画示例：
![](https://pic1.zhimg.com/v2-ac2e5ce7060b5d0fe6292b329928c2c0_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='95' height='95'></svg>)![](https://pic1.zhimg.com/v2-ffe3b2c069151769dc38fd86484f200c_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='95' height='95'></svg>)



具体内容参见：[ECCV 2018 | GANimation 让图片秒变 GIF 表情包，秒杀 StarGAN](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650746763%26idx%3D5%26sn%3Ddda532baba6bc945be697d488b3380ab%26scene%3D21%23wechat_redirect)

除了最佳论文，ECCV 2018 还颁布了 Everingham 奖、Koenderink 奖两大奖项。前者是为了纪念 Mark Everingham，后者是为了奖励经得起时间考验的计算机视觉基础研究。




**Everingham 奖**
![](https://pic1.zhimg.com/v2-b9b064b7e45dbb0fe135a3f82f72a870_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='575'></svg>)- 获奖人：Alan Smeaton、Wessel Kraaij、Paul Over、George Awad
- 贡献：自 2003 年以来参与了一系列数据集和研讨会，推动了大规模视频检索方面的进展。
- 获奖人：Changchang Wu
- 贡献：为运动恢复结构（structure from motion）提供了一个记录完备的软件库。




**Koenderink 奖**
![](https://pic3.zhimg.com/v2-e25f76c7d5291c8244ff988ffe1a8356_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='575'></svg>)



**论文：Hamming Embedding and Weak Geometric Consistency for Large Scale Image Search**
- 作者：Herve Jegou, Matthijs Douze, and Cordelia Schmid 
- 机构：INRIA Grenoble, LEAR, LJK
- 论文链接：[https://lear.inrialpes.fr/pubs/2008/JDS08/jegou_hewgc08.pdf](https://link.zhihu.com/?target=https%3A//lear.inrialpes.fr/pubs/2008/JDS08/jegou_hewgc08.pdf)




**论文：Semi-supervised On-Line Boosting for Robust Tracking **
- 作者：Helmut Grabner, Christian Leistner, Horst Bischof
- 机构：奥地利格拉茨科技大学计算机图形与视觉研究所、瑞士苏黎世联邦理工学院计算机视觉实验室
- 论文链接：[http://www.vision.ee.ethz.ch/boostingTrackers/Grabner2008Semi-supervisedOn-lineboosting.pdf](https://link.zhihu.com/?target=http%3A//www.vision.ee.ethz.ch/boostingTrackers/Grabner2008Semi-supervisedOn-lineboosting.pdf)
*![](https://pic1.zhimg.com/v2-18cc987d5f379a82f1208b6d90722318_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='73' height='24'></svg>)*





