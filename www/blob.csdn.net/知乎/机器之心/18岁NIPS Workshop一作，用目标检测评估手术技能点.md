# 18岁NIPS Workshop一作，用目标检测评估手术技能点 - 知乎
# 



**选自Stanford Medicine，作者：Ruthann Richter，机器之心编辑部。**

> 由李飞飞教授创办的公益机构 AI4All 致力于提高人工智能领域的多样性和包容性。该组织提供教育和导师计划为美国和加拿大的少数群体人才提供学习途径，AI4All 为高中学生提供尽早接触 AI 的机会。刚刚，李飞飞发推赞扬 AI4All 成员 Amy Jin、斯坦福大学博士 Serena Yeung 和斯坦福 PAC 团队的合作者一道在 AI+医疗领域做出的贡献：他们合作设计了一款软件来评估外科医生的技能。

PAC 团队的负责人是李飞飞和医学教授 Arnold Milstein，其整合了斯坦福以及其他医学院的一系列跨学科资源，主要是想用 AI、计算机视觉等技术解决一些医疗健康中的难题。



![](https://pic3.zhimg.com/v2-a314a129469f18bff118979d258bd656_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='582' height='173'></svg>)
该研究论文已在 arXiv 上发布，一作 Amy Jin 今年 18 岁，最近刚刚高中毕业，是个喜欢 hip-hop、小提琴和英国文学的女孩。而她对计算机科学的热情使她成为人工智能领域的 superstar。

据斯坦福大学医学院的报道，Amy Jin 六年级时就对 AI 产生了兴趣，但直到成为高中生，她对 AI 的热情才开始燎原，当时她听到 IBM 科学家介绍 Watson 超级计算机能够通过人工智能扩展人类在医疗及其他领域的能力，教会机器「思考」和「看见」。「Watson 能够成为医生的第二双眼睛」，这使 Amy 震惊又兴奋，她认为 AI 领域可以产生很多跨学科的可能性，因此非常有潜力。
![](https://pic1.zhimg.com/v2-301d52d19764b92825316d245a134790_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='620' height='413'></svg>)Amy Jin 其它两位斯坦福的导师共同设计了一款软件，可以评估外科医生的技能。
过去两年，Jin 与斯坦福大学的导师共同设计了一款新的软件，用于评估外科医生的技能。该软件的工作原理是：「观看」外科手术的视频，然后追踪手术过程中的动作、计算每个步骤中使用器械的时长。该创新成果获得了 NIPS 2017 Machine Learning for Health 研讨会的顶级研究奖项。斯坦福大学医学院 Clinical Excellence Research Center 负责人、医学博士 Arnold Milstein、研究论文共同作者预测该方法将在客观评估临床医生的多项临床技能中实现新突破。

Milstein 表示：「它提供了一种方式，根据医生的学习速度定制外科训练的时间。以及它提供了一套更客观的方法来定期评估外科医生的技能，或者在医生大手术期间及时提醒 Ta 需要休息。」
![](https://pic3.zhimg.com/v2-296557394cdd27632e2890717208958a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='620' height='414'></svg>)Serena Yeung（左）和 Jeff Jopling（右）与 Amy Jin 合作设计该软件。



Amy Jin 在读高中时参加了斯坦福 AI 实验室举办的 Outreach Summer Program，该项目旨在鼓励年轻女性投入科学研究。在该项目中，她与 Serena Yeung、Jeff Jopling 等人合作开展了利用 AI 技术改善医疗卫生的研究。

Serena Yeung 在 AI4All 导师计划中负责指导 Amy Jin，当时她仍是李飞飞和 Arnold Milstein 的博士生，看过 CS231n 2017 的读者可能会对她比较熟。Serena Yeung 对医学一直很感兴趣，而在斯坦福大学的教育经历使她对工程、AI 产生了兴趣，曾在 Facebook 和 Google 实习。后加入 Arnold Milstein 的项目，致力于使用技术来改善医疗实践。

Jeff Jopling 是医学博士，前 CERC 学者，他提出使用计算机技术来追踪外科手术技能，认为手术技能非常重要。根据 National Academy of Medicine 1999 年的一份报告，医疗卫生中的安全问题是重点，很高比例的死亡率和伤残率来源于医疗过程中的人为误差。医生想利用手术安全核查表最小化可避免的并发症、避免错误。

Jeff Jopling 称，很多研究聚焦于改善系统，但医生及其技能也很重要。

评估外科医生技能这一项目于 2016 年夏天正式启动，其挑战在于「教」计算机识别并追踪手术工具的移动路径。这是一个目标检测问题，该领域近年来发展迅速，李飞飞实验室功不可没。

**定位数据点**

研究人员开发了一种算法，教计算机从馈入的上千个数据点中学习。计算机根据每个比特的数据逐渐调整，直到达到可以形成准确目标图像的程度，在这个项目中目标指的是外科手术工具。Jin 改进了一些目标检测技术，将其应用于外科手术。她表示，「总的想法是，如果我们可以追踪、识别视频中的工具，我们就能更好地分析工具使用模式及其移动。」

为简单起见，研究人员主要聚焦胆囊切除手术。这种手术最多用到 7 种工具。他们拿到了 15 个相关手术视频，标注了其中的 2500 帧，而且为每一帧附加了一个值，以便计算机构建工具的视觉图像，并在手术野范围内定位它们。他们利用度量来追踪工具的使用时间，即何时使用何种工具、使用了多久，并绘制了每种工具的路径图。此外，他们还绘制了热图，显示这些工具在手术野内的分布。娴熟的外科医生通常会将工具放得比较集中。

研究人员可以根据视觉信息和数据从多个角度评估外科医生的表现，包括他们的动作是否简洁、每个步骤的操作是否高效等。接下来，他们请三位斯坦福的医生单独观看视频，并依据效率、双手灵活性和对人体组织的处理等广泛使用的指标按 1-5 分的范围进行打分。

「机器对手术的评价机制与医生的评分机制相关。」Yeung 表示。

例如，胆囊切除手术有一个关键步骤，医生必须夹住并切断向胆囊供血的胆囊动脉和传输胆汁的胆囊管。如果操作得当，这个步骤可以防止术中和术后出血及胆汁渗漏。如果夹子放错了位置或者松动了，病人会遭受致命的并发症。

娴熟的医生可以用较少的动作高效地处理这一问题。其中一个视频显示了一名外科医生的娴熟技巧，他/她将剪刀和其他工具放得恰到好处。而在另一段视频中，一名外科医生多用了一个夹子并努力将其放在适当的位置，之后又花了些时间将其弄开。计算机不仅通过查看器械的放置位置和路径，还通过查看手术持续时间来检测技能水平的差异。

研究小组将分析结果——《Tool Detection and Operative Skill Assessment in Surgical Videos Using Region-Based Convolutional Neural Networks》提交给 NIPS 2017 Machine Learning for Health 研讨会，该论文在 120 多份论文中脱颖而出，被选为 10 份 spotlight 论文之一。

**进一步优化**

Jopling 表示，项目的下一步是收集 1000 多个记录不同手术的视频。斯坦福将与犹他州联合医疗中心（Intermountain Healthcare，旗下有 22 家医院）合作，共同分析视频并改进这一评估工具。未来的研究还将考虑外科手术的复杂性，例如，有些胆囊切除手术很简单，有些却很难，因为不同患者的医疗情况不同。

他还表示，这项技术在外科手术培训中特别有用。外科医生检查受训者表现时通常一坐就是几小时，非常吃力。而自动系统可以为他们代劳，还可以在受训者可能出现失误时实时提醒医生。知道医生什么时候开始疲劳、精力不济，对手术结果来说非常重要。根据这个可以判断主刀医生何时应该休息并由助手接手。

Milstein 向斯坦福大学外科教授兼主席 Mary Hawn 分享了这项研究，后者非常乐意将完善后的模型提交给美国外科委员会（American Board of Surgery），作为当前委员会认证考试的补充。

但并非所有外科医生都乐意让一台机器来评价自己的技术。甚至有人表示，当这么一天到来时，自己将提前退休。

不过，Yeung 指出，此项 AI 技术可以广泛应用于医疗领域。例如，该研究组一直在测试用它来监控 ICU 病人的活动、护理人员是否遵循了确保病人安全的步骤。这项技术还能用来监控家中虚弱的老人，测试其活动和行动能力，当他们跌倒或发生其他意外时提醒其他人。

Yeung 还表示，如今的临床医生、护士和其他医疗保健服务人员都不堪重负，随着婴儿潮一代年龄的增长，这个问题将变得更加严峻。而人工智能存在巨大潜力，可以帮助我们持续了解、监控正在发生的事，进而帮助医疗保健服务人员，防止认知过载。

不过，Jin 不会继续参与这项斯坦福的研究。她现在是哈佛的大一新生，跟随其兄的步伐。虽然没法再继续参与项目，但 Jin 对该项技术的后续发展仍然充满期待。

**相关论文：Tool Detection and Operative Skill Assessment in Surgical Videos Using Region-Based Convolutional Neural Networks**
![](https://pic1.zhimg.com/v2-db5ce5cfc4add92deff8d4a0891ea168_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='785' height='216'></svg>)



论文链接：[https://arxiv.org/abs/1802.08774](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1802.08774)

**摘要**：世界上约有 50 亿人无法获得高质量的外科护理。外科医生的技能差异很大，很多接受外科手术的患者会遭受并发症和本来能避免的伤害。改善外科手术的训练和反馈机制可以帮助降低并发症的发生率，其中一半的并发症已经证明可以被预防。要做到这一点，重要的是评估手术操作技能，手术过程目前仍需要专家参与，它是手动、耗时且主观的。

本研究介绍了一种自动评估外科医生表现的方法，该方法主要通过基于区域的卷积神经网络自动追踪和分析手术视频中的工具运动而完成。为了研究这个问题，我们引入了一个新数据集 m2cai16-tool-locations，它标注了工具的空间界限。虽然以前的方法已经解决了工具的存在性检测问题，但我们的方法是第一种不仅能够检测工具的存在性，还能在实际的腹腔镜手术视频中对手术工具进行空间定位的方法。

我们的实验表明该方法既能高效地检测手术工具的空间界限，同时显著优于现有的工具存在性检测方法。我们进一步证明了该方法通过分析手术工具的使用模式、作业范围和作业有效性来评估外科手术质量的能力。

*参考链接：[http://stanmed.stanford.edu/2018fall/young-scientist-artificial-intelligence-measures-surgeons-skill.html#](https://link.zhihu.com/?target=http%3A//stanmed.stanford.edu/2018fall/young-scientist-artificial-intelligence-measures-surgeons-skill.html%23)*


