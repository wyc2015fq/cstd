# CVPR2018 | 摆好Pose却没管理好面部表情？腾讯优图Facelet-Bank人脸处理技术了解一下 - 知乎
# 



选自arXiv，作者：Ying-Cong Chen等，机器之心编译。

> 拍的照片看起来太严肃？蓄着胡子有点老？没关系，Facelet-Bank 可以通通帮你解决。近日，腾讯优图研发出一种数字人脸处理技术——Facelet-Bank，可以帮助我们改善图片中的人脸效果。再也不用担心拍照时表情管理失败被做成表情包了呢！

项目链接：[https://github.com/yingcong/Facelet_Bank](https://link.zhihu.com/?target=https%3A//github.com/yingcong/Facelet_Bank)




**引言**

数字人脸处理技术旨在改变语义表达和有意义的特征，如微笑和悲伤，或给人脸添加虚拟妆容/配饰，例如小胡子和眼镜。随着智能手机和数码相机的日益普及，人们迫切需要一个实用且快速的系统。人脸处理在计算机视觉和图形领域已经受到广泛关注 [14, 3, 6, 4, 33, 31, 28]。以前的方法致力于美颜 [19, 8]，去美颜 [10]，表情处理 [28] 和看脸辨龄等等。

通过这些方案，我们知道，不同的妆容或属性变化需要不同的处理操作。例如，美颜会处理肤色和纹理，而面部表情处理则更关注 2D 或 3D 几何体。基于此，大多数方法都是专门为单个任务设计的，任何专业效果都需要专家努力和专业知识才能制定有效的新方案。
![](https://pic1.zhimg.com/v2-2c2a150a14021116aec1c6db463b11ec_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='397' height='384'></svg>)图 1. 使用我们的模型进行脸部处理的样例
接下来，我们将阐述我们在寻求统一的人脸属性处理框架过程中遇到的问题，而后介绍我们最终的方案。




**1.1 可能的解决方案及问题**

**直接回归**

从外部数据学习人脸处理操作的直接方法是直接回归编辑前的输入和编辑后的真实图像 [10, 5]。但是，这一过程需要标注好的配对数据，而很多情况下没有这些数据或者需要大量人力来创建。对于任何以前没有的效果，这些处理都不易建立。




**生成对抗网络**

最近，生成对抗网络（GAN）已经显示了它在集合至集合的无监督学习中的能力 [36]。它使用循环一致性损失来保存图像内容，并且利用对抗损失将一组的属性转移到另一组中去。

虽然这个概念很明了而且效果惊人，但是很难训练，特别是对于需要修改系统组件的新效果。训练需要保持生成和判别的平衡。我们发现非最佳训练会产生很差的效果，这在视觉敏感的人脸上很容易被发现。




**深度特征插值**

深度特征插值 [29] 为学习两个不同集合的图像属性转换提供了另一种解决方案。这种方案需要基于两个图像集的深层特征。但是，这不是一个端到端的框架，因此无法进行全局优化。此外，即使在测试过程中，由于涉及数百个面部对齐和卷操作，它仍然是计算密集型的。




**1.2 我们的方案**

我们追求一个通用、灵活和高质量输出的人脸处理网络。图 1 展示了我们的方法生成的效果。我们采用了编码器解码器架构，而不是流行的生成对抗网络。

受 Style-Bank[9] 学习可替换风格转移层的启发，我们提出了一个 Facelet-Bank 框架，该框架可以用不同的中层网络（称为 Facelet）来对不同的人脸属性处理操作建模。有意思的是，为了产生不同的效果，只需更新中层网络就可以了，而无需完全重新设计框架。

此外，考虑到很多人脸处理任务缺乏参考标准，我们利用 [29] 的结果来生成伪目标以学习 Facelet 网络。有趣的是，尽管伪目标通常包含噪音，由于 Facelet 网络的架构中隐式地带有正则化功能，它仍然可以正确地捕获真正的属性操作。

最后，我们表明 Facelet 网络可以自动关注最重要的区域，以便以端对端的方式执行面部处理。我们专门设计为允许用户自定义效果级别，因此可以实现交互式脸部处理。我们的总体贡献是多方面的。

我们为面部处理提出了一个集合到集合的 CNN 框架。它不需要配对数据来训练。

该框架很灵活，可以通过简单地更新一些卷积层来生成不同的效果和级别，这对系统开发人员非常友好。

受益于卷积网络对图像的约束，我们的方法对伪目标中的噪声不敏感。

实验表明，我们的方法可以快速处理各种各样的人脸效果。
![](https://pic1.zhimg.com/v2-62f8ec1b3128d8c98bada5290f4c62c8_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='834' height='341'></svg>)



图 2. 我们的框架图。（a）是编码器 E（·）;（b）是 facelet-bank V（·）的卷积层;（c）是解码器 D（·）。facelet-bank 的结构是 Conv-ReLU-Conv-ReLU-Conv，其中所有 Convs 的内核尺寸都是 3×3。此外，facelet-bank 的所有 Convs 都不会改变先前输入的高度，宽度和通道数量。
![](https://pic3.zhimg.com/v2-53062c5ce1c5e5de0c4c41e7b77686ca_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='827' height='188'></svg>)
图 3. 抗噪效果图。（a）原始图像。（b）由等式（3）计算的伪偏移方向的热图。蓝色矩形标记不需要变化的区域。（c）等式（3）的对应结果。（d）我们估计的方向转移热图。（e）我们的结果。
![](https://pic2.zhimg.com/v2-e668967c97d26707ca522b10501cab4d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='395' height='190'></svg>)
图 4. 关注区域可视化。注意力掩模由对应于添加胡须、制作笑脸和改变年龄的操作等式（8）、（a）、（b）和（c）计算得来。注意，对于胡子效果，facelet-bank 专注于嘴巴区域。对于微笑效果，它会出现在与微笑有关的面部肌肉上。至于年龄变化的效果，关注区域覆盖整个脸部。这些结果符合我们的直觉。
![](https://pic1.zhimg.com/v2-f85e0c2f47ef8859a8a32b052564daf8_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='808' height='226'></svg>)
图 5. 比较 facelet-bank 方法和基准方法。
![](https://pic4.zhimg.com/v2-f2edaa89bb5ef0aba2646119d5f9d017_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='808' height='266'></svg>)
图 6. 去除面部毛发的结果。（a）原始图像;（b）、（c）和（d）分别是使用层 5，层 5 +层 4 和全部三层的结果。
![](https://pic3.zhimg.com/v2-cc6678759531530ce21586d79a4c519a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='828' height='444'></svg>)
图 7. 不同编辑强度的效果图。（a）、（b）和（c）分别表示不同编辑强度的效果
![](https://pic1.zhimg.com/v2-0c235fa20c4683b2ec884a4054422b14_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='836' height='470'></svg>)
图 8. 与 CycleGAN [36] 和 DFI [29] 的比较。




**论文：Facelet-Bank：快速人像处理**
![](https://pic2.zhimg.com/v2-8bb28f9c8af85bb4900e823240330099_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='766' height='209'></svg>)
论文链接：[https://arxiv.org/abs/1803.05576](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1803.05576)

**摘要：**随着智能手机和社交网络的普及，数字人脸处理技术已成为美图的热门方式。鉴于用户对面部表情和配饰的各种偏好，迫切需要一个通用且灵活的模型，以适应不同类型的面部处理。

为实现此目标，本文提出了一个基于端到端卷积神经网络的模型，这种端到端的卷积神经网络支持快速推理、编辑效果可控及部分模型快速更新。另外，该模型基于不同属性的非成对图像集训练。实验结果表明，我们的框架可以处理各种各样的表情，配饰和化妆效果。它可以快速生成高分辨率和高质量的效果。


