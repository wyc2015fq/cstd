# CVPR 2018 | Spotlight 论文：非参数化方法实现的极端无监督特征学习 - 知乎
# 



选自arXiv，机器之心编译。

> 本研究受监督学习中的输出排序的启发，指出数据本身的表面相似性而非语义标签，使得某些类比其他类更加接近。研究者据此提出了一种极端化的无监督学习方法，主要特点是非参数化训练、实例级判别（一个实例视为一个类）。在 ImageNet 上的实验结果表明，该方法在图像分类方面远超过最先进的无监督方法。若有更多的训练数据和更好的网络架构，该算法会持续提高测试结果。

深度神经网络，特别是卷积神经网络（CNN）的兴起，在计算机视觉领域取得了若干突破。大多数成功的模型都是通过监督学习进行训练的，而这需要大量的依任务类型而定的特定标注数据集。但是，在某些情况下，获取标注数据通常代价昂贵甚至不可行。近年来，无监督学习受到学界越来越多的关注 [5,2]。

研究者在本文中提出的无监督学习的创新方法源于对监督学习物体识别结果的一些观察。在 ImageNet 上，top-5 分类误差远低于 top-1 误差 [18]，并且图像在 softmax 层输出中的预测值排第二的响应类更可能与真实类有视觉关联。

如图 1 所示，包含猎豹（leopard）的图像被识别成美洲豹（jaguar）的概率比识别成书柜（bookcase）高很多 [11]。这一观察表明，经典的判别式学习方法在没有干预时可以自动发现语义类别之间的表面（明显的）相似性。换句话说，明显的相似性不是来自语义注释，而是来自图像本身。
![](https://pic3.zhimg.com/v2-14ac2819746def6c9cfd158d14661bda_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='718' height='577'></svg>)
图 1：激励研究者提出无监督方法的有监督学习效果图。以猎豹图片为例，网络输出的几个最高响应类都是视觉相关的，例如美洲豹和猎豹。数据本身的表面相似性而非语义标签，使得某些类比其他类更加接近。该无监督方法将类监督发展到极致，并学习了辨别各个单独实例的特征表示。




研究者将类监督发展到极端的实例监督，并提出这样的问题：我们是否可以通过纯粹的判别学习来学到反映实例间表面相似性的度量？图像本身具有鲜明的特征，并且每幅图像与相同语义类别中的其他图像都可能有很大差异 [23]。

如果我们在没有语义信息的情况下学习区分单独实例，那么我们最终可能会得到一个可以捕获实例间的表面相似性的特征表示，就像类监督学习在类别间仍然保留表面相似性那样。

无监督学习作为实例级别的判别形式在技术上也引人入胜，因为它可以受益于监督学习判别网络的最新进展，例如，新的网络架构。

然而，现在我们还面临着一个重大挑战，即现在「类别」的数量就是整个训练集的大小。对于 ImageNet 来说，「类别」将是 120 万而不是 1000 个类。简单将 softmax 扩展到更多的类是不可行的。研究者通过使用噪声对比估计（NCE）[9] 逼近的 softmax 分布并采用近端正则化方法 [29] 以稳定训练过程来解决这个挑战。

为了评估无监督学习的有效性，过去的工作如 [2,31] 依赖于线性分类器（例如，支持向量机（SVM）），在测试时将学习到的特征与类别信息结合以便进行分类。但是，我们不清楚未知的测试任务为什么可以将训练学习到的特征线性分离。

研究者提倡在训练和测试时都采用非参数化方法。他们将实例级别的分类看作度量学习问题，其中实例之间的距离（相似度）是以非参数方式直接从特征中计算得到的。也就是说，每个实例的特征都存储在离散的内存块中，而不是网络中的权重。

在测试阶段，使用基于学习度量的 k-近邻（kNN）进行分类。因为模型的学习和评估都与图像间的相同的度量空间有关，所以其训练和测试是一致的。研究者总结了与 SVM 和 kNN 的准确率对比实验结果。

实验结果表明，在无监督领域，该方法在图像分类方面远超过最先进的方法。具体地，在 ImageNet 1K [1] 上的 top-1 准确率为 46.5％，Places 205 [41] 为 41.6％。若有更多的训练数据和更好的网络架构，该算法会持续提高测试结果。

通过微调学习到的特征，可进一步获得半监督学习和物体检测任务的具竞争性的结果。最后，该非参数化模型非常紧凑：每张图片有 128 个特征，存储一百万张图像仅需 600MB，从而在运行时实现快速最近邻检索。
![](https://pic1.zhimg.com/v2-bbd542861b2254f4d16f2ce3dd660108_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='250'></svg>)
图 2：本文提出的无监督特征学习方法的工作流图。研究者使用骨干 CNN 将每个图像编码为 128 维空间并进行 L2 归一化的特征向量。最佳特征嵌入过程是通过实例级判别器学习的，该判别器尝试将训练样本的特征最大程度地散布在 128 维的单位球上。
![](https://pic2.zhimg.com/v2-9dd1a45d82a2c11756ddb229fc71f109_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='650' height='280'></svg>)
表 1：通过在学习到的特征上应用线性 SVM 或 kNN 分类器在 CIFAR10 的 Top-1 准确率。本文提出的非参数化的 softmax 优于参数化的 softmax，并且用 NCE 方法 得到的准确率随 m 单调递增。




**图像分类**

研究者在 ImageNet ILSVRC [34] 上学习特征表示，并将他们的方法与代表性的无监督学习方法进行比较。

实验设置。研究者通过经验验证来选择并设计参数。具体来说，他们设定 τ= 0.07，并使用 m = 4,096 的 NCE 来平衡性能和计算成本。该模型使用带 momentum 的 SGD 训练 200 个 epoch。批量大小为 256，学习率初始化为 0.03，在训练 120 个 epoch 后每 40 个 epoch 乘一次 0.1。

对比实验。研究者将他们的方法与随机初始化的网络（作为下界）及各种无监督学习方法进行了比较，包括自监督学习 [2,47,27,48]、对抗学习 [4] 和 Exemplar CNN [3]。split-brain 自编码器 [48] 提供代表当前最佳水平的强大基线。

在他们的初版论文中，他们的实验网络都基于 AlexNet 架构 [18]，除了 exemplar CNN [5]，其基于 ResNet-101 [3]。由于网络架构对性能有很大影响，研究者考虑了一些经典的架构：AlexNet [18]、VGG16 [36]、ResNet-18 和 ResNet-50 [10]。

研究者使用两种不同的标准评估性能：（1）对从 conv1 到 conv5 的中间特征运行线性 SVM。注意，VGG16 和 ResNet 中也有对应层 [36,10]。（2）对输出特征运行 kNN。
![](https://pic4.zhimg.com/v2-f9fc7b44ad0750907c463b38a5995013_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='723' height='554'></svg>)
表 2：在 ImageNet 上的 Top-1 分类准确率。
![](https://pic2.zhimg.com/v2-49fb902ae0d99dfd180bb109306ae6c1_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='721' height='519'></svg>)
表 3：直接基于在 ImageNet 上学习特征的、没有微调的在 Places 上的 Top-1 分类准确率。
![](https://pic3.zhimg.com/v2-fd1e676b9f9b2fdf9621f36bb2f41eba_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='980' height='642'></svg>)
图 5：查询示例的检索结果。左列是验证集的查询，右列是训练集中检索到的 10 个最接近的实例。上半部分展示了最好的表现。下半部分展示了最差的表现。




**论文：Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination**
![](https://pic1.zhimg.com/v2-ebd5815d6a695d7084ef6d67fa463b38_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='164'></svg>)
论文地址：[https://arxiv.org/abs/1805.01978](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.01978)

开源代码：[http://github. com/zhirongw/lemniscate.pytorch](https://link.zhihu.com/?target=http%3A//github)

**摘要：**在标注数据集上训练过的神经网络分类器无须人为干预就可以在各个类别间捕捉明显的视觉相似性。我们研究了这一行为是否可以扩展到传统的监督学习领域之外：我们是否可以仅通过获取可区分单独实例的特征来学习一个可以很好捕捉实例间而非类间明显相似性的特征表示？我们将该思路看做实例级的非参数化分类问题，并使用噪声对比估计来解决大量实例类带来的计算挑战。我们的实验结果表明，在无监督学习条件下，我们的算法性能远超 ImageNet 分类问题上最先进的算法。若有更多的训练数据和更好的网络架构，我们的算法会持续提高测试结果。通过微调学习到的特征，我们进一步获得了半监督学习和物体检测任务的有竞争力的结果。我们的非参数化模型非常紧凑：每张图片有 128 个特征，我们的方法存储一百万张图像仅需 600MB，从而在运行时实现快速最近邻检索。


