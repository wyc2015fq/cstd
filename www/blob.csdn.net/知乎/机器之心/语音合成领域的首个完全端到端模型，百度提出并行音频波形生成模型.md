# 语音合成领域的首个完全端到端模型，百度提出并行音频波形生成模型 - 知乎
# 



**选自百度，作者：Wei Ping、Kainan Peng、Jitong Chen ，机器之心编辑。**

> 语音合成（Text-to-Speech，TTS）是将自然语言文本转换成语音音频输出的技术，在 AI 时代的人机交互中扮演至关重要的角色。百度硅谷人工智能实验室最近提出了一种全新的基于 WaveNet 的并行音频波形（raw audio waveform）生成模型ClariNet，合成速度提升了数千倍，可以达到实时的十倍以上。此外，这也是语音合成领域第一个真正的端到端模型：单个神经网络，直接从文本到原始音频波形。

最近，百度硅谷人工智能实验室的研究员提出了 ClariNet，一种全新的基于 WaveNet 的并行音频波形（raw audio waveform）生成模型。WaveNet 是能够完美模仿人类声音的最前沿语音合成技术（Google I/O 大会所展示的超逼真合成语音的背后技术）。自从其被提出，就得到了广泛的离线应用。但由于其自回归（autoregressive）的特点，只能按时间顺序逐个生成波形采样点，导致合成速度极慢，无法在 online 应用场合使用。ClariNet 中所提出的并行波形生成模型基于高斯逆自回归流（Gaussian inverse autoregressive flow），可以完全并行地生成一段语音所对应的原始音频波形。比起自回归的 WaveNet 模型，其合成速度提升了数千倍，可以达到实时的十倍以上。

对比 DeepMind 稍早提出的 Parallel WaveNet，ClariNet 中的概率分布蒸馏（probability density distillation）过程更加简单优美，直接闭式地（closed-form）来计算训练目标函数 KL 散度（KL divergence），大大简化了训练算法，并且使得蒸馏过程效率极高——通常 5 万次迭代后，就可以得到很好的结果。同时作者还提出了正则化 KL 散度的办法，大大提高了训练过程的数值稳定性，使得结果简单易训练（注：Clari 在拉丁语中是 clear, bright 的意思）。而 Parallel WaveNet 由于需要蒙特卡洛采样来近似 KL 散度，使得梯度估计的噪音很大，训练过程很不稳定，外界极难重现 DeepMind 的实验结果。

更值得注意的是，ClariNet 还是语音合成领域第一个完全端到端的系统，可以通过单个神经网络，直接将文本转换为原始的音频波形。先前为业界所熟知的「端到端」语音合成系统（比如 Google 提出的 [Tacotron](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650734959%26idx%3D4%26sn%3D2094dc7aed9c2500039e7cfa58f9b5ab%26chksm%3D871ac511b06d4c07a3fe4777ced0101935c3e31224009150739de755c9e5cd9be0607591b55e%26scene%3D21%23wechat_redirect)，百度之前提出的[Deep Voice 3](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650732316%26idx%3D4%26sn%3D18c869cd8355343c62231ab0795c95ee%26chksm%3D871b3362b06cba7427c2a7871d0a8dd7d368c04c5483ee00e828eb8621ef45937f3f4788e40c%26scene%3D21%23wechat_redirect)），实际是先将文本转换为频谱（spectrogram），然后通过波形生成模型 WaveNet 或者 Griffin-Lim 算法，将频谱转换成原始波形输出。这种方法由于文本到频谱的模型和 WaveNet 是分别训练优化的，往往导致次优的结果。而百度研究员提出的 ClariNet，则是完全打通了从文本到原始音频波形的端到端训练，实现了对整个 TTS 系统的联合优化，比起分别训练的模型，在语音合成的自然度上有大幅提升（参见 合成语音示例）。另外，ClariNet 是全卷积模型，训练速度比起基于循环神经网络（RNN）的模型要快 10 倍以上。

ClariNet 的网络结构如下图所示。它使用基于注意力机制（Attention）的编码器-解码器（Encoder-Decoder）模块来学习文本字符与频谱帧之间的对齐关系。解码器的隐状态（hidden states）被送给 Bridge-net 来进行时序信息处理和升采样（upsample）。最终 Bridge-net 的隐状态被送给音频波形生成模块（Vocoder），用来最终合成原始音频波形。
![](https://pic2.zhimg.com/v2-24c3544de2713b139b7cbfbfb72318e5_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='710' height='394'></svg>)



**论文：ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech**
![](https://pic1.zhimg.com/v2-c1ea1a1a0c0e8a4494b56290f2edeac4_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='389'></svg>)- 论文地址：[https://arxiv.org/pdf/1807.07281.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1807.07281.pdf)
- 合成语音示例：[https://clarinet-demo.github.io/](https://link.zhihu.com/?target=https%3A//clarinet-demo.github.io/)
[百度 ClariNet_腾讯视频​v.qq.com![图标](https://pic3.zhimg.com/v2-a772a2982020f0c43d39432a93d041da_180x120.jpg)](https://link.zhihu.com/?target=https%3A//v.qq.com/x/page/z1345272h9u.html)





