# 2017机器学习与自然语言处理学术全景图：多产的作者与机构 - 知乎
# 



选自marekrei

**机器之心编译**

**参与：黄小天、刘晓坤、蒋思源**

> 在这篇文章中，作者统计了来自 ACL、EMNLP、NAACL、EACL 等学术会议的信息，用可视化的方式展现了 2017 年机器学习与自然语言处理领域的学术情况，例如最高产的作者、机构、主题等。机器之心在展现这些以 NLP 为主的会议后，还增加了如计算机视觉等会议的情况。值得一提的是，该作者在 2017 年初也统计了 2016 年的信息，感兴趣的读者可查看[《2016 机器学习与自然语言处理学术全景图：卡耐基梅隆大学排名第一》](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650722085%26idx%3D1%26sn%3D14a9cc3610e0de25587a707f554939f0%26chksm%3D871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5%26scene%3D21%23wechat_redirect)。 

2017 年是自然语言处理（NLP）和机器学习（ML）非常高产的一年。两个领域持续增长，会议论文数量纷纷打破记录。本文中我将根据个人作者和组织进行更详细的细分。统计信息来自以下会议：ACL、EMNLP、NAACL、EACL、COLING、TACL、CL、CoNLL、Sem+SemEval、NIPS、ICML、ICLR。与上年不同，这次把 ICLR 包含了进来，它在过去两年飞速发展为一个很有竞争力的会议。此外，机器之心也将我们统计的会议结果添加到该报告中，并作一定的分析。

MAREK REI 的分析是通过爬虫自动抓取会议官网和 ACL 选集的发表信息而完成的，因此分析主要集中在自然语言处理。MAREK REI 表示作者姓名一般列在议程之中，因此可轻松提取；但是机构名称相对麻烦，需要从 PDF 直接抓取。而我们添加的信息主要来源于 2017 年报道过的人工智能方面的顶会，因此它正好可以补充原作者提供的信息。




**会议**

首先，让我们看看 2012-2017 年间的公开会议。NIPS 当仁不让，今年共发表 677 篇论文，排名第一。其他多数会议也快速增长，是 ICML、ICLR、EMNLP、EACL 和 CoNLL 规模最大的一年。相比之下，TACL 和 CL 的论文发表数量似乎每年保持不变。NAACL 和 COLING 的论文数量则为零，期望其在 2018 年有更好表现。
![](https://pic3.zhimg.com/v2-c4bb768829cb54f9d80bfd1a76c157ca_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='919'></svg>)
其实从接收论文的情况我们就能看出一些趋势，因为自 2015 年来 NIPS 的接收论文就有很大的提升，这与机器学习和深度学习的崛起有很大的关系。神经信息处理系统大会（Neural Information Processing Systems，NIPS）是机器学习与计算神经科学方面的顶会，本届 NIPS（31st）大会注册人数超过 8000 人；共收到 3240 篇提交论文。其中有 20.9% 被组委会接收；议程包括 679 个 Poster 演讲，40 个长演讲（Oral）, 112 个短演讲（Spotlight）。若根据 NIPS 2017 提交论文数量进行分析，最热门的三个子领域为算法、深度学习和应用，由于深度学习目前并没有一种给我们美感的完整体系，所以很可能这一领域的研究在 2018 年将会继续进行下去。
![](https://pic1.zhimg.com/v2-7d3dc1fb0c905ba49536423a159fe724_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='798' height='472'></svg>)
*NIPS 2017 的热门子领域。*




MAREK REI 更多关注的是自然语言处理与 ML 会议，而其它如 CVPR、ICCV 和 KDD 等计算机视觉顶会与数据挖掘顶会都没有涉及到。因此我们可以补充一些 2017 年的论文提交与接收情况，如下展示了 11 项顶会的论文提交与接收情况。其中除了上述的 NIPS，AAAI 和 CVPR 等大会也非常值得我们关注。
![](https://pic2.zhimg.com/v2-e365c27974383ebd3f0db9a8500e5a71_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1008' height='760'></svg>)
*AAAI、CVPR、IJCAI、ICCV、NIPS 今年的投稿数量均超过 2000，接收的论文数量均超过 600。ICLR 2017 是举办以来的第五届，去年的论文录用率接近 30%，今年达到了 40%。KDD 论文录用率 18.9%，是上图九大会议中论文录用率最低的会议。*




**作者**

2017 年最多产的个人作者是 Iryna Gurevych（达姆施塔特工业大学），共发表论文 18 篇。Lawrence Carin (杜克大学) 发表论文 16 篇，其中 10 篇被 NIPS 收录。紧随其后的是 Yue Zhang（新加坡大学）、Yoshua Bengio（蒙特利尔大学）和 Hinrich Schütze（慕尼黑大学）。
![](https://pic1.zhimg.com/v2-ef70686692251afd483c7d0fafdf9cdc_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='964'></svg>)
值得注意的是，曾撰文批评了蒙特利尔大学的新论文《Adversarial Generation of Natural Language》的 Yoav Goldberg 也有 10 篇论文被这些会议接收。他曾表明：「尽管我同意 arXiv 上短时间的发布周期比现在长时间的同行评议流程更好，但现在人们在使用 arXiv 树旗帜、占山头，规避同行评议过程，而且这个趋势已越来越显著。这种情况对于那些「强」研究组而言更是显著。目前来说，将你的成果（通常是初步的和不完整的）发在 arXiv 上没有什么实质的坏处，只有潜在的好处。」

其实目前很多作者都将论文预先发表在 arXiv 上，以上 MAREK REI 统计的接收论文情况很大程度上反映了这些学者的学术水平，只不过由于原作者重点关注自然语言处理，所以还有很多 2017 年优秀的学者与论文没有展示在统计中。

看一下 2012-2017 年的累积统计结果，Chris Dyer（DeepMind）遥遥领先，紧随之后的是 Iryna Gurevych（达姆施塔特工业大学）和 Noah A. Smith（华盛顿大学）。Lawrence Carin（杜克大学）、Zoubin Ghahramani（剑桥大学）和 Pradeep K. Ravikumar（卡内基梅隆大学）发表的论文主要在机器学习会议，而其他人则在 NLP 和机器学习之间平衡。
![](https://pic4.zhimg.com/v2-234c4faf9bb446a4146917d92b8bc0bf_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='987'></svg>)
按年份将发表论文数分开表明 Chris Dyer 在今年的发表论文数有所下降，而 Iryna Gurevych 的发表论文数有很强的上升趋势。
![](https://pic4.zhimg.com/v2-ab14d046f7745c94f75430293a6bbf1f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='932'></svg>)



**第一作者**

我们来看看第一作者的情况，第一作者通常是实现代码和运行实验的人。Ivan Vulić（剑桥大学）、Ryan Cotterell（约翰霍普金斯大学）和 Zeyuan Allen-Zhu（微软研究院）都在 2017 年以第一作者的身份发表了 6 篇论文。紧随其后的是 Henning Wachsmuth（魏玛大学）、 Tsendsuren Munkhdalai（微软 Maluuba）、李纪为（斯坦福大学）和 Simon S. Du（卡内基梅隆大学）。
![](https://pic4.zhimg.com/v2-a7003121b255a345b06c83a03272eaaf_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='957'></svg>)



如上所示，斯坦福博士李纪为在 2017 年也有非常多的接收论文，他主要的研究方向是自然语言处理（NLP）。在三年的博士生涯中，他的多篇论文被各类顶级会议接收。在四月底结束的 ICLR 2017 上，李纪为有三篇论文被大会接收，其中两篇为第一作者；而在即将于 9 月份举行的 EMNLP 2017 上，他有两篇论文被大会接收，均为第一作者（参见：[如何生物转CS，并在斯坦福大学三年拿到PhD：独家专访李纪为博士](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s/mwjMfAF7gLqd3P-lCc315A)）。

此外，由于 ICCV 等计算机视觉领域的会议没有得到统计，因此何恺明等人并没有在以上统计中展现。在 ICCV 2017 中，Facebook AI 研究员何恺明获得最佳论文奖，同时是最佳学生论文的作者之一。算上此前在 CVPR 2009、CVPR 2016 上的两篇「最佳论文」，何恺明现在已获得了四个最佳论文称号（参见：[ICCV 2017奖项公布：最大赢家何恺明获最佳论文，参与最佳学生论文](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650732316%26idx%3D1%26sn%3D9e57f25f4ca45c950ce90e769fa89f3f%26chksm%3D871b3362b06cba7434d1d0ab9130427a508183bc45b3cb2c8e6c4d4696cc5ad6a8384596afaa%26scene%3D21%23wechat_redirect)）。




**机构组织**

看一下 2017 年的不同机构组织的发表模式，卡内基梅隆发表了 126 篇论文，处于领先地位，而微软、谷歌和斯坦福紧随其后。包括 MIT、哥伦比亚、牛津、哈佛、多伦多、普林斯顿和苏黎世在内的大学发表的论文中，相比 NLP，机器学习占比例更大。相比之下，包括爱丁堡、IBM、北京、华盛顿、约翰霍普金斯、宾州、中科院、达姆施塔特、卡塔尔在内的大学和机构更关注 NLP 会议。
![](https://pic1.zhimg.com/v2-eaabdbbc67d1e4252361d7942e3cec68_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='978'></svg>)
如上在 2017 年的大会接收论文中，清华大学和北京大学分别以 38、37 篇接收论文取得了非常好的成绩，中国科学院在 2017 在这些大会中也有 22 篇接收论文。

看一下 2012-2017 年的整段时期，卡内基梅隆依然是其中的佼佼者，而微软、谷歌和斯坦福紧随其后。
![](https://pic4.zhimg.com/v2-fd69e5d5803fdf5f80505b3be5ebf1c3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='899' height='867'></svg>)
在这些会议历年的累积接收论文中，北京大学、清华大学、中国科学院和哈尔滨工业大学都有非常好的排名。但这这些会议偏重于自然语言处理，因此国内还有其他一些非常优秀的学府没有统计并展示在内。

看看下方的时间序列，卡内基梅隆、斯坦福和 MIT 在发表论文数上呈上升趋势。相比之下，行业领袖谷歌、微软和 IBM 的发表论文数略微有所下降。
![](https://pic2.zhimg.com/v2-6583b773f7f3fdc9bc051e402e56d85d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='932'></svg>)
**主题聚类**

最后，我对所有发表过 9 篇或以上论文的作者的论文文本进行了 LDA 分析，并用 tsne 将结果可视化。图中间是机器学习、神经网络和对抗学习的主题。最密集的聚类涵盖了强化学习和不同的学习策略。图左的聚类包含 NLP 应用、语言建模、文本解析和机器翻译。图底的聚类包含信息建模和特征空间。
![](https://pic1.zhimg.com/v2-18cc987d5f379a82f1208b6d90722318_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='73' height='24'></svg>)





![](https://pic3.zhimg.com/v2-55192dacdc395bad0daf68a8145321f6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='871' height='473'></svg>)






*原文链接：[http://www.marekrei.com/blog/ml-nlp-publications-in-2017/](https://link.zhihu.com/?target=http%3A//www.marekrei.com/blog/ml-nlp-publications-in-2017/)*




