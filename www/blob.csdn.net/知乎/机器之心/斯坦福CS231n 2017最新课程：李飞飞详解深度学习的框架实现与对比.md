# 斯坦福CS231n 2017最新课程：李飞飞详解深度学习的框架实现与对比 - 知乎
# 



斯坦福大学的课程 CS231n (Convolutional Neural Networks for Visual Recognition) 作为深度学习和计算机视觉方面的重要基础课程，在学界广受推崇。今年 4 月，CS231n 再度开课，全新的 CS231n Spring 2017 仍旧由李飞飞带头，带来了很多新鲜的内容。今天机器之心给大家分享的是其中的第八讲——深度学习软件（Deep Learning Software）。主要内容有：CPU 和 GPU 的对比；深度学习框架简介；TensorFlow 和 PyTorch 的实例；以及各种深度学习框架的比较。

**一、 CPU 和 GPU**

 CPU：核芯的数量更少；

    但是每一个核芯的速度更快，性能更强；

    更适用于处理连续性（sequential）任务。

 GPU：核芯的数量更多；

     但是每一个核芯的处理速度较慢；

     更适用于并行（parallel）任务。
![](https://pic2.zhimg.com/v2-8f718d0b7fdea53bbca376ded59c5885_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='716' height='468'></svg>)

**二、深度学习框架简介**

去年我们还仅有 Caffe、Torch、Theano 和 TensorFlow 这些深度学习框架可供使用；但是到了今年，在此基础上我们又新增加了 Caffe2、Pytorch、TensorFlow、PaddlePaddle、 CNTK、MXNet 等等一系列新的框架，可谓「百花齐放」。如今最常用的框架当数 Pytorch 和 TensorFlow 了, 而 Caffe 和 Caffe2 次之。
![](https://pic4.zhimg.com/v2-aec45e2214e34c825aa75b561c88fc73_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='523' height='280'></svg>)

深度学习框架的关键点在于：

（1）易于建造大型的计算机图形；

（2）易于在计算机图形中进行梯度计算；

（3）能在 GPU 上高效运行（cuDNN, cuBLA 等）

**三、TensorFlow 简单实例**

下面我们将详细说明一个在 TensorFlow 下训练神经网络的简单实例：即用随机数据训练一个两层的网络，激活函数为 ReLU。

**a. 定义计算机图形**
![](https://pic1.zhimg.com/v2-ec2f3b2e22c3a00cf195d9eaeb2b166c_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='868' height='399'></svg>)

1. 为输入 x，权重系数 w1、w2, 和目标函数 y 创建 placeholder：
![](https://pic3.zhimg.com/v2-3b418fe02f5e187a9d7c69dc99c661d6_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='708' height='145'></svg>)

2. 定义前向传输：这是为了计算 y 的预测值和误差损失（loss）；实际上这里是没有计算过程的——仅仅是为了创建图形！![](https://pic3.zhimg.com/v2-455757ebd410ef11276e4f34b06a99f6_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='863' height='131'></svg>)


3. 告诉 Tensorflow 去计算关于 w1 和 w2 的梯度损失；这里仍然不产生计算过程——仅仅是为了创建图形。![](https://pic2.zhimg.com/v2-45a16d9cbee0e3ec7706052470b85b2d_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='796' height='68'></svg>)


**b. 运行**

现在已经完成了创建图形的步骤，所以我们进入对图形进行运算的部分。![](https://pic2.zhimg.com/v2-196e25b0bb7e5e0db3999631d35f868d_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='823' height='274'></svg>)


创建 Numpy 数组，这个数组将会被填进上方的 placeholder 中。![](https://pic3.zhimg.com/v2-ea0762fac2eef3348eb54f135f43fd96_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='788' height='132'></svg>)


对图形进行运算：将 x、y、w1、w2 输入到 numpy 数组中；得到关于损失（loss），w1 梯度和 w2 梯度的 numpy 数组。![](https://pic4.zhimg.com/v2-050aeede88cba54362d35a968143d377_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='847' height='122'></svg>)


训练网络：反复对图形进行运算，用梯度（gradient）来更新权重（weights）。![](https://pic1.zhimg.com/v2-904977c1ba932539f82540a53b6c0268_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='713' height='192'></svg>)


把 w1 和 w2 的相应函数从 placeholder() 改为 Variable()。![](https://pic4.zhimg.com/v2-dca0115d5e700f87e96bc9868f53477b_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='695' height='81'></svg>)


添加 assign 操作来更新 w1 和 w2（图形的一部分）。![](https://pic3.zhimg.com/v2-f5fb926c16115608f14e2c563f4bffde_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='809' height='112'></svg>)


对图形进行一次运算来初始化 w1 和 w2，然后进行多次迭代训练。![](https://pic1.zhimg.com/v2-715b227efe281bbebdd65a7c039354c8_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='897' height='210'></svg>)


完整代码如下：![](https://pic1.zhimg.com/v2-68a8992bd21819f6689b19666d820a2c_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='895' height='718'></svg>)


但是产生一个问题：误差损失（loss）并没有下降！这是因为 Assign 指令实际上并没有被执行。![](https://pic1.zhimg.com/v2-7ff9359f7158dba88184e40220c690a4_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='397' height='275'></svg>)


这时我们就需要添加虚拟图形节点，并且告诉图形去计算虚拟节点。![](https://pic3.zhimg.com/v2-4922ac3bd1012992cf82d258dbf6167a_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='792' height='714'></svg>)


可以使用 optimizer 来计算梯度和更新权重系数；记得要执行 optimizer 的输出！![](https://pic4.zhimg.com/v2-beeeaadf057be008517e63031cc8027b_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='844' height='379'></svg>)


使用预先定义的常用损失函数：![](https://pic4.zhimg.com/v2-d4705541063c84c682d7ee3c1d216397_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='943' height='403'></svg>)


使用 Xavier 进行初始化；tf.layer 会自动设置权重系数（weight）和偏置项（bias）！![](https://pic3.zhimg.com/v2-7fb1b75ba7dcc94b400082c3b08f6d2a_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='937' height='711'></svg>)


**c. 高级 Wrapper——Keras**

Keras 可以理解为是一个在 TensorFlow 顶部的 layer，它可以让一些工作变得更加简单（也支持 Theano 后端）。![](https://pic2.zhimg.com/v2-f4ca08ec6a7da31a24f63365e5faeb99_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='545' height='460'></svg>)


把模型目标定义成一系列的 layer :![](https://pic2.zhimg.com/v2-dfc440d0892ac73f1024ac0008ae5061_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='521' height='115'></svg>)


定义优化器目标（optimizer object）：![](https://pic3.zhimg.com/v2-a593284418e83e1a22005259f76d62f6_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='520' height='39'></svg>)


创建模型，明确规定损失函数（loss function）:![](https://pic3.zhimg.com/v2-19381a493f15fa634018f19773facde6_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='517' height='59'></svg>)


仅用一行代码就能训练模型！![](https://pic2.zhimg.com/v2-7dfcba38c08e064406d9ee83b612bbcd_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='518' height='58'></svg>)


除了 Keras, 还有一些其他类型的高级容器（Wrapper）可供使用:![](https://pic2.zhimg.com/v2-05ebf796c35368afbdbdd0dc3c9ea385_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='830' height='412'></svg>)


**四、PyTorch 实例**

PyTorch 是 Facebook 推出的深度学习框架，不论是在工业界还是学术界，它都得到了广泛的应用。它包括三个等级的抽象概念：
- 张量（Tensor）：命令式的多维数组对象（ndarray），在 GPU 上运行；
- 变量（Varaible）：计算型图形（computational graph）的节点；用于存储数据和梯度（gradient）
- 模块（Module）：代表一个神经网络层；可以存储状态（state）, 也可以存储可学习的权重系数（learnable weights）

PyTorch 和 TensorFlow 中抽象概念的等价对应关系：![](https://pic4.zhimg.com/v2-8e799a89bc533864e936b8871130be0b_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='757' height='189'></svg>)

a. Pytorch 中的张量（Tensor）设置

PyTorch 中的张量就像 numpy 中的数组，但是这些张量可以在 GPU 上运行；

这里我们用 PyTorch 的张量设置了一个两层网络：![](https://pic4.zhimg.com/v2-7ed50775c04ef9a3896183ffda11e923_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='422' height='544'></svg>)


下面我们来分步解读：

1. 为数据和权重（weights）创建随机张量：![](https://pic3.zhimg.com/v2-a7fb307f70f16e75c2916ca37c2e6c5e_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='372' height='110'></svg>)


2. 设置前向传播：计算预测值（prediction）和损失（loss）：![](https://pic2.zhimg.com/v2-74c547028968dfbb5c98b1430249c895_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='371' height='76'></svg>)


3. 设置反向传播：计算梯度（gradients）：![](https://pic3.zhimg.com/v2-1eec48a301f37bfa5dac58fe43a099de_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='371' height='125'></svg>)


4. 梯度下降（Gradient descent）和权重（weights）相对应：![](https://pic3.zhimg.com/v2-30912ced327f4d226ce7111fc8a3aa86_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='369' height='60'></svg>)


5. 为了在 GPU 上运行，将张量（tensors）设置为 cuda 数据类型：![](https://pic2.zhimg.com/v2-495bf5a3c0f6b2a50aca8bca311f49a1_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='369' height='69'></svg>)


b. PyTorch 中的 Autogradient 设置

PyTorch 的张量（Tensors）和变量（Variables）拥有相同的应用编程接口 API。变量（Variables）可以记忆它们是怎么产生的（因为反向传播的缘故）。![](https://pic3.zhimg.com/v2-7077fda31337f86b787f6654d85edd46_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='525' height='380'></svg>)


下面仍进行分步解读：

1. 我们不希望（损失 loss 的）梯度和数据（data）有相关性，但我们希望梯度和权重（weights）是相关的。相关设置如图： ![](https://pic4.zhimg.com/v2-35db1f7230769c64058bf3271333416f_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='522' height='105'></svg>)


2. 这里的前向传播看上去和上述张量（Tensor）的对应版本很相似，但是需要注意的是现在这里全部都是变量（variable）。![](https://pic1.zhimg.com/v2-f117dfc641bd443f781af9b864e7a48c_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='532' height='46'></svg>)


3. 计算损失函数对 w1 和 w2 的梯度（开始的时候梯度置零）：![](https://pic2.zhimg.com/v2-5645b18a76b78ab0e5fd0f06e99b272d_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='530' height='69'></svg>)


4. 让梯度和权重（weights）相对应：![](https://pic1.zhimg.com/v2-0b9cfe3188bf1e6e5c84f677da48cd40_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='529' height='62'></svg>)


C. 定义新型 Autograd 函数

通过张量的前向和反向传播来定义你自己的 autograd 函数：![](https://pic2.zhimg.com/v2-159d9fba4f1040237fc8f1f776c6a961_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='521' height='296'></svg>)


可以在前向传播中使用新的 autograd 函数：![](https://pic2.zhimg.com/v2-20cdad1fc21f6eb65ce60f99f2fcdbd1_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='541' height='366'></svg>)


d. PyTorch 中的神经网络（nn）设置

用更高级的「容器」（wrapper）来处理神经网络（neural nets）, 和 Keras 相似。完整代码如下：![](https://pic3.zhimg.com/v2-efe64f9e99e11ffa7b2c5401534d755e_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='553' height='460'></svg>)


下面进行分步解读：

把我们的模型定义成一系列的 layers：![](https://pic1.zhimg.com/v2-99c8676e08debbae3301b863a1421c5c_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='518' height='86'></svg>)


也要定义常用损失函数：![](https://pic4.zhimg.com/v2-5bd50034a6fb895495550c9fadfeb0db_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='523' height='27'></svg>)


前向传播：给模型输入数据；给损失函数（loss function）输入预测信息（prediction）：![](https://pic2.zhimg.com/v2-58f523dc0e5e28a56a2410f774a8cf29_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='516' height='63'></svg>)


反向传播：计算所有的梯度（gradients）：![](https://pic4.zhimg.com/v2-2026be02f480fc34b291fec85d57be83_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='521' height='51'></svg>)


让梯度和每一个模型参数对应：![](https://pic2.zhimg.com/v2-a973169d7a2e7788dba2da0bf0b82e41_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='528' height='49'></svg>)


下面我们添加一个优化器（optimizer）:![](https://pic3.zhimg.com/v2-89ac530457ccb8ce4b0f7b3f584bdaf6_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='442' height='204'></svg>)


在计算完梯度以后对所有的参数（parameters）进行更新：![](https://pic4.zhimg.com/v2-1b5138cdb19ec32082b33b346543a21b_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='282' height='163'></svg>)


E. PyTorch 中的神经网络——定义新的模型

Pytorch 中的模块（Module）其实是一个神经网络层（neural net layer），需要注意它的输入和输出都是变量；模块（Module）中包含着权重 (当作变量处理) 或者其他模块；你可以使用 autograd 来定义你自己的模块。详细代码如下：![](https://pic4.zhimg.com/v2-f31765479a48324abe7f2c7b3bfeecaf_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='474' height='511'></svg>)


下面进行分步解读：

1. 把我们的整体模型定义成一个单一的模块：![](https://pic1.zhimg.com/v2-377de6f5ded6cbba7151b013e941aa60_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='473' height='199'></svg>)


2. 用初始化程序来设置两个子模块（一个父模块可以包含子模块）![](https://pic4.zhimg.com/v2-eebfc84e3dd80b5e4cfc394bce94102b_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='438' height='154'></svg>)


3. 用子模块和变量上的 autograd ops 定义前向传播；不需要定义反向传播——因为 autograd 会作相应处理：![](https://pic2.zhimg.com/v2-70dc305195b5c0871a32eddbbd9eaf7d_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='358' height='71'></svg>)


4. 创建并训练一个模型实例：![](https://pic1.zhimg.com/v2-76d6ba969e27d1da20f78d8f35f135ec_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='482' height='196'></svg>)


E. PyTorch 中的资料存储器（Dataloaders）

资料存储器（DataLoader）包括一个数据集 (Dataset)，而且给你提供了小批量处理（minibatching），「洗牌」处理（shuffling）和多线程处理（multithreading）；当你需要载入自定义数据（custom data）时，写下你自己的数据集类型（dataset class）就可以了。![](https://pic2.zhimg.com/v2-aca7f0adb394b5a8fe980e29be672131_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='475' height='411'></svg>)


通过遍历存储器（loader）来形成小批量（minibatch）；存储器会给你提供张量（Tensors）, 所以你需要将其「打包」（wrap）进变量中：![](https://pic3.zhimg.com/v2-0f8c094da1be313ed00e2af7ca8a937e_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='436' height='54'></svg>)


注意：使用带有 torchvision 的预先训练好的模型（pretrained model）将会更加简单易行。

F. Torch 和 pytorch 的简单对比![](https://pic4.zhimg.com/v2-def1f4eb13f8e7cf43ae3088cba26d4f_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='878' height='362'></svg>)


结论：尽量使用 PyTorch 来做你的新项目。

**五、Caffe2 简介**
![](https://pic2.zhimg.com/v2-157c9a89decc526a1992d19c685062ed_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='835' height='246'></svg>)

**六、深度学习框架之争，究竟谁更胜一筹？**

![](https://pic2.zhimg.com/v2-39f356398cfbb1eb4fdcdaa715ac3b51_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1070' height='517'></svg>)![](https://pic4.zhimg.com/v2-6c0a5973b8b3cd4a29ba7525d426a4db_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1132' height='531'></svg>)![](https://pic2.zhimg.com/v2-5b9426d929b55536a52510eb0e2e2f09_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1103' height='534'></svg>)
其实具体选择何种框架来进行深度学习取决于我们要做什么。在参阅相关文献之后，我们大致可以得出以下结论（仅供参考）：
- PyTorch 和 Torch 更适用于学术研究（research）；TensorFlow，Caffe，Caffe2 则更适用于工业界的生产环境部署（industrial production）。
- Caffe 适用于处理静态图（static graph）；Torch 和 PyTorch 更适用于动态图（dynamic graph）；而 TensorFlow 在两种情况下都很实用。
- Tensorflow 和 Caffe2 可在移动端使用。  

附主要参考文献CS231n_2017_Lecture8，链接可直接下载PPT：
[http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf](https://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf)
其他参考资料：
[http://203.187.160.132:9011/dl.ee.cuhk.edu.hk/c3pr90ntc0td/slides/tutorial-caffe.pdf](https://link.zhihu.com/?target=http%3A//203.187.160.132%3A9011/dl.ee.cuhk.edu.hk/c3pr90ntc0td/slides/tutorial-caffe.pdf)
[http://203.187.160.132:9011/dl.ee.cuhk.edu.hk/c3pr90ntc0td/slides/DL_in_Action.pdf](https://link.zhihu.com/?target=http%3A//203.187.160.132%3A9011/dl.ee.cuhk.edu.hk/c3pr90ntc0td/slides/DL_in_Action.pdf)
**机器之心整理**


