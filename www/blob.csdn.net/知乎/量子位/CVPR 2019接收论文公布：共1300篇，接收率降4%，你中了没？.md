# CVPR 2019接收论文公布：共1300篇，接收率降4%，你中了没？ - 知乎
# 



> 铜灵 发自 凹非寺
量子位 出品 | 公众号 QbitAI

这一天终于来了。

昨天，一年一度的视觉顶会CVPR放出了今年的接收论文。翘首以盼多日的CV er纷纷前来围观，场面一下子好生热闹。

官网数据显示，本届CVPR大会共收到5265篇有效投稿，共接收论文1300篇，接收率为25.2%。

目前放出的只有接收论文的ID，组委会表示，Oral、Spotlight和Poster论文的评审结果改日再放。

接收**论文编号**在此，来看看你的论文ID在不在里面：

[http://cvpr2019.thecvf.com/files/cvpr_2019_final_accept_list.txt](https://link.zhihu.com/?target=http%3A//cvpr2019.thecvf.com/files/cvpr_2019_final_accept_list.txt)

## **人气连年上升**

Github用户t-taniai统计了从2019年来CVPR的接收数据，可以窥见CVPR 2019的接收趋势。

数据中可看出，CVPR 2019的人气值从2011年起逐年上涨，提交论文数只增不减。

并且，今年的增长数量尤其多，从2018年的3359篇有效提交论文直接涨到5265篇，**提交数量增加了56%**。
![](https://pic4.zhimg.com/v2-5a0191b3ac155fa0de443d9cfe53be87_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='612' height='596'></svg>)
可能也和申请人数的激增有关，CVPR论文**接收率从去年的29.1%直接降至25.15%**，成为史上接收率下降最严重的一年。

那么，论文的ID与接收结果的关系如何，早早提交论文会不会“中奖”几率要大一些？

那倒没有。推特用户Abhishek Das‏统计了今年接收论文的ID，结果发现，ID编号与接收关系不大，每个区间的论文数量相差不大。
![](https://pic2.zhimg.com/v2-3e318bb5eb4f34aacd6590ab521ab639_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='1076'></svg>)
作为视觉领域的国际顶会，CVPR 2019的一举一动都牵动着CV er的心。

今年的CVPR将于6月16-6月20日在美国加州长滩市举办，为期5天。

CVPR大会目前还未放出议程，官网显示Demo的接收日期截止到3月31日，4月15日公布接收Demo，6月18-20号演示Demo。

## **部分接收论文**

结果放出后，投中的网友热情晒出了自己团队的接收论文表示庆祝，其中不乏有我们平日经常见到的熟悉身影。量子位收集了部分论文，好研究提前看：

An Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition（模式识别国家重点实验室、中科院、中国科学院大学、中国科学技术大学）

**地址：**
[https://128.84.21.199/abs/1902.09130](https://link.zhihu.com/?target=https%3A//128.84.21.199/abs/1902.09130)

DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion（斯坦福大学，李飞飞夫妇参与）

**地址：**
[https://arxiv.org/abs/1901.04780](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.04780)

EELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation（RWTH Aachen University，谷歌）

**地址：**
[https://128.84.21.199/abs/1902.09513](https://link.zhihu.com/?target=https%3A//128.84.21.199/abs/1902.09513)

Attention-guided Unified Network for Panoptic Segmentation（中国科学院大学）

**地址：**
[https://arxiv.org/abs/1812.03904](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1812.03904)

Deep High-Resolution Representation Learning for Human Pose Estimation（中国科学技术大学、微软亚洲研究院）

**地址：**
[https://128.84.21.199/abs/1902.09212](https://link.zhihu.com/?target=https%3A//128.84.21.199/abs/1902.09212)

Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation（杭州科技大学、悉尼科技大学等）

**地址：**
[https://arxiv.org/abs/1809.09478](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1809.09478)

InverseRenderNet: Learning single image inverse rendering（约克大学）

**地址：**
[https://arxiv.org/abs/1811.12328](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.12328)

Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation（加州大学，微软研究院，杜克大学）

**地址：**
[https://arxiv.org/abs/1811.10092](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.10092)

GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction（伦敦帝国理工学院等）

**地址：**
[https://arxiv.org/abs/1902.05978](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1902.05978)

Variational Bayesian Dropout（武汉大学，阿德莱德大学）

**地址：**
[https://arxiv.org/abs/1811.07533](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.07533)

LiFF: Light Field Features in Scale and Depth（斯坦福大学，悉尼大学）

**地址：**
[https://arxiv.org/abs/1901.03916](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1901.03916)

Classification-Reconstruction Learning for Open-Set Recognition（东京大学、Data61-CSIRO、澳大利亚国立大学）

**地址：**
[https://arxiv.org/abs/1812.04246](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1812.04246)

Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition with Multimodal Training（Rutgers University、微软等）

**地址：**
[https://arxiv.org/abs/1812.06145](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1812.06145)

如果你的论文也被接收了，**欢迎在评论区留下论文介绍与地址**，等你来！

## **传送门**

CVPR2019官网首页：

[CVPR2019​cvpr2019.thecvf.com![图标](https://pic1.zhimg.com/v2-f82aa4baf7b4ac62476de9c1eefb90cc_180x120.jpg)](https://link.zhihu.com/?target=http%3A//cvpr2019.thecvf.com/)
CVPR各种统计数据：

[A List of Computer Vision and Image Processing Conferences​taniai.space](https://link.zhihu.com/?target=https%3A//taniai.space/cvconf/)
接收论文ID趋势统计：

[https://twitter.com/abhshkdz/status/1099855206744051712​twitter.com](https://link.zhihu.com/?target=https%3A//twitter.com/abhshkdz/status/1099855206744051712)
接收论文编号地址：

[http://cvpr2019.thecvf.com/files/cvpr_2019_final_accept_list.txt​cvpr2019.thecvf.com](https://link.zhihu.com/?target=http%3A//cvpr2019.thecvf.com/files/cvpr_2019_final_accept_list.txt)
— **完** —

量子位 · QbitAI

վ'ᴗ' ի 追踪AI技术和产品新动态

戳右上角「+关注」获取最新资讯↗↗

如果喜欢，请分享or点赞吧~比心❤


