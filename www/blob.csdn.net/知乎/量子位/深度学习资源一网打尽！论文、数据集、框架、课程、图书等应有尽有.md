# 深度学习资源一网打尽！论文、数据集、框架、课程、图书等应有尽有 - 知乎
# 



> 乾明 发自 凹非寺
量子位 出品 | 公众号 QbitAI



![](https://pic4.zhimg.com/v2-9f7d326bb44533041c4294df18557167_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='614' height='178'></svg>)



最近，GitHub上出现一份深度学习资源，涵盖深度学习的各个方面，包括论文、数据集、课程、图书、博客、教程、框架等。

资源的贡献者说，与其他同类资源相比，这份资源更有针对性。

如果有人知道自己在找哪方面的深度学习资源，在这份资源里，可以很容易找到最相关的资源。

即使有人不知道要找什么样的资源，来到这里，也会找到最通用的资源。

这是因为他们对深度学习各方面的资源进行了细致的分类。

比如论文版块，不仅仅只是细化到各个笼统的类别，还会依据用途对论文进行分类，比如用于句子分类的卷积神经网络等等。

目前，这份资源在GitHub上已经获得1250多星。

## **资源里都有什么？**

整体来说，这份资源可以理解为是深度学习领域的hao123，一共将深度学习各方面的资源分成了7大类。具体是：

## **论文**

论文资源版块，一共分成3个类别，分别是模型、核心和应用。



![](https://pic4.zhimg.com/v2-2fcc038753ac3db83302aa0950e47da7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='770' height='949'></svg>)



在每个类别之下，又进行了两次细化分类。以模型分类为例：


在模型分类中，细化到卷积网络、循环网络、自编码器、生成模型和概率模型。在每个模型下面会根据模型的用途进行分类，来给出相关的论文。



![](https://pic4.zhimg.com/v2-3ef404e7d70993a75828e5674d0d550f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1040' height='320'></svg>)



比如卷积网络，提供了关于图像分类、句子分类、视频分类、人脸识别等方面应用论文，并附上论文的链接，部分论文有相应的实现代码，还对论文进行了星级评价。




![](https://pic2.zhimg.com/v2-b0173cd69852dbcb284ba886eff53211_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='736'></svg>)



## **数据集**

数据集版块，也是3个类别，分别是图片数据集、文本与自然语言处理数据集和语音技术数据集。



![](https://pic2.zhimg.com/v2-f3f43140158c0aa3dd762288f4dfc88d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='719' height='699'></svg>)



每个方向，也会再进一步分类，并在给出资源链接的同时，附以相应数据集的特点与用途。以图片数据集为例：

图片数据集一共被分成了4类：通用、面部识别、物体识别、行为识别。

人脸识别类别中，一共有8个数据集，分别是FERET、CMU的PIE、YouTube Faces DB、Grammatical Facial Expressions、FaceScrub、IMDB-WIKI和FDDB。都给出了介绍与数据集下载链接。



![](https://pic3.zhimg.com/v2-3697f9a3682bb368a68fea560363e392_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='402'></svg>)



## **课程、图书、博客与教程**

相比论文与数据集资源，课程、图书等方面的资源相对就少了很多。但在深度学习领域有价值的资源都被囊括在内。

**课程**

覆盖了斯坦福、CMU、谷歌、英伟达、Fast.ai等业内知名高校、企业或机构提供的课程。



![](https://pic2.zhimg.com/v2-ac3494dbdbd831ef3d836cb9d720210d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='379'></svg>)



**图书**


一共四本，分别是《深度学习》、《神经网络和深度学习》、《Python深度学习》和《Scikit-Learn与TensorFlow机器学习实用指南》，其中第一本和第四本有中文版。涵盖了深度学习的原理介绍，实现方式等。



![](https://pic2.zhimg.com/v2-917a14216a812433dd6845df03331665_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='203'></svg>)



**博客**


深度学习领域的喜欢写博客的大牛，基本上都列入在内。



![](https://pic4.zhimg.com/v2-40406a931481a7564491f578bd6d93cb_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='354'></svg>)



**教程**


包括深度学习的教程以及将深度学习应用到NLP领域的教程等。



![](https://pic2.zhimg.com/v2-4a3f9e5e773fe1d477578f4bb0e9b051_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='333'></svg>)



## **框架资源**

框架方面，一共有10个。分别是Tensorflow、Pytorch、CNTK、MatConvNet、Keras、Caffe、Theano、CuDNN、Torch、Deeplearning4j。



![](https://pic2.zhimg.com/v2-a2e81c4c88b58299df0b9192da3184e5_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='584'></svg>)



每个框架都给出了指向框架官方网站的链接，只有Torch给出的是GitHub链接。

## **谁贡献的这份资源**

这份资源的贡献者是一个致力于开源的组织Open Source for Science，其中的成员有两位小哥和一位小姐姐。



![](https://pic2.zhimg.com/v2-22111e5cb02e1977660ac06e620c68c9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='377'></svg>)



他们都与弗吉尼亚理工大学有关。两位小哥是Amirsina Torfi和Ali T Z Kasgari，弗吉尼亚理工大学的博士生；小姐姐名叫Negin Forouzesh，弗吉尼亚理工大学的博士生候选人。


## **传送门**

[https://github.com/osforscience/deep-learning-ocean#what-s-the-point-of-this-open-source-project](https://link.zhihu.com/?target=https%3A//github.com/osforscience/deep-learning-ocean%23what-s-the-point-of-this-open-source-project)

— **完** —
量子位 · QbitAI
վ'ᴗ' ի 追踪AI技术和产品新动态

[量子位​www.zhihu.com![图标](https://pic4.zhimg.com/v2-ca6e7ffc10a0d10edbae635cee82d007_ipico.jpg)](https://www.zhihu.com/org/liang-zi-wei-48)
欢迎大家关注我们，以及订阅[我们的知乎专栏](https://zhuanlan.zhihu.com/qbitai)


