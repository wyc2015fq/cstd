# 中国团队再次称雄AI大赛，微软谷歌FB都甩在身后 - 知乎
# 



> 李林 假装发自 威尼斯
量子位 出品 | 公众号 QbitAI

又一次！中国团队拿下一项AI赛事的多个大奖！

8天的计算机视觉顶会ICCV 2017在威尼斯悄然落幕，期间中国团队在物体检测、人体关键点检测等竞争激烈的比赛中击败了谷歌、微软、Facebook等国际巨头AI实验室。

ICCV 2017 “Joint COCO and Places Recognition Challenge” Workshop中，一共公布了7项竞赛的结果。

中国AI创业公司旷视科技（Face++）在**MS COCO物体检测**、**人体关键点检测**，以及**Places物体分割**三项比赛中击败微软、谷歌、Facebook等对手，夺得了第一名。



![](https://pic2.zhimg.com/v2-509a88792127b612be6aae5784d7614d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='448'></svg>)





![](https://pic1.zhimg.com/v2-15ce2fe87c1563f7f9c96d2a2d9d9020_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='480'></svg>)



**△** 旷视科技获COCO物体检测、人体关键点检测冠军；UCenter获COCO物体分割冠军

而在**MS COCO物体分割检测**中，由北京大学和香港中文大学联合组成的UCenter队（也可以理解为商汤科技队）夺得冠军，旷视科技（Face++）团队获得了第二名。

**Places场景分割挑战赛**的冠军由中科院自动化所和京东联合建立的CASIA_IVA_JD队拿下，第二名是今日头条的WinterIsComing队。



![](https://pic3.zhimg.com/v2-fc7c883e679f7ed8baaecb99dca937b6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='480'></svg>)



## 参赛选手总结

量子位还得到一份旷视Face++此次参赛主力队员的一份赛后总结。这份总结应该是出自大三学生肖特特，他还特别提到队友罗睿轩和姜博睿。转发如下：

拿奖拿到手软

终于，可以自豪地宣布，我们Face++团队在备受关注的MSCOCO和由MIT牵头的Places比赛中参与四个项目，击败Facebook, Google, Microsoft, 国内外高校和企业等，拿下三项世界冠军一项第二名。其中我作为核心成员之一参与了COCO Detection & Instance Segmentation与Places Instance Segmentation三个项目，并为COCO Skeleton做了一点点微小的贡献

关于比赛

一支团队能同事拿下那么多冠军是史无前例的。在最重要的COCO Detection中，我们赢了第二名近2个绝对百分点。在Places比赛，我们在准备不充分的情况下(我的错)，赢了第二名Google4.5个绝对百分点。为我们的队伍感到自豪。

“Face++模式”

对于我来说，赢了是团队好输了当然是自己做得不够好。这次比赛，我特别要介绍旷视的platform组。他们负责维护和建立上千块gpu的集群，支持各种功能。而我们，动辄要求几十上百块gpu跨机训练，给他们造成了前所未有的压力。但是，他们每次几乎立即处理问题，以最快的速度解决。这是我见过的最敬业，效率最高的team. 每一块奖牌后面都应该有他们的名字。

“姚班模式”

我特别想提一下，在两个Segmentation比赛中，我的两位室友，罗睿轩和姜博睿，比我做出了更大贡献。他们也是我的ACM队友。这是我一直追求的姚班模式。作为朋友，室友。大家每时每刻、自发地讨论学术问题，取得比赛好成绩，或者一起发表论文。很高兴我在身体力行，为这个模式做了一些微小的贡献。感谢室友的不杀之恩，因为我实在太push了…把人从床里拖出来review代码这事发生了不止一次。比赛结束前每天熬夜到三四点，第二天接着干。很不容易，Good job!

关于ICCV

第一次在国际会议做Presentation, 居然上台后一点都不紧张。我要了一个手持麦克风，借了个遥控器，成为了唯一一个不在讲台后讲slides的人 XD. 被偶像级前辈Ross Girshick夸报告讲得非常好，真的特别开心。

关于research

准备今年的CVPR和明年ECCV submissions. 手里攒了不少东西。借用Kaiming的一句话”涨3个点很容易，涨3个点讲个故事也不难，最难的是想一个idea, 并且指出它能涨3个点”. 跟这些人交流得越多，我越来越知道自己应该做什么样的工作，什么样的工作是有意义的，值得尊敬的。希望在明年ECCV投稿的工作中，能看到自己一点点往这个方向的努力。

有趣的事情
- 与Ross和Kaiming聊了一会，我表达了对两位role models的敬佩，讲我一直在向各位学习。Ross大神说你明年要是能来FAIR实习就太好了。我们没准还能向你学习呢。脑子一下空白了…回答，现在不够格和各位一起工作，phd时一定一定会申你的intern :)
- 三年级本科生的身份倒是能让大家迅速记住你 23333 真的比平均年龄小了太多。。
- 感谢NVIDIA送了一块TITAN XP。以为还是之前的一万美元呢哈哈

（插播，此处的Ross和Kaiming，可以参考量子位之前的报道）

另外，据商汤科技透露他们的队伍也是实习生担任主力。

## 历史战绩

物体检测这个项目，是MS COCO大赛的重头戏，从2015年第一届就存在，第二、三届中依然延续了下来。

其实，拿下2015年物体检测项目冠军的MSRA团队，就是孙剑在微软亚洲研究院带领的一组研究员，包括何恺明、任少卿、代季峰和Xiangyu Zhang，所用的算法，是何恺明和RBG大神第一次合作的Faster R-CNN。

2016年的物体检测冠军，是谷歌研究院的G-RMI队，而用的算法，依然是Faster R-CNN。

2015年第一届MS COCO大赛中除了物体检测，还有个生成图片说明（Captioning Challenge）项目，当时夺冠的谷歌团队，与人类baseline相比依然差了一大截，这个比赛项目也没能继续下去。

在2016年，物体检测之外的比赛项目变成了人体关键点检测，当时夺冠的团队来自CMU。

## COCO+Places 2017简介

MS COCO是一个已经举办了三年，在业内颇有名气的比赛。今年的MS COCO共有四个项目，包括物体检测、物体分割、人体关键点检测和场景分割。

和MS COCO联合公布结果的Places今年还是第一届，由MIT和CMU牵头，包括物体分割、场景分割和边缘检测三个项目，旨在深度理解图像场景。



![](https://pic1.zhimg.com/v2-fd3a0f41f8ac4b4a0487480043bc3794_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='230'></svg>)



COCO挑战赛

COCO是一个图像数据集，被设计用来推动物体检测研究，特别是检测上下文中的物体。其中提供的注释包括80个分类的物体像素级分割，人体实例的关键点注释，91个类别的背景语义分割。

大赛具体包括：

**COCO检测挑战**

COCO 2017检测挑战赛已在推动物体检测领域的进步。参赛队伍要在两类物体检测挑战中竞争：使用包围盒（bounding box）输出或者物体分割输出。



![](https://pic1.zhimg.com/v2-7fc703381c0de2733c692870652cc970_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='755' height='153'></svg>)



**COCO关键点挑战**

这项挑战需要在复杂环境下对人体关键点进行定位。这项挑战需要在检测出人体的同时，对关键点进行定位标注。



![](https://pic3.zhimg.com/v2-15f5556b1db9f6bd549f7e26c6cfb6f2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='300'></svg>)



**COCO背景语义分割挑战**

今年的挑战中，已经给出人、汽车、大象等物体的分类，所以重点主要在背景分类的部分，例如草坪、墙壁、天空等。



![](https://pic1.zhimg.com/v2-41cf0d845d6ba888120dbf1be11b250c_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1117' height='275'></svg>)



相关详情可以访问：

//[http://cocodataset.org/](https://link.zhihu.com/?target=http%3A//cocodataset.org/)

Palces挑战赛



![](https://pic4.zhimg.com/v2-097eda97a1396d97ebc587c887a9809b_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='787' height='123'></svg>)



Places挑战的数据，是一个像素级标注的图像数据及ADE20K。这个数据集中有2万张图像用于训练，2千张用于验证，3千张用于测试。

数据集地址在此：

//[http://groups.csail.mit.edu/vision/datasets/ADE20K/](https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/datasets/ADE20K/)

Places 2017的挑战主要有三个任务：场景分割（scene parsing）、物体分割（instance segmentation）、边缘检测（semantic boundary detection）。



![](https://pic1.zhimg.com/v2-11716f5c0fd3d32001e1663186d47300_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='242'></svg>)



详细信息可以访问这里：

[//placeschallenge.csail.mit.edu/](https://link.zhihu.com/?target=//placeschallenge.csail.mit.edu/)

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai)

վ'ᴗ' ի 追踪AI技术和产品新动态


