# 英特尔研发神经元AI处理器，模仿大脑功能，无需训练数据集 - 知乎
# 



> 陈桦 问耕 编译整理
量子位 出品 | 公众号 QbitAI




刚刚，黄仁勋在北京跑步上台演讲，庄严宣布：CPU的时代结束了。

好巧，英特尔说：不单CPU不行了，GPU也不行了。

这位CPU霸主表示，随着高度动态和非结构既然数据的相关需求逐渐增加，未来计算的需求将超越经典的CPU和GPU体系结构。

那怎么办？

英特尔这么说，肯定有办法。英特尔实验室今天宣布，正在研发出代号“Loihi”的自学习神经元芯片，模仿了大脑的功能，能从环境反馈中直接学习。

所谓自学习、模仿大脑，意思是Loihi内部由128个计算核心组成，每个核心有1024个“神经元”，总计超过13万个神经元和1.3亿个突触链接，和大脑的神经元一样，它们可以调整相互之间的联系，以适应新的任务。

从神经元数量上讲，Loihi比龙虾的大脑还要复杂一点。不过与人脑相比还相去甚远，人脑由超过800亿个神经元组成。

Loihi不需要通过传统的方式进行训练，而且会随着时间的增加变得越来越智能，而且功耗极低，这款处理器使用异步脉冲方式进行计算。

“大脑内部的沟通没有想象中的频繁”，英特尔实验室资深首席工程师兼首席科学家Narayan Srinivasa表示：“这款芯片只有脉冲出现时才消耗能量”。



![](https://pic4.zhimg.com/v2-c37532b4ac972901fe07bc57fab726a3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='353'></svg>)



下面是英特尔对Loihi芯片的详细说明。

## Loihi简介

Loihi芯片包含模拟大脑基本机制的数字电路，使机器学习更快、更高效，同时降低对计算资源的需求。

神经形态芯片模型的灵感来自于神经元通信和学习的方式，利用了可根据时间调节的脉冲和塑料触突。基于模式和关联，这将帮助计算机实现自组织，做出决策。

Loihi芯片提供了非常灵活的片上学习能力，将训练和推理整合至同一块芯片上。这帮助机器实现自动化，实时调整，而无需等待来自云计算平台的下一次信息更新。

研究人员已证明，与其他典型的脉冲神经网络相比，在解决MNIST数字识别问题时，以实现一定准确率所需要的总操作数来看，Loihi芯片学习速度提高了100万倍。

与卷积神经网络和深度学习神经网络相比，Loihi芯片在同样的任务中需要更少的资源。

在优化汽车和工业应用，以及个人机器人方面，这款测试芯片的自学能力带来了巨大潜力，例如识别汽车或自行车的运动。在非结构化环境中，这些应用可以受益于自动化操作和持续学习。

此外，与通常用于训练人工智能系统的芯片相比，Loihi芯片的能效提升了1000倍。

参数
- 全异步神经形态多核心网络，支持多种稀疏、分层和循环神经网络拓扑结构。每个神经元可以与成千上万个其他神经元通信。
- 每个神经形态核心都包含一个学习引擎，在操作中可以通过编程去适配网络参数，支持监督学习、无监督学习、强化学习和其他学习范式。
- 芯片的制造采用了英特尔14纳米工艺。
- 总共提供了13万个神经元和1.3亿个触突。
- 对于多种算法的开发和测试，实现了极高的算法效率。这些算法包括路径规划、约束满足、稀疏编码、字典学习，以及动态模式学习和适配。



![](https://pic4.zhimg.com/v2-e059b7d092c4b95ef01b237afb0f9b47_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='427'></svg>)



## 下一步

英特尔表示，在计算机和算法创新的推动下，人工智能的变革性力量预计将给社会带来重大影响。这家芯片巨头正通过多种产品，解决从网络边缘到数据中心和云计算平台，人工智能计算任务的独特需求。

随着人工智能计算任务越来越多多样化，越来越复杂，研究者将关注当前主流计算架构的局限性，提出新的颠覆性方法。展望未来，英特尔认为，神经形态计算带来了一种方式，以类似大脑的结构提供超大规模的计算性能。

但英特尔不是第一家使用神经科学指导芯片设计的公司。

IBM已经构建了两代神经形态处理器，称为TrueNorth，这个芯片同样基于脉冲神经元模式。TrueNorth芯片包括4096个核心和540万个晶体管，功耗70毫瓦，模拟了一百万个神经元和2.56亿个突触，这个数字在Loihi之上。

TrueNorth相当于一个蜜蜂的大脑。

不过与英特尔的芯片不同，TrueNorth芯片无法基于输入数据进行学习。IBM的研究得到了DARPA的资助，并且与两家实验室合作，但目前也没有商业可用性的进展。

不少AI专家对神经元芯片心存疑虑。IBM在2014年发表TrueNorth的第一篇论文时，Yann LeCun就曾指出，这类芯片很难运行卷积神经网络进行图像识别计算。Srinivasa也证实Loihi在某些深度学习模型上表现不佳。

无论英特尔神经元芯片最终结果如何，这都显示出英特尔已经意识到CPU不是唯一。随着AI的重要性日益增加，英特尔正不断拥抱其他芯片。2015年，英特尔亿167亿美元收购FPGA厂商Altera。去年，英特尔4亿美元收购AI芯片商Nervana。

至于Loihi，2018年上半年，英特尔将与部分大学和研究机构分享Loihi测试芯片。不过，这款芯片有可能三五年内，都是实验性的产品。

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai)


