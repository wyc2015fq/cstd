# 从此，激光雷达和摄像头，就是一个东西了？ - 知乎
# 



> 车栗子 发自 凹非寺 
量子位 出品 | 公众号 QbitAI
![](https://pic4.zhimg.com/v2-283ef0131997958541f514f78da4230b_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='432' height='368'></svg>)
最近几年，放在**摄像头**上的深度学习研究，发展很蓬勃。相比之下， **激光雷达** (LiDAR) 身上的学术进展并不太多。

可是，激光雷达采集的数据，有很多优点。比如**空间信息**丰富，比如**光照不足**也不影响感知，等等。

当然，也有**缺点**。激光雷达数据，缺乏RGB图像的**原始分辨率**、以及高效的**阵列结构** (Array Structure) 。并且，**3D点云**很难在神经网络里**编码**。
![](https://pic2.zhimg.com/v2-cd6cee7e8595959fa77e04125db5ffbd_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='338'></svg>)
要是能把激光雷达和摄像头，**变成一台设备**就好了。

## **如何“淘汰”摄像头？**

激光雷达厂商**Ouster**，是领域内独角兽Quanergy的前联合创始人Angus Pacala，出走之后建立的新公司。
![](https://pic3.zhimg.com/v2-2305df356b3a9f01b9b1d9ae17e4aa02_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='400'></svg>)△ Ouster联合创始人兼CEO
去年11月，公司推出了**OS-1**激光雷达，想要**打破**激光雷达与摄像头之间的**界限**。

中心思想是，只要激光雷达的数据**足够好**，就算专为处理**RGB图像**而生的深度学习算法，也可以拿来用。

Pacala说，现在OS-1可以**实时输出**固定分辨率的**深度图像** (Depth Image) ，**信号图像** (Signal Image) 以及**环境图像** (Ambient Image) 。

这些任务都**不需要摄像头**的参与。
![](https://pic2.zhimg.com/v2-7f3213c9fcbcaa1c4c456296a839a6a5_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='427'></svg>)△ 高速相对运动中，容易产生果冻效应
数据层与数据层之间，是**空间相关**的。拍摄**高速运动**的物体，也不容易产生**果冻效应** (Shutter Effects) 。

另外，OS-1的**光圈**，比大多数单反相机的光圈要大，适合光照不足的场景。

团队还开发了光敏度很低的**光子计数ASIC**，在低光照的情况下采集**环境**图像。
![](https://pic4.zhimg.com/v2-dc554b428cd593c0f37f5669239498ef_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1000' height='710'></svg>)△ 自上而下：环境、强度、范围图像、点云
设备可以在**近红外**波段捕捉**信号**与**环境信息**，获得的数据，跟普通**可见光**图像差不太多。

这样，分析RGB图像用的算法，也可以处理激光雷达的数据。

小伙伴们可以用Ouster (刚刚进行了固件升级) 的**开源驱动**，把数据转换成360度的全景动态：
![](https://pic4.zhimg.com/v2-3b7c947940a7ba2b2ddee332f2041d67_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='360'></svg>)△ 动图有压缩
传感器输出的数据，**不需要预处理**，就是这样的效果。

## **数据跑一跑**

就像刚才说的，只要数据够好，就可以用那些为摄像头开发的算法，来做深度学习。

把**深度**、**强度**和**环境信息**，编码成向量。就像**RGB图像**可以编码成**红绿蓝通道**一样。

所以，OS-1的数据质量究竟怎么样？
![](https://pic3.zhimg.com/v2-3ca4f0ccdfddbfcc49a6b400e70b4e1e_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='439' height='341'></svg>)△ 数据跑得很开心
Pacala说，他们用过的算法，和激光雷达的合作都很愉快。

举个栗子，他们训练了一个**像素语义分类器**，来分辨可以行驶的道路，其他汽车，行人，以及自行车。

这里是旧金山，在英伟达GTX 1060上运行分类器，实时生成了这样的**语义分割**效果：
![](https://pic3.zhimg.com/v2-b31239e31c9db984d41c9eb6fff4480e_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='74'></svg>)△语义分割：路是路，车是车
这是团队做的第一个实现。

数据是逐像素的数据，所以能够无缝将**2D**翻译成**3D**帧，来做边框估计 (Bounding Box Estimation) 这类实时处理。

除此之外，团队还把深度、信号和周围环境**分开**，**单独**放进神经网络里去跑。

一个栗子，用了SuperPoint项目里**预训练**的神经网络，来跑**强度**和**深度**图像。

网络是在RGB图像上训练的，从来没接触过激光雷达/深度数据。初次见面，却一见如故：
![](https://pic3.zhimg.com/v2-49edf3da655e6e7c987aeb90fdec4ba2_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='160'></svg>)△ 还是语义分割，只是单独跑了强度 (上) 和深度 (下) 数据
Pacala说，**激光雷达**测距，在隧道、高速公路这样的规则几何环境里，可能不是很开心；而**视觉**测距，会在缺乏**质地**变化、缺乏**光照**的情况下，无所适从。

OS-1用**多模态**的方法，把两者结合起来，疗效就不一样。

1 + 1 > 2，这可能就是Ouster想要表达的意思。

## **还没有真正上路**

2015年年初，Angus Pacala离开Quanergy。

同年，Ouster在硅谷成立。
![](https://pic3.zhimg.com/v2-a54e8f58ecee1d02070007696e8d674a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='256'></svg>)
2017年12月，公司宣布完成**2,700万**美元A轮融资，并同时推出了售价**3,500美元**的**OS-1**。

脚步不算快，但团队也算找到了自己要走的路。图像语义分割算法展现的效果，或许就是一个初步的肯定。

不过到目前为止，并没有消息显示，Ouster与哪间车厂达成过合作。也可能是之前推出的某些产品，性能并不尽如人意。

带有摄像头属性的激光雷达，上路之后究竟会又怎样的表现，还不得而知。

单从思路来看，依然有理由期待。




Medium原文传送门：

[https://medium.com/ouster/the-camera-is-in-the-lidar-6fcf77e7dfa6](https://link.zhihu.com/?target=https%3A//medium.com/ouster/the-camera-is-in-the-lidar-6fcf77e7dfa6)

GitHub项目传送门：

[https://github.com/ouster-LIDAR](https://link.zhihu.com/?target=https%3A//github.com/ouster-LIDAR)

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai)· 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


