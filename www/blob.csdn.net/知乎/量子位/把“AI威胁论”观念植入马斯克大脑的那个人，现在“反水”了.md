# 把“AI威胁论”观念植入马斯克大脑的那个人，现在“反水”了 - 知乎
# 



唐旭 发自 凹非寺
量子位 报道 | 公众号 QbitAI

如何把一个想法植入富豪的大脑？要么来一套“盗梦空间”，要么写一本书。

Nick Bostrom（尼克·波斯特洛姆），牛津大学人类未来研究院院长、教授、哲学家，畅销书《超级智能》的作者——比尔·盖茨和马斯克都将他的书列为必读推荐，马斯克甚至出资100万英镑支持他的机构继续自己的研究。

Bostrom被认为是在很大程度上影响了马斯克对于AI态度的人。

2014年8月，刚刚读完《超级智能》的马斯克难掩内心澎拜，并在推特上第一次呼吁人们警惕人工智能的威胁，从此一发而不可收。
![](https://pic4.zhimg.com/v2-5057c3d0abfed8d694c190133e6195ef_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1224' height='492'></svg>)
**△** “我们必须对AI保持警惕。它们可能比核武器更加危险。”

在书中，Bostrom将超越人类的通用机器智能视作人类“灭亡性的威胁”（existential risk），[上周末在罗德岛的美国全国州长协会(NGA)夏季会议上](https://link.zhihu.com/?target=http%3A//m.toutiao.com/i6443228756239712781/%3Fgroup_id%3D6443223430132547841%26group_flags%3D0)，马斯克谈及人工智能时，使用的是相同的表述；除此之外，去年六月，马斯克在Code大会上曾经声称我们活在电脑模拟出来的虚拟世界中，其来源其实也是Bostrom在2003年提出的观点。

然而，在对AI的态度上，马斯克显然已经比他的“导师”更为激进，以至于最近Bostrom都坐不住了。

“几年前我写了一本探讨AI长期影响的书，给一些人留下了点印象。我想借这个机会说一句，我对此其实并没有那么悲观。”Bostrom在今年USI的演讲上说。

“我花了好多页去论述，一旦超级智能实现之后，哪些糟糕的事情将可能会发生——但那是因为对于写一本书来言，将细节、纹理描绘出来更为重要，这样才能让人们看清其中的隐患在哪并更好地避开它们。”

“但花了这么多篇幅描绘悲观的一面，并不意味着我认为这种悲观的情况是更有可能发生的。”

Bostrom说出上述这番话的时间是今年的6月19日，比马斯克最近一次发出警告的时间早了近一个月。
![](https://pic1.zhimg.com/v2-32b3cd9b4a61cd3d9cdce7c546f352ac_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1280' height='720'></svg>)
他当然没听进去。事实上这也仅仅是个开始。

这不是马斯克第一次公开呼吁人们注意、警惕乃至管控AI。不管他把AI比作核武器还是恶魔，前几次，反对者们其实也就是一笑了之，毕竟这么想的也不只他一个；但这回全美国的州长面前再次重复了一遍自己的观点之后，马斯克被怼惨了。

“想象一下，你有机会告诉全美国最有权势的50位政客，自己认为需要政府立即行动的、最急迫的问题是什么。过去的这个周末马斯克就有这样的机会。结果他选择提醒这些州长对人工智能保持警惕，以免其消灭人类。”

马斯克发出警告两天之后，《MIT科技评论》在旧金山的总编辑Tom Simonite发表了一篇题为《不去解决真正的AI问题，马斯克已经被杀手机器人吓尿了》的文章，批评马斯克总在异想天开，不切实际。

一位华盛顿大学机器学习方面的教授Pedro Domingos在文中称：“我们中的许多人都在试图教会他以及其他一些像他这样的人，在AI的危险性上什么是真实的，什么是虚幻的，但显然没人能打动他。”

Yann LeCun后来也转推了这篇文章。

没完。转天，《发现》杂志干脆直接了联系了几位计算机科学和未来学领域的大牛，正面对马斯克的观点进行回应。

量子位将其中一些回应节选如下：

Oren Etzioni（华盛顿大学计算机科学教授、艾伦人工智能研究所CEO）：“伊隆·马斯克对于将AI视作人类根本存在性威胁的执拗让他心烦意乱，而他真正应该关心的问题是AI对于工作和武器系统这些东西的影响。公众真正需要的是能够说明AI积极和消极两种影响的、有价值的信息。我们需要分清科学和科幻。在科幻中，AI经常被刻画成阴谋夺取世界的坏人，但在现实中，AI只是一种工具。”

Toby Walsh（新南威尔士大学人工智能教授）：“伊隆·马斯克的言论危言耸听了。我最近对300名领先的AI研究者做了一次调查（ 论文在这儿：[https://arxiv.org/abs/1706.06906](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.06906) ），他们中的绝大部分都认为，要让机器变得和人一样聪明至少还需要50年时间。因此这不是一个需要立即注意的问题。”

“不过伊隆在一件事上说对了：我们需要政府现在就开始对AI进行管控。然而，需要开始管控的是今天我们所用的傻瓜人工智能，比如带有偏见的算法、开发“杀手机器人”的军备竞赛、科技公司对于个人、医疗数据隐私的威胁。”

李飞飞（斯坦福人工智能实验室主任）：“独立的机器价值观并不存在，机器价值观就是人类的价值观。如果人类真的担心一种技术会对未来造成的影响，AI、能源或是其它什么东西，那就让各行各业都参与到这项技术的开发和应用中来。
![](https://pic3.zhimg.com/v2-1d596809e4842db37eec0ab4e361f476_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1280' height='720'></svg>)
**△** 马斯克在NGA大会上

“不管是斯坦福、谷歌还是特斯拉，每个技术专家都有责任去开发那些‘善意’的技术，来让我们的社会变得更好。作为一名AI教育者和技术专家，我最大的愿望就是能在这个领域看到更多的多元性和内涵，不管是在AI的发展上，还是在AI观点的传播上。”

机器人领域的知名大牛、MIT计算机科学与人工智能实验室的创始主任Rodney Brooks，在接受TechCrunch采访时同样谈到了这个问题。

“有很多人都声称AI是人类存在的威胁：斯蒂芬·霍金、马丁·里斯爵士……在没有亲身在AI领域工作的情况下，这样的想法很普遍。我们能够理解，对于那些不在AI领域工作的人，要通过产品级别的东西来弄明白一些问题有多么困难。”

这就是包括伊隆在内的那些人所犯的错误。当看见一个人把某件任务完成得很好，我们能够理解这其中所需的能力——我认为，他们把机器学习当成了同样的模式。当人们看到DeepMind开发的AlphaGo接连战胜韩国和中国的冠军时，他们会想，‘哦天啊，机器太聪明了，它几乎能做任何事情！’但三周之间我就在DeepMind位于伦敦的总部，他们自己都承认，人们很容易就会对这件事产生误解。”

对于马斯克提到的监管问题，Brooks接着怼道：“如果你现在要有一个监管措施，要么它会被用到什么东西上改变一些事情，要么它根本用不到任何东西上。如果它用不到任何东西上面，你要这监管有毛用？告诉我，你到底想改变什么行为，伊隆？顺便，我们还是谈谈对特斯拉无人车的监管吧，这才是真正的问题。”
![](https://pic1.zhimg.com/v2-4f0ff0af0b8b852997003fdf9997a018_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1280' height='853'></svg>)
当然，也不是完全没人同意马斯克的看法。美军空军四星上将Paul Selva在回答关于美国国防部一道指令的相关问题时，就表达了对马斯克的支持。这道指令要求，当自动机器能够杀死敌军士兵时，人类操控者必须介入这一决策过程。将军说，在战争中，军队在恰当的位置坚守道德准则非常重要，否则我们可能会同胞放出了一群自己控制不了的机器人。

对于马斯克的观点，Selva说：“在真正看到机器人到街上杀人之前，人们都不会知道怎么应对。因为它看上去太虚无缥缈了。”

“在我看来AI就属于这种非常罕见的情况，我们需要主动、提前去监管，而不是被动地去反应。在我们需要对AI的监管进行反应时，已经太晚了。”

马斯克还是那个马斯克。无论是支持还是反对，对这些言论，他没有做出任何回应——在最近的推特上，他宣布自己刚刚拿到了政府对于在地下建造连接纽约、费城、巴尔的摩与华盛顿的超级高铁Hyperloop的口头许可。

实现之后，从纽约到华府只需要29分钟。

【完】

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)


