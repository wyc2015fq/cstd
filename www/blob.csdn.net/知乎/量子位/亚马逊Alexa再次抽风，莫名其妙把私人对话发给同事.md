# 亚马逊Alexa再次抽风，莫名其妙把私人对话发给同事 - 知乎
# 



> Root 发自 凹非寺
量子位 出品 | 公众号 QbitAI
![](https://pic1.zhimg.com/v2-a79c0c7c54aa44614e690d47b0b2c750_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='720'></svg>)
> 赶紧拔插头！你们的亚马逊音箱被黑了！

两周前的一个晚上，俄勒冈波特兰一名女士Danielle接到她老公同事的电话，提醒他们赶紧关掉亚马逊音箱Echo。

这个同事说他收到了一封语音邮件，内容是她和老公的对话录音。

> 当时还以为同事在恶作剧，但当他说“你们两刚刚在聊木地板”时，我们一下就懵圈了。

细思则恐。

Danielle赶紧扯掉了屋里4个亚马逊音箱的电源，第一时间打电话给亚马逊客服质问他们怎么回事。
![](https://pic2.zhimg.com/v2-9d969b27a7c31aef4737c576c8002c7d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='825' height='510'></svg>)Danielle原本在每个屋都放了一个Echo
## **亚马逊初次回应**

事关隐私，亚马逊相当重视。马上找工程师调出Danielle音箱的log日志，试图搞清楚Alexa抽风的原因。

初步调查后，亚马逊的客服代表给Danielle回电解释说，“我们工程师看完你音箱的log之后，事情确实如你所说的一样，Alexa出现故障了。我们真的很抱歉。”

但具体啥原因也没有给个交代。

客服只是一味地在长达30分钟的电话里，说了15次“我们真的很抱歉。”

Danielle自然不能接受这样的结果。自己的隐私受到了侵犯，至少亚马逊应该给个事故发生的原因说明吧。

## **舆论发酵，亚马逊再次解释**

既然打电话给客服只能收到个道歉，那么Danielle只能转向当地电视台KIRO 7了。
![](https://pic4.zhimg.com/v2-34c6637fff8e130311473e40f1865713_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='879' height='536'></svg>)![](https://pic3.zhimg.com/v2-7fa7ccd1ff07f86e706e5ecf335ac3e2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='887' height='525'></svg>)
采访视频一放出来，亚马逊面临很大舆论压力，不得不向Kiro 7进一步解释发生这样隐私泄露事故可能的原因。

> 首先要声明的是，亚马逊没有监听用户对话。
这次隐私泄露是因为语音助手Alexa被误唤醒了，把用户的对话当成了指令，才产生了错误的操作。

亚马逊这样牵强的官方解释无法让人信服。

因为这个解释要成立的话，至少得错误识别4次。

首先Echo要先被**误唤醒**，然后用户接下来的对话还得出现类似**“发送短信”的指令**。

收到指令后，Alexa还会大声问“发给谁”。如果背景音含有和**联系人**名单中名字发音相似的词，会再次问用户“确认发给XXX？”。除非用户最后说**“确认”**，Alexa才会把信息发出去。

用过智能音箱的人都知道，这哪一步单拎出来说Alexa智障了识别错了都还在可理解可接受的范围内。但一连串事件都出错，那不是语音识别太弱鸡，就可能是还存在什么用户不知道的触发词和语音对话搜集目的。

这还不包含人也忽略掉Alexa询问的情况。两个人聊得再high，也不可能没注意到旁边音箱突然问“（你要把信息）发给谁？”吧？

亚马逊官方带盐人也承认：

> 我们也觉得出现这种情况的概率非常小，现在我们正在重新评估怎么样降低错误识别率，减少类似的事故再次发生。
![](https://pic3.zhimg.com/v2-38dfe5e752d4e0f3532c9ffc2388c476_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='679' height='389'></svg>)
## **Danielle不是个例**

绕了一大圈，Danielle还是没有得到明确的隐私泄露原因。

不过这件事被多家媒体报道之后，不少人也冒出来说，他们也遇到过类似的事情。
![](https://pic3.zhimg.com/v2-e169a7c380c6a692590fcee7c0b48eea_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='388'></svg>)
 HackerNews上有用户留言说，他就曾经收到过他朋友和女票聊天的信息。

还有人说，他朋友的同事收到过语音邮件，里面全是警笛声和尖叫声，吓得对方以为他朋友出什么事了，后来联系上才确认是他朋友在追警剧。还好是虚惊一场。

## **民间脑洞**

还有自带产品思维的用户留言说，音箱能不能来个类似手机锁屏的设计，像防止手机乱拨号那样防止音箱被聊天误触。
![](https://pic4.zhimg.com/v2-56491258bb337ae21c9075a32c90dc9f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='475'></svg>)
评论区马上就有人回，音箱顶部的静音键就起这样的功能。

Reddit上还有人扔出了黑客黑完Alexa后好心告诉亚马逊哪里有漏洞的链接，可能是在呼唤那些大隐隐于市的有良知(ethical)黑客重出江湖。
![](https://pic1.zhimg.com/v2-2cf01ed5660137a305ef63b2e7cba9dc_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='173'></svg>)
## **来自亚马逊工程师的defense**

Hacker News上Po出这个新闻才短短的11个小时内，就引发了500多条评论。有讨论要真有人监听的话，手机其实比智能音箱更容易；也有讨论其他家智能音箱也存在语音识别不准的问题。

有亚马逊的工程师看到坐不住了，站出来说出了自己的理解和看法。

> 这次事件，总的来说是Alexa错误识别了语音指令，导致错误激活了一个发送语音邮件的功能。可是很多人倾向于把这件事和NSA全民监控联系起来。亚马逊是很看重用户隐私的，不会故意开发一个窃取用户对话随意发给联系人的功能，这逻辑讲不通。
![](https://pic4.zhimg.com/v2-bf7826cab6d711b4536706d0fa194937_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='413'></svg>)
可是据外媒the guardian报道，亚马逊前年提交过一个专利（[http://t.cn/R1z3Vll](https://link.zhihu.com/?target=http%3A//t.cn/R1z3Vll)）。可以做到随时听用户对话（functionalities that involve always listening）。
![](https://pic4.zhimg.com/v2-72ee7c4da5aceb9d9d13383195b4d723_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='499'></svg>)
这个专利背后的算法，专门理解分析用户对话的内容，尤其是当对话出现喜欢或购买字眼的片段。毫无疑问，亚马逊希望用这个专利获得更细分的用户群，投放更有针对性的广告。

## **OMT**

目前家居使用Echo或谷歌Home等语音助手已经成为主流趋势。

据市场研究公司eMarketer统计，在美国，超过6千万的消费者每个月至少使用过一次智能语音助手，其中的4千万人用的亚马逊Alexa。

但这次事件之后，像Danielle一样担心自己隐私的人，再也不会给Alexa接上电源。

> 我不会再相信它了。
![](https://pic3.zhimg.com/v2-fef0d9fbad48cc3b3c5b166fd98ebbf6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='788' height='532'></svg>)Danielle接受视频采访时说，I will never trust it again.
Danielle已经联系亚马逊要退款，但官方还没有正式给出回复。

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


