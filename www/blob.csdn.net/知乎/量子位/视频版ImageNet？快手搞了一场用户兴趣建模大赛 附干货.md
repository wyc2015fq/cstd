# 视频版ImageNet？快手搞了一场用户兴趣建模大赛|附干货 - 知乎
# 



> 雷刚 发自 凹非寺
量子位 出品 | 公众号 QbitAI

千图易读，一video难读。


或许你多少有些了解，在以深度学习为核心的AI算法大杀四方，机器在理解图像、语音等方面都取得了很大的进步时，理解视频内容仍还是一件很困难的事情。

**挑战无非三方面**：

首先，**信息量大**，不是简单的词语就能概括视频的内容。

一图胜千言，仅一张图片就包含大量信息，难以用几个词来描述，更何况是短视频这种富媒体形态。

其次，**维度多**，视频是视觉听觉多模态信息融合载体。

多模态深度语义理解能让机器更深地理解短视频背后的含义，然而也面临着很多挑战，例如图像像素如何与语音波形或声谱图产生相关性。

最后，**业内始终缺乏大规模的数据集**。

更大、更具挑战性的数据集，必然会对学术界和工业界研究和实践方向的推动起着重大作用，如图像分类里的ImageNet，目标检测里的COCO，而对于短视频，一直没有大规模的数据集。

而且要解决这些问题，并非一朝一夕之努力能完成，但若从今打造一个有信服力的数据集，未来可期。

所以，快手自知：舍TA其谁。作为拥有数亿用户的短视频平台，快手不仅拥有大量的视频数据，而且拥有海量用户的视频行为数据。通过对海量用户行为的预测，来判断视频内容理解算法的优劣，不仅数据量够大，而且也足够客观。

这也是快手联合中国多媒体大会，共同发起举办**用户兴趣建模大赛**的原因。
![](https://pic4.zhimg.com/v2-e526bdf8189d6f37d8fd51939722a7f3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='720'></svg>)
## **用户兴趣建模**

顾名思义，该比赛围绕用户兴趣进行建模，核心是充分挖掘AI理解的视频内容来挖掘用户兴趣数据，使得推荐给用户的视频更加精准，最终以AUC得分高者胜。

作为主办方，快手提供了一批脱敏之后的用户点击、点赞和关注等交互行为数据，同时提供这批作品封面的视觉特征、人脸特征和文字描述特征，这些数据特征共计**3w+用户、920w+视频，以及6000w+行为数据**。

而且为了激发更多参赛者，快手还特地设置了**30w+奖金池**。3人结队，为期3个月，分为初赛和复赛，最后取前10名嘉奖，一等奖20万元，二等奖5万，三等奖3万，另外还有2个极客奖1万元和5个优胜奖各3千元，总奖金池高达31.5万元。

此外，复试排名的前30，还能在毕业前随时直通快手面试。

听起来就一颗赛艇。
![](https://pic1.zhimg.com/v2-31b0f9a4891f3a1fd8860e88c565decc_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='686'></svg>)
**△** 本次大赛提供的训练数据


具体任务中，选手要通过一个视频及用户交互行为数据集对用户兴趣进行建模，然后预测用户在另一视频数据集上的点击行为。

值得注意的是，这两个数据集的视频ID交集为空。

这使得本次大赛和以往大多数用户兴趣建模大赛有很大的区别，选手必须充分利用AI算法提供的视频理解结果，对视频内容进行提炼，从而建立两个数据集的关联点。

无论在学术界，还是工业界，这都是一个难且新的问题。
![](https://pic4.zhimg.com/v2-5d740f5e2ca8ee5e3ba903e437923eff_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='590'></svg>)
## **内容理解在快手**


不过，这样的问题在快手其实每天都在得到训练和解决。

现在整个快手平台，已经累计拥有超过50亿条视频，日活跃用户超过1.2亿，其核心产品逻辑是视频内容的个性化推荐。

一方面，这需要机器对内容的理解足够极致，从多种维度、综合利用多种技术对短视频进行分析理解，再把理解应用到推荐模型中去。
![](https://pic4.zhimg.com/v2-2c00a9b87b423c0168c6082d10bb605f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='826'></svg>)
另一方面，内容安全是悬在每家互联网公司头上的达摩克里斯之剑，在非法违规内容监测上，机器对内容的理解将大大减少审核所需的人力，原创视频的保护亦然。视频搜索、商业化也需要机器对视频的深度理解。


而上述原因，也是为什么快手愿意花费人力、拿出数据、重金激赏参赛项目的核心原因。

## **快手之脑**

在快手内部，用AI来理解视频的团队叫做**多媒体内容理解部门（Multimedia Understanding）**，简称MMU ，这个团队正在试图打造“快手之脑”。

该部门负责人李岩，也在此次比赛中，分享了部门技术建设的核心思路。
![](https://pic2.zhimg.com/v2-4109ec54cca5f713d475bce559f5aa21_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='697'></svg>)
理解视频之所以难，是因为目前AI展示的诸多能力，还停留在图像、语音等感知层面， 然而视频则是二者的叠加，所谓多模态，在此体现得最为充分，而AI在这个领域才刚刚开始起步。
此外，对高层语义的识别理解也是AI亟待解决的问题。

而解决思路方面，李岩认为，视频内容理解从大方面分为感知和推理两个阶段。

感知阶段，快手目前主要从四个维度分析理解视频内容，分别是人脸、图像、语音，和音乐。

其中，人脸信息在社交视频中占据重要地位，需要对视频中的人脸进行检测、跟踪、识别，并分析出视频中人物的年龄、性别等属性，挖掘其中的3D形状、表情等信息。

图像维度，通过分类、物体检测等算法分析场景、物体，通过图像质量分析算法对图像的主观质量进行评估，通过 OCR 分析图像中包含的文字信息等。

语音方面，不仅要识别语音，还要识别说话人，对说话人的情绪、年龄等语音属性进行信息分析。

音乐方面，则要进行音乐识别、歌声、伴奏分离、歌声美化打分等分析任务，对音乐信息进行结构化。

基于以上四个维度，来完成对视频低级语义信息的感知。
![](https://pic1.zhimg.com/v2-a8ff63cf53372a2a016a693d9c948754_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='478'></svg>)
在完成上述任务后，机器才进入到推理阶段。机器需要基于感知阶段的输出，将视频看做一个整体，进行分类、描述、检索。


此外，像人将学到的知识存到大脑一样，令机器把视频内容整理并存储到知识图谱中，也是目前快手的主要做法，这样融合感知内容和知识图谱，使得理解视频高层语义及情感成为可能。

值得一提的是，为了实现对视频内容的理解，还有一大拦路虎要克服。

## **挑战和未来**

非常直接而现实的是，当前AI技术还处于严重依赖人工标注的阶段。

这需要人类坐在电脑前，一个个画框打标签，以帮助机器更好地理解。该做法不仅成本高，效率低，而且对标注员而言非常枯燥。未来减少人类标注，或者让机器能够更智能地去理解新内容，是AI算法进化的核心方向之一 。

这也是快手发起此次用户兴趣建模大赛的核心原因之一，希望培养、吸引更多年轻力量，加入到这场AI未来变革的先锋部队之中。

在过去几年中，快手的多媒体内容理解团队拥有近百名资深算法研究员和研发工程师，大部分研发人员具有多年 BAT 工作经历，核心算法研究员拥有超过十年的研发经验。

也有清华、中科院、港科大、南京大学、上交、京都大学等国内外高校学生加入快手，实现产学研一体，打造了人才梯队培养的机制。

但李岩强调，一切还远远不够。

快手还希望找到更多有志于计算机视觉、语音识别、视频内容理解、人脸识别&3D重建等相关领域的人才。

李岩相信，快手目前拥有的数据资源，以及正在尝试的攻坚，都会是吸引人才的重要砝码。
![](https://pic3.zhimg.com/v2-2fd48bc58daeb512312d055de579928e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='759'></svg>)
## **One more thing**

最后，也附上本次兴趣建模大赛的**答辩干货**。

这次比赛Top10的答辩选手解决方案，一句话总结：一个框架、两类思路。

**一个框架**

这里说的框架并不是算法框架，而是在处理这类问题时的通⽤代码。这个框架能够使算法在处理不同数据时能够简单快速地完成验证。

框架设计的整体思路就是特征群分离，并且不同数据类型进⾏分离。特征群分离主要指的是不同的数据来源。

提取的特征进行分类，例如用户行为特征群、视觉特征群等。每个特征群又可以分为连续特征或者离散特征，例如视觉特征群可以包括连续的降维特征以及离散的视频聚类特征等。

这样做有三点好处:
- 对于新发现的特征可以快速知道适用于哪一侧的模型，方便特征扩容。
- 特征群分开，可以快速定位哪些特征对线上效果增益最大。代码与特征分离，框架一次开发，后期添加特征的成本大大降低。

下图为一个典型的框架设计图：



![](https://pic3.zhimg.com/v2-5d9c44035dda3547820dc93ba80ab542_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='650'></svg>)



总体来看，比赛的特征分为：原始特征、Embedding特征，⼿⼯特征。这些特征又可以分成连续特征和离散特征。所以一个好的框架，在设计之初就可以充分考虑到这些数据，从而在后期对这些特征进行很好的扩容。


大部分选手针对大赛提供的数据把特征分成了了若干个特征群，每个特征群对应一大类数据的输入，然后分别针对每个特征群进行特征提取。

在框架设计的时候，会把特征按照不同的类别进行划分。这样做可以尽可能复⽤代码框架。

**两大类思路**

选手的思路大致可以分为两大类，⼀个是以特征工程加模型调参为代表的传统机器学习算法。

另⼀类是以模型构造加注意力机制的深度学习算法。

特征工程主要是以第一名为代表的伏地魔团队，模型主要是第二、三名团队。

当然这两种算法在具体的实现过程中存在一定的交叉，但是不同的实现都有所侧重。



![](https://pic2.zhimg.com/v2-d0084159ffa771dcd22aa954ef1f11d9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='680'></svg>)


![](https://pic4.zhimg.com/v2-f739a72ea9debaef53fe8f0e6a3ba95f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='451'></svg>)
**△**第一名“ 伏地魔团队”的特征工程



![](https://pic2.zhimg.com/v2-ea5943f9327910eb6b60e7894348e3d1_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='666'></svg>)


![](https://pic1.zhimg.com/v2-05d1d36490f440245f1504e32710d5c4_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='998' height='906'></svg>)
**△** 第二、三名的网络结构


总体来说，特征工程需要对数据极其敏感，而且需要对快手App本身有更深入的了解，知道用户的使用习惯，并且对数据具有极强嗅觉。
设计模型最多的工作则是调整网络参数，需要对模型不同层、不同网络之间有极高的能力。深度模型可以隐式地提取数据的特征，具有很好的数据抽象能力 。

当然，如果还希望了解更多相关比赛和多媒体内容理解信息，欢迎移步快手招聘公众号。

也希望能有更多类似的数据集开放、类似的比赛举办，不管是为解决行业难题，还是实现人才培养，最终都能促进整个产学研向前进步。

嗯，一举多得，值得鼓励~

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai)· 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


