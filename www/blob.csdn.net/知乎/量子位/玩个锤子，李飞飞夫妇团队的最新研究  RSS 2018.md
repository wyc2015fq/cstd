# 玩个锤子，李飞飞夫妇团队的最新研究 | RSS 2018 - 知乎
# 



> 机械栗 发自 凹非寺 
量子位 报道 | 公众号 QbitAI

锤子是一个神奇的工具，各种画风都能驾驭。

比如，神族玩锤子是这样。
![](https://pic2.zhimg.com/v2-5919916392bd7f01db34c4ef69459409_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='500' height='376'></svg>)
兽族玩锤子是这样。
![](https://pic2.zhimg.com/v2-51aa51eca58e19f0a973d7467c2b3d45_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='407' height='285'></svg>)
人族嘛……
![](https://pic4.zhimg.com/v2-92c15bf58ef6dac578b59b96cb1e24a3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='810'></svg>)
误。

回归正片，今天来看看，机器人玩（个）锤子，且是自学成才，会有怎样的画风？

今天的机器人主角，诞生在斯坦福**李飞飞夫妇**的实验室里，拥有花样锤技，还被机器人顶会**RSS 2018**选中了。

关于锤技，先看两个小栗子。

**任务一**：把钉子敲进木盒

人类只告诉机器人这个任务，没有其他多余的指示。使用什么工具，用什么姿势完成，全靠机器人自己判断。
![](https://pic4.zhimg.com/v2-6748d4d6bfb3f67544419b1d3aa7b3f7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='308' height='183'></svg>)
它发现了桌上的一把锤子。

于是，抓起锤子的把手，把钉子敲了进去。
![](https://pic1.zhimg.com/v2-346e565b8fb4e61dc964ded34ed1dcf0_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='448' height='250'></svg>)
完成。

**任务二**：清除桌面的易拉罐

同样，人类只告诉机器人这个任务，没有其他多余的指示。使用什么工具，用什么姿势完成，全靠机器人自己判断。

于是，它又抓起了桌上的锤子。
![](https://pic2.zhimg.com/v2-45c16c05751b081e69285327f24619b5_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='448' height='249'></svg>)
同样完成。

**注意**，两个不同的任务，**握锤姿势**不一样（不一样……）
![](https://pic2.zhimg.com/v2-a67cbad4ecc3692ed7cb99ed80f69431_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='775' height='300'></svg>)
这个机智的机器人，能够根据不同的任务，决定应该如何握住手里的锤子，以及用什么方式完成指定的任务。

其实，就算是它从来**没见过**的、骨骼清奇的锤子，也是一眼就会玩。
![](https://pic3.zhimg.com/v2-706eec9f638c618e47eb2324bc13b552_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='693' height='393'></svg>)
锯都算上了，但这也只是很小的一部分。

而且，机器人脑子里的**神经网络**，是**自我监督**学习的，不需要人类传授什么秘籍。

这只为了**任务**定制抓取**姿势**的机器人，是如何修炼成仙的？

## **先审题，再行动**

从前的机器人，大多是用**保守的方式**抓取工具——抓**质心**最稳。

简单粗暴，但这并不一定**适合**它下一步要完成的操作。
![](https://pic1.zhimg.com/v2-e01bf317c4cc4aa970b04e6fd36379e4_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='416' height='255'></svg>)△ 左为两眼一抹黑，右为找得着北
毕竟，钉子要完全敲进去，易拉罐要掉下桌面去，才算**成功**。

所以，抓取的牢固程度，与适合任务的程度之间，需要一些妥协。
![](https://pic3.zhimg.com/v2-e6d4a6aa610085b969d88bc02071ee7e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='809' height='485'></svg>)
 为了让机器人，在执行任务的时候更有**针对性**，斯坦福团队制定了**四步方略**如下——

**一是**，机器人要懂得，人类**希望**的结果是什么。

**二是**，机器人要识别物体的**特征**，知道它是好用的工具。

**三是**，找到合适的**抓握方向**，才能更有效地做任务。

**四是**，去吧，皮卡丘。
![](https://pic4.zhimg.com/v2-0def9d744e0f3a7d42fdcf8d3848751f_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='416' height='256'></svg>)
 知之为知之，审题真的有用。

## **神经网络两步走，一抓取二操作**

> 机器人：
咦，任务是扫桌
咦，锤子长这样
咦，这姿势不错
咦，易拉罐没了

为了让机器人选择正确的姿势，执行特定的任务，团队设计的神经网络结构，也并非一步登天。
![](https://pic2.zhimg.com/v2-364678948622b495b93b1f3f30675e69_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='560' height='332'></svg>)
**△** TOG = 任务导向的抓取

这个名叫TOG-Net的神经网络，可以**同时训练**两个模型——

一是**抓取模型**，二是**操作模型**，对应每个任务 (锤击/扫除) 的两个阶段。

优秀的抓取姿势，是任务成功的一半。
![](https://pic2.zhimg.com/v2-76cf71d5349d0a63b2abe0929ee9f119_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='210' height='174'></svg>)
 给神经网络输入一幅图，它就会提出几种抓取姿势。

**抓取模型**会为每个姿势算出一个分数，代表抓取质量。

选择分数最高的一种姿势，给机器人去执行，并且把这个姿势发送给**操作模型**。

这样一来，系统就能根据**已经采取**的动作，来规划后面的动作。

步步为营。

## **虚拟的训练，现实的测试**

神经网络不是直接在真实世界里训练的，而是在一个名叫“**Bullet** (子弹) ”的开源物理**模拟器**里训练的。
![](https://pic2.zhimg.com/v2-2e6b458eab816059168d10e28655a09d_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='480' height='268'></svg>)
 虚拟世界里，机器人可以尝试**无数次**失败，修炼出锤子的使用技能。

虽然，团队也在思考，是不是直接进三次元修炼，也会同样有效。

模拟器可以生成大量的模拟**数据**。
![](https://pic2.zhimg.com/v2-2dd7c8ff5ff7738c04a41e9984384101_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='235'></svg>)
 比如，这样那样的锤子。大体分为三类，**T型**、**L型**、**X型**。

当然，现实更复杂，所以，**混合型**也要包含进去。

除了工具之外，**抓取姿势的数据**也非常重要，难点也在这里。

因为，姿势采样的时候，抓握的点大多集中在工具的**长边**上。许多姿势之间，距离都非常小，太相似了，多样性又不够。
![](https://pic2.zhimg.com/v2-8590df8153b8a98ae0c1311e86adba21_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='468' height='365'></svg>)△ 适用于扫除的姿势，作用点就不在长边上
于是，团队用了物体识别中，常见的**非极大抑制** (NMS) 方法，去除了一些与**高分姿势**非常相近的姿势。

这样，训练集里面的姿势**各不相同**，对训练来说更有力。
![](https://pic4.zhimg.com/v2-170d107888331b14d0476020f424c317_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='377'></svg>)
 另外，**自我监督**学习机制，会用每一次**抓取成功**和**任务成功**的标签，来指导训练过程。

当然，模拟器终究是模拟器，最后还是要把训练成果搬到**现实**里来。

三次元里，机器人的夹具，是依靠**深度摄像头**的**点云**来工作的。
![](https://pic4.zhimg.com/v2-963951c2d1f0c4383e118b438e146913_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='564' height='316'></svg>)
 像这样，稍稍超出常理的“锤子”，机器人还会给它**转体**180度，再扫掉易拉罐。

驾轻就熟。

## **成果，万变不离其宗**

其实，来这里的路上，各位已经陆陆续续看过一些测试的效果了。

不过，还是要强调，以下这些锤子，机器人在训练的时候，都没见过。
![](https://pic1.zhimg.com/v2-70a475d18578f4c943c490c86165cb78_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='697' height='472'></svg>)
**T型锤**的扫除玩法。
![](https://pic1.zhimg.com/v2-7c04c98caca7c3e94eef5e73328f079c_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='331'></svg>)
**L型锤**的敲钉玩法。
![](https://pic4.zhimg.com/v2-6aa6a37b0b6f0bbd77fc9aef5f23644b_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='564' height='328'></svg>)
**混合锤**，就是刚才那只**绿色脑袋**的奇怪物体，再出现一次。
![](https://pic4.zhimg.com/v2-963951c2d1f0c4383e118b438e146913_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='564' height='316'></svg>)△ 要打架么
隐隐感觉，机器人看到这样不科学的工具，还是有些情绪。

不过，内心戏放在一边，研究人员对AI和机器人一起做的任务，还是很满意的。

除了直观地看出，碾压了某**不知任务**的算法，数据也很硬—— 
![](https://pic4.zhimg.com/v2-91698a91cd7ac0f51e16c8300d8b23df_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='881' height='587'></svg>)
 不管锤子是T型，L型，还是奇型。

也不管任务是锤击，还是扫除。

成功率都比**忽略任务**的同行，高出许多。

## **实验室里的人类们**

这项研究的团队主要来自斯坦福计算机视觉与学习实验室（SVL Lab），包括李飞飞、Silvio Savarese，和他们的学生们。 
![](https://pic3.zhimg.com/v2-a973154f31f37349a275b3ab2718e6e2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='273' height='273'></svg>)△ 房宽
论文的第一作者房宽是斯坦福大学读博士，师从Silvio Savarese。在进入斯坦福大学之前，他在清华大学读完了本科，当时曾经在微软亚洲研究院机器学习组实习。

房宽在个人主页上透露，去年夏天，他是在Google [X] Robotics度过的；而今年暑假，他要去Google Brain实习了~

其他几位作者也都来自斯坦福大学，其中二作Yuke Zhu和Animesh Garg都是李飞飞和Savarese的学生，而Andrey Kurenkov师从Silvio和Ken Goldberg。

而最后两位作者，也就是指导这项研究老师们，你们应该都很熟悉啦。
![](https://pic3.zhimg.com/v2-d75fb6b1fe2fe60e15a1471f214a5696_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1031' height='1339'></svg>)
 一位是计算机视觉界的国民女神李飞飞：
![](https://pic1.zhimg.com/v2-37f4b6832e5efb3ea65f7c0a3afbdf48_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='270' height='270'></svg>)
 另一位，是她的丈夫，同是斯坦福大学副教授的Silvio Savarese。

不知道这张实验室全家福里，有没有你熟悉的身影：
![](https://pic3.zhimg.com/v2-5d630b6bef6b2e2302c685564080ec56_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='675'></svg>)
## **传送门**
![](https://pic3.zhimg.com/v2-38e563d5e95316e67be74eedc12a306a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='588'></svg>)
Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision
Kuan Fang, Yuke Zhu, Animesh Garg, Andrey Kurenkov, Viraj Mehta, Li Fei-Fei, Silvio Savarese

[https://arxiv.org/abs/1806.09266](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1806.09266)

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


