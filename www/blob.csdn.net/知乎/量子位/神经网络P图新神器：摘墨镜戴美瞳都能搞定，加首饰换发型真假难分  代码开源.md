# 神经网络P图新神器：摘墨镜戴美瞳都能搞定，加首饰换发型真假难分 | 代码开源 - 知乎
# 



> 乾明 安妮 发自 凹非寺
量子位 出品 | 公众号 QbitAI

城里新来了个AI修图师，可以说有求必应。

拍了一张美美的照片，但是我还不满意。想瘦脸，想按照我想要的弧线瘦脸；还想让眉毛俏皮上挑、鼻子也挺一点。



![](https://pic4.zhimg.com/v2-95d184b8b9a09803cc7c402fcea1d96f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='380' height='384'></svg>)



AI修图师，行不行？

行。

简单。把不满意的地方涂掉，接着想怎么改，就怎么简单勾勒一下线条。



![](https://pic4.zhimg.com/v2-ea037a5634764249413ccef71f9fb38f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='376' height='380'></svg>)



然后，点一下按钮。效果你看看，行不行？



![](https://pic1.zhimg.com/v2-acb8c1513053a87a4c03052bb5667a34_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='382' height='382'></svg>)



求大神帮忙：帮我P成咧嘴微笑，以及眼珠换个颜色。


行。



![](https://pic4.zhimg.com/v2-15f4655393d2a9e08bc1b3e5472013f7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='362'></svg>)



世间P图的要求不过尔尔，对于这个AI修图师来说，简直信手拈来。只要你提好需求，然后一键就能完美实现。


来个实战演示，譬如给美女加个刘海、画个眼影。也是轻轻松松快速完成。



![](https://pic2.zhimg.com/v2-1c7bbfe1d3f350200c56193085372f39_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='364'></svg>)



给小伙去掉墨镜、露出眼睛。没问题，分分钟搞定。




![](https://pic3.zhimg.com/v2-f41622fe3213cfb357b03b61eee9d77a_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='364'></svg>)



真的，这都不算难事儿。


## **加首饰、换发型、补全脸**

其实，过去我们也介绍过一些类似的神经网络P图大师。

不过这次的AI修图师，还有一些新本领。

例如，对于色彩的掌握。

可以根据要求，改变眼球的颜色，轻松告别美瞳或者红眼。



![](https://pic3.zhimg.com/v2-a954e66b90c24ffe8eb9cab3d5c4f6e2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='359'></svg>)



还能改变发型。




![](https://pic2.zhimg.com/v2-64aee8966bab27ea21910c5b6bff4195_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='363'></svg>)



甚至，给光头P上秀发，而且头发可以是不同颜色的混搭，直接生成一种挑染的风范~




![](https://pic3.zhimg.com/v2-8f417edecd2c3b0d4711b39191d0b2c2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='900' height='383'></svg>)



不仅如此，这个AI还能按照需求，定制生成搭配的首饰。


耳坠啊什么的，全都不在话下。



![](https://pic2.zhimg.com/v2-4975fc2418d13e8abaf78f47741131f1_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='1427'></svg>)



当然，以上种种还都是小儿科。


这个AI能脑补的范围可不只是一点点，而是一大片。

即便你给它这样一张图片。



![](https://pic1.zhimg.com/v2-02a7bee73579559a1718b6d666dae9ec_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='862' height='856'></svg>)



只要给出要求。




![](https://pic3.zhimg.com/v2-83045eff73d099e8cd281843493b9d66_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='540'></svg>)



AI修图师也能很好的重建出来。




![](https://pic1.zhimg.com/v2-3d49d287ffcd10889c2c941b17babe48_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='543'></svg>)



左边是脑补的结果，右边是真实的照片，对比一下，你会点赞的……

再展示一组。



![](https://pic4.zhimg.com/v2-a50d5dafe13b33821178fa1d70c135eb_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='357'></svg>)





![](https://pic1.zhimg.com/v2-421a456b88d738afd732c1fb3020c6f4_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='543'></svg>)



甚至，只给一个带颜色的简笔画，AI修图师也能生成接近原照片的结果。

你看：



![](https://pic3.zhimg.com/v2-922272efad0cdf82a6abb4c60278e6d2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='766'></svg>)



这是怎么做到的？


## **原理解读**

其实这个最新出现的AI修图大师，来自韩国电子通信研究院（ETRI）。背后是一个名叫SC-FEGAN的模型，可以分为生成器、鉴别器两大部分。



![](https://pic3.zhimg.com/v2-7ff96183756b9177ad5d78171b5949b6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='586'></svg>)



输入一张不完整的图片，加上蒙版、线稿或者颜色信息，生成器就能推断出编辑后的照片。然后，鉴别器来判断这张照片是不是P得天衣无缝。


生成器基于英伟达推出的图像修复模型U-net，一共有16个卷积层，所有卷积层都使用3x3大小的门控卷积（gated convolution）。

除了输入和输出之外，所有卷积层之后都应用英伟达在2017年提出的局部响应归一化（LRN）。

生成器中还引入了各种损失训练，包括每像素损失、感知损失、风格损失、总方差损失以及通用的GAN损失函数。

鉴别器，使用的是伊利诺伊大学厄巴纳-香槟分校（UIUC）和Adobe研究团队在2018年提出SN-PatchGAN中的架构。

使用了3x3大小的卷积核并应用了梯度惩罚损失项，并没有将ReLu函数应用到GAN损失之中。

## **数据集**

在这项研究中，训练使用的是香港中文大学汤晓鸥组收集的人脸数据集CelebA-HQ数据集。

在其中随机选择两组共29000张图像用于训练，1000张图像用于测试。

将图像统一调整为了512x512像素之后，通过自由蒙版和加州大学联合Adobe推出的面部图像生成算法GFC创建对应的草图和颜色数据。

创建颜色数据时，使用直方图均衡化来避免光反射和阴影造成的颜色污染。

然后，使用加州大学HED边沿检测器，来生成与用户输入相对应的草图数据，修改面部图像，然后平滑曲线，并擦除修改图像产生的细小边缘。

## **效果怎么样？**

研究中，与伊利诺伊大学厄巴纳-香槟分校和Adobe研究团队的网络Deepfillv1进行了对比。



![](https://pic3.zhimg.com/v2-7a4ba2ce13e4d1734cdd63061b7cd296_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1014' height='1071'></svg>)



在对人物面部进行了大面积胡抹乱画之后，Deepfillv1虽然对整体进行了复原，但是各种涂抹痕迹，以及细节处理，都远远不及新提出的SC-FEGAN。


此外，与其他的研究相比，SC-FEGAN对数据的依赖并没有那么高。

哪怕是是输入一幅完全涂抹掉的图像，也能生成一些头发丝出来。



![](https://pic2.zhimg.com/v2-688fefa5e81de2a532d396aac5538c59_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='643'></svg>)



## **传送门**

这篇论文，来自韩国电子通信研究院，作者是Youngjoo Jo和Jongyoul Park。



![](https://pic4.zhimg.com/v2-9c3c88c152fba68334b6c78f5049452f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='321'></svg>)



这项研究的模型代码，已经在GitHub上开源了，并且提供了带有图形界面的Demo，但需要下载安装。


如果你对这项研究感兴趣，请收好传送门：

SC-FEGAN: Face Editing Generative Adversarial Network with User’s Sketch and Color
[https://arxiv.org/pdf/1902.06838.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1902.06838.pdf)

GitHub项目地址：
[https://github.com/JoYoungjoo/SC-FEGAN](https://link.zhihu.com/?target=https%3A//github.com/JoYoungjoo/SC-FEGAN)

—**完**—

量子位 · QbitAI

վ'ᴗ' ի 追踪AI技术和产品新动态

戳右上角「+关注」获取最新资讯↗↗

如果喜欢，请分享or点赞吧~比心❤


