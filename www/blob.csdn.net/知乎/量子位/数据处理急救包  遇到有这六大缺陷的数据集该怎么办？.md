# 数据处理急救包 | 遇到有这六大缺陷的数据集该怎么办？ - 知乎
# 



> 原作：Julien Despois
安妮 编译自 Hackernoon
量子位 出品 | 公众号 QbitAI

不要再向你的机器学习模型里喂垃圾了！

在这篇文章中，身兼AI工程师/音乐家/围棋爱好者多职的“斜杠青年”Julien Despois给出了数据科学中需要避免的6大错误。

量子位将全文编译整理如下：
![](https://pic4.zhimg.com/v2-4fe7054dd1dd3e0eedcefc548a89b9e3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='434'></svg>)
## **简介**

身为一名数据科学工作者，你应该听说过一句话：

> 你的结果会和你的数据一样好。

很多人试图通过提升模型来弥补不太理想的数据集。这等同于你的旧车因为用了廉价汽油性能不好，但你买了一辆豪华跑车。很明显药不对症嘛！

在这篇文章中，我会讲一讲如何通过优化数据集提升模型结果，并将以图像分类任务为例进行说明，但这些tips可被应用在各种各样的数据集中。

今天的正餐，正式开始——
![](https://pic2.zhimg.com/v2-18381f54dbeddad0f7cd190ed036af71_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题一：数据集太小**

如果数据集太小，模型将没有足够样例概括可区分特征。这将使数据过拟合，从而出现训练误差（training error）低但测试误差（test error）高的情况。

**解决方案1**：

去收集更多数据吧~尝试找到更多和原始数据集来源相同的数据，如果图像很相似或者你追求的就是泛化，也可用其他来源的数据。

**小贴士**：这并非易事，需要你投入时间和经费。在开始之前，你要先分析确定需要多少额外数据。将不同大小的数据集得出的结果做比较，然后思考一下这个问题。
![](https://pic4.zhimg.com/v2-4284f5723b1b1ea3759d0159c77b3bf7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1058' height='528'></svg>)△ 数据集中数据量和错误率的关系
**解决方案2**：

通过为同一张图像创建多个细微变化的副本来扩充数据，可以让你以非常低的成本创造很多额外的图像。你可以试着裁剪、旋转或缩放图片，也可以添加噪音、模糊、改变图片颜色或遮挡部分内容。



![](https://pic4.zhimg.com/v2-bf515cd8a6322ba04133b508086299b7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='631' height='664'></svg>)△ 一张图片的各种变化
不管怎么操作吧，只需保证这些数据仍代表相同类就好了。

虽然这种操作很厉害，但仍不如收集更多原始数据效果好。
![](https://pic4.zhimg.com/v2-601cadc2ccab897378bb8979a90bdb37_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='250' height='228'></svg>)△ 处理后图像仍被分类为猫
**小贴士**：这种“扩充术”不适合所有问题，比如如果你想分类黄柠檬和绿柠檬，就不要调颜色了嘛~
![](https://pic1.zhimg.com/v2-cca54665ed2286ef7a759527f9068748_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='330'></svg>)
数据集太小的问题解决后，第二个问题来了——
![](https://pic3.zhimg.com/v2-d0bd0cc007337ae319bf8f97ffb218c6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题二：分类质量差**

这是个简单但耗时的问题，需要你浏览一遍数据集确认每个样例的标签打得对不对。

除此以外，一定为你的分类选择合适的粒度（granularity）。基于要解决的问题，来增加或减少你的分类。

比如，要识别猫，你可以用全局分类器先确定它是动物，之后再用动物分类器确定它是一只小猫。一个大型的模型能同时做到这两点，但分起类来也更加困难。
![](https://pic2.zhimg.com/v2-a5188fa8d5612676e7569bb774a6df45_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1073' height='476'></svg>)△ 小猫的分类过程![](https://pic2.zhimg.com/v2-c92c7b85ab0cceaa86ca58725bd37c4d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题三：数据集质量差**

就像前言中说的那样，数据质量差会导致结果的质量差。

可能你的数据集中有一些样例离达标真的很远，比如下面这几张图像。
![](https://pic3.zhimg.com/v2-2173a8a8f287f818cd96dde275ab2172_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='935' height='335'></svg>)△ 三张不合格的猫咪图像样例
这些图像会干扰模型的正确分类，你需要将这些图像在数据集中剔除。

虽然是个漫长枯燥的过程，但对结果的提升效果很明显。

另一个常见问题是，数据集可能是由与实际应用程序不匹配的数据组成的。如果图像来自完全不同来源，这个问题可能尤为严重。

**解决方案**：先思考一下这项技术的长期应用，因为它关系到获取生产中的数据。尝试用相同的工具查找/构建一个数据集。
![](https://pic1.zhimg.com/v2-5d6a97e0a5d4441664b598875a8d3580_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='771' height='569'></svg>)△ 使用与实际应用差别太大的数据训练模型非常不明智![](https://pic3.zhimg.com/v2-96a55965a97602bcba840131d1619eb2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题四：分类不平衡**

如果每个分类的样例数量与其他类别数量差距太大，则模型可能倾向于数量占主导地位的类，因为它会让错误率变低。

**解决方案1**：

你可以收集更多非代表性的分类。然而这通常需要花费时较多间和金钱，也可能根本不可行。

**解决方案2**：

对数据进行过采样/降采样处理。这意味着你可能需要从那些比例过多的分类中移除一些样例，也可以在比例较少的类别中进行上面提到过的样例扩充处理。
![](https://pic4.zhimg.com/v2-5ebb7b3ca4b9e17386f2245ca8bd3d9f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='700' height='339'></svg>)△ 先扩充样例不足的分类（猫咪），这将使类别的分布更平滑![](https://pic2.zhimg.com/v2-6c7b56e4bf7a725fe9007d81db7cd0ad_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题五：数据不平衡**

如果你的数据没有专门的格式，或者它的值没有在特定的范围，模型处理起来可能很困难。如果图像有特定的纵横比或像素值，得到的结果会更好。

**解决方案1**：

裁剪或拉伸数据，使其与其他样例的格式相同，如下图所示。



![](https://pic2.zhimg.com/v2-229759771ce6a8ef9d44d8a3b7ce5ad9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1038' height='329'></svg>)△ 裁剪和拉伸是改善格式的两种方法
**解决方案2**：

将数据规范化，使每个样例在相同的值范围内。



![](https://pic4.zhimg.com/v2-935b133663769862586a1cc3221f25b7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1071' height='388'></svg>)![](https://pic2.zhimg.com/v2-8362b80f3905fa6cbb43e3231a034981_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='228'></svg>)
## **问题六：没有验证或测试**

数据集被清理、扩充并打上标签后，你就需要把它们分个组了。

许多数据研究人员会将这些数据分成两组：80%用于训练，20%用于测试，这将会使发现过拟合变容易。

然而，如果你在同一个测试集上尝试多个模型，情况则有所不同。选择测试精度的最佳模型，实际上是对测试集进行过拟合处理。

**解决方案**：

将数据集分为训练、验证和测试三组，这可以保护你的测试集，防止它因为所选的模型而过拟合。那这个过程就变成了:
- 在训练集上训练模型
- 在验证集上测试它们，确保它们没有过拟合
- 选择最佳模型，并用测试集测试，看看你的模型准确性有多高。
![](https://pic2.zhimg.com/v2-889eb1d03cdcf20e1f3a649c050eb1b9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1006' height='360'></svg>)
**注意**：提醒一句，记得经常用整个数据集去训练模型，数据越多，效果越好。

## **总结**

最后，送广大数据科学工作者一句N字箴言：

> 拥有最好模型的人不是赢家，拥有最好数据的人才是。

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态




