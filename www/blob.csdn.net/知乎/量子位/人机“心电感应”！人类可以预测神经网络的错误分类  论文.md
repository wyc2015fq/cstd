# 人机“心电感应”！人类可以预测神经网络的错误分类 | 论文 - 知乎
# 



> 铜灵 发自 凹非寺
量子位 出品 | 公众号 QbitAI

对抗图像是神经网络的顽敌，比如让AI错误检测路标信息、把乌龟认成步枪，都曾是对抗图像的“恶搞”。
![](https://pic2.zhimg.com/v2-a939193fff915ef4f48c423efe222eb1_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='338'></svg>)
当千辛万苦调试的神经网络遇到了对抗图像，一场你死我活的尊严战就开始了。

或许，人类可以理解并帮助神经网络进行判断。

约翰霍普金斯大学发表的最新论文Humans can decipher adversarial images显示，**人类可以直观理解神经网络犯错的逻辑**，并预测机器的错误分类。

目前，这篇论文已经被Nature子刊Nature Communications接收。

**人机“心电感应”**

在这个项目中，研究人员向人类志愿者展示了一些对抗性图片的图集，让人类判断神经网络会将这些图片认成什么。

这个图集本来是用来检测机器学习模型用的，里面的图像包含了一些微小的、不易被机器察觉的干扰。这48张显著对抗攻击产生的图像，都曾经击败过AlexNet和Inception V3等常用图像识别模型。

人类能猜出来神经网络是怎么想的吗？

这是一项庞大的工程，研究人员找来了1800名人类志愿者参与这个项目。他们将志愿者分成了8组，包括7个200名志愿者组成的组和1个400名志愿者组成的组，共进行7组实验。

为了保证参与者之间的多样性，每一组志愿者分别负责一组实验。

实验开始前，研究人员怎么也没料到，人类的直觉与神经网络的选择竟然可以这么相似。

**实验开始**

第一关，**用多余的图像标签迷惑神经网络**。

研究人员让人类依次识别48张图像，每一张图像给出两个标签，一个是机器为该图像选择的，另一个是从其他47张图像中随机抽取的。人类需要猜测，到底哪一个才是机器给出的标签。
![](https://pic4.zhimg.com/v2-79fdd75e96d5dbdb5e141af9c2a6e99b_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='679'></svg>)
结果发现，人类选择的图片标签中有74%与机器选择的标签一致，98%的人更倾向于选择与机器相同的标签，远高于50%随机选择概率。初步实验表明，**人类的选择与机器有着惊人的普遍性**。

人类与机器的思维有多相似？研究人员继续进行了下一场实验。

第二关，**找出机器的首选与次选**。

在这场实验中，研究人员要求人类为每张图像排序。他们用AlexNet模型给每张图像的首选标签和次选标签给人类，让人类猜测哪些是神经网络的首选。
![](https://pic2.zhimg.com/v2-874476e42ddd8e695183ca655b3ba57d_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='313'></svg>)
结果依旧证明了实验一的结论，91%的选择与机器的首选一致，人类似乎真的能猜透神经网络的心。

研究人员加大难度，继续进行了第三场实验，**多向分类**。

这一次，人类志愿者需要处理的标签数量一下子从2个增加到48个：研究人员给定一张图片，让人类在48个可能的标签中挑选最符合图片内容的标签。

人类的判断与机器分类再一次重合，90%的人类与机器的首选一致。这些结果表明，人类与机器的错误分类具有一致性。

研究还在继续，难度仍在加大。

第四场实验看起来似乎有些“玄学”，判断**雪花状电视图像中是什么**。

比如下图这些类似电视没信号时出现雪花点：
![](https://pic1.zhimg.com/v2-3c7f5a120edb0e435ebf1d5d2a5bbbc8_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='228'></svg>)
你能猜出哪张里面包含一只知更鸟么？
![](https://pic2.zhimg.com/v2-f6388baf216d6ed8f1845afd87c420a9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='317'></svg>)
这些图像看起来只是色彩块的集合，让人摸不到什么规律。仔细看会发现，每张图中央都会有一块色彩密集的区域，但是也看不出是什么。
![](https://pic3.zhimg.com/v2-eaa81acec7193d6f15368f8fc1f5faa6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='316' height='326'></svg>)
但是，依然有80%的人类志愿者与机器达成一致。并且，人类为75%的图像选择的首选标签也是机器的首选图像。

此外，研究人员还进行了数字干扰实验、自然图像和局部扰动实验、3D物体实验。
![](https://pic4.zhimg.com/v2-603e266a4a253ad53af90d1dab0528bb_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='370'></svg>)
7组实验下来，研究人员断定：人类的思维直觉与机器的相似性极高，因此人类可以预测机器会不会进行错误分类，进而预测、修正机器的判断逻辑。

黑盒，看起来也没有那么不可捉摸了。

**传送门**

论文Humans can decipher adversarial images地址：

[https://www.nature.com/articles/s41467-019-08931-6#Sec1](https://link.zhihu.com/?target=https%3A//www.nature.com/articles/s41467-019-08931-6%23Sec1)

VentureBeat报道：

[https://venturebeat.com/2019/03/23/humans-can-predict-how-machines-misclassify-adversarial-images/](https://link.zhihu.com/?target=https%3A//venturebeat.com/2019/03/23/humans-can-predict-how-machines-misclassify-adversarial-images/)

— **完** —

量子位 · QbitAI

վ'ᴗ' ի 追踪AI技术和产品新动态

戳右上角「+关注」获取最新资讯↗↗

如果喜欢，请分享or点赞吧~比心❤


