# AI有了更强的想象力！DeepMind又立功了｜附两篇新论文 - 知乎
# 



陈桦 编译自 DeepMind Blog

量子位 报道 | 公众号 QbitAI

人类，可以在行动之前预想到后果，这是我们认知能力中一种强大的工具。

举例来说，当我们将玻璃杯放在桌子边缘时，我们很可能会考虑一下放得稳不稳，是否会掉下来。基于对后果的思考，我们可能会调整玻璃杯的位置，避免掉在地上打碎。

这种慎重性的思考本质上是“**想象力**”。这是一种人类独有的能力，也是日常生活中重要的工具。

如果我们希望算法实现同样的复杂行为，那么算法也必须能够“想象”，对未来进行推理。除此以外，算法必须利用这些知识构建计划。

在这个领域，我们已看到了丰富的成果，例如AlphaGo这样的程序。AlphaGo利用“内部模型”，分析每步操作会在未来带来什么样的结果，从而进行推理和计划。

这些内部模型非常强大，因为围棋是一种“完美的”环境。围棋有明确定义的规则，因此在几乎任何情况下都可以非常准确地预测结果。

然而，现实世界情况更复杂，规则没有明确定义，预期之外的结果常常会出现。即使是最聪明的人工智能系统，在这种复杂环境中展开想象都会是漫长而成本高昂的过程。

在两篇最新论文中，我们描述了一类新方法，让人工智能建立以想象力为基础的计划能力。我们还提出了一种架构，给人工智能系统提供新方式，去学习并构建计划，最大化任务效率。对于不完美模型，这些架构高效而健壮，可以利用灵活的策略去发挥想象力。

这两篇新论文是：

Imagination-Augmented Agents for Deep Reinforcement Learning

[https://arxiv.org/abs/1707.06203](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1707.06203)

Learning model-based planning from scratch

[https://arxiv.org/abs/1707.06170](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1707.06170)
![](https://pic3.zhimg.com/v2-0e074cbd7560f48ce19b363461351aca_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='606' height='406'></svg>)



## 想象力增强的人工智能系统

我们介绍的这些人工智能系统受益于“**想象编码器**”。这种神经网络可以学会提取有用信息，用于未来的决策，同时忽略不相关的信息。

这样的人工智能系统拥有许多独特之处：

**它们学会表达内部模拟结果。**这意味着它们可以利用模型，捕捉粗略的环境变化，即使这样的变化并不完美。

**它们有效地利用想象力。**它们可以利用多条想象轨迹来适配问题。此外，编码器也提高了效率。这种编码器可以从奖励之外的想象中提取额外信息。这样的想象轨迹并不一定带来最高的回报，但可能包含有用的线索。

**它们可以学习不同策略，从而构建计划。**它们可以选择继续当前的想象轨迹，或重新开始一条想象轨迹。或者说，它们可以使用不同的想象模型，而这些模型拥有不同的精确度和计算成本。这带来了广泛而高效的规划策略，而不会被局限于单一方法，导致对不完美环境的适应性受限。

## 架构的测试

我们利用多种任务去测试提出的架构，包括解谜游戏《Sokoban》，以及一款太空飞船导航游戏。这两款游戏都需要前瞻性的规划和推理，因此是测试我们人工智能系统的绝佳环境。

在《Sokoban》游戏中，人工智能系统将盒子推到目标之上。由于盒子只能向前推，因此许多操作是不可逆的（例如盒子一旦推到角落，就无法再拉出来）。

在太空飞船游戏中，人工智能系统必须按照固定次数去启动推进器，使飞船保持稳定。这样的操作需要适应不同星球的引力。因此，这是一种非线性的复杂持续控制任务。

为了限制这两种任务中的试错次数，每一关卡都用程序生成，而人工智能系统只能尝试一次。这就鼓励人工智能系统在现实环境测试之前，尝试不同的策略。
![](https://pic4.zhimg.com/v2-bed564c31e6d5c2210f3c4399859eaa3.jpg)https://www.zhihu.com/video/871687725076602880
**△** 人工智能agent在不了解规则的情况下，玩Sokoban游戏时的表现。我们在某些时间点，对agent想象的五种未来进行可视化，agent会根据这种信息决定该如何采取行动。



![](https://pic1.zhimg.com/v2-362c052772a57de0b2e6cba764c2179c_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='558'></svg>)
**△** 上图是agent在太空飞船游戏中的表现，红线是实际的轨迹，绿线和蓝线是agent“想象”的轨迹。

**对于这两种任务，想象力增强的人工智能系统表现得都比没有想象力的更好。**它们可以根据较少的经验进行学习，并且有能力处理建模环境中的不完美之处。

由于人工智能系统可以从内部模拟中提取更多知识，因此相对于传统搜索方法，例如蒙特卡洛树搜索，可以借助较少的想象步数去更好地完成任务。

当我们添加能协助构建计划的额外“管理”组件之后，人工智能系统可以更高效地学会用更少的步数解决问题。

在太空飞船任务中，人工智能系统可以分辨环境中引力的强弱，而引力的不同需要配合不同的想象步数。当人工智能系统面对多种环境模型，每种环境模型的质量和成本优势各不相同时，它可以学会做出有意义的权衡。最后，如果每步行动会导致想象的计算成本上升，那么人工智能系统就会提前想象多个连锁行为产生的后果，随后持续依赖这样的计划，而不会再次展开想象。

能够处理不完美模型，并学会如何使规划策略适应当前状态，这是重要的研究课题。

我们的两篇新论文，以及Hamrick等人此前的工作考虑了这些问题。基于模型的增强学习和规划是热门研究领域，而我们仍需要进一步分析和思考，从而带来可以规模化的解决方案，帮助人工智能系统利用想象力对未来进行推理和计划。

## OMT

昨天，DeepMind创始人兼CEO哈萨比斯，还在访谈中提到想象力以及神经科学和人工智能的融合借鉴。他说：只有了解大脑，才能开发出更强的AI。而且也发了论文~

【完】

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

量子位读者6群开启，对人工智能感兴趣的朋友，欢迎加量子位小助手的微信qbitbot2，申请入群，一起探讨AI。

想要更深一步的交流？

量子位还有自动驾驶、NLP、CV三个专业讨论群，仅接纳相应领域的一线工程师、研究人员等。

同样需要添加qbitbot2为微信好友，提交相应说明，符合条件后将被邀请入群。（审核较严，敬请谅解）

诚挚招聘

量子位正在招募编辑/记者等岗位，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。


