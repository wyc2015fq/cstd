# 新年快乐！这是份值得收藏的2017年AI与深度学习要点大全 - 知乎
# 



> 若朴 夏乙 编译自 WILDML
量子位 出品 | 公众号 QbitAI

2017已经正式离我们远去。

过去的一年里，有很多值得梳理记录的内容。博客WILDML的作者、曾在Google Brain做了一年Resident的Denny Britz，就把他眼中的2017年AI和深度学习的大事，进行了一番梳理汇总。

量子位进行概要摘录如下，详情可前往原文查看，地址：[http://www.wildml.com/2017/12/ai-and-deep-learning-in-2017-a-year-in-review/](https://link.zhihu.com/?target=http%3A//www.wildml.com/2017/12/ai-and-deep-learning-in-2017-a-year-in-review/)

## 强化学习称霸人类游戏

如果说2016年AlphaGo击败李世乭之后，大家对它的棋坛地位还有些许怀疑的话，2017年击败柯洁，让它成了毫无疑问的围棋霸主。

作为一个强化学习Agent，它的第一个版本使用了来自人类专家的训练数据，然后通过自我对局和蒙特卡洛树搜索的改进来进化。

不久之后，AlphaGo Zero更进一步，使用了之前一篇论文Thinking Fast and Slow with Deep Learning and Tree Search提出的技术，从零开始下围棋，在训练中没有用到人类对局的数据。



![](https://pic2.zhimg.com/v2-1bb3836cfa30781ac04918a466f8e7e5_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='341'></svg>)



临近年底，我们又看到了新一代的AlphaGo：AlphaZero，在围棋之后，用同样的技术搞定了国际象棋和日本将棋。

这些算法在对局中所用的策略，有时候甚至让经验丰富的棋手都觉得惊讶，他们也会向AlphaGo学习，改变着自己的对局风格。为了让学习更容易，DeepMind还发布了AlphaGo Teach工具。



![](https://pic4.zhimg.com/v2-375418ad7183344b7417352341809657_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='234'></svg>)



下面是相关论文，认真的同学们可以收藏回顾啦：

AlphaGo

[https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf](https://link.zhihu.com/?target=https%3A//storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf)

AlphaGo Zero

[https://www.nature.com/articles/nature24270.epdf](https://link.zhihu.com/?target=https%3A//www.nature.com/articles/nature24270.epdf)

AlphaZero

[https://arxiv.org/abs/1712.01815](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.01815)

Thinking Fast and Slow with Deep Learning and Tree Search

[https://arxiv.org/abs/1705.08439](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1705.08439)



![](https://pic4.zhimg.com/v2-ae4dfb282785bc44c9a41f5db6e4669f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='480'></svg>)



AI今年取得重大进展的游戏不止围棋。CMU研究人员的Libratus（冷扑大师）在20天的一对一无限注德州扑克比赛中，击败了人类顶级扑克玩家。

再早些时候，查尔斯大学、捷克技术大学和加拿大阿尔伯塔大学开发的DeepStack，首先击败了专业德扑玩家。

有一点值得注意，这两个程序玩的都是一对一扑克，也就是两名玩家之间的对局，这比多人游戏更容易。2018年，我们很可能看到算法在多玩家扑克上取得一些进步。

Libratus论文：

[http://science.sciencemag.org/content/early/2017/12/15/science.aao1733.full](https://link.zhihu.com/?target=http%3A//science.sciencemag.org/content/early/2017/12/15/science.aao1733.full)

用强化学习玩人类游戏的下一个领域，似乎是更复杂的多人游戏，除了多人扑克之外，还有星际争霸、DotA等等。DeepMind正在积极研究星际争霸2，发布了相关的研究环境。

星际争霸2研究环境：

[https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/](https://link.zhihu.com/?target=https%3A//deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/)

而OpenAI在DotA中单比赛中取得了初步的成功，玩转5v5游戏，是他们的下一步目标。

## 进化算法回归

对于监督学习来说，基于梯度的反向传播算法已经非常好，而且这一点可能短期内不会有什么改变。

然而，在强化学习中，进化策略（Evolution Strategies, ES）似乎正在东山再起。因为强化学习的数据通常不是lid（独立同分布）的，错误信号更加稀疏，而且需要探索，不依赖梯度的算法表现很好。另外，进化算法可以线性扩展到数千台机器，实现非常快的平行训练。它们不需要昂贵的GPU，但可以在成百上千便宜的CPU机器上进行训练。

2017年早些时候，OpenAI的研究人员证明了进化策略实现的性能，可以与Deep Q-Learning等标准强化学习算法相媲美。

相关论文：

[https://arxiv.org/abs/1703.03864](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.03864)

年底，Uber内部一个团队又连发5篇论文，来展示遗传算法和新颖性搜索的潜力。他们使用非常简单的遗传算法，没有任何梯度信息，学会了玩各种雅达利游戏。他们的进化算法在Frostbite游戏中达到了10500分，而DQN、AC3、ES等算法在同样的游戏中得分都不到1000。



![](https://pic4.zhimg.com/v2-a5fcdc18ede7e4f17956332aef3da0ab_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='379'></svg>)



## WaveNets，CNNs以及注意力机制



![](https://pic4.zhimg.com/v2-39d3de04513c77e090938c4bcc0bdb63_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='347'></svg>)



谷歌的Tacotron 2文本转语音系统效果令人印象深刻。这个系统基于WaveNet，也是一种自动回归模型，也被部署于Google Assistant之中，并在过去一年得到快速提升。

远离昂贵且训练漫长的回归架构是一个更大的趋势。在论文Attention is All you Need里，研究人员完全摆脱了循环和卷积，使用一个更复杂的注意力机制，只用了很小的训练成本，就达到了目前最先进的结果。

论文地址：[https://arxiv.org/abs/1706.03762](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.03762)

## 深度学习框架这一年

如果非要用一句话总结2017，那只能说是框架之年。

Facebook搞出了PyTorch，这个框架得到了搞自然语言处理的研究人员大爱。

TensorFlow在2017年继续领跑，目前已经发布到1.4.1版本。除了主框架之外，还发布了多个伴随库。TensorFlow团队还发布了一个全新的eager execution模式，类似PyTorch的动态计算图。

此外，
- 苹果发布了CoreML移动机器学习库；
- Uber的一个团队发布了Pyro，一个深度概率编程语言；
- 亚马逊宣布在MXNet上提供更高级别的API Gluon；
- Uber发布了内部米开朗基罗机器学习基础设施平台的详情；
- 由于框架已经太多，Facebook和微软宣布推出ONNX开放格式，以便跨框架共享深度学习模型。

除了通用的深度学习框架外，我们还看到大量的强化学习框架发布：
- OpenAI Roboschool，用于机器人仿真

[https://blog.openai.com/roboschool/](https://link.zhihu.com/?target=https%3A//blog.openai.com/roboschool/)
- OpenAI Baselines，一套强化学习算法的高质量实现

[https://github.com/openai/baselines](https://link.zhihu.com/?target=https%3A//github.com/openai/baselines)
- Tensorflow Agents，用TensorFlow来训练RL智能体

[https://github.com/tensorflow/agents](https://link.zhihu.com/?target=https%3A//github.com/tensorflow/agents)
- Unity ML Agents，研究人员可用Unity Editor来创建游戏，并展开强化训练

[https://github.com/Unity-Technologies/ml-agents](https://link.zhihu.com/?target=https%3A//github.com/Unity-Technologies/ml-agents)
- Nervana Coach，用最先进的强化学习算法进行试验

[http://coach.nervanasys.com/](https://link.zhihu.com/?target=http%3A//coach.nervanasys.com/)
- Facebook ELF，游戏研究平台

[https://code.facebook.com/posts/132985767285406/introducing-elf-an-extensive-lightweight-and-flexible-platform-for-game-research/](https://link.zhihu.com/?target=https%3A//code.facebook.com/posts/132985767285406/introducing-elf-an-extensive-lightweight-and-flexible-platform-for-game-research/)
- DeepMind Pycolab，定制化的游戏引擎

[https://github.com/deepmind/pycolab](https://link.zhihu.com/?target=https%3A//github.com/deepmind/pycolab)
- Geek.ai MAgent，多智能体强化学习平台

[https://github.com/geek-ai/MAgent](https://link.zhihu.com/?target=https%3A//github.com/geek-ai/MAgent)

为了让深度学习更易普及，还有一些面向web的框架，例如谷歌的deeplearn.js和MIL WebDNN执行框架。

2017，还有一个流行框架跟我们告别了。

那就是Theano。

## 学习资源

随着深度学习和强化学习越来越流行，2017年有越来越多的课程、训练营等活动举行并分享到网上。以下是我最爱的一些。
- Deep RL Bootcamp，由OpenAI和UC Berkeley联合主办，主要讲授关于强化学习的基础知识和最新研究成果

地址：[https://sites.google.com/view/deep-rl-bootcamp/lectures?authuser=0](https://link.zhihu.com/?target=https%3A//sites.google.com/view/deep-rl-bootcamp/lectures%3Fauthuser%3D0)
- 斯坦福视觉识别卷积神经网络课程2017春季版

[http://cs231n.stanford.edu/](https://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/)
- 斯坦福自然语言处理与深度学习课程2017冬季版

[http://web.stanford.edu/class/cs224n/](https://link.zhihu.com/?target=http%3A//web.stanford.edu/class/cs224n/)
- 斯坦福的深度学习理论课程

[https://stats385.github.io/](https://link.zhihu.com/?target=https%3A//stats385.github.io/)
- Coursera上最新的深度学习课程

[https://www.coursera.org/specializations/deep-learning](https://link.zhihu.com/?target=https%3A//www.coursera.org/specializations/deep-learning)
- 蒙特利尔深度学习和强化学习暑期学校

[http://videolectures.net/deeplearning2017_montreal/](https://link.zhihu.com/?target=http%3A//videolectures.net/deeplearning2017_montreal/)
- UC Berkeley的深度强化学习课程2017秋季版

[http://rll.berkeley.edu/deeprlcourse/](https://link.zhihu.com/?target=http%3A//rll.berkeley.edu/deeprlcourse/)
- TensorFlow开发者大会上关于深度学习和TensorFlow API相关的内容

[https://www.youtube.com/playlist?list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv](https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv)

几大学术会议，延续了在网上发布会议内容的新传统。如果你想赶上最尖端的研究，可以查看这些顶级会议的录像资料。
- NIPS 2017：

[https://nips.cc/Conferences/2017/Videos](https://link.zhihu.com/?target=https%3A//nips.cc/Conferences/2017/Videos)
- ICLR 2017：

[https://www.facebook.com/pg/iclr.cc/videos/](https://link.zhihu.com/?target=https%3A//www.facebook.com/pg/iclr.cc/videos/)
- EMNLP 2017：

[https://ku.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx](https://link.zhihu.com/?target=https%3A//ku.cloud.panopto.eu/Panopto/Pages/Sessions/List.aspx)

研究人员也开始在arXiv上发布低门槛的教程和综述论文。以下是过去一年我的最爱。
- 深度强化学习：概述

Deep Reinforcement Learning: An Overview

[https://arxiv.org/abs/1701.07274](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1701.07274)
- 给工程师的机器学习简介

A Brief Introduction to Machine Learning for Engineers

[https://arxiv.org/abs/1709.02840](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1709.02840)
- 神经机器翻译

Neural Machine Translation

[https://arxiv.org/abs/1709.07809](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1709.07809)
- 教程：神经机器翻译和序列到序列模型

Neural Machine Translation and Sequence-to-sequence Models: A Tutorial

[https://arxiv.org/abs/1703.01619](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.01619)

## 应用：AI和医学

2017年，有不少人宣称用深度学习解决了医疗问题，而且还击败了人类专家。这其中有真正的突破，也有一些炒作。对这方面感兴趣的话，推荐关注Luke Oakden-Rayner的人类医生终结系列博客：

[https://lukeoakdenrayner.wordpress.com/2017/04/20/the-end-of-human-doctors-introduction/](https://link.zhihu.com/?target=https%3A//lukeoakdenrayner.wordpress.com/2017/04/20/the-end-of-human-doctors-introduction/)

这里简要介绍一些发展。其中最重要的事件包括：斯坦福的一个团队公布了用深度学习识别皮肤癌的算法细节。

相关研究：[https://cs.stanford.edu/people/esteva/nature/](https://link.zhihu.com/?target=https%3A//cs.stanford.edu/people/esteva/nature/)

另一个斯坦福的团队则开发了一个模型，能比人类专家更好的发现心律失常。

相关研究：[https://stanfordmlgroup.github.io/projects/ecg/](https://link.zhihu.com/?target=https%3A//stanfordmlgroup.github.io/projects/ecg/)



![](https://pic1.zhimg.com/v2-3e7b22e392fbd7b8a54eff6551885ee4_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='604'></svg>)



当然也有一些风波。例如DeepMind与NHS之间的问题；NIH发布了一个不适合训练AI的胸部X光片数据集等等。

## 应用：艺术和GAN

应用于图像、音乐、绘图和视频领域的生成模型，今年也越来越受到关注。NIPS 2017还首次推出了面向创意与设计的机器学习研讨会。



![](https://pic1.zhimg.com/v2-16e00c03ba86818cd378e4ad518bbf34_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='360'></svg>)



最流行的应用之一是谷歌的QuickDraw，使用神经网络来识别你的涂鸦。基于已经发布的数据集，你甚至可以让机器帮你画完草稿。

一起去玩一下：

[https://quickdraw.withgoogle.com/](https://link.zhihu.com/?target=https%3A//quickdraw.withgoogle.com/)

GAN今年取得了不少重大进展。例如CycleGAN、DiscoGAN、StarGAN等新模型在生成人脸方面令人印象深刻。GAN通常难以生成逼真的高分辨率图像，但pix2pixHD改变了这种现状。

相关地址：

CycleGAN

[https://arxiv.org/abs/1703.10593](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.10593)

DiscoGAN

[https://github.com/carpedm20/DiscoGAN-pytorch](https://link.zhihu.com/?target=https%3A//github.com/carpedm20/DiscoGAN-pytorch)

StarGAN

[https://github.com/yunjey/StarGAN](https://link.zhihu.com/?target=https%3A//github.com/yunjey/StarGAN)

## 应用：无人车

无人车领域的大玩家包括Uber、Lyft、Waymo和Tesla。Uber这一年都麻烦不断，但是这家公司一直没有停下在无人车方面的脚步。

Waymo在亚利桑那的凤凰城进行了一系列无人车实验，还公布了测试和模拟技术的细节。Lyft正在建立自己的无人车硬件和软件体系。特斯拉的Autopilot没有太多更新。



![](https://pic1.zhimg.com/v2-bfdd1352c1bd902f4175b54968e25b7c_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='421'></svg>)



当然还有一个“新的”入局者，库克证实苹果公司也在研究自动驾驶。

## 超酷的研究和应用

今年有很多好玩的项目和展示，这里不可能提及所有：
- 用深度学习去除背景
- 用深度学习创造动漫角色

一起来试试吧~ [http://make.girls.moe/#/](https://link.zhihu.com/?target=http%3A//make.girls.moe/%23/)
- 用神经网络给黑白照片着色
- 神经网络玩《马里奥赛车》
- 实时《马里奥赛车 64》AI

[https://github.com/rameshvarun/NeuralKart](https://link.zhihu.com/?target=https%3A//github.com/rameshvarun/NeuralKart)
- 使用深度学习鉴别赝品
- 随手画猫

在研究层面，
- 无监督情绪神经元 - 一个可以学习情绪的系统，尽管只被亚马逊训练用于预测评论的下一个字符。
- 学会沟通 - 智能体“开发”了自己的语言。
- 习得索引结构 - 使用神经网络优化高速缓存B-Tree。

[https://arxiv.org/abs/1712.01208](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.01208)
- Attention is All You Need - Google推出的翻译架构Transformer完全舍弃了RNN/CNN结构。

[https://arxiv.org/pdf/1706.03762.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1706.03762.pdf)
- Mask R-CNN
- Deep Image Prior，图像去噪、超分辨率和修补。

## 数据集

神经网络需要大量的数据，因此开放数据集是对行业的重要贡献。以下是今年几个新推出的数据集代表。
- Youtube Bounding Boxes

[https://research.google.com/youtube-bb](https://link.zhihu.com/?target=https%3A//research.google.com/youtube-bb)
- Google QuickDraw Data

[https://quickdraw.withgoogle.com/data](https://link.zhihu.com/?target=https%3A//quickdraw.withgoogle.com/data)
- DeepMind Open Source Datasets

[https://deepmind.com/research/open-source/open-source-datasets](https://link.zhihu.com/?target=https%3A//deepmind.com/research/open-source/open-source-datasets)
- Google Speech Commands Dataset

[https://research.googleblog.com/2017/08/launching-speech-commands-dataset.html](https://link.zhihu.com/?target=https%3A//research.googleblog.com/2017/08/launching-speech-commands-dataset.html)
- Atomic Visual Actions

[https://research.google.com/ava/](https://link.zhihu.com/?target=https%3A//research.google.com/ava/)
- Several updates to the Open Images data set

[https://github.com/openimages/dataset](https://link.zhihu.com/?target=https%3A//github.com/openimages/dataset)
- Nsynth dataset of annotated musical notes

[https://magenta.tensorflow.org/datasets/nsynth](https://link.zhihu.com/?target=https%3A//magenta.tensorflow.org/datasets/nsynth)
- Quora Question Pairs

[https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs](https://link.zhihu.com/?target=https%3A//data.quora.com/First-Quora-Dataset-Release-Question-Pairs)

## 深度学习，重现性和炼金术

过去一年中，研究人员对学术论文结果的可复现性提出了担忧。深度学习模型通常依赖于大量的超参数，必须对其进行优化才能获得足够好的结果。这种优化代价高昂，可能只有Google和Facebook才能负担得起。

另外，研究人员并不总是同步公开代码，论文中有时还会漏掉重要的细节，或者使用特殊的评估方法……这些因素都让可复现性成为一个大问题。

在论文Are GANs Created Equal? A Large-Scale Study中，使用昂贵的超参数搜索调整GAN，可以击败更为复杂的方法。

论文地址：[https://arxiv.org/abs/1711.10337](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1711.10337)

同样，在论文On the State of the Art of Evaluation in Neural Language Models中，研究人员表明，简单的LSTM架构在正确调整后，表现就能比最近的多数模型都好。

论文地址：[https://arxiv.org/abs/1707.05589](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1707.05589)

在NIPS 2017大会上，阿里·拉希米称现在的深度学习就像“炼金术”，呼吁更为严谨的学术管理。不过Yann LeCun随即进行了实名反击。

## 竞争，炒作和失败

加拿大和中国，正在加速AI方面的部署。

硬件方面，AI芯片竞争提速，英伟达发布了最新的Titan V旗舰GPU、Google发布了第二代TPU、英特尔的Nervana也发布了新的芯片。就连特斯拉也在开发AI硬件。另外，来自中国的竞争者也不容小觑。

宣传非常重要，但有些宣传和实验室实际发生的事情不符。IBM沃森就是过度营销的传奇，并没有带来相符的结果。大家都不喜欢沃森，所以他们在医疗方面一再失败也不奇怪。

Facebook的人工智能发明了自己的语言那事，其实也跟真相不符。这不简单是媒体的误导，研究人员所用的标题和摘要也越了界，没能反映实验的实际结果。

— 完 —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


