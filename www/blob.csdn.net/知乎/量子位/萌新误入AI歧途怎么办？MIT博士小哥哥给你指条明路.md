# 萌新误入AI歧途怎么办？MIT博士小哥哥给你指条明路 - 知乎
# 



> 原作 Tom Silver
栗子 & Root 编译自 MIT Blog
量子位 出品 | 公众号 QbitAI

做研究，特别是在AI领域做研究，时常挑战人类的智力极限和心理极限。来自MIT的汤姆，入坑已有两年，并在坑里向广大准同行们发来了倾心打造的攻略，帮助大家在漫漫夜路上，不要迷失自己的方向。

以下为汤姆第一人称——

我的一个小伙伴啊，终于也要踏上AI研究的不归路了。他惶惶地问我，两年前刚入行的时候，有没有过一些，“如果我懂这个就好了”的东西。

回想这两年走过的路，我不禁……
![](https://pic4.zhimg.com/v2-fc0ea8bae6323b5cd9dd461d8dd37833_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='314' height='225'></svg>)忍住没笑出声
为自己感到骄傲。毕竟，身边的渣渣都已经改行了。

所以，由我来总结一套攻略也是非常合适。大到人生指南，小到技术细节，本篇总有各位需要的章节。

闲言少叙，我要开始bb了，可能停不下来。
![](https://pic3.zhimg.com/v2-1e7f753dcf65b0eb4e131db986e8e412_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='519' height='449'></svg>)我准备好了
## **菜鸡不要方**
- **用来回答菜比问题的美妙物种**

一开始，我被同事们强大的气场震慑了，就怕不小心问出什么暴露智商的问题。过了好一段时间才发现，有那么几个人，我在他们面前发问感觉蛮舒服的，不过那时候的问题还是自己精心组织过的。现在，我的“不会就找他”名单里，已经有三四个人了。我只要有问题，就立刻问，困惑才不会积压。



![](https://pic4.zhimg.com/v2-de46cce7fbf59ac2a93f70add3fdd6e7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='225' height='173'></svg>)我有个问题


- **研究灵感需要四处搜刮**

想好自己要做什么，这可能是研究中最困难的一步。你可能需要以下策略：




**1. 和其他领域的研究人员面基**




看他们对什么问题感兴趣，再用计算机语言重述那些问题。再问他们有没有需要分析的数据集，传统方法分析起来费劲的那些。
![](https://pic1.zhimg.com/v2-0ce8c09b0671279fbc60064d203ac8b4_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='860' height='487'></svg>)
机器学习领域，许多有影响力的研究都是学科之间碰撞出来的。物化生，社会科学，或者纯数学，都可以去试试。

比如，Matthew Johnson和他的基友们发表在NIPS 2016的那篇论文，受到了小鼠行为的启发。再比如，Justin Gilmer他们在ICML 2017发表的成果，就是机器学习在量子化学里的应用。




**2. 写个简单的baseline找找感觉**




比如，写写用来操控倒立摆的、仔细校准了的代码，或者看看你能用一个自然语言数据集、把词袋 (BOW) 模型玩成什么样。
![](https://pic4.zhimg.com/v2-dbdb91cf2e1c63a317f2d12a89ab7ea7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='500' height='333'></svg>)
我写基线的时候，就经常出bug。Bug修复的时候，我的脑子里就有了一些新想法可以去试，对问题的理解也更深刻了。

3. 帮喜欢的论文扩展实验部分

仔细读实验方法和结果的部分。先考虑最简单的扩展方法，看看论文里的方法够不够用。想下文中没讨论过的基线方法，看看它们哪里不好。



- **可视化工具和技能**




我做研究的时候，一个重要的策略，就是从可视化脚本开始。其他部分的代码都写完之后，跑一下可视化脚本，我就能迅速看到代码和我想象的一不一样。
![](https://pic4.zhimg.com/v2-cbb6781b18357e6921564277a4d9d68b_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='260' height='243'></svg>)TensorBoard
有了好的可视化，代码中的问题，和思路的问题，都会更加清楚的显现，也更好理解。当然，这样做有一个最直接的好处，就是有视频可以拿出去秀了。

不过，为自己要处理的问题，找到合适的可视化方法，可能并不容易。如果你正在不断的迭代中优化模型，绘制损失曲线大概是个不错的选择。
![](https://pic1.zhimg.com/v2-dc5ae548ad3070fef4a044670609f9fc_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='243' height='243'></svg>)画出分布
还有很多技术，适合给神经网络 (特别是CNN) 中的学习权重做可视化——比如有导向的反向传播 (guided backpropagation) 。

在强化学习和规划中，最需要可视化的就是智能体在环境里的表现，不管是雅达利，机器人人物，还是简单的网格世界。
![](https://pic4.zhimg.com/v2-fb6caa40549ec4158db487ee00cf25cb_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='272' height='243'></svg>)价值函数
根据设定的不同，我们或许也可以把价值函数可视化，看它在训练过程中会发生怎样的变化。当处理图形模型的时候，把一维或二维变量的分布可视化，可以获得许多的信息。

可视化技术有没有效果，就要看你从里面能获得多少有效信息了。如果可视化做的不好，就要回头去看代码。优秀的可视化，可以给人直击灵魂的结论。



- **看出论文和研究人员的原始动机**




即便是参加同一个会议，用着同一套术语，并且同样以“人工智能”一词来表述自己的领域，两个研究人员的出发点可能完全不同。
![](https://pic1.zhimg.com/v2-aa9115d0f4716d2340e8779cc1b76824_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1021' height='640'></svg>)
乔丹甚至提议，可以多起几个名字，来把这个混沌的领域变得更加清晰。但情况好像也没有到完全无法理解的地步，AI领域至少还有三个主要的方向——数学，工程，以及认知。

· “数学”方向研究的是：某个智能系统，它的基本属性和限制是什么？

· “工程”方向讨论的是：怎样开发一些智能系统来解决现实问题，还比其他方法好用？

· “认知”方向关心的是：怎样用机器来模拟人类或其他动物的智能？

这些动机是可以和谐共生的，许多AI论文也是包含多重视角的。而且，许多研究人员也不只有一种动机，可能大家原本就是一家人。
![](https://pic3.zhimg.com/v2-22c3bf4975a1bf5fd1a94179ad099012_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='300' height='300'></svg>)
不过，就算是一家人，也还是会有分歧。我有一些纯“工程”方向的小伙伴，还有一群兄弟对“生物”情有独钟。

有一篇论文的结论说，在某个benchmark上，一些现有技术的某种巧妙结合，足以打败最前沿的技术。

攻城狮可能会为这样的研究成果而感动，但认知科学家们可能就洗洗睡了。如果是一篇纯理论论文，他们的态度就会反过来。

一些优秀的论文和优秀的研究人员，一开始就会表明立场，但多数情况下动机还是被埋没的。我发现，在论文动机不明显的时候，站在不同的角度多读几遍还是有用的。

## **坐在巨人的大腿上**



- **找论文**




AI领域的论文大多都在arXiv，很容易找到。大量的论文排山倒海，让人在兴奋的同时，也有点喘不过气。于是，有些善良的业内人士，提供了披沙拣金的有效途径——
![](https://pic2.zhimg.com/v2-41358c6c0ae55601d3e5559737061cd1_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='494'></svg>)这不是我，是我的机
Andrej Karpathy建起了”arXiv Sanity Preserver”，帮助大家对论文进行分类筛选，搜索，以及特征过滤。Miles Brundage以前也经常在推特上，发一些经过轻度炮制的arXiv论文清单，单子大概率是AI列的。

还有很多其他推友，非常乐于分享他们看到的有趣论文。这里是我可爱的关注列表：

[https://twitter.com/tomssilver/following](https://link.zhihu.com/?target=https%3A//twitter.com/tomssilver/following)

如果喜欢Reddit的话，当然要关注r/MachineLearning。不过，上面的内容还是更适合吃瓜群众动手实践，对于学术研究的帮助可能小一些。

另外，大会上发表的论文是有必要看看的。NIPS、ICML以及ICLR是重中之重，其他有名的大会还包括AAAI、IJCAI和UAI等等。

分方向来说，计算机视觉会议有CVPR、ECCV和ICCV；自然语言会议有ACL、EMNLP以及NAACL；说到机器人，就是CoRL、ICAPS、ICRA、IROS和RSS。要看理论研究的话，AISTATS、COLT和KDD都是不错的选择。
![](https://pic2.zhimg.com/v2-e10f1b685ad396684041c40e07a0d2ed_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='200' height='200'></svg>)论文中奖
目前，参加各大会议是论文发表的主要途径，不过期刊也是有的。JAIR和JMLR这两个是AI领域的主流期刊。偶尔也有厉害的论文，登上Nature和Science。

比起新论文，老论文比较难找，但是同样不可忽视。许多“经典”一直被人们翻出来看，除了出现在引用列表里，也会出现在研究生课程的阅读清单里。

还有一个搜寻旧论文的方法，就是从业内某个知名老教授开始，找他过往的研究成果，比如评上教授职称的时候用到的论文。也可以发邮件给教授，问他们还有没有更多资料可以参考。不过，要从Google Scholar上找老论文，我还没有发现太好的搜索方式。

## **泡在Paper的海洋里**
![](https://pic3.zhimg.com/v2-ff1feb8d905ba459496d66274fafa4e6_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='435' height='416'></svg>)
关于花多少时间在读paper上，常见的两种观点是：

1）刚开始，什么都读，别挑。很多人都说研一就是读Paper，其余啥也别干；2）但过了这个阶段，就不要再花那么多时间在论文上了。

后者的逻辑，是在提出解决问题阶段很需要创新的思维，如果这个时候还读太多Paper容易被带偏。

我个人觉得，第一个说得，非常有道理。只要有时间，就应该尽可能地多读paper。

但我diss第二个。

那些认为不必了解其他同行的研究工作，可以闭门自己憋出好方法的人，有点拿衣服。虽然我们时不时会听到，有些业余的外行可以想出不错的办法，也确实解决了长久以来的问题。

不过我们作为长期从事AI研究的人，不能寄希望于那个“灵光乍现”的瞬间。大部分的时候，问题的解决过程都是非常漫长的。

要搞清楚我们的研究目前处于什么阶段，下一步该怎么做，阅读相关的文献是一个更高效的方法。

这里推荐阅读Julian Togelius的《小修小补和真正研究的区别》：

[http://togelius.blogspot.com/2016/04/the-differences-between-tinkering-and.html](https://link.zhihu.com/?target=http%3A//togelius.blogspot.com/2016/04/the-differences-between-tinkering-and.html)

另外，还要提醒一点。不要一味地追求阅读的数量，更重要的是把读过的每一篇论文认真的做笔记，做好反思，深度消化之后，再读下一篇。不要一个劲地一篇接一篇地读但不经大脑加工处理。
![](https://pic1.zhimg.com/v2-3d836caf3c702dd0be7374c71393c578_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='196' height='144'></svg>)


- **交流>>看视频>>读论文>>听讲座**




如果要了解一个全新的研究工作，读文献是最容易获取信息的途径。

但理想的高效方式，我认为，是找机会和在这行做的研究人员聊聊天。

当然，这样的机会不是经常有。所以看这些人的论文讲解直播，也是个不错的选择。

一般大家习惯在直播的时候，把自己的工作讲清楚，让受众尽可能听得懂；而写文章的时候，因为要考虑到字数的限制，会追求极简的行文。对比之下，显然前者更便于用户消化信息。

另外大家还有个说不出口的原因：写文章时介绍太多背景知识，也会显得自己很弱鸡，像是刚入行什么都不太懂。

为什么我觉得听讲座的效果最不好呢？

通常来说，讲座更多都是走形式，并不是个非常好的学习机会。不过讲座完之后，完全可以趁机找主讲人聊两句。



- **警惕名利**




成功的AI研究工作，会吸引公众的关注。这会进一步鼓励更多的人加入到这个领域，对研究工作来说，是一个非常好的良性循环。

不过负面的影响是，招来无效的媒体曝光。做新闻的人想要更多的点击量，企业想拉投资和招大牛，做技术的人希望发表更高级别的文章，以及文章被更多的人引用。这些都会制造更大的名利泡沫。

大家要时刻提醒自己，留心所有参与方背后的动机。在文章标题、新闻稿、论文方面要十分小心。

在NIPS 2017的会上，有一个很有名的教授当着几百个参会人的面，在Q&A的环节拿到话筒之后，指出主讲人不应该在论文标题里使用“想象(imagination)”一词，并强烈地表达了对主讲人的不满。

这篇被质疑的论文，正好是我非常喜欢的。

不过我也非常认同这个教授的观点。总有人想搞大新闻，把很久以前的工作，冠一个大家没听过的新词，假装自己在搞新的方向。AI圈里，这可以说是十分的尴尬了。

所以要警惕那些喜欢玩概念的文章。尽量从实验和结果的部分，来判断研究工作的质量。

## **做好“跑马拉松”的心理准备**



- **让自己看见可量化的进步**




早期寻找研究项目时，我会花大量时间脑暴。我当时傻傻地觉得，脑子里那些模糊的想法，会自己慢慢生成一个具体的思路。

然后一天下来，我脑子就宕机了。啥具体结论也没想出来，很受挫。我还一度怀疑自己，这是研究吗？

研究工作如何取得进展，没有固定的路径可循。

不过，我慢慢发现把研究工作分解成更小的可量化的目标，相对来说是更简单点的办法。

每当找不着北的时候，我的目标就是：把模糊的想法写下来，然后找出论据来证明它不可行，而不是敷衍地直接划掉。

或者当脑子连模糊的想法都没有时，就把目标定位读文献或找同行聊天。

这样至少一天下来，我可以看到自己实实在在做了些事情，是有推进工作往前走的。即使很多想法难产，我认知上也有很大的收获。现在排除掉的不靠谱的想法，相当于节省了未来的思考判断时间。



- **不钻牛角尖，遇到死胡同早点掉头**




功底深厚的研究人员会把更多时间留在好的问题上。所以学会分辨问题的好坏是一个很强大的技能。
![](https://pic1.zhimg.com/v2-3da45268ec7f31306968ca63656481a8_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='340' height='274'></svg>)
不管是什么level的研究人员，都会面临的一个问题是，我的课题思路有缺陷，无法下结论。我是该继续补救这个课题呢还是直接找不必继续的理由？

我非常后悔。曾经的我一根筋，即意识到了这可能是一条死胡同，但还是坚持补救，然后耗费了很多时间。对沉没成本的不甘心，导致了我再这个问题上犹豫不决。执念的力量相当可怕。

最后放弃这个课题，心情悲痛。但我现在有意识地改变自己的认知，放弃死胡同往回退几步，看起来反直觉，但也算是一种“进步”。

接受失败也是精神认知上很重要的一课。像提出量子点动力学理论的理查德·费曼说的，“尽早证明自己错了，才能进步。”
![](https://pic1.zhimg.com/v2-522e185c8dd502ccd54aaa9df9cd85e8_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='452' height='107'></svg>)





- **最重要的是：写！写！写！**




我有次很幸运，遇到一个业内大神。他给我的早期职业建议就是：写！

写博客记录自己的研究历程，写论文。更重要的是，记录自己每一天的思考。自从那以后，我每天都复盘。我很明显地感觉到主动写作的收获，比光在脑子里想要大得多。

## **要想研究做得好，还得身体好，脑子好**




搞学术的人，总是很忘我。觉得睡觉都浪费时间，也不怎么注意身体。完全沉浸在追求学术进步的世界里。
![](https://pic1.zhimg.com/v2-69721de62ad508fa7dbdd60728f989ec_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='906' height='636'></svg>)刷起夜来不要命……
我自己也有这个毛病。但现在理智的我意识到了，养成习惯锻炼身体和多休息，并不是浪费时间或分散专注力，而是非常必要的投资。

睡4小时对身体是非常不好的，8小时的工作会让脑子变傻。
![](https://pic3.zhimg.com/v2-c40ca1a0bf01812602a5d0c5ac7c34c2_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1037' height='521'></svg>)
但反过来，每天花8个小时睡觉，4个小时工作，我的工作产出效率反而会更高。

我非常理解，在解决一个非常难的问题过程中，很难说做到一半时扔下跑去干别的。我经常都困过点了还死撑着泡在工作里，但没有取得一点点进展。

现在，我可以做到强迫自己走开来，做个深呼吸放松一下自己。我很开心自己做到这个进步，相信这会对我未来的事业有长远的好处。
![](https://pic2.zhimg.com/v2-1d201cb076bd78560dcb0d7fe0e9b9a1_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='284' height='213'></svg>)
善待自己：）


[http://web.mit.edu/tslvr/www/index.html](https://link.zhihu.com/?target=http%3A//web.mit.edu/tslvr/www/index.html)

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


