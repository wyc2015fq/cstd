# 怎样构建深度学习模型？六步走，过拟合是最大的怪兽 | 入门指南 - 知乎
# 



> 夏乙 栗子 编译自 [http://Khanna.cc](https://link.zhihu.com/?target=http%3A//Khanna.cc)
量子位 报道 | 公众号 QbitAI
![](https://pic4.zhimg.com/v2-4482bb3c8d175baae14ad2d9f0b52df3_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='321' height='208'></svg>)
想要训练个**深度神经网络**，也准备好了可以直接用的数据，要从哪里开始上手？

来自美国的Harry Khanna，精心编织了一套**六步法**。大家可以瞻仰一下，然后决定要不要行动。

整个过程中，**过拟合**的问题时时刻刻都要注意。

## **1. 选个损失函数**

选择怎样的损失函数，取决于需要解决怎样的问题。

如果是**回归问题**，就可以用**均方误差** (MSE) 损失函数。
![](https://pic2.zhimg.com/v2-414dc215b129fce314db1f7ab2dec315_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='963'></svg>)
如果是**分类问题**，就用交叉熵 (Cross-Entropy) 损失函数。

只有两类的话，要用二值交叉熵 (Binary Cross-Entropy) 。

如果遇到了**不常见**的问题，比如**一次性学习** (One-Shot Learning) ，可能就要自行定制一个损失方程了。

## **2. 选个初始架构**

说到**结构化学习**，比如预测**销售情况**，从**全连接**的隐藏层开始，是个不错的选择。

这一层的激活数 (Number of Activations) ，要在**输入**神经元与**输出**神经元的数量之间。

两者取个平均数，就可以。

像下面这样的取法，也可以。
![](https://pic4.zhimg.com/v2-17925ef26b051d65a21b15c5c67dae33_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='234' height='88'></svg>)
Ni，是输入神经元数。
No，是输出神经元数。
Ns，训练集里的样本数。
a，尺度因子，在2到10之间选。

对**计算机视觉**领域的小伙伴来说，像ResNet这样的架构，就很友好。

## **3. 拟合训练集**

这一步，最重要的**超参数**，是**学习率** (Learning Rate) (α) 。

不需要**试错**，fast.ai的库里面，有一个**rate finder**。
![](https://pic1.zhimg.com/v2-0e953752bf2e56c8b1a190816a73f224_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='722' height='125'></svg>)
只要写几行代码，就可以得到一个学习率的曲线。
![](https://pic3.zhimg.com/v2-99f46922b3ed21f06faa0b492b0e6106_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='484' height='335'></svg>)
在损失还在**明显**下降的区域，选取学习率——

比如，最陡部分的**旁边**一点点，损失仍在剧烈下降，没有到平坦的地方。

上图的话，10-4就可以。

如果，模型训练还是很慢，或者效果不好的话，可以用**Adam优化**，代替初始架构里的随机梯度下降 (**SGD**) 优化。

这时候，如果模型还是不能和训练集愉快玩耍，考虑一下**学习率衰减** (Learning Rate Decay) ——

有指数衰减，离散阶梯衰减 (Discrete Staircase Decay) ，甚至还有一些**手动**方法，人类可以在**损失**不再下降的时候，自己把学习率 (α) 往下调。

其中，余弦型 (Cosine) 衰减，在一个回合 (Epoch) **开始**的时候，衰减最慢，**中间**最快，**结束**时又最慢。
![](https://pic1.zhimg.com/v2-34b860cf063b7911043a2a08b7930268_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='586' height='295'></svg>)
 然后，可以加上一个“重启 (Restart) ”功能。这样，每 (几) 个回合开始时，学习率都会回到**没有衰减**的状态。

**迁移学习**的话，要把开始几层**解冻** (Unfreeze) ，然后用差分学习率来训练神经网络。

如果，**训练集**还是不开心，还有另外几个**超参数**可以调整——

**·** 隐藏层的unit数
**·** 小批量 (Minibatch) 的大小：64，128，256，512……
**·** 隐藏层数

还不行的话，就要看**目标**能不能再细化一下。
![](https://pic3.zhimg.com/v2-951230a72a92347086e6ba072d90b4ce_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='480' height='360'></svg>)
输入的训练数据，可能并没有预测**输出值**所需的有效信息。

举个栗子，仅仅基于股票的**历史价格**，来预测**未来走势**，就很难。

## **4. 拟合验证集**

这一步，是最难的，也最花时间。

怎样才能解决训练集上的**过拟合**问题？

## **丢弃 (Dropout)**

把训练集中的一些神经元，随机清零。
![](https://pic2.zhimg.com/v2-c3b0fa12a2ab949bf5593df7b2aa0751_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='608'></svg>)
那么，**概率 (p)** 要怎么设置？

虽然，没有万能之法，但还是有一些可以尝试的方法——

找到p=0.25的最后一个线性层，对这之前 (包含本层) 的那些层，执行随机抛弃。

然后，在把p往上调到0.5的过程中，实验几次。

如果还是不行，就给**再往前**的线性层，也执行随机丢弃操作，还是用p=0.25到0.5之间的范围。
![](https://pic4.zhimg.com/v2-f299290e94aa7856e13d8e2d5b2b4f07_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='542' height='374'></svg>)
并没有通天大法，所以有时候还是要**试错**，才能知道在**哪些层**里，取**多大**的p，更有效。

## **权重衰减/L2正则化 (Weight Decay/ L2 Regularization)**

第二小步，加上权重衰减。就是在损失函数里面添加一项——
![](https://pic4.zhimg.com/v2-f1a9d8f9babdb49424ef45c57a84cc6f_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='123' height='81'></svg>)
λ，是**正则化超参数**。

wj，是权重矩阵w里面的特征j。

n，是权重矩阵w里的特征数。

**过拟合**的其中一个原因，就是权重大。而权重衰减，可以有效打击大权重。

## **输入归一化 (Normalize Inputs)**

减少过拟合的第三小步，就是把输入特征的**均值**和**方差**，各自**除以**训练集，归一化。

特征x1除以训练样本总数m，要等于0，方差要等于1。x2，x3…也一样。
![](https://pic3.zhimg.com/v2-dbabdde21d2fdb513f64b597b1c8b5da_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='181' height='120'></svg>)
﻿μ向量，**维数**等于单个训练样本的**输入特征数**。

x是一个n x m矩阵，n是**输入特征数**，m是训练样本数。

x-μ，就是x的每一列都要减掉μ。

标准差归一化的公式，看上去就比较熟悉了——
![](https://pic3.zhimg.com/v2-9507d5c2b30c1a12c4f582870bc97466_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='208' height='149'></svg>)
注意，要归一化的是，除以训练样本总数m，之后的均值和方差，不是除以每个样本的特征数n。

再注意，是用**训练集**的均值和方差，不是验证集。

## **批量归一化 (Batch Normalization)**

上一小步，归一的是输入特征，而这里，要把隐藏层神经元的**均值**和**方差**归一化。

和之前一样的是，用了训练集的**均值**和**方差**，来调教验证集。
![](https://pic1.zhimg.com/v2-4b263ea2393b4951034a9af99631e824_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='364' height='292'></svg>)△ 不支持一次吃太多
不同的是，要一小批一小批地进行，并非整个训练集一步到位。

这种情况下，可以使用均值和方差的**指数加权平均** (exponentially weighted average) ，因为有很多的均值，和很多的方差。

## **多一点训练数据、数据扩增**

根据经验，过拟合最好的解决办法，就是**增加**训练数据，继续训练。

如果没有太多数据，就只好做**数据扩增**。计算机视觉最爱这种方法，调光，旋转，翻转等等简单操作，都可以把一张图变成好几张。
![](https://pic1.zhimg.com/v2-3f9a4e06d5f0a0f9ba017197a3f53750_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='720' height='562'></svg>)
不过，在结构化数据和自然语言处理中，数据扩增就没有什么栗子了。

## **梯度消失，梯度爆炸**

**梯度消失** (Vanishing Gradients) ，是指梯度变得很小很小，以至于**梯度下降**的学习效果不怎么好。

**梯度爆炸** (Exploding Gradients) ，是指梯度变得很大很大，超出了设备的**计算能力**。

解决这两个问题，第一条路，就是用一种特殊的方式把权重矩阵**初始化**——名曰“**He Initialization**”。

不是**第三人称**，是出自**何恺明**等2015年的论文：
Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification。

把权重矩阵W[*l*]，变成一个均值为零的高斯分布。标准差长这样：
![](https://pic3.zhimg.com/v2-b287781920645e403fb2c0e01832f5be_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='114' height='82'></svg>)
 效果意想不到的好，梯度消失和爆炸，都少有发生了。

如果是训练**自然语言处理**RNN，**LSTM**是首选，也是一种减少梯度消失或爆炸的方式。

出现NaN，很可能就是梯度爆炸了。
![](https://pic4.zhimg.com/v2-f486d5a5a2dd39a9dadbc9c2d9752693_b.gif)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='435' height='244'></svg>)
一个简单粗暴的处理方式是，**梯度裁剪** (Gradient Clipping) ，给梯度设一个上限。超出了限制，梯度就会被切。

## **神经网络架构搜索**

有时候调整超参数没什么用，不管怎么调，验证集的loss还是比训练集高好多。

这时候就该好好看看神经网络的架构了。

输入里有太多特征、隐藏层太多激活数，都可能会导致神经网络拟合了训练集里的噪音。
![](https://pic3.zhimg.com/v2-93b3126878a7a2fb11fb96b44e65ec96_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='852' height='553'></svg>)
这时候就要调整隐藏层的神经元数量，或者增减隐藏层的数量。

这个过程需要试错，可能要试过很多架构才能找到一个好用的。

## **5. 在测试集上检验性能**

当神经网络在训练集和验证集上都表现良好，要保持警惕：优化过程中，有可能一不小心在验证集上**过拟合**了。

上一步拟合验证集时，超参数都向着在验证集上优化的方向调整。于是，这些超参数有可能将验证集中的噪音考虑了进去，模型对新数据的**泛化**能力可能很差。

所以，到了这一步，就要在一个**没见过的测试集**上来运行神经网络，确认还能取得和验证集上一样的成绩。
![](https://pic4.zhimg.com/v2-be0c2bf1151b838ae60272b281249db3_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='567' height='366'></svg>)
如果在测试集上表现不好，就要通过增加新数据或者数据增强（data augmentation）的方式，扩大验证集规模。

然后重复第4、5步。

注意：**不要根据测试集损失来调整超参数！**这样只能得到一个对训练集、验证集和测试集都过拟合了的模型。

## **6. 在真实世界中检验性能**

如果你训练了一个猫片识别器，就喂它一些你的猫片；
![](https://pic1.zhimg.com/v2-24f807cd5d2e1c6ab188ecfa65466080_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='606'></svg>)
如果你训练了一个新闻稿情绪识别器，就喂它一些微软最近的新闻。

如果这个神经网络在训练、验证、测试集上表现都不错，到了现实世界却是个**渣渣**，那一定出了什么问题。比如说，有可能**过拟合了测试集**。

这时候就需要换个验证集、测试集，看看模型表现怎么样。如果这个现实世界的渣渣依然表现良好，那么问题可能出在**损失函数**身上。

这种情况，还是挺少见的。
![](https://pic4.zhimg.com/v2-5fcbdc3cf91e72522dd8ea81e79a2083_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='320' height='320'></svg>)
一般只要成功熬到第6步，模型在现实世界里都挺厉害的。

## **来，我们回顾一下**

刚才讲的这么多，最后可以汇集成下面这个checklist：
- **第1步：**损失函数
- 回归问题用MSE
- 多类别分类问题用交叉熵
- 二分类问题用二值交叉熵
- **第2步：**初始神经网络架构
- 结构化学习：一个激活数在输入输出神经元数之间的全连接层
- 计算机视觉：从ResNet开始
- **第3步：**训练集
- 用learning rate finder来选学习率
- Adam优化
- 余弦学习率衰减
- 学习率重启
- 如果做迁移学习，尝试一下可微分学习率
- 隐藏层的神经元数量
- minibatch大小
- 隐藏层数量
- **第4步：**验证集
- Dropout
- L2正则化
- 输入特征归一化
- 批量归一化
- 数据扩增
- 为训练集补充数据
- 梯度消失或爆炸
- He初始化
- 用LSTM神经元
- 梯度裁剪
- 调整神经网络架构
- **第5步：**测试集
- 如果有问题，扩大验证集，回到第4步
- **第6步：**真实世界
- 如果有问题，换个验证集和测试集，回到第4步
![](https://pic2.zhimg.com/v2-58e9bb9e91de54c101b82e2710ce0799_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='874' height='444'></svg>)
恭喜你看到这里，还有信心的话，就开始搭模型吧。

— **完** —

欢迎大家关注我们的专栏：[量子位 - 知乎专栏](https://zhuanlan.zhihu.com/qbitai)

诚挚招聘

量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。

[量子位 QbitAI](https://zhuanlan.zhihu.com/qbitai) · 头条号签约作者

վ'ᴗ' ի 追踪AI技术和产品新动态


