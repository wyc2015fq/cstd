# 吴恩达新书《机器学习训练秘籍》六大要点总结 | 资源 - 知乎
# 



> 乾明 编译整理 
量子位 报道 | 公众号 QbitAI
![](https://pic3.zhimg.com/v2-d70ad83699a1eb9485394169bcb2ee92_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='533'></svg>)



如何读懂吴恩达的《机器学习训练秘籍》？

学霸的笔记来了！

近日，一位名叫Niklas Donges的工程师小哥发表了一篇博客文章，提炼出了《机器学习训练秘籍》中的六大要点。

这本书读起来并不那么容易，不仅需要掌握理论知识，还需要一定的实战经验。

跟着这份要点，你能学到如何选择问题、分割数据集、迭代模型等等，来又快又好地构建一个机器学习系统。

量子位将主要内容编译如下，希望能够为你带来启发。



![](https://pic2.zhimg.com/v2-52cdb9dfa7541ebdb9dd2629cf4b80f9_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1000' height='664'></svg>)



## **迭代、迭代、迭代**

在整本书中，吴恩达都在强调，机器学习是一个迭代的过程，快速迭代非常重要。

与其花大量时间考虑如何构建一个完美的机器学习系统，还不如尽快构建一个简单的原型。

在几天内构建第一个原型，然后就会看到新的线索，告诉你该选择什么样的方向去改进原型的性能。

在下一次迭代中，可以根据这些线索改进系统，并构建系统的下一个版本。一次接一次，循环往复。

吴恩达说，**迭代的速度越快，原型取得的进步就越大。**

其他的几个要点，都是基于这一原则。

不过要注意，这一原则只适用于构建人工智能应用程序解决世界问题的人，对于想要在这个领域进行研究的人，仅供参考。

## **使用单一的评估指标**

为什么应该选择单一的评估指标，理由非常简单：能够快速对算法性能表现进行评估，进而更快地进行迭代。



![](https://pic4.zhimg.com/v2-0e2704ad0324949600f15607cb01fdff_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='400'></svg>)



使用多个指标进行评估，只会让这个过程变得更困难。

假设有两个算法，一个准确率（precision）为94%，召回率（recall ）为89% 。另一个准确率为88% ，召回率为95% 。

像这样不用单一指标，就很难判断孰优孰劣，需要花一些时间来评估到底哪一个算法更适合你要解决的问题。

而且，在后面的每次迭代中，都会在这个流程上损失大量的时间。

如果使用的是单一的评估指标，比如精度或f1评分，就可以根据性能对所有的算法或者模型进行排序，并快速决定哪一个最有效。

改进评估过程的另一种方法，是将几个指标合并成一个指标，比如，取多个误差指标的平均值。

但是，与机器学习有关的问题解决方案，需要满足的不止一个指标，例如说，除了要考虑误差之外，还都要有足够短的运行时间。

吴恩达解释说，应该定义一个可以“可以接受的”运行时间，这可以快速排除速度太慢的算法，并根据单一评估指标来找出好的算法。

简而言之，单一评估指标可以快速评估算法表现，加快迭代速度。

## **误差分析至关重要**

误差分析，是查看算法输出不正确的样例的过程。想象一下，一个猫鉴别器，将鸟类误认为是猫，你可能会有好几种改进的方法。

通过适当的误差分析，可以对这些改进的方法进行评估，看看它们能否提高系统的性能。而不必花几个月的时间来实现这些方法，到最后才发现没用。



![](https://pic3.zhimg.com/v2-2a0e7ee8df00860905d4a9ae3bb58a8e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='800' height='314'></svg>)



这能够帮你做出更好的决定。

如果所有被鉴别器错误分类的图像中只有9%是鸟类，那就不用专门针对鸟类图像进行优化了，因为提升再多最多也不超过这9%的误差。

此外，误差分析也能对几个可以同时进行的改进方法进行评估。

首先，创建一个电子表格，在每一行填入每个错误分类的图像，在每一列，填入改进方法。

之后，检查每一个被错误分类的图像和标记，看看正确的分类是什么。

通过电子表格可以看出，哪种方法能更好地改进算法。比如，使用“方法1”，系统可以正确分类40%的错误分类图像，“方法2”12% ,“方法3”只有9% 。基于此，可以得出结论，方法1是应该进行的改进。

通常情况下，只要一看这些样本，如何改进算法就会一目了然。

## **明确定义最优误差率**

最优误差率，有助于推进后续的迭代步骤。在统计学中，它也经常被称为贝叶斯误差率（Bayes error rate）。

假设你正在构建一个语音-文本转换系统，其中19%的音频文件有显著的背景噪音，哪怕是人类都没法听清楚。

这种情况下，即使是最好的人工智能系统，也可能会有大约19%的误差。

如果处理最优误差率接近0%的问题，人工智能系统也应该以0误差为目标。



![](https://pic4.zhimg.com/v2-f4e86422b3cf746eb605d8d1bc10709b_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='550' height='308'></svg>)



它还可以帮助你检测算法是否受到了高偏差或高方差的影响，这有助于接下来改进算法。

但是我们如何知道最优误差率是多少呢？对于人类擅长的任务，可以将系统的性能与人类进行比较，从而估算出最优误差率。

在其他情况下，通常很难定义一个最优误差率。所以，应该专注于人类能够做的很好的问题。

## **解决人类能做得很好的问题**

在整本书中，吴恩达一直建议大家研究人类能做得很好的问题，比如语音识别、图像分类、物体检测等等，也多次解释了为什么。

首先，获取或创建一个有标签的数据集比较容易，如果人们可以自己解决问题，他们可以直接为学习算法提供高精度的标签。

第二，可以使用人的表现作为算法的最优误差率。吴恩达解释说，定义了合理且可实现的最优误差有助于推动团队的进步。它还可以检测算法是否存在高偏差或高方差。



![](https://pic3.zhimg.com/v2-b2415640431a0e07562412bf6c61177e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1080' height='524'></svg>)



第三，能够对人类直觉进行误差分析。如果你在构建一个语音识别系统，对输入进行了错误分类，你可以试着去理解，人类会根据哪些信息来获得正确的分类，然后使用这些信息改进算法。

尽管算法在越来越多的人类无法完成的任务上超越了人类，但还是应该尽量避开这些任务。

这使得获取数据标签变得更加困难，不能再依靠人类的直觉，也很难知道最优误差率是多少。

## **如何拆分数据集**

任务选定了， 也知道应该如何迭代模型了，该怎么选择数据集呢？

吴恩达还提出了分割数据集的方法。他的建议如下:
- 训练集：只是来训练算法，不再用于其他用途。
- 验证集：这个数据集用于进行超参数调整，选择和创建合适的特性，以及进行误差分析。它基本上就是用来决定算法的。
- 测试集：用于评估系统的性能，但不用于做决策。 它只是用来评估的，没有别的用途。

验证集和测试集用于快速评估算法的性能。 它们的目的是指导你对系统进行最重要的更改。




![](https://pic4.zhimg.com/v2-51ae5866142e80939a123886fc0b9d97_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='590' height='443'></svg>)



吴恩达建议，选择验证和测试数据集的时候一定要慎重。

这些数据，一定要与系统要解决的问题有很高的关联性，这样才能够帮助系统进一步优化。

尤其是系统将要处理的数据与训练过程中使用的数据差别较大的时候，一定要注意这一点。

比如说，使用普通相机拍摄出来的照片训练模型，但之后这个模型要来处理智能手机拍摄出来照片。但又没有足够的智能手机拍摄的照片当做训练集。

这时，就应该使用智能手机拍摄的照片当做验证集与测试集，来迭代模型。

在测试集中，应该选择那些能够准确反映系统表现的数据，而不是用来训练的数据。

此外，在选择验证集和测试集数据的时候，要注意一致性。

如果出现系统在验证集上表现良好，在测试数据上表现极差的情况，就麻烦了。

## **传送门**

《机器学习训练秘籍》中文版：
[https://accepteddoge.com/machine-learning-yearning-cn/docs/ch58/](https://link.zhihu.com/?target=https%3A//accepteddoge.com/machine-learning-yearning-cn/docs/ch58/)

博客原文：
[https://towardsdatascience.com/6-concepts-of-andrew-ngs-book-machine-learning-yearning-abaf510579d4](https://link.zhihu.com/?target=https%3A//towardsdatascience.com/6-concepts-of-andrew-ngs-book-machine-learning-yearning-abaf510579d4)

— **完** —

量子位 · QbitAI

վ'ᴗ' ի 追踪AI技术和产品新动态

戳右上角「+关注」获取最新资讯↗↗

如果喜欢，请分享or点赞吧~比心❤


