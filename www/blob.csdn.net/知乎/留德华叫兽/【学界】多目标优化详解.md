# 【学界】多目标优化详解 - 知乎
# 

> **作者：三名狂客 **
『运筹OR帷幄』责任编辑： [@爱牛氓的帆爷](https://www.zhihu.com/people/fae7884b195335168893c95d833bcd6c) （东北大学系统工程硕士生）
本篇文章是由以上作者在CSDN上的优秀文章（原文链接:  [多目标优化详解 - CSDN博客](https://link.zhihu.com/?target=https%3A//blog.csdn.net/xyisv/article/details/77799875) ），通过『运筹OR帷幄』责任编辑整理修改而成的。
*欢迎原链接转发，转载请私信*[@留德华叫兽](https://www.zhihu.com/people/961e8cc4f7512fda1ea6626ce9a05e8e)*获取信息，盗版必究。*
敬请关注和扩散本专栏及同名公众号，会邀请**全球知名学者**发布运筹学、人工智能中优化理论等相关干货、[知乎Live](https://www.zhihu.com/lives/users/961e8cc4f7512fda1ea6626ce9a05e8e)及行业动态：[『运筹OR帷幄』大数据人工智能时代的运筹学](https://zhuanlan.zhihu.com/operations-research)

## 1、**前言**

生活中 ,许多问题都是由相互冲突和影响的多个目标组成。人们会经常遇到使多个目标在给定区域同时尽可能最佳的优化问题 ,也就是多目标优化问题。优化问题存在的优化目标超过一个并需要同时处理 ,就成为多目标优化问题。

多目标优化问题在工程应用等现实生活中非常普遍并且处于非常重要的地位 ,这些实际问题通常非常复杂、困难 ,是主要研究领域之一。自 20世纪 60年代早期以来 ,多目标优化问题吸引了越来越多不同背景研究人员的注意力。因此 ,解决多目标优化问题具有非常重要的科研价值和实际意义。

实际中优化问题大多数是多目标优化问题 ,一般情况下 ,多目标优化问题的各个子目标之间是矛盾的 ,一个子目标的改善有可能会引起另一个或者另几个子目标的性能降低 , 也就是要同时使多个子目标一起达到最优值是不可能的 , 而只能在它们中间进行协调和折中处理 , 使各个子目标都尽可能地达到最优化。其与单目标优化问题的本质区别在于 ,它的解并非唯一 ,而是存在一组由众多 Pareto最优解组成的最优解集合 ,集合中的各个元素称为 Pareto最优解或非劣最优解。

## 2、**多目标优化问题的描述**

多目标优化问题用文字描述为 D 个决策变量参数、N 个目标函数、m + n个约束条件组成一个优化问题 ,决策变量与目标函数、约束条件是函数关系。在非劣解集中决策者只能根据具体问题要求选择令其满意的一个非劣解作为最终解。

多目标优化问题的数学形式可以如下描述 [1 ] :

min　y = f( x) = [ f1 ( x) , f2 ( x) , …, fn ( x) ]

n = 1, 2, …, N

s. t. 　gi ( x) ≤0　i = 1, 2, …, m hj ( x) = 0　j = 1, 2, …, k

x = [ x1 , x2 , …, xd , …, xD ]

xd_min ≤xd ≤xd_max　d = 1, 2, …, D

其中: x为 D维决策向量 , y为目标向量 , N 为优化目标总数 ; gi

( x) ≤0为第 i个不等式约束 , hj ( x) = 0为第 j个等式约束 , fn

( x)为第 n个目标函数; X是决策向量形成的决定空间 , Y是目标向量形成的目标空间。gi ( x) ≤0和 hj ( x) = 0确定了解的可行域 , xd_max和 xd_m in为每维向量搜索的上下限。
![](https://pic2.zhimg.com/v2-15635625009798bb15d56309d075fdcd_b.jpg)
 对于多目标优化问题中最优解或非劣最优解可进行如下定义 :

定义 1    f(x)的支配关系与 x的支配关系是一致的。

定义 2　Pareto最优解是不被可行解集中的任何解支配的解 ,若 x3 是搜索空间中一点 ,说 x3 为非劣最优解 ,当且仅当不存在 x (在搜索空间可行性域中 )使得 fn ( x) ≤fn ( x3 )成立 ,

n = 1, 2, …, N。  

定义 3　给定一个多目标优化问题 f( x) , f ( x3 )是全局最优解当且仅当对任意 x (在搜索空间中 ) ,都有 f( x3 ) ≤f( x) 。

定义 4　由所有非劣最优解组成的集合称为多目标优化问题的最优解集 ( Pareto op timal set) ,也称为可接受解集或有效解集。

## 3、**不同算法在多目标优化中的应用**

多目标优化问题不存在唯一的全局最优解 ,过多的非劣解是无法直接应用的 ,所以在求解时就是要寻找一个最终解。求最终解主要有三类方法 :

a)生成法 ,即先求出大量的非劣解 ,构成非劣解的一个子集 ,然后按照决策者的意图找出最终解 ;

b)交互法 ,不先求出很多的非劣解 ,而是通过分析者与决策者对话的方式逐步求出最终解 ;

c)事先要求决策者提供目标之间的相对重要程度 ,算法以此为依据 ,将多目标问题转换为单目标问题进行求解。而这些主要是通过算法来实现的 ,一直以来很多专家学者采用不同算法解决多目标优化问题 ,如多目标进化算法、多目标粒子群算法和蚁群算法、模拟退火算法及人工免疫系统等。

（1）多目标进化算法

多目标进化算法 (MOEA )是一类模拟生物进化机制而形成的全局性概率优化搜索方法 ,在 20世纪 90年代中期开始迅速发展 ,其发展可以分为两个阶段。第一阶段主要有两种方法即不基于 Pareto优化的方法和基于 Pareto优化的方法 ;第二个阶段就是在此基础上提出了外部集这个概念 ,外部集存放的是当前代的所有非支配个体 ,从而使解集保持较好的分布度。这个时期提出的多目标进化算法更多地强调算法的效率和有效性。在这两个阶段中 , 比较典型的多目标进化算法有 NS2 GA2[ 3 ]、PESA2和 SPEA2。对于这三种算法而言 ,其优点较多但是其缺点也比较明显的。如 NSGA2的优点在于运行效率高、解集有良好的分布性 ,特别对于低维优化问题具有较好的表现 ;其缺点在于在高维问题中解集过程具有缺陷 ,解集的多样性不理想。PESA2的优点在于其解的收敛性很好 ,比较容易接近最优面 ,特别是在高维问题情况下 ;但其不足之处在于选择操作一次只能选取一个个体 ,时间消耗很大 ,而且阶级的多样性不佳。SPEA2的优点在于可以取得一个分布度很好的解集 ,特别是在高维问题的求解上 ,但是其聚类过程保持多样性耗时较长 ,运行效率不高。

多目标进化算法的基本原理描述如下 : 多目标进化算法从一组随机生成的种群出发 ,通过对种群执行选择、交叉和变异等进化操作 ,经过多代进化 ,种群中个体的适应度不断提高 , 从而逐步逼近多目标优化问题的 Pareto最优解集。与单目标进化算法不同 ,多目标进化算法具有特殊的适应度评价机制。为了充分发挥进化算法的群体搜索优势 ,大多数 MOEA均采用基于 Pareto排序的适应度评价方法。在实际应用中 ,为使算法更好地收敛到多目标优化问题的 Pareto最优解 ,现有的MOEA通常还采用了精英策略、小生境和设置外部集等关键技术。

 MOEA一般框架所描述的算法思想如下 : MOEA通过对种群 X ( t)执行选择、交叉和变异等操作产生下一代种群 X ( t + 1) 。在每一代进化过程中 ,首先将种群 X ( t)中的所有非劣解个体都复制到外部集 A ( t)中 ,然后运用小生境截断算子剔除A ( t)中的劣解和一些距离较近的非劣解个体 ,以得到个体分布更为均匀的下一代外部集 A ( t + 1) ,并且按照概率 pe从 A ( t + 1)中选择一定数量的优秀个体进入下代种群。在进化结束时 ,将外部集中的非劣解个体作为最优解输出 , 目前 , MOEA研究取得了大量成果 ,已被应用于许多领域 ,如工程领域、工业领域和科学领域。其中 ,工程领域的应用最多 ,如电子工程、水利工程、风电工程和控制等。

（2）多目标粒子群算法

粒子群优化算法 ( PSO )是一种源于对鸟群捕食行为的研究而发明的进化计算技术 ,最先由 Barnhart博士和 Kennedy博士于 1995年提出 [ 7 ]。它是一种基于迭代的优化工具 ,系统初始化一组随机解 ,通过迭代搜寻最优值 ,不但具有全局寻优能力 ,而且具有较强的局部寻优能力。在基本粒子群算法 [ 8, 9 ]中 , 粒子群由 n个粒子组成 ,每个粒子的位置 xi 代表优化问题在 D维搜索空间中潜在的解。粒子在搜索空间中以一定的速度飞行 , 这个速度根据它本身的飞行经验和同伴的飞行经验来动态调整下一步飞行方向和距离。所有的粒子都有一个被目标函数决定的适应值 , 并且知道自己到目前为止发现的最好位置 (个体极值 pi )和当前的位置 ( xi ) 。除此之外 , 每个粒子还知道到目前为止整个群体中所有粒子发现的最好位置(全局极值 pg ) , 是所有最好位置中的最优值 。

粒子群算法的数学描述如下 :每个粒子 i包含为一个 D维的位置向量 xi = ( xi1 , xi2 , …, xiD )和速度向量 vi = ( vi1 , vi2 ,…, viD ) ,粒子 i搜索解空间时 ,保存其搜索到的最优经历位置pi = ( pi1 , pi2 , …, piD ) 。在每次迭代开始时 ,粒子根据自身惯性和经验及群体最优经历位置 pg = ( pg1 , pg2 , …, pgD )来调整自己的速度向量以调整自身位置。 c1、c2 是正常数 , 称之为加速因子 ; r1、r2 为 [ 0, 1 ]中均匀分布的随机数 , d为 D维中的维数 ;ω是惯性权重因子。由于粒子群算法具有高效的搜索能力 , 有利于得到多目标意义下的最优解 ;通过代表整个解集种群 ,按并行方式同时搜索多个非劣解 ,也即搜索到多个 Pareto最优解 ;同时 ,粒子群算法的通用性比较好 ,适合处理多种类型的目标函数和约束 ,并且容易与传统的优化方法结合 ,从而改进自身的局限性 ,更高效地解决问题。因此 ,将粒子群算法应用于解决多目标优化问题上具有很大的优势。
![](https://pic1.zhimg.com/v2-e21ae1fdb59ed4d659d1a638f674b698_b.jpg)
 粒子群算法思想描述如下 :初始化种群后 ,种群的大小记为 N。基于适应度支配的思想 ,将种群划分成两个子群 ,一个称为非支配子集 A,另一个称为支配子集 B ,两个子集的基数分别为 n1、n2 ,满足两个子群基数之和为 N [13 ]。外部精英集用来存放每代产生的非劣解子集 A,每次迭代过程只对 B 中的粒子进行速度和位置的更新 , 并对更新后的 B 中的粒子基于适应度支配思想与 A中的粒子进行比较 ,若 xi ∈B , ϖ xj ∈A,使得 xi 支配 xj,则删除 xj,使 xi 加入 A 更新外部精英集 ;且精英集的规模要利用一些技术维持在一个上限范围内 ,如密度评估技术、分散度技术等。最后 ,算法终止的准则可以是最大迭代次数 Tmax、计算精度ε或最优解的最大凝滞步数 Δt等。

如果你是运筹学/人工智能硕博或在读，请在下图的公众号后台留言：**“加微信群”**。系统会自动辨认你的关键字，并提示您进一步的加群要求和步骤，邀请您进全球运筹或AI学者群（群内学界、业界大佬云集）。

同时我们有：【**运筹学|优化爱好者**】【**供应链|物流**】【**人工智能**】【**数据科学|分析**】千人QQ群，想入群的小伙伴可以关注下方公众号**点击“加入社区”按钮**，获得入群传送门。

学术界|工业界招聘、征稿等信息**免费发布**，请见下图：
![](https://pic3.zhimg.com/v2-1ad3bac32612bc7bb090f1143b107702_b.jpg)

