# BAT机器学习面试1000题系列（196-200题） - 知乎
# 



**196.L1与L2范数**

在Logistic Regression 中,如果同时加入L1和L2范数,会产生什么效果()

A.可以做特征选择,并在一定程度上防止过拟合

B.能解决维度灾难问题

C.能加快计算速度

D.可以获得更准确的结果




正确答案:A

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

Ｌ１范数具有系数解的特性，但是要注意的是，Ｌ１没有选到的特征不代表不重要，原因是两个高相关性的特征可能只保留一个。如果需要确定哪个特征重要，再通过交叉验证。

在代价函数后面加上正则项，Ｌ１即是Ｌｏｓｓｏ回归，Ｌ２是岭回归。L1范数是指向量中各个元素绝对值之和，用于特征选择。L2范数 是指向量各元素的平方和然后求平方根，用于 防止过拟合，提升模型的泛化能力。因此选择A。

对于机器学习中的范数规则化，也就是L0,L1,L2范数的详细解答，请参阅《范数规则化》([http://blog.csdn.net/zouxy09/article/details/24971995/](https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/24971995/))




**197.正则化**

机器学习中L1正则化和L2正则化的区别是？

A.使用L1可以得到稀疏的权值

B.使用L1可以得到平滑的权值

C.使用L2可以得到稀疏的权值

D.使用L2可以得到平滑的权值




正确答案:AD

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

L1正则化偏向于稀疏，它会自动进行特征选择，去掉一些没用的特征，也就是将这些特征对应的权重置为0.

L2主要功能是为了防止过拟合，当要求参数越小时，说明模型越简单，而模型越简单则，越趋向于平滑，从而防止过拟合。

L1正则化/Lasso 

L1正则化将系数w的l1范数作为惩罚项加到损失函数上，由于正则项非零，这就迫使那些弱的特征所对应的系数变成0。因此L1正则化往往会使学到的模型很稀疏（系数w经常为0），这个特性使得L1正则化成为一种很好的特征选择方法。

L2正则化/Ridge regression 

L2正则化将系数向量的L2范数添加到了损失函数中。由于L2惩罚项中系数是二次方的，这使得L2和L1有着诸多差异，最明显的一点就是，L2正则化会让系数的取值变得平均。对于关联特征，这意味着他们能够获得更相近的对应系数。还是以Y=X1+X2为例，假设X1和X2具有很强的关联，如果用L1正则化，不论学到的模型是Y=X1+X2还是Y=2X1，惩罚都是一样的，都是2alpha。但是对于L2来说，第一个模型的惩罚项是2alpha，但第二个模型的是4*alpha。可以看出，系数之和为常数时，各系数相等时惩罚是最小的，所以才有了L2会让各个系数趋于相同的特点。

可以看出，L2正则化对于特征选择来说一种稳定的模型，不像L1正则化那样，系数会因为细微的数据变化而波动。所以L2正则化和L1正则化提供的价值是不同的，L2正则化对于特征理解来说更加有用：表示能力强的特征对应的系数是非零。

因此，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。

具体的，可以参阅《机器学习之特征选择》与《机器学习范数正则化》。




**198.势函数法**

位势函数法的积累势函数K(x)的作用相当于Bayes判决中的()

A.后验概率

B.先验概率

C.类概率密度

D.类概率密度与先验概率的乘积




正确答案:AD

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

事实上，AD说的是一回事。 具体的，势函数详解请看——《势函数法》。




**199.隐马尔可夫**

隐马尔可夫模型三个基本问题以及相应的算法说法正确的是（ ）

A.评估—前向后向算法

B.解码—维特比算法

C.学习—Baum-Welch算法

D.学习—前向后向算法




正确答案:ABC

解析：评估问题，可以使用前向算法、后向算法、前向后向算法。




**200.特征比数据量还大时，选择什么样的分类器？**

线性分类器，因为维度高的时候，数据一般在维度空间里面会比较稀疏，很有可能线性可分。




