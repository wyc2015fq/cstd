# BAT机器学习面试1000题（501~505题） - 知乎
# 



**501、下列属于无监督学习的是**

A、k-means

B、SVM

C、最大熵

D、CRF




正确答案是：A

解析：

正确答案：A

 A是聚类，属于无监督学习。BC是分类，属于监督学习。至于D是序列化标注，也是有监督学习。







**502、下列哪个不属于CRF模型对于HMM和MEMM模型的优势（ ）**

A、特征灵活

B、速度快

C、可容纳较多上下文信息

D、全局最优




正确答案是： B

解析：

CRF 的优点：特征灵活，可以容纳较多的上下文信息，能够做到全局最优CRF 的缺点：速度慢

CRF没有HMM那样严格的独立性假设条件，因而可以容纳任意的上下文信息。特征设计灵活（与ME一样） ————与HMM比较

同时，由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔可夫模型标记偏置（Label-bias）的缺点。 ­­————与MEMM比较

CRF是在给定需要标记的观察序列的条件下，使用维特比算法，计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布。————与ME比较







**503、以下哪个是常见的时间序列算法模型**

A、RSI

B、MACD

C、ARMA

D、KDJ




正确答案是：C

解析：

自回归滑动平均模型(ARMA) 

其建模思想可概括为：逐渐增加模型的阶数，拟合较高阶模型，直到再增加模型的阶数而剩余残差方差不再显著减小为止。

其他三项都不是一个层次的。 

A.相对强弱指数 (RSI, Relative Strength Index) 是通过比较一段时期内的平均收盘涨数和平均收盘跌数来分析市场买沽盘的意向和实力 , 从而作出未来市场的走势 .

B.移动平均聚散指标 (MACD, Moving Average Convergence Divergence), 是根据均线的构造原理 , 对股票价格的收盘价进行平滑处理 , 求出算术平均值以后再进行计算 , 是一种趋向类指标 .

D. 随机指标 (KDJ) 一般是根据统计学的原理 , 通过一个特定的周期 ( 常为 9 日 ,9 周等 ) 内出现过的最高价 , 最低价及最后一个计算周期的收盘价及这三者之间的比例关系 , 来计算最后一个计算周期的未成熟随机值 RSV, 然后根据平滑移动平均线的方法来计算 K 值 , D 值与 J 值 , 并绘成曲线图来研判股票走势 .







**504、下列不是SVM核函数的是**

A、多项式核函数

B、logistic核函数

C、径向基核函数

D、Sigmoid核函数

正确答案是： B

解析：

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

SVM核函数包括线性核函数、多项式核函数、径向基核函数、高斯核函数、幂指数核函数、拉普拉斯核函数、ANOVA核函数、二次有理核函数、多元二次核函数、逆多元二次核函数以及Sigmoid核函数。

核函数的定义并不困难，根据泛函的有关理论，只要一种函数 K ( x i , x j ) 满足Mercer条件，它就对应某一变换空间的内积．对于判断哪些函数是核函数到目前为止也取得了重要的突破，得到Mercer定理和以下常用的核函数类型：

(1)线性核函数 

K ( x , x i ) = x ⋅ x i

(2)多项式核 

K ( x , x i ) = ( ( x ⋅ x i ) + 1 ) d

(3)径向基核（RBF） 

K ( x , x i ) = exp ( − ∥ x − x i ∥ 2 σ 2 ) 

Gauss径向基函数则是局部性强的核函数，其外推能力随着参数 σ 的增大而减弱。多项式形式的核函数具有良好的全局性质。局部性较差。

(4)傅里叶核 

K ( x , x i ) = 1 − q 2 2 ( 1 − 2 q cos ( x − x i ) + q 2 )

(5)样条核 

K ( x , x i ) = B 2 n + 1 ( x − x i )

(6)Sigmoid核函数 

K ( x , x i ) = tanh ( κ ( x , x i ) − δ )

采用Sigmoid函数作为核函数时，支持向量机实现的就是一种多层感知器神经网络，应用SVM方法，隐含层节点数目(它确定神经网络的结构)、隐含层节点对输入节点的权值都是在设计(训练)的过程中自动确定的。而且支持向量机的理论基础决定了它最终求得的是全局最优值而不是局部最小值，也保证了它对于未知样本的良好泛化能力而不会出现过学习现象。

核函数的选择

在选取核函数解决实际问题时，通常采用的方法有：

一是利用专家的先验知识预先选定核函数；

二是采用Cross-Validation方法，即在进行核函数选取时，分别试用不同的核函数，归纳误差最小的核函数就是最好的核函数．如针对傅立叶核、RBF核，结合信号处理问题中的函数回归问题，通过仿真实验，对比分析了在相同数据条件下，采用傅立叶核的SVM要比采用RBF核的SVM误差小很多．

三是采用由Smits等人提出的混合核函数方法，该方法较之前两者是目前选取核函数的主流方法，也是关于如何构造核函数的又一开创性的工作．将不同的核函数结合起来后会有更好的特性，这是混合核函数方法的基本思想．







**505、解决隐马模型中预测问题的算法是**

A、前向算法

B、后向算法

C、Baum-Welch算法

D、维特比算法




正确答案是：D

解析：

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

A、B：前向、后向算法解决的是一个评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型。

C：Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；

D：维特比算法解决的是给定 一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题。

**今日学习推荐：**

为了让小伙伴们更好的学习，我们为你准备了 **机器学习，深度学习，计算机视觉，推荐系统实战** 相关方面知识，详情点击下方学习~
[机器学习集训营 第六期「线上线下结合，线下在北上深广杭沈济郑成武西十一城」- 七月在线​www.julyedu.com![图标](https://pic2.zhimg.com/v2-0d5b82db757beb2dcc9eb1c23938bf99_180x120.jpg)](https://link.zhihu.com/?target=http%3A//www.julyedu.com/weekend/train6)[深度学习集训营 第二期「线上线下结合，线下在北京和上海」- 七月在线​www.julyedu.com![图标](https://pic4.zhimg.com/v2-620bf2896a8efee54df506fbff928993_180x120.jpg)](https://link.zhihu.com/?target=http%3A//www.julyedu.com/weekend/dl2)[计算机视觉 第二期 [催生数千亿市值公司的核心技术，3人拼团立减100]​www.julyedu.com![图标](https://pic1.zhimg.com/v2-ad678df023d3186019376baff35f88f4_180x120.jpg)](https://link.zhihu.com/?target=https%3A//www.julyedu.com/course/getDetail/123)[推荐系统实战 [从十大层面从零构建一个个推荐系统]​www.julyedu.com![图标](https://pic2.zhimg.com/v2-bdd7b4ffb850ec6fafd9ac889d5bcd59_180x120.jpg)](https://link.zhihu.com/?target=https%3A//www.julyedu.com/course/getDetail/124)

