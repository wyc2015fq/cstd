# BAT机器学习面试1000题系列（246-250） - 知乎
# 



**246.对于神经网络的说法, 下面正确的是 : **

1. 增加神经网络层数, 可能会增加测试数据集的分类错误率
 2. 减少神经网络层数, 总是能减小测试数据集的分类错误率
 3. 增加神经网络层数, 总是能减小训练数据集的分类错误率




A. 1

B. 1 和 3

C. 1 和 2

D. 2

答案: A

深度神经网络的成功, 已经证明, 增加神经网络层数, 可以增加模型范化能力, 即, 训练数据集和测试数据集都表现得更好. 但更多的层数, 也不一定能保证有更好的表现（[https://arxiv.org/pdf/1512.03385v1.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1512.03385v1.pdf)）. 所以, 不能绝对地说层数多的好坏, 只能选A




**247.假如我们使用非线性可分的SVM目标函数作为最优化对象, 我们怎么保证模型线性可分？**

A. 设C=1

B. 设C=0

C. 设C=无穷大

D. 以上都不对




答案: C

C无穷大保证了所有的线性不可分都是可以忍受的.




**248.训练完SVM模型后, 不是支持向量的那些样本我们可以丢掉, 也可以继续分类:**

A. 正确

B. 错误

答案: A

SVM模型中, 真正影响决策边界的是支持向量




**249.以下哪些算法, 可以用神经网络去构造: **

1. KNN
 2. 线性回归
 3. 对数几率回归




A. 1和 2

B. 2 和 3

C. 1, 2 和 3

D. 以上都不是

答案: B

1. KNN算法不需要训练参数, 而所有神经网络都需要训练参数, 因此神经网络帮不上忙
 2. 最简单的神经网络, 感知器, 其实就是线性回归的训练
 3. 我们可以用一层的神经网络构造对数几率回归




**250.请选择下面可以应用隐马尔科夫(HMM)模型的选项: **

A. 基因序列数据集

B. 电影浏览数据集

C. 股票市场数据集

D. 所有以上




答案: D

只要是和时间序列问题有关的 , 都可以试试HMM


