# BAT机器学习面试1000题（561~565题） - 知乎
# 



**561、下列哪个不属于常用的文本分类的特征选择算法？**

A、卡方检验值

B、互信息

C、信息增益

D、主成分分析

正确答案是：D

解析：

主成分分析是特征转换算法（特征抽取），而不是特征选择







**562、在数据清理中，下面哪个不是处理缺失值的方法?**

A、估算

B、整例删除

C、变量删除

D、成对删除

正确答案是：D

解析：

数据清理中，处理缺失值的方法有两种：

一、删除法：

1）删除观察样本

2）删除变量：当某个变量缺失值较多且对研究目标影响不大时，可以将整个变量整体删除

3）使用完整原始数据分析：当数据存在较多缺失而其原始数据完整时，可以使用原始数据替代现有数据进行分析

4）改变权重：当删除缺失数据会改变数据结构时，通过对完整数据按照不同的权重进行加权，可以降低删除缺失数据带来的偏差

二、查补法：均值插补、回归插补、抽样填补等







**563、统计模式分类问题中，当先验概率未知时，可以使用（）**

A、最小最大损失准则

B、最小误判概率准则

C、最小损失准则

D、N-P判决

正确答案是：A

解析：

A. 考虑p(wi)变化的条件下，是风险最小 

B. 最小误判概率准则， 就是判断p(w1|x)和p(w2|x)哪个大，x为特征向量，w1和w2为两分类，根据贝叶斯公式，需要用到先验知识 

C. 最小损失准则，在B的基础之上，还要求出p(w1|x)和p(w2|x)的期望损失，因为B需要先验概率，所以C也需要先验概率 

D. N-P判决，即限定一类错误率条件下使另一类错误率为最小的两类别决策，即在一类错误率固定的条件下，求另一类错误率的极小值的问题，直接计算p(x|w1)和p(x|w2)的比值，不需要用到贝叶斯公式_







**564、决策树的父节点和子节点的熵的大小关系是什么？**

A、A. 决策树的父节点更大

B、B. 子节点的熵更大

C、C. 两者相等

D、D. 根据具体情况而定

正确答案是：D

解析：

正确答案：D。

假设一个父节点有2正3负样本，进一步分裂情况1：两个叶节点（2正，3负）；情况2：两个叶节点（1正1负，1正2负）。分别看下情况1和情况2，分裂前后确实都有信息增益，但是两种情况里不是每一个叶节点都比父节点的熵小。







**565、语言模型的参数估计经常使用MLE（最大似然估计）。面临的一个问题是没有出现的项概率为0，这样会导致语言模型的效果不好。为了解决这个问题，需要使用（ ）**

A、平滑

B、去噪

C、随机插值

D、增加白噪音

正确答案是：A

解析：

A，拉普拉斯平滑假设，将分子和分母各加上一个常数项。




**今日学习推荐：**

为了让小伙伴们更好的学习，我们为你准备了 **深度学习，机器学习，推荐系统实战** 相关方面知识，详情点击下方学习~
[深度学习集训营 第二期「线上线下结合，线下在北京和上海」- 七月在线​www.julyedu.com](https://link.zhihu.com/?target=http%3A//www.julyedu.com/weekend/dl2)[机器学习集训营 第六期「线上线下结合，线下在北上深广杭沈济郑成武西长十二城」- 七月在线​www.julyedu.com![图标](https://pic2.zhimg.com/v2-0d5b82db757beb2dcc9eb1c23938bf99_180x120.jpg)](https://link.zhihu.com/?target=http%3A//www.julyedu.com/weekend/train6)[推荐系统实战 [从十大层面从零构建一个个推荐系统]​www.julyedu.com![图标](https://pic2.zhimg.com/v2-bdd7b4ffb850ec6fafd9ac889d5bcd59_180x120.jpg)](https://link.zhihu.com/?target=https%3A//www.julyedu.com/course/getDetail/124)

