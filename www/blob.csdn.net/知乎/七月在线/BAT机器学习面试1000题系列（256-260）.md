# BAT机器学习面试1000题系列（256-260） - 知乎
# 



**256.对于下图, 最好的主成分选择是多少 ? **
![](https://pic4.zhimg.com/v2-7bd76801a434f4a3994907e92d5387d7_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='528' height='333'></svg>)
A. 7

B. 30

C. 35

D. 不确定




答案: B

主成分选择使variance越大越好， 在这个前提下， 主成分越少越好。




**257.数据科学家可能会同时使用多个算法（模型）进行预测， 并且最后把这些算法的结果集成起来进行最后的预测（集成学习），以下对集成学习说法正确的是 :**

A. 单个模型之间有高相关性

B. 单个模型之间有低相关性

C. 在集成学习中使用“平均权重”而不是“投票”会比较好

D. 单个模型都是用的一个算法

答案: B

详细请参考下面文章:

Basics of Ensemble Learning Explained in Simple English

Kaggle Ensemble Guide

5 Easy questions on Ensemble Modeling everyone should know




**258.在有监督学习中， 我们如何使用聚类方法？** :

A. 我们可以先创建聚类类别， 然后在每个类别上用监督学习分别进行学习

B. 我们可以使用聚类“类别id”作为一个新的特征项， 然后再用监督学习分别进行学习

C. 在进行监督学习之前， 我们不能新建聚类类别

D. 我们不可以使用聚类“类别id”作为一个新的特征项， 然后再用监督学习分别进行学习

A. 2 和 4

B. 1 和 2

C. 3 和 4

D. 1 和 3




答案: B

我们可以为每个聚类构建不同的模型， 提高预测准确率。

“类别id”作为一个特征项去训练， 可以有效地总结了数据特征。

所以B是正确的




**259.以下说法正确的是 :**

A. 一个机器学习模型，如果有较高准确率，总是说明这个分类器是好的

B. 如果增加模型复杂度， 那么模型的测试错误率总是会降低

C. 如果增加模型复杂度， 那么模型的训练错误率总是会降低

D. 我们不可以使用聚类“类别id”作为一个新的特征项， 然后再用监督学习分别进行学习

答案: C

考的是过拟合和欠拟合的问题。




**260.对应GradientBoosting tree算法， 以下说法正确的是 :**

A. 当增加最小样本分裂个数，我们可以抵制过拟合

B. 当增加最小样本分裂个数，会导致过拟合

C. 当我们减少训练单个学习器的样本个数，我们可以降低variance

D. 当我们减少训练单个学习器的样本个数，我们可以降低bias

A. 2 和 4

B. 2 和 3

C. 1 和 3

D. 1 和 4

答案: C

最小样本分裂个数是用来控制“过拟合”参数。太高的值会导致“欠拟合”，这个参数应该用交叉验证来调节。

第二点是靠bias和variance概念的。


