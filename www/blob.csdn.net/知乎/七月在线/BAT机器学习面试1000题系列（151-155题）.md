# BAT机器学习面试1000题系列（151-155题） - 知乎
# 



**151.在下面哪种情况下，一阶梯度下降不一定正确工作（可能会卡住）？**



![](https://pic4.zhimg.com/v2-ee663892ab2f899264b9f2108552d5ab_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='299'></svg>)



　　答案：（B）

这是鞍点（Saddle Point）的梯度下降的经典例子。另，本题来源于：[https://www.analyticsvidhya.com/blog/2017/01/must-know-questions-deep-learning/](https://link.zhihu.com/?target=https%3A//www.analyticsvidhya.com/blog/2017/01/must-know-questions-deep-learning/)。




**152.下图显示了训练过的3层卷积神经网络准确度，与参数数量(特征核的数量)的关系。**



![](https://pic4.zhimg.com/v2-b389482fee69928b38b9cffb921c7723_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='630' height='289'></svg>)



　　从图中趋势可见，如果增加神经网络的宽度，精确度会增加到一个特定阈值后，便开始降低。造成这一现象的可能原因是什么？

　　A 即使增加卷积核的数量，只有少部分的核会被用作预测

　　B 当卷积核数量增加时，神经网络的预测能力（Power）会降低

　　C 当卷积核数量增加时，它们之间的相关性增加(correlate)，导致过拟合

　　D 以上都不正确

　　答案：（C）

　　如C选项指出的那样，可能的原因是核之间的相关性。




**153.假设我们有一个如下图所示的隐藏层。隐藏层在这个网络中起到了一定的降纬作用。假如现在我们用另一种维度下降的方法，比如说主成分分析法(PCA)来替代这个隐藏层。 **



![](https://pic1.zhimg.com/v2-f26af0ed5229c4d55f2f392d41d79fdc_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='370' height='274'></svg>)



　　那么，这两者的输出效果是一样的吗？

　　答案：不同，因为PCA用于相关特征而隐层用于有预测能力的特征




**154.神经网络能组成函数(y=1/x)吗？**

　　答案：可以，因为激活函数可以是互反函数




**155.下列哪个神经网络结构会发生权重共享？**

　　A.卷积神经网络

　　B.循环神经网络

　　C.全连接神经网络

　　D.选项A和B

　　答案：（D）


