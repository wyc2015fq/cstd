# BAT机器学习面试1000题系列（101-105题） - 知乎
# 



**101.深度学习（CNN RNN Attention）解决大规模文本分类问题**

[https://zhuanlan.zhihu.com/p/25928551](https://zhuanlan.zhihu.com/p/25928551)


**102.如何解决RNN梯度爆炸和弥散的问题的？**

本题解析来源：[http://blog.csdn.net/han_xiaoyang/article/details/51932536](https://link.zhihu.com/?target=http%3A//blog.csdn.net/han_xiaoyang/article/details/51932536)

为了解决梯度爆炸问题，Thomas Mikolov首先提出了一个简单的启发性的解决方案，就是当梯度大于一定阈值的的时候，将它截断为一个较小的数。具体如算法1所述：

算法：当梯度爆炸时截断梯度（伪代码）
![](https://pic1.zhimg.com/v2-43c2638aa7d1e516ebb873090e791e18_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='229' height='151'></svg>)



下图可视化了梯度截断的效果。它展示了一个小的rnn（其中W为权值矩阵，b为bias项）的决策面。这个模型是一个一小段时间的rnn单元组成；实心箭头表明每步梯度下降的训练过程。当梯度下降过程中，模型的目标函数取得了较高的误差时，梯度将被送到远离决策面的位置。截断模型产生了一个虚线，它将误差梯度拉回到离原始梯度接近的位置。
![](https://pic3.zhimg.com/v2-17cc9e9c2fc26f57a77eae0e1e53f36e_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='500' height='334'></svg>)






梯度爆炸，梯度截断可视化 

为了解决梯度弥散的问题，我们介绍了两种方法。第一种方法是将随机初始化W(hh)改为一个有关联的矩阵初始化。第二种方法是使用ReLU（Rectified Linear Units）代替sigmoid函数。ReLU的导数不是0就是1.因此，神经元的梯度将始终为1，而不会当梯度传播了一定时间之后变小。




**103.如何提高深度学习的性能**[http://blog.csdn.net/han_xiaoyang/article/details/52654879](https://link.zhihu.com/?target=http%3A//blog.csdn.net/han_xiaoyang/article/details/52654879)




**104.RNN、LSTM、GRU区别**  @我愛大泡泡，本题解析来源：[http://blog.csdn.net/woaidapaopao/article/details/77806273](https://link.zhihu.com/?target=http%3A//blog.csdn.net/woaidapaopao/article/details/77806273)

RNN引入了循环的概念，但是在实际过程中却出现了初始信息随时间消失的问题，即长期依赖（Long-Term Dependencies）问题，所以引入了LSTM。

LSTM：因为LSTM有进有出且当前的cell informaton是通过input gate控制之后叠加的，RNN是叠乘，因此LSTM可以防止梯度消失或者爆炸的变化是关键，下图非常明确适合记忆：



![](https://pic4.zhimg.com/v2-8352a4e333b4a5db36cb69c316f4f083_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='241'></svg>)



GRU是LSTM的变体，将忘记门和输入们合成了一个单一的更新门。  



![](https://pic3.zhimg.com/v2-843ecec460397f5811d1a7566f2f453a_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='640' height='198'></svg>)
**105.当机器学习性能遭遇瓶颈时，你会如何优化的？**

可以从这4个方面进行尝试：、基于数据、借助算法、用算法调参、借助模型融合。当然能谈多细多深入就看你的经验心得了。这里有一份参考清单：机器学习性能改善备忘单（[http://blog.csdn.net/han_xiaoyang/article/details/53453145](https://link.zhihu.com/?target=http%3A//blog.csdn.net/han_xiaoyang/article/details/53453145)）


