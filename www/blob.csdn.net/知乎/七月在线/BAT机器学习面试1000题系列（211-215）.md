# BAT机器学习面试1000题系列（211-215） - 知乎
# 



**211.解决隐马模型中预测问题的算法是?**

A.前向算法
 B.后向算法
 C.Baum-Welch算法
 D.维特比算法


正确答案：D
 @刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)
 A、B：前向、后向算法解决的是一个评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型。
 C：Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；
 D：维特比算法解决的是给定 一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题。




**212.一般，k-NN最近邻方法在( )的情况下效果较好**

 A.样本较多但典型性不好
 B.样本较少但典型性好
 C.样本呈团状分布
 D.样本呈链状分布


正确答案：B
 解析：K近邻算法主要依靠的是周围的点，因此如果样本过多，那肯定是区分不出来的。因此应当选择B
 样本呈团状颇有迷惑性，这里应该指的是整个样本都是呈团状分布，这样kNN就发挥不出其求近邻的优势了，整体样本应该具有典型性好，样本较少，比较适宜。


**213.下列方法中，可以用于特征降维的方法包括（）**

A.主成分分析PCA
 B.线性判别分析LDA
 C.深度学习SparseAutoEncoder
 D.矩阵奇异值分解SVD
 E.最小二乘法LeastSquares


正确答案：ABCD
 解析：降维的3种常见方法ABD，都是线性的。深度学习是降维的方法这个就比较新鲜了，事实上，细细想来，也是降维的一种方法，因为如果隐藏层中的神经元数目要小于输入层，那就达到了降维，但如果隐藏层中的神经元如果多余输入层，那就不是降维了。
最小二乘法是线性回归的一种解决方法，其实也是投影，但是并没有进行降维。




**214.下面哪些是基于核的机器学习算法?()**

A.Expectation Maximization（EM）（最大期望算法）
 B.Radial Basis Function（RBF）（径向基核函数）
 C.Linear Discrimimate Analysis（LDA）（主成分分析法）
 D.Support Vector Machine（SVM）（支持向量机）


正确答案：BCD
 解析：径向基核函数是非常常用的核函数，而主成分分析法的常规方法是线性的，但是当遇到非线性的时候，同样可以使用核方法使得非线性问题转化为线性问题。支持向量机处理非线性的问题的时候，核函数也是非常重要的。





**215.试推导样本空间中任意点x到超平面（w,b）的距离公式。**
![](https://pic3.zhimg.com/v2-9562bab105bfa7780ae53a765f285272_b.jpg)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='600' height='617'></svg>)



