# BAT机器学习面试1000题系列（201-205题） - 知乎
# 



**201.下列属于无监督学习的是： **

A.k-means

B.SVM

C.最大熵

D.CRF




正确答案：A

解析： A是聚类，BC是分类，D是序列化标注，也是有监督学习。




**202.下列哪个不属于CRF模型对于HMM和MEMM模型的优势（ ） **

A.特征灵活

B.速度快

C.可容纳较多上下文信息

D.全局最优




正确答案：B

解析： CRF 的优点：特征灵活，可以容纳较多的上下文信息，能够做到全局最优CRF 的缺点：速度慢

CRF没有HMM那样严格的独立性假设条件，因而可以容纳任意的上下文信息。特征设计灵活（与ME一样） ————与HMM比较

同时，由于CRF计算全局最优输出节点的条件概率，它还克服了最大熵马尔可夫模型标记偏置（Label-bias）的缺点。 ­­————与MEMM比较

CRF是在给定需要标记的观察序列的条件下，使用维特比算法，计算整个标记序列的联合概率分布，而不是在给定当前状态条件下，定义下一个状态的状态分布。————与ME比较




**203.数据清理中，处理缺失值的方法是? **

A.估算

B.整例删除

C.变量删除

D.成对删除




正确答案：ABCD

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

由于调查、编码和录入误差，数据中可能存在一些无效值和缺失值，需要给予适当的处理。常用的处理方法有：估算，整例删除，变量删除和成对删除。

估算(estimation)。最简单的办法就是用某个变量的样本均值、中位数或众数代替无效值和缺失值。这种办法简单，但没有充分考虑数据中已有的信息，误差可能较大。另一种办法就是根据调查对象对其他问题的答案，通过变量之间的相关分析或逻辑推论进行估计。例如，某一产品的拥有情况可能与家庭收入有关，可以根据调查对象的家庭收入推算拥有这一产品的可能性。 

整例删除(casewise deletion)是剔除含有缺失值的样本。由于很多问卷都可能存在缺失值，这种做法的结果可能导致有效样本量大大减少，无法充分利用已经收集到的数据。因此，只适合关键变量缺失，或者含有无效值或缺失值的样本比重很小的情况。

变量删除(variable deletion)。如果某一变量的无效值和缺失值很多，而且该变量对于所研究的问题不是特别重要，则可以考虑将该变量删除。这种做法减少了供分析用的变量数目，但没有改变样本量。

成对删除(pairwise deletion)是用一个特殊码(通常是9、99、999等)代表无效值和缺失值，同时保留数据集中的全部变量和样本。但是，在具体计算时只采用有完整答案的样本，因而不同的分析因涉及的变量不同，其有效样本量也会有所不同。这是一种保守的处理方法，最大限度地保留了数据集中的可用信息。

采用不同的处理方法可能对分析结果产生影响，尤其是当缺失值的出现并非随机且变量之间明显相关时。因此，在调查中应当尽量避免出现无效值和缺失值，保证数据的完整性。 




**204.关于线性回归的描述,以下正确的有: **

A.基本假设包括随机干扰项是均值为0,方差为1的标准正态分布

B.基本假设包括随机干扰下是均值为0的同方差正态分布

C.在违背基本假设时,普通最小二乘法估计量不再是最佳线性无偏估计量

D.在违背基本假设时,模型不再可以估计

E.可以用DW检验残差是否存在序列相关性

F.多重共线性会使得参数估计值方差减小 




正确答案：ACEF

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

1、AB一元线性回归的基本假设有： 

（1）随机误差项是一个期望值或平均值为0的随机变量； 

（2）对于解释变量的所有观测值，随机误差项有相同的方差； 

（3）随机误差项彼此不相关； 

（4）解释变量是确定性变量，不是随机变量，与随机误差项彼此之间相互独立； 

（5）解释变量之间不存在精确的（完全的）线性关系，即解释变量的样本观测值矩阵是满秩矩阵； 

（6）随机误差项服从正态分布

2、CD 违背基本假设的计量经济学模型还是可以估计的，只是不能使用普通最小二乘法进行估计。 

当存在异方差时，普通最小二乘法估计存在以下问题： 参数估计值虽然是无偏的，但不是最小方差线性无偏估计。

3、E杜宾-瓦特森（DW）检验，计量经济，统计分析中常用的一种检验序列一阶 自相关 最常用的方法。

4、F所谓多重共线性（Multicollinearity）是指线性回归模型中的解释变量之间由于存在精确相关关系或高度相关关系而使模型估计失真或难以估计准确。影响  

（1）完全共线性下参数估计量不存在 

（2）近似共线性下OLS估计量非有效 

多重共线性使参数估计值的方差增大，1/(1-r2)为方差膨胀因子(Variance Inflation Factor, VIF) 

（3）参数估计量经济含义不合理 

（4）变量的显著性检验失去意义，可能将重要的解释变量排除在模型之外 

（5）模型的预测功能失效。变大的方差容易使区间预测的“区间”变大，使预测失去意义。

对于线性回归模型,当响应变量服从正态分布,误差项满足高斯–马尔科夫条件（零均值、等方差、不相关）时,回归参数的最小二乘估计是一致最小方差无偏估计。

当然，该条件只是理想化的假定，为的是数学上有相应的较为成熟的结论。其实大多数实际问题都不完全满足这些理想化的假定。

线性回归模型理论的发展正是在不断克服理想化条件不被满足时得到许多新方法。如加权LSE、岭估计、压缩估计、BOX_COX变换等一系列段。做实际工作时一定是要超越书本上的理想化条件的。 




**205.影响聚类算法效果的主要原因有：**

A.特征选取

B.模式相似性测度

C.分类准则

D.已知类别的样本质量




正确答案：ABC

@刘炫320，本题题目及解析来源：[http://blog.csdn.net/column/details/16442.html](https://link.zhihu.com/?target=http%3A//blog.csdn.net/column/details/16442.html)

解析：这道题应该是很简单的，D之所以不正确，是因为聚类是对无类别的数据进行聚类，不使用已经标记好的数据。

前面的ABC选项，可以参考：《聚类分析》与《各类算法的比较》。


