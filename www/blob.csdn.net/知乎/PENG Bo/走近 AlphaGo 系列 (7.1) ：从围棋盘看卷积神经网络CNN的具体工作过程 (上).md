# 走近 AlphaGo 系列 (7.1) ：从围棋盘看卷积神经网络CNN的具体工作过程 (上) - 知乎
# 



最近几个月在专栏没写“自制 AlphaGo 系列”（[技术备忘录 - 知乎专栏](https://zhuanlan.zhihu.com/mathNote)），有朋友留言问是否会有下文。其实是因为有出版社约稿，所以在写稿子。

然而我自己公司的事情也很忙，希望今年或明年中能出来吧。其中也会包括深度学习的介绍和经典例子。如果 AlphaGo 发布 2.0 版的论文，其中也会包括相关的内容。

> 顺便提几句，AlphaGo 2.0 为什么强，我猜它会用 GAN / VAE 之类生成各种围棋局面（比直接 self-play 自我对弈生成的局面更丰富），然后直接用网络去拟合蒙特卡洛树搜索的输出。

还有就是策略网络和价值网络会相互拟合，也许会合二为一，也许还会加个地域网络、贴目网络之类。

由于神经网络什么都可以拟合，所以也可能会去拟合更多搜索树中的信息，例如拟合盲点，拟合  MCTS 的节点初始化，甚至拟合整颗搜索树。之前在这个答案也写过一点：[AlphaGo 2.0 与其 1.0 相比有哪些提升？](https://www.zhihu.com/question/60009142/answer/173874185) 

此外，最近 Hassabis 说 2.0 版本的方法更有通用性，考虑到目前还没有“脱离人类棋谱”的版本的消息，这是否会在 2.0 版论文看到？

言归正题。近期会从草稿摘选一些内容发在这里。这里继续之前的编号，所以是 (7.1)。

## **1. 围棋棋盘的编码：为什么不直接编码**

围棋棋盘，初看上去可以直接用一个数组表示。比如假设本方是黑棋，那么用 1 代表本方棋子，用 -1 代表对方棋子，用 0 代表空点**（如果不会围棋，可以看我专栏从前写的简介：[围棋 AI 基础](https://zhuanlan.zhihu.com/p/24801451)）**。

例如对于这个角部：（这是 AlphaGo 喜欢的"点三三"变化，这里红点代表最后的一个落子）
![](https://pic1.zhimg.com/v2-fcb7c0cf3c3ca6b74a85457fc80c8370_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='999' height='300'></svg>)
**但，如果我们把这样的输入数据喂给网络，会发现训练效果不佳。**为什么？

两个原因：
- **卷积操作（后文会说什么是卷积）是线性的**，因此 +1 和 -1 在卷积操作后，会互相抵消，使得我们很难单独分析某一方的棋形情况，必然会受到另一方的棋子的影响。
- “数气”对于围棋太重要了。**然而神经网络很难学会怎么精确数气**（有兴趣的读者可以思考这个问题）。所以即使是天下无敌的 AlphaGo，也仍然要一点人类的帮助，帮它把棋盘上的棋子按照气的多少做分类，做成不同的输入（下文会看到）。

是的，AlphaGo 自己是不会数气的，这个概念目前仍然是人硬性写进去的。**因为"气"是一个非常精确的概念。对于这种精确概念的掌握，迄今仍然不是神经网络的强项。**有兴趣的读者可以试试自己训练。目前所见，如果让网络自己学数气，大龙一复杂它就会晕，边角的地方也会晕。

有没有可能 AlphaGo 2.0 能够自己学会数气？也许训练数据足够丰富后，网络能够基本学会数气，然后 MCTS 可以解决偶尔看错的问题。但是，如果网络能自己学会精确数气，我会很惊讶。

## 2. **围棋棋盘的编码：更好的方法**

更适合作为神经网络的输入的棋盘编码方式，**是所谓 one-hot 编码，就是用 1 代表有某个性质的地方，用 0 代表没有某个性质的地方。**例如，先做这样三个数组（学名叫 feature plane 特征平面）：
- 数组一：其中 1 代表本方棋子，0 代表其它。
- 数组二：其中 1 代表对方棋子，0 代表其它。
- 数组三：其中 1 代表空点，0 代表其它。

如前文所述，这样做很有好处。分得越清楚，越适合神经网络的学习（另外还有一个隐蔽的好处是以后做卷积 padding 时有助于认清棋盘边界）。

于是就是这样：
![](https://pic2.zhimg.com/v2-3c6c4206894a260da2c8fa5e2aae9c45_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='999' height='600'></svg>)
然后如前文所说，我们还要按气分类。实际上 AlphaGo 用了二十多个数组，比如按气分类，还有按征子的情况之类。

而我试过比较简单的方法是只再加 5 个数组，效果也很好（当然，越多会越好，但是训练也越慢）：
![](https://pic3.zhimg.com/v2-8a2e53af936f06beaf660a6653215c72_b.png)![](data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='999' height='876'></svg>)
上述八个数组，就是神经网络的真正输入。

## **3. 两个有趣的问题，与“招数的连贯性”**

观察一下上面的数组，非常有趣的问题来了：

> **为什么我们在数气的时候，竟然把双方的棋子一视同仁，没有做区分？！AlphaGo 的论文也没有做这个区分。**

这确实是反直觉的一个事情。如果你可以想清楚这个问题，说明你对于神经网络和围棋都有一定的了解。**读者可以先思考。**Facebook 的 DarkForest 论文做了这个区分，从前很多论文也做了这个区分，但你在实际训练时，会发现这种区分并不重要。AlphaGo 2.0 也许会做，也许没有做，总之就是貌似不是很重要。

另一个问题：

> **为什么要使用最后一手的位置？**

理论上，策略网络确实是不需要使用上一手的位置（请思考为什么）。AlphaGo 2.0 有可能就不用这个了。

不过，我们首次训练的策略网络，是希望尽可能拟合人类棋手的行为，而人类是会考虑上一手的位置，所以要用这个。人类考虑上一手的位置有一定道理，因为许多情况应该回应对手的上一步。

但，如果棋力特别强之后，这个确实是不需要考虑。如果棋力特别强，**正确的做法，是把每一步都当做全新的一步，忘记对手的上一步，由棋局全盘决定下一步的策略。**

所以 AlphaGo 的脱先会比人类更灵活，因为它会逐渐摆脱这种影响。这让它看上去好像“招数的连贯性”不够，但这只是人类的惯性思维使然，在追求更高境界的时候需要克服。

另外，电脑的“东一榔头西一斧子”风格，对付人还真的往往有奇效（因为人会想这是什么意思）。

## **4. 后文预告**

这是上篇。

在中篇，我们会看卷积操作在棋盘上的例子，以及在图像上的例子。

在下篇，**我们会看一个简化的策略网络的详细运作过程，即使你不会下围棋，也能初步体验“半人半狗”的感觉**，请大家期待。

（如果还有续篇，就是看深层策略网络的运作了，但这个的可视化比较麻烦，需要想一想）

***最后，欢迎关注我的专栏： [技术备忘录 - 知乎专栏](https://zhuanlan.zhihu.com/mathNote)，其中有更多文章。***

***欢迎关注本司产品 [Blink Sunshine护眼无频闪97显色指数灯泡系列](https://link.zhihu.com/?target=https%3A//item.taobao.com/item.htm%3Fid%3D40134613056)，提升生活品质~~~***






