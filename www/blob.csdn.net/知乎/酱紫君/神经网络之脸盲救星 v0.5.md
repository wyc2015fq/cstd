# 神经网络之脸盲救星 v0.5 - 知乎
# 

作为一个死宅, 连老婆都分不清退群算了...

当然作为一个脸盲, 确实是分不清自己的老婆和外边的妖艳贱货的...

我们可以训练一个神经网络来帮助分辨.

*(柚子厨: 什么, 难道不是不管三七二十一先带回家吗...)*

项目在此地址更新: 
[Moe-Net/Waifu-X​github.com![图标](https://pic2.zhimg.com/v2-7c255044ac363b2ee9d758675914b971_ipico.jpg)](https://link.zhihu.com/?target=https%3A//github.com/Moe-Net/Waifu-X)
第一要明确的是这个任务可以划分到现有的什么类别里.

你要说了, 这不废话吗, 人脸识别啊, 看人不都靠脸吗?

sorry, 还真不是靠脸, 你画过插画的话会发现...

其实脸型就那几个, 然后不同画师, 不同时期的风格还有很大差异.

偏 Q 版和偏写实差距就更大了, 我都没加上手办和 cos 这种三次元情况呢.

如何判别身份, 很多时候和配色, 外设(比如头发, 翅膀), 背景, 周围人物之类的都相关.

所以这并不是比较精细的人脸身份识别, 而是一个分类问题.

反正不是看脸, 这还是可以肯定的...
![](https://pic4.zhimg.com/v2-e5bf1d952df37508531e01e2033cc3fb_b.gif)
首先需要一个数据集, Kaggle 上去搞一个来: [https://www.kaggle.com/mylesoneill/tagged-anime-illustrations/home](https://link.zhihu.com/?target=https%3A//www.kaggle.com/mylesoneill/tagged-anime-illustrations/home)

我们这次采用 ResNet 分类模型.

这个网络可以从 NetModel Zoo 下, 你想自己写灵活调整的话, 源码在最下面. 
![](https://pic3.zhimg.com/v2-9c2aaa1a6c7b00619b8880894ebc0b12_b.jpg)
别看它这么长, 其实思路很简单的

第一部分就是一个逐层的卷积特征提取的过程, 最后一级一级升到一个 2048 维向量, 用来表示这个原来的图片

第二部分, 那就是对这个 2048 维向量分类, 我这里用了两层全连接层, 然后外接一个 Softmax 输出概率就行了.

最后把它嵌入一个后向网络, 没有特殊 Loss 的话直接训练就行了, 自动会给你补一个默认的后向网络的.

要说有点特殊的地方就是要分两次训练, 第一次整体训练, 随便跑就是了.
![](https://pic4.zhimg.com/v2-98a452e0bee0b7fed724d870863e41f3_b.jpg)
然后你会发现严重过拟合, 验证集十倍误差还怎么玩啊...

别急, 你把第一部分特征提取学习率置零, 然后第二部分预测网络重置权重, 给他加 L2, 上数据增强.
![](https://pic2.zhimg.com/v2-1d69300102a017b41b408b7da03c0b51_b.jpg)
这验证集不就也下来了吗, 当然这里后面又有点过拟合, 直接停止训练即可....

然后取 Checkpoints 里验证集误差最小的拿出来.
![](https://pic1.zhimg.com/v2-37743ccbf5352d9523b96c6a528ed1f8_b.jpg)
(话说我一直觉得这个编号命名简直傻帽...关键是还不能自定义....)

我们可以随机取两个类别看下是不是线性可分的
![](https://pic1.zhimg.com/v2-3e9bed322e16f488622c72c54449755c_b.jpg)
大抵上可以直接用一条直线划分.

困惑矩阵可以找到最难的那些分类, 我们来看一下困惑矩阵
![](https://pic3.zhimg.com/v2-06d6f70a4493869200deecc2596c702e_b.jpg)
Forget it, 我们可以看一下极困惑矩阵.
![](https://pic3.zhimg.com/v2-833531e7ae395e8b99dd39aae2bc93a6_b.jpg)
鏡音鈴(Kagamine Len)和鏡音連(Kagamine Rin)...这个海星

初音岛的 Asakura Yume, Asakura Otome, 情有可原, 我也分不清.

蕾米莉亚 Remilia Scarlet 和 帕秋莉 (Patchouli Knowledge), 严重分类错误...WTF
![](https://pic3.zhimg.com/v2-e5011367e7d8923be6e66d73150749fa_b.jpg)
这很难分辨吗.....

另外这个数据库好像有点老, 你至少得用 2010 年以前的角色...

你要是放个小恩......
![](https://pic2.zhimg.com/v2-00698ee547a382ab896bcaad1e138ce5_b.jpg)
我闭着眼睛都能知道这个会被识别成 CC 或者 早苗....

附 Res50 的源码:

```
block0[nChannels_, stride_] := NetGraph[
	<|
		"res_branch1" -> ConvolutionLayer[nChannels, , "Stride" -> stride],
		"bn_branch1" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res_branch2a" -> ConvolutionLayer[nChannels / , , "Stride" -> stride],
		"bn_branch2a" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res_branch2a_relu" -> ElementwiseLayer[Ramp],
		"res_branch2b" -> ConvolutionLayer[nChannels / , , "PaddingSize" -> ],
		"bn_branch2b" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res_branch2b_relu" -> ElementwiseLayer[Ramp],
		"res_branch2c" -> ConvolutionLayer[nChannels, ],
		"bn_branch2c" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res" -> TotalLayer[],
		"res_relu" -> ElementwiseLayer[Ramp]
	|>,
	{
		NetPort["Input"] -> "res_branch1" -> "bn_branch1" -> "res" -> "res_relu",
		NetPort["Input"]
			-> "res_branch2a" -> "bn_branch2a" -> "res_branch2a_relu" -> "res_branch2b"
			-> "bn_branch2b" -> "res_branch2b_relu" -> "res_branch2c" -> "bn_branch2c" -> "res"
	}
]
blockN[nChannels_] := NetGraph[
	<|
		"res_branch2a" -> ConvolutionLayer[nChannels / , ],
		"bn_branch2a" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res_branch2a_relu" -> ElementwiseLayer[Ramp],
		"res_branch2b" -> ConvolutionLayer[nChannels / , , "PaddingSize" -> ],
		"bn_branch2b" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res_branch2b_relu" -> ElementwiseLayer[Ramp],
		"res_branch2c" -> ConvolutionLayer[nChannels, ],
		"bn_branch2c" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
		"res" -> TotalLayer[],
		"res_relu" -> ElementwiseLayer[Ramp]
	|>,
	{
		NetPort["Input"] -> "res" -> "res_relu",
		NetPort["Input"]
			-> "res_branch2a" -> "bn_branch2a" -> "res_branch2a_relu"
			-> "res_branch2b" -> "bn_branch2b" -> "res_branch2b_relu"
			-> "res_branch2c" -> "bn_branch2c" -> "res"
	}
]
blockChain[names_, nChannels_, stride_] := Association@Prepend[
	Thread[Rest[names] -> Table[blockN[nChannels], {i, Length[names] - }]],
	First[names] -> block0[nChannels, stride]
]
extractor = NetChain[
	Join[
		<|"conv1" -> ConvolutionLayer[, , "Stride" -> , "PaddingSize" -> ],
			"bn_conv1" -> BatchNormalizationLayer["Epsilon" -> 0.0001],
			"conv1_relu" -> ElementwiseLayer[Ramp],
			"pool1_pad" -> PaddingLayer[{{, }, {, }, {, }}, "Padding" -> "Fixed"],
			"pool1" -> PoolingLayer[, "Stride" -> ]
		|>,
		blockChain[{"2a", "2b", "2c"}, , ],
		blockChain[{"3a", "3b", "3c", "3d"}, , ],
		blockChain[{"4a", "4b", "4c", "4d", "4e", "4f"}, , ],
		blockChain[{"5a", "5b", "5c"}, , ],
		<|"pool5" -> PoolingLayer[, "Function" -> Mean]|>
	]
]
predictor = NetChain[{
	FlattenLayer[],
	LinearLayer[],
	Ramp,
	LinearLayer[],
	SoftmaxLayer[]
}]
res50 = NetChain[
	{extractor, predictor},
	"Input" -> NetEncoder[{"Image", {, }}],
	"Output" -> NetDecoder[{"Class", Append[cap /@ tags, _]}]
]
```

