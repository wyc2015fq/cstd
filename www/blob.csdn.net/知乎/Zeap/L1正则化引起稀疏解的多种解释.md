# L1正则化引起稀疏解的多种解释 - 知乎
# 

最近看知乎这个回答（[李强：2019 秋招的 AI 岗位竞争激烈吗？](https://www.zhihu.com/question/286925266/answer/502439994)）获得的启发，面试AI岗位的时候，比起只能画图解释l1正则可以引起稀疏性，如果能一下回答出多种解释方式（图，导数，概率论。。。），可以更惊艳面试官，所以网上搜集了下面的回答，真没想到l1正则有这么多种解释方式，被惊艳到了。所以整理了一下，希望对大家可以有帮助。其实知乎对这个问题已经有讨论了（[l1 相比于 l2 为什么容易获得稀疏解？](https://www.zhihu.com/question/37096933)） 我自己在总结一下，相当于写个小笔记吧。

**I：用图解释：**

L2正则相当于用圆去逼近目标，而L1正则相当于用菱形去逼近目标，所以更容易引起交点在坐标轴上即得到稀疏解。详情可以查看下面的博客：
[L1正则化的稀疏性解释 - 纯净的天空​vimsky.com](https://link.zhihu.com/?target=https%3A//vimsky.com/article/3852.html)
**II: 从导数角度解释：**

**1> **L2正则无法将目标函数的极值点拉拢到稀疏解上，而L1 正则因为L1导函数的特殊性从而可以在一定范围内将极值点直接拉拢到稀疏解答，详情可以查看下面的博客：
[L1正则为什么更容易获得稀疏解 - keep forward, go, go, go - CSDN博客​blog.csdn.net![图标](https://pic3.zhimg.com/v2-73ec5aaa429d225e971210917cd401aa_ipico.jpg)](https://link.zhihu.com/?target=https%3A//blog.csdn.net/b876144622/article/details/81276818)
这个答友将上面的现象画成了图，画的很棒，推荐一下：
[l1 相比于 l2 为什么容易获得稀疏解？​www.zhihu.com![图标](https://pic3.zhimg.com/40de2e79cf8af8a9f75ba2d48ae05f16_180x120.jpg)](https://www.zhihu.com/question/37096933/answer/70426653)
**2>** 如果考虑梯度下降，L1正则给与了更大的下降力度，从而更快收敛到悉数点上。详情可以看这个回答：
[l1 相比于 l2 为什么容易获得稀疏解？​www.zhihu.com![图标](https://pic4.zhimg.com/e6517774399f92619e598cab2a6501ff_180x120.jpg)](https://www.zhihu.com/question/37096933/answer/70494622)
**III: 从先验概率分布角度解释**： 

L2 正则相当于假设了参数是服从高斯分布的，而L1正则相当于假设了参数是服从拉普拉斯分布的，自然拉普拉斯分布比高斯分布更集中在0这个点上。详情可以看这个回答：
[l1 相比于 l2 为什么容易获得稀疏解？​www.zhihu.com![图标](https://pic3.zhimg.com/82ba0546d4713b242df43bfe2de96e22_180x120.jpg)](https://www.zhihu.com/question/37096933/answer/70668476)
最后推荐一下知乎在这个问题的讨论,其实上面的解释方式下面这个问题都有，感兴趣的可以深度挖掘一下：
[l1 相比于 l2 为什么容易获得稀疏解？​www.zhihu.com](https://www.zhihu.com/question/37096933)
以及一个总结的回答，笔记写的相当整洁漂亮，建议大家收藏：
[l1 相比于 l2 为什么容易获得稀疏解？​www.zhihu.com![图标](https://pic3.zhimg.com/v2-ecbbfb8519ea58a60ef845867f990b8e_ipico.jpg)](https://www.zhihu.com/question/37096933/answer/475278057)
欢迎大家关注我 [@Zeap](https://www.zhihu.com/people/08b0dcf08389c7e2ca1676442ef45079) 和非凸优化专栏[非凸优化学习之路](https://zhuanlan.zhihu.com/optimization)，一起努力呗，少年。

