# 如何理解非凸优化极值条件: 梯度= 0 & 二阶导> 0？ - 知乎
# 

**引子： ** 我们都知道优化问题最终希望找到全局最小值点，在凸函数下而衡量最小值最重要的标准就是极值的必要条件： ![\|\nabla f(x^\star)\| = 0](https://www.zhihu.com/equation?tex=%5C%7C%5Cnabla+f%28x%5E%5Cstar%29%5C%7C+%3D+0) ，而在非凸函数下，大家一般希望找到一个点 ![x^\star](https://www.zhihu.com/equation?tex=x%5E%5Cstar) ,能满足二阶极值必要条件： ![\|\nabla f(x^\star)\| = 0, \nabla^2 f(x^\star) \succcurlyeq 0](https://www.zhihu.com/equation?tex=%5C%7C%5Cnabla+f%28x%5E%5Cstar%29%5C%7C+%3D+0%2C+%5Cnabla%5E2+f%28x%5E%5Cstar%29+%5Csucccurlyeq+0) , 那么如何直观的理解这些极值条件，就是我今天想要分享的一点小小体会了。

另外：因为也是在接触，学习和尝试理解优化, 理解不对的地方还望大家指正。十分感谢！！

——————————————————————————————————————

在优化问题里，我们处理的问题是:
![](https://pic2.zhimg.com/v2-90307aae79c4ed6419be81f7143fcc35_b.jpg)
而我们希望找到的这个问题的全局最小值点 ![x^\star](https://www.zhihu.com/equation?tex=x%5E%5Cstar) ，对于任意 ![x \in \mathbb{R}^d](https://www.zhihu.com/equation?tex=x+%5Cin+%5Cmathbb%7BR%7D%5Ed) , 都有：
![](https://pic3.zhimg.com/v2-cc8c8080155cc3d75eb88c7e0e70f762_b.jpg)
然而，**我们无法遍历空间 ![\mathbb{R}^d](https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5Ed) 上所有的点**, 去确认我们确实得到了最小的点。在一个有穷多个点的 ![\mathbb{R}^d ](https://www.zhihu.com/equation?tex=%5Cmathbb%7BR%7D%5Ed+) 空间上，说要遍历简直是天方夜谭。

那么如何确保我们得到的点，就是最小值点呢？于是凸函数就出现了。

## Part I: 凸函数

最初的想法便是约束一下我们研究的函数。如果目标函数比较特殊，从而能有一些具体可行的方法来确保我们拿到点最小值点，于是凸函数便应运而生。 我们说一个函数是凸的，如果它满足：
![](https://pic1.zhimg.com/v2-9adfa595af677364a26dbb2a0ec0ceac_b.jpg)
凸函数的一个重要性质就是如果某个点的梯度为零，那么这个点一定是全局最小值点。我们只需将 ![x = x^\star](https://www.zhihu.com/equation?tex=x+%3D+x%5E%5Cstar) ， ![\nabla f(x^\star) = 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%5E%5Cstar%29+%3D+0) 代入上式即可得到：
![](https://pic1.zhimg.com/v2-720c1f293f32473134464a36c9b43658_b.jpg)
这刚好就是极小值的定义，空间上所有的点 多对应的函数值![f(y)](https://www.zhihu.com/equation?tex=f%28y%29) 都大于等于 ![f(x^\star)](https://www.zhihu.com/equation?tex=f%28x%5E%5Cstar%29) ,** 于是当我们检查我们拿到的点的梯度为零时便可以自信的宣传我们拿到了最小值点了。而算一个点的梯度往往比遍历空间所有的点要来的简单的多。**更细节的关于凸函数的讨论可以参照我之前写的那篇（[从Nesterov的角度看：我们为什么要研究凸优化？](https://zhuanlan.zhihu.com/p/27435669)）。

然后构成这个世界的不是只有凸函数，在Deep Learning 的浪潮下， 对非凸函数的处理显得尤为重要，其中最重要的一项便是先确定，优化一个非凸目标函数的时候，我们想要的结果，或者谁目标是什么？ 

## Part II: 非凸函数

对于一个非凸函数而言，函数图像崎岖突兀。 梯度为零的点，有可能是：
- 全局最小值点 （global minima）
- 局部最小值点 （local ninima）
- 鞍点 （saddle points） 

非凸函数是一个全局最小值点( global minima)与局部最小值点(local minima)并存，而且还有诸多的鞍点（saddle points）的函数地貌。 而且无论在全局最小值点上,局部最小值点上还是鞍点上，它们的梯度都为零。 这就提醒我们，梯度为零已经不能判别所获得的点是不是全局最优了。 *而且传统依靠梯度的算法 （gradient descent 以及诸多变种 ）都会卡在这些点上*。 

***但是这个时候传来一个好消息就是： 在挺多情况下，许多非凸函数没有局部最小值点， 或者说， 许多非凸函数局部最小值点就是全局最小值点。 这是一个令人振奋的消息，也就是说，如果我们能找到局部最小值点，那么我们就是找到了全局最小值点。 （PS. 可以想象sin(x),所有的局部最小值点都是全局最小值点）***

当然里面涉及到一个重要的问题就是 逃离鞍点 （escape saddle points）。 但这不是这篇文章的重点，我们先轻轻略过，以后有空再谈。 我们得先使我们的**目标清晰**，就是要定义局部最小值点和量化标准。 

## Part III: 局部最小值点

首先在最原始的定义就是在一个围绕我的小区域内，我是最小的。严格点来说，我们用 ![B(x^\star, \epsilon)](https://www.zhihu.com/equation?tex=B%28x%5E%5Cstar%2C+%5Cepsilon%29) 表示一个以 ![x^\star](https://www.zhihu.com/equation?tex=x%5E%5Cstar)为中心，半径为 ![\epsilon ](https://www.zhihu.com/equation?tex=%5Cepsilon+) 的球，那么局部最小值的定义就是，存在一个 ![\epsilon > 0](https://www.zhihu.com/equation?tex=%5Cepsilon+%3E+0) ,

使得：
![](https://pic4.zhimg.com/v2-ad4d94cfd2ce425bd5a75b8d3c8c47db_b.jpg)
然而这个定义也不好检测，因为即使这个球再小，里面也包含着无穷多的点。于是我们便常看到非凸优化算法了大家定义了这样一个标准， 我们希望找到一个![x^\star](https://www.zhihu.com/equation?tex=x%5E%5Cstar) , 它满足
![](https://pic4.zhimg.com/v2-80961ce96adbd4cced96812025709473_b.jpg)
即使要求梯度为零，Hessian半正定。（到底是正定还是半正定文章后面有个简短的讨论）。

如何直观这个标准，便是我今天最觉得有趣的了。我想从泰勒展开的角度聊一聊这个条件。

我们先对一个函数做二阶泰勒展开 （高阶的泰勒展开的推导方式可以看一看这个小笔记：[多元变量函数，泰勒如何展开？（泰勒展开）](https://zhuanlan.zhihu.com/p/32274749)）
![](https://pic1.zhimg.com/v2-cbd5f13bd65cc1f5792a113e0a0032ac_b.jpg)
里面 ![o(\|y-x\|^2)](https://www.zhihu.com/equation?tex=o%28%5C%7Cy-x%5C%7C%5E2%29) 指的是, 当一个![y ](https://www.zhihu.com/equation?tex=y+) 足够靠近 ![x](https://www.zhihu.com/equation?tex=x) 的时候比 ![\|y-x\|^2](https://www.zhihu.com/equation?tex=%5C%7Cy-x%5C%7C%5E2) 小许多许多的一个项。从展开中，我们可以看到，如果想让 ![x](https://www.zhihu.com/equation?tex=x) 成为一个局部最小值点，只要保证在 ![y ](https://www.zhihu.com/equation?tex=y+) 足够靠近 ![x](https://www.zhihu.com/equation?tex=x) 的时候恒有 ![\nabla f(x)^\top(y-x) + \frac{1}{2} (y-x)^\top \nabla^2 f(x) (y-x) + o(\|y-x\|^2) \geq 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%28y-x%29%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29+%5Cgeq+0) , 那么我们就一定有 ![f(y)\geq f(x)](https://www.zhihu.com/equation?tex=f%28y%29%5Cgeq+f%28x%29) . 然后如何实现这个条件呢？  

我们的先观察到一个事实就是当 ![x](https://www.zhihu.com/equation?tex=x) 足够小的时候，恒有 ![|x| > |x|^2 >|x|^3>\cdots](https://www.zhihu.com/equation?tex=%7Cx%7C+%3E+%7Cx%7C%5E2+%3E%7Cx%7C%5E3%3E%5Ccdots) 。然后对应到泰勒展开里面，我们有
![](https://pic2.zhimg.com/v2-720e5599d714df5aa857644ab6692c21_b.jpg)
 就是说当![y ](https://www.zhihu.com/equation?tex=y+) 足够靠近 ![x](https://www.zhihu.com/equation?tex=x) 的时候，![\nabla f(x)^\top(y-x) ](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+) 一定占主导地位, **它的符号就确定了整个增量的符号。**也就是说 ，如果 ![\nabla f(x)^\top(y-x) > 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%3E+0) ，那么一定有 ![\qquad \qquad\quad \quad \quad \nabla f(x)^\top(y-x) + \frac{1}{2} (y-x)^\top \nabla^2 f(x) (y-x) + o(\|y-x\|^2) > 0](https://www.zhihu.com/equation?tex=%5Cqquad+%5Cqquad%5Cquad+%5Cquad+%5Cquad+%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%28y-x%29%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29+%3E+0) ，

反之如果 ![\nabla f(x)^\top(y-x) < 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%3C+0) 那么一定有![\qquad \qquad\quad \quad \quad \nabla f(x)^\top(y-x) + \frac{1}{2} (y-x)^\top \nabla^2 f(x) (y-x) + o(\|y-x\|^2) < 0](https://www.zhihu.com/equation?tex=%5Cqquad+%5Cqquad%5Cquad+%5Cquad+%5Cquad+%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%28y-x%29%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29+%3C+0)

对于一个点 ![x](https://www.zhihu.com/equation?tex=x) , 它的梯度 ![\nabla f(x)](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29) 是固定的，而![y](https://www.zhihu.com/equation?tex=y)是在一个球里面的任意的点，于是我们可以随意选择方向，比如可以使 ![ y-x = -\nabla f(x)](https://www.zhihu.com/equation?tex=+y-x+%3D+-%5Cnabla+f%28x%29) ，那么无论球的半径多小，我们总有 ![\nabla f(x)^\top(y-x) = -\|\nabla f(x)\|^2 ](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%3D+-%5C%7C%5Cnabla+f%28x%29%5C%7C%5E2+) , 如果 ![ \nabla f(x) \neq 0 ](https://www.zhihu.com/equation?tex=+%5Cnabla+f%28x%29+%5Cneq+0+), 那么我们一定有 
![](https://pic1.zhimg.com/v2-19fd7446f9b96e964ae3b490bf3957a4_b.jpg)
从而导致：

![\qquad \qquad\quad \quad \quad \nabla f(x)^\top(y-x) + \frac{1}{2} (y-x)^\top \nabla^2 f(x) (y-x) + o(\|y-x\|^2) < 0](https://www.zhihu.com/equation?tex=%5Cqquad+%5Cqquad%5Cquad+%5Cquad+%5Cquad+%5Cnabla+f%28x%29%5E%5Ctop%28y-x%29+%2B+%5Cfrac%7B1%7D%7B2%7D+%28y-x%29%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29+%3C+0)

于是在任意小的球体里面都存在一个点使得 ![f(y) < f(x)](https://www.zhihu.com/equation?tex=f%28y%29+%3C+f%28x%29) 。 所以要想成为局部最小值点，一点要有 ![\nabla f(x) = 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29+%3D+0) .

以同样的方式，我们来讨论一下在梯度等于零之后，对于Hessian的要求又是什么了？首先 ![\nabla f(x) = 0](https://www.zhihu.com/equation?tex=%5Cnabla+f%28x%29+%3D+0) 之后，我们的泰勒展开就变成了：
![](https://pic2.zhimg.com/v2-83f07211ca1fb01b373ce925d835ab8d_b.jpg)
为了保证 ![f(y) \ge f(x)](https://www.zhihu.com/equation?tex=f%28y%29+%5Cge+f%28x%29) , 其实就是要求：

![\qquad \qquad \qquad \qquad \qquad \qquad (y-x)^\top \nabla^2 f(x)(y-x) + o(\|y-x\|^2) \ge 0](https://www.zhihu.com/equation?tex=%5Cqquad+%5Cqquad+%5Cqquad+%5Cqquad+%5Cqquad+%5Cqquad+%28y-x%29%5E%5Ctop+%5Cnabla%5E2+f%28x%29%28y-x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29+%5Cge+0)

如果 ![x](https://www.zhihu.com/equation?tex=x) 是标量，那么只需要 ![\nabla^2 f(x) > 0](https://www.zhihu.com/equation?tex=%5Cnabla%5E2+f%28x%29+%3E+0) 就可以了，这样二阶项就是 ![\nabla^2 f(x) （y-x）^2](https://www.zhihu.com/equation?tex=%5Cnabla%5E2+f%28x%29+%EF%BC%88y-x%EF%BC%89%5E2) ,它对于所有的 ![y](https://www.zhihu.com/equation?tex=y) 都是恒大于零的并且占主导地位，于是自然满足了我们的需求，从而得到了一个点作为极值点的充分条件，就是***梯度为零，Hessian 大于零*。**

我们往高阶扩展一下， 我们考虑 ![x](https://www.zhihu.com/equation?tex=x) 是高维向量的时候，什么时候才能保证对于任意的 ![y](https://www.zhihu.com/equation?tex=y) ,都有 ![（y-x）^\top \nabla^2 f(x) (y-x)](https://www.zhihu.com/equation?tex=%EF%BC%88y-x%EF%BC%89%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29) 恒大于零呢？其中 ![y,x](https://www.zhihu.com/equation?tex=y%2Cx) 是向量， ![\nabla^2 f(x) ](https://www.zhihu.com/equation?tex=%5Cnabla%5E2+f%28x%29+) 是以个矩阵。更简化一点，如果定义 ![z = y-x](https://www.zhihu.com/equation?tex=z+%3D+y-x) , 那么什么时候，对于任意的向量 ![z](https://www.zhihu.com/equation?tex=z) 都 ![z^\top \nabla^2f (x)z > 0](https://www.zhihu.com/equation?tex=z%5E%5Ctop+%5Cnabla%5E2f+%28x%29z+%3E+0) 呢？？这个形式看着多眼熟啊。  答案就是当矩阵是正定的时候么。 这就是正定矩阵的定义啊。于是我们就得到了，高维函数局部最小值点的条件了：
![](https://pic4.zhimg.com/v2-eb4d060664e57cca838de5d830e91c53_b.jpg)
也就是梯度为零，二阶导正定。然而其实还有一种特殊情况，就是如果二阶导是半正定的呢？也就是对于任意 ![y](https://www.zhihu.com/equation?tex=y) , 我们都有 ![（y-x）^\top \nabla^2 f(x) (y-x) \geq 0](https://www.zhihu.com/equation?tex=%EF%BC%88y-x%EF%BC%89%5E%5Ctop+%5Cnabla%5E2+f%28x%29+%28y-x%29+%5Cgeq+0) , 而不是严格大于零，特别是在等于零的时候，我们有 ![f(y) = f(x) + o(\|y-x\|^2)](https://www.zhihu.com/equation?tex=f%28y%29+%3D+f%28x%29+%2B+o%28%5C%7Cy-x%5C%7C%5E2%29) , ![f(y)](https://www.zhihu.com/equation?tex=f%28y%29) 和 ![f(x)](https://www.zhihu.com/equation?tex=f%28x%29) 的大小取决于最后的无穷小量，我们是无法判断的，那么我们该怎么办呢？这个留给大家思考。（Hint: 考虑更高阶的泰勒展开看看，嘿嘿）

**最后，我感觉吧，这样理解极值条件的核心观念就是： 用泰勒展开来看微小扰动后的函数值变化，如果全都会增加函数值而不是减小，那么这个点就是局部最小值点了。**

**体会很小，还望大家不要介意啊，在努力学习中。欢迎关注我（**[@Zeap](https://www.zhihu.com/people/08b0dcf08389c7e2ca1676442ef45079)**）和我的专栏（**[非凸优化学习之路](https://zhuanlan.zhihu.com/optimization)**），一起学习优化。**


