# 求最短路径算法_用户5706034127_新浪博客
|||
区分，负权边，负权环
，BellmanFord是以考虑至多k条路径为规则来dp的。
**Floyd：**，
其[状态转移方程](https://baike.baidu.com/item/%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB%E6%96%B9%E7%A8%8B)如下：
map[i,j]:=min{map[i,k]+map[k,j],map[i,j]}；
map[i,j]表示i到j的最短距离，K是穷举*i,j的[断点](https://baike.baidu.com/item/%E6%96%AD%E7%82%B9)*，map[n,n]初值应该为0，或者按照题目意思来做。
当然，如果这条路没有通的话，还必须特殊处理，比如没有map[i,k]这条路。
。
**Dijkstra**：是每次选取i能到达的路径中的最短路径，不能处理负权边，复杂度是**n^2**。因为有n次路径查找，每次需要遍历一遍N选出当前最小的路径，以及根据这个点，对其它路径进行更新。选最小路径可以使用堆来优化。对其它路径更新，和该点的出边有关。优化后是**O(E+VlgV)**。（堆优化这个部分，一个是将每次更新的距离直接push到堆里面，这就会有重复的，当你pop出重复的，忽略即可，而且你每push一次复杂度都是logN。第二种是每次更新，就像二叉堆调整一样，你调整更新的点的位置，每次更新也是logN）
**BellmanFord**：适用于权值有负值的图的单源最短路径，并且能够检测负圈，复杂度**O(VE)**。也是动态规划的思想，依次考虑起点s经过k条边，到达j的最短距离，首先是初始化为直连接，即经过1条边。求最多经过k边到达j的最短路径，要么等于最多经过k-1边的路径，要么等于a[j]
= a[i]_k-1 + e(i,j)，而a[i]_k-1一定是包含了k-1条边，否则，就违背了定义，就应该属于最多经过k-1边的路径的范畴。（因为没有过多的对，a[i]_k-1一定是包含了k-1条边，这个条件进行限定，所以效率不高，每次都要遍历所有的边，所以复杂度是VE，这也是下面SPFA改进的地方）
**SPFA**：从直连接开始，如果一个点周围点的路径权重变化了，这个点的路径才有可能变化。也就是每次只考虑路径变化的点，然后考虑他们附近的点是否可以被变化。参考**BellmanFord**的说明，故而**SPFA**的最坏情况和一样，是**O(VE)**。但是有个别细节可以优化，主要有SLF和LLL两个优化，所有变化的点都会存放在优先级队列中，但标准的设定不同。比如变化点中路径最短的点，排在最前面，路径最长的点排在最后面。也可以不放在优先级队列中，直接不做任何优先级处理。（SPFA的优先级队列也涉及到队列中更新，这个没关系，因为不用严格按照值的大小来排序，如果队列中有，则不插入即可）
SLF：Small Label First 策略，设要加入的节点是j，队首元素为i，若dist(j) <
dist(i)，则将j插入队首，否则插入队尾。
LLL：Large Label Last
策略，设队首元素为i，每次弹出时进行判断，队列中所有dist值的平均值为x，若dist(i)>x则将i插入到队尾，查找下一元素，直到找到某一i使得dist(i)<=x，则将i出对进行松弛操作。
**A*算法**：首先是估值函数F=G+H，G是已知实际s到k的距离，H是估计的k到e的距离。根据F的最小值选取下一个扩展点，进行扩展。已经走过的点放到闭集合里面，为走过的，已知G距离的点放到开集合里面。dj相当于只考虑G，即实际距离的最短。最佳优先搜索（BFS）只考虑H，是一个贪心算法，不保证得到最优解。A×就同时考虑两者。
启发式函数可以控制A*的行为：
- 
一种极端情况，如果h(n)是0，则只有g(n)起作用，此时A*演变成Dijkstra算法，这保证能找到最短路径。
- 
如果h(n)经常都比从n移动到目标的实际代价小（或者相等），则A*保证能找到一条最短路径。h(n)越小，A*扩展的结点越多，运行就得越慢。
- 
如果h(n)精确地等于从n移动到目标的代价，则A*将会仅仅寻找最佳路径而不扩展别的任何结点，这会运行得非常快。尽管这不可能在所有情况下发生，你仍可以在一些特殊情况下让它们精确地相等（译者：指让h(n)精确地等于实际值）。只要提供完美的信息，A*会运行得很完美，认识这一点很好。
- 
如果h(n)有时比从n移动到目标的实际代价高，则A*不能保证找到一条最短路径，但它运行得更快。
- 
另一种极端情况，如果h(n)比g(n)大很多，则只有h(n)起作用，A*演变成BFS算法。
　　所以我们得到一个很有趣的情况，那就是我们可以决定我们想要从A*中获得什么。理想情况下（注：原文为At
exactly the right
point），我们想最快地得到最短路径。如果我们的目标太低，我们仍会得到最短路径，不过速度变慢了；如果我们的目标太高，那我们就放弃了最短路径，但A*运行得更快。
在游戏中，A*的这个特性非常有用。例如，你会发现在某些情况下，你希望得到一条好的路径（"good"
path）而不是一条完美的路径（"perfect"
path）。为了权衡g(n)和h(n)，你可以修改任意一个。
注**:**在学术上，如果启发式函数值是对实际代价的低估，A*算法被称为简单的A算法（原文为simply
A）。然而，我继续称之为A*，因为在实现上是一样的，并且在游戏编程领域并不区别A和A*。

动态规划博大精深，想完全掌握是很难的，不过我们可以从一些简单的例子之中去体会她的奥妙。
不说废话、先来一个简单的例子吧：
longest path in DAG
Problem:
Given a weighted directed acyclic graph 
G=(V, E),  an vertex v,  where
each edge is assigned an integer weight,  find a
longest path in graph G
问题描述：
给一个带权有向无环图G=（V，E），找出这个图里的最长路径。
![](http://pic002.cnblogs.com/images/2011/348708/2011111219072059.png)
说实话初学者直接给出这个图会看蒙的、再看看问题，不知道从何下手。
好了，对上图做个简单的处理：
![](http://pic002.cnblogs.com/images/2011/348708/2011111219091180.png)
现在看起来是不是清晰多了呢
用dilg(v)表示 以点结尾的最长路径，现在考虑dilg(D), dilg(B), dilg(C)
dilg(D)=max{dilg(B)+1, dilg(C)+3}
来解释一下：点D的入度边有CD、BD。
以D结尾的最短路径必定经过C、D中的最后一点；如果是C点，则以dilg(C)+3(权值)定会大于等于dilg(D)+2(权值)
如果没能看懂，请注意dilg(V)的定义
对于任意的点V可以有如下表达式：
dilg(v)=max(u,v)∈E{dilg(u)+w(u,
v)}
这样、问题dilg(V)就会被转化为较小的子问题dilg(U)（当然，U是连入V的点）
任何一个问题都可以用这样的方式转化、变小。
但总不能无限变小啊，最后回成为最简单的问题。当有两个点，且其中的一个点入度为0的时候如图中的S-->C他们的最长距离就是
权值2。入门篇中说过，思考方向是从复杂到简单，而计算方向是从简单到复杂。
算法如下
Initialize all dilg(.) values to ∞;
1.Let S be the set of vertices with
indegree=0; 
////设集合S，里面的是入度为0的点
2.For each vertex v in S do　　　　　　　　　　　　
dilg(v)=0;
3. For each v∈V\S in Topological Sorting order
do　　　　//对于V中除S外的点、按照拓扑排序的顺序，依次求出最长路径并保存好
dilg(v)=max(u,v)∈E{dilg(u)+w(u,
v)}　　　　　　　　//拓扑排序可以简单的理解为从起点到终点的最短路径
4. Return the dilg(.) with maximum value.
现在是找到最长路径的大小了、但是如何得到最长路径呢？
只需做点小小的改动：
Dplongestpath(G)
Initialize all dilg(.) values to ∞;
Let S be the set of vertices with indegree=0;
for each vertex v in S do
dist(v)=0;
4. For each v∈V\S in Topological Sorting order do
dilg(v)=max(u,v)∈E{dilg(u)+w(u, v)}
let (u,v) be the edge to get the
maximum 
value;
dad(v)=u;
5. Return the dilg(.) with maximum value.


http://blog.csdn.net/xiazdong/article/details/8193680

对迪杰斯特拉算法不能有负权值边
Ford 弗洛里德算法，可以有负权值边。思想在于，一次求解，最多经过k个点后，i到j的最短距离是多少。
a[i][j] = min(a[i][j], a[i][k]+a[k][j])
其次，从源点s可达的所有顶点如果存在最短路径，则这些最短路径构成一个以s为根的最短路径树。Bellman-Ford算法的迭代松弛操作，实际上就是按顶点距离s的层次，逐层生成这棵最短路径树的过程。
在对每条边进行1遍松弛的时候，生成了从s出发，层次至多为1的那些树枝。也就是说，找到了与s至多有1条边相联的那些顶点的最短路径；对每条边进行第2遍松弛的时候，生成了第2层次的树枝，就是说找到了经过2条边相连的那些顶点的最短路径……。因为最短路径最多只包含|v|-1条边，所以，只需要循环|v|-1
次。
每实施一次松弛操作，最短路径树上就会有一层顶点达到其最短距离，此后这层顶点的最短距离值就会一直保持不变，不再受后续松弛操作的影响。（但是，每次还要判断松弛，这里浪费了大量的时间，这就是Bellman-Ford算法效率底下的原因，也正是SPFA优化的所在）

# [彻底弄懂最短路径问题](http://transcoder.tradaquan.com/tc?srd=1&dict=32&h5ad=1&bdenc=1&lid=14350672850558128935&nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_ytK1DK6mlrte4viZQRAWifgOXPTUS4dgTCcshsGwHCb0nhunM5X)
http://transcoder.tradaquan.com/tc?srd=1&dict=32&h5ad=1&bdenc=1&lid=14350672850558128935&nsrc=IlPT2AEptyoA_yixCFOxXnANedT62v3IEQGG_ytK1DK6mlrte4viZQRAWifgOXPTUS4dgTCcshsGwHCb0nhunM5X
SPFA   short path fast algorithm
用一个队列来进行维护。初始时将源加入队列。每次从队列中取出一个元素，并对所有与他相邻的点进行松弛，若某个相邻的点松弛成功，则将其入队。直到队列为空时算法结束；这个算法，简单的说就是队列优化的bellman-ford，利用了每个点不会更新次数太多的特点发明的此算法(看我上面那个图，只有相邻点更新了，该点才有可能更新) 
判断有无负环：如果某个点进入队列的次数超过N次则存在负环(SPFA无法处理带负环的图)，假设这个节点的入度是k(无向权则就是这个节点的连接的边)如果进入这个队列超过k,说明必然有某个边重复了，即成环；换一种思路：用DFS，假设存在负环a1->a2->…->an->a1。那么当从a1深搜下去时又遇到了a1，那么直接可以判断负环了所有用。当某个节点n次进入队列，则存在负环，此时时间复杂度为O(n*m),n为节点，m为边。
SPFA算法有两个优化算法
SLF 和 LLL： SLF：Small Label First
策略，设要加入的节点是j，队首元素为i，若dist(j)x则将i插入到队尾，查找下一元素，直到找到某一i使得dist(i)<=x，则将i出对进行松弛操作。
SLF 可使速度提高 15 ~ 20%；SLF + LLL 可提高约
50%。在实际的应用中SPFA的算法时间效率不是很稳定，为了避免最坏情况的出现，通常使用效率更加稳定的Dijkstra算法。个人觉得LLL优化每次要求平均值，不太好，为了简单，我们可以之间用c++STL里面的优先队列来进行SLF优化。
http://blog.csdn.net/b2b160/article/details/4057781
## 1.2Dijkstra算法与最佳优先搜索
Dijkstra算法从物体所在的初始点开始，访问图中的结点。它迭代检查待检查结点集中的结点，并把和该结点最靠近的尚未检查的结点加入待检查结点集。该结点集从初始结点向外扩展，直到到达目标结点。Dijkstra算法保证能找到一条从初始点到目标点的最短路径，只要所有的边都有一个非负的代价值。（我说“最短路径”是因为经常会出现许多差不多短的路径。）在下图中，粉红色的结点是初始结点，蓝色的是目标点，而类菱形的有色区域（注：原文是teal
areas）则是Dijkstra算法扫描过的区域。颜色最淡的区域是那些离初始点最远的，因而形成探测过程（exploration）的边境（frontier）：
![](http://theory.stanford.edu/~amitp/game-programming/a-star/dijkstra.png)
　　最佳优先搜索（BFS）算法按照类似的流程运行，不同的是它能够评估（称为启发式的）任意结点到目标点的代价。与选择离初始结点最近的结点不同的是，它选择离目标最近的结点。BFS不能保证找到一条最短路径。然而，它比Dijkstra算法快的多，因为它用了一个启发式函数（heuristic
function）快速地导向目标结点。例如，如果目标位于出发点的南方，BFS将趋向于导向南方的路径。在下面的图中，越黄的结点代表越高的启发式值（移动到目标的代价高），而越黑的结点代表越低的启发式值（移动到目标的代价低）。这表明了与Dijkstra 算法相比，BFS运行得更快。
![](http://theory.stanford.edu/~amitp/game-programming/a-star/best-first-search.png)
　　然而，这两个例子都仅仅是最简单的情况——地图中没有障碍物，最短路径是直线的。现在我们来考虑前边描述的凹型障碍物。Dijkstra算法运行得较慢，但确实能保证找到一条最短路径：
![](http://theory.stanford.edu/~amitp/game-programming/a-star/dijkstra-trap.png)
　　另一方面，BFS运行得较快，但是它找到的路径明显不是一条好的路径：
![](http://theory.stanford.edu/~amitp/game-programming/a-star/best-first-search-trap.png)
　　问题在于BFS是基于贪心策略的，它试图向目标移动尽管这不是正确的路径。由于它仅仅考虑到达目标的代价，而忽略了当前已花费的代价，于是尽管路径变得很长，它仍然继续走下去。
　　结合两者的优点不是更好吗？1968年发明的A*算法就是把启发式方法（heuristic
approaches）如BFS，和常规方法如Dijsktra算法结合在一起的算法。有点不同的是，类似BFS的启发式方法经常给出一个近似解而不是保证最佳解。然而，尽管A*基于无法保证最佳解的启发式方法，A*却能保证找到一条最短路径。
## 1.3A*算法
　　我将集中讨论A*算法。A*是路径搜索中最受欢迎的选择，因为它相当灵活，并且能用于多种多样的情形之中。
　　和其它的图搜索算法一样，A*潜在地搜索图中一个很大的区域。和Dijkstra一样，A*能用于搜索最短路径。和BFS一样，A*能用启发式函数（注：原文为heuristic）引导它自己。在简单的情况中，它和BFS一样快。
![](http://theory.stanford.edu/~amitp/game-programming/a-star/a-star.png)
　　在凹型障碍物的例子中，A*找到一条和Dijkstra算法一样好的路径：
![](http://theory.stanford.edu/~amitp/game-programming/a-star/a-star-trap.png)
　　成功的秘决在于，它把Dijkstra算法（靠近初始点的结点）和BFS算法（靠近目标点的结点）的信息块结合起来。在讨论A*的标准术语中，g(n)表示从初始结点到任意结点n的代价，h(n)表示从结点n到目标点的启发式评估代价（heuristic
estimated
cost）。在上图中，yellow(h)表示远离目标的结点而teal(g)表示远离初始点的结点。当从初始点向目标点移动时，A*权衡这两者。每次进行主循环时，它检查f(n)最小的结点n，其中f(n)
= g(n) + h(n)。
