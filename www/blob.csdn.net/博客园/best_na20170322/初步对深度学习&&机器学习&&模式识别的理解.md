# 初步对深度学习&&机器学习&&模式识别的理解 - best_na20170322 - 博客园




- [博客园](https://www.cnblogs.com/)
- [首页](https://www.cnblogs.com/believe-in-me/)
- [新随笔](https://i.cnblogs.com/EditPosts.aspx?opt=1)
- [联系](https://msg.cnblogs.com/send/best_na20170322)
- [管理](https://i.cnblogs.com/)
- [订阅](https://www.cnblogs.com/believe-in-me/rss)![订阅](https://www.cnblogs.com/images/xml.gif)





# [初步对深度学习&&机器学习&&模式识别的理解](https://www.cnblogs.com/believe-in-me/p/6601226.html)





本文内容来自：http://www.csdn.net/article/2015-03-24/2824301

首先模式识别是最古老的，机器学习是最基础的（当下初创公司和研究实验室的热点领域之一）。而深度学习是非常崭新和有影响力的前沿领域。可以看一下下图的谷歌趋势图。

![](https://images2015.cnblogs.com/blog/1131958/201703/1131958-20170322174523033-1162253941.jpg)

模式识别是70年代和80年代非常流行的一个术语。它强调的是如何让一个计算机程序去做看起来很智能的事例如识别“3”这个数字。而且在融入了很多的智慧和直觉后，人们也的确构建了这样的一个程序。例如，区分“3”和“B”或者“3”和“8”。早在以前，大家也不会去关心你是怎么实现的，只要这个机器不是由人躲在盒子里面伪装的就好（图2）。不过，如果你的算法对图像应用了一些像滤波器、边缘检测和形态学处理等等高大上的技术后，模式识别社区肯定就会对它感兴趣。光学字符识别就是从这个社区诞生的。因此，把模式识别称为70年代，80年代和90年代初的“智能”信号处理是合适的。决策树、启发式和二次判别分析等全部诞生于这个时代。而且，在这个时代，模式识别也成为了计算机科学领域的小伙伴搞的东西，而不是电子工程。从这个时代诞生的模式识别领域最著名的书之一是由Duda & Hart执笔的“模式识别（Pattern Classification）”。对基础的研究者来说，仍然是一本不错的入门教材。不过对于里面的一些词汇就不要太纠结了，因为这本书已经有一定的年代了，词汇会有点过时。

在90年代初，人们开始意识到一种可以更有效地构建模式识别算法的方法，那就是用数据（可以通过廉价劳动力采集获得）去替换专家（具有很多图像方面知识的人）。因此，我们搜集大量的人脸和非人脸图像，再选择一个算法，然后冲着咖啡、晒着太阳，等着计算机完成对这些图像的学习。这就是机器学习的思想。“机器学习”强调的是，在给计算机程序（或者机器）输入一些数据后，它必须做一些事情，那就是学习这些数据，而这个学习的步骤是明确的。相信我，就算计算机完成学习要耗上一天的时间，也会比你邀请你的研究伙伴来到你家然后专门手工得为这个任务设计一些分类规则要好。

![](http://img.ptcms.csdn.net/article/201503/24/5510f5a57e7ea_middle.jpg?_=28133)

在21世纪中期，机器学习成为了计算机科学领域一个重要的研究课题，计算机科学家们开始将这些想法应用到更大范围的问题上，不再限于识别字符、识别猫和狗或者识别图像中的某个目标等等这些问题。研究人员开始将机器学习应用到机器人（强化学习，操控，行动规划，抓取）、基因数据的分析和金融市场的预测中。另外，机器学习与图论的联姻也成就了一个新的课题---图模型。每一个机器人专家都“无奈地”成为了机器学习专家，同时，机器学习也迅速成为了众人渴望的必备技能之一。然而，“机器学习”这个概念对底层算法只字未提。我们已经看到凸优化、核方法、支持向量机和Boosting算法等都有各自辉煌的时期。再加上一些人工设计的特征，那在机器学习领域，我们就有了很多的方法，很多不同的思想流派，然而，对于一个新人来说，对特征和算法的选择依然一头雾水，没有清晰的指导原则。但，值得庆幸的是，这一切即将改变……

快进到今天，我们看到的是一个夺人眼球的技术---深度学习。而在深度学习的模型中，受宠爱最多的就是被用在大规模图像识别任务中的卷积神经网络（Convolutional Neural Nets，CNN），简称ConvNets。

![](http://img.ptcms.csdn.net/article/201503/24/5510f5cdaa82f_middle.jpg?_=1645)

图4 ConvNet框架（图来源于[Torch的教程](http://torch.cogbits.com/doc/tutorials_supervised/)）

深度学习强调的是你使用的模型（例如深度卷积多层神经网络），模型中的参数通过从数据中学习获得。然而，深度学习也带来了一些其他需要考虑的问题。因为你面对的是一个高维的模型（即庞大的网络），所以你需要大量的数据（大数据）和强大的运算能力（图形处理器，GPU）才能优化这个模型。卷积被广泛用于深度学习（尤其是计算机视觉应用中），而且它的架构往往都是非浅层的。

如果你要学习Deep Learning，那就得先复习下一些线性代数的基本知识，当然了，也得有编程基础。我强烈推荐Andrej Karpathy的博文：“[神经网络的黑客指南](http://karpathy.github.io/neuralnets/)”。另外，作为学习的开端，可以选择一个不用卷积操作的应用问题，然后自己实现基于CPU的反向传播算法。














