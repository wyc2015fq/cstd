# 朴素贝叶斯分类 - Orisun - 博客园







# [朴素贝叶斯分类](https://www.cnblogs.com/zhangchaoyang/articles/2586402.html)





先上问题吧，我们统计了14天的气象数据(指标包括outlook，temperature，humidity，windy)，并已知这些天气是否打球(play)。如果给出新一天的气象指标数据:sunny,cool,high,TRUE，判断一下会不会去打球。

table 1
|**outlook**|**temperature**|**humidity**|**windy**|**play**|
|----|----|----|----|----|
|sunny|hot|high|FALSE|no|
|sunny|hot|high|TRUE|no|
|overcast|hot|high|FALSE|yes|
|rainy|mild|high|FALSE|yes|
|rainy|cool|normal|FALSE|yes|
|rainy|cool|normal|TRUE|no|
|overcast|cool|normal|TRUE|yes|
|sunny|mild|high|FALSE|no|
|sunny|cool|normal|FALSE|yes|
|rainy|mild|normal|FALSE|yes|
|sunny|mild|normal|TRUE|yes|
|overcast|mild|high|TRUE|yes|
|overcast|hot|normal|FALSE|yes|
|rainy|mild|high|TRUE|no|

这个问题可以用[决策树](http://www.cnblogs.com/zhangchaoyang/articles/2196631.html)的方法来求解，当然我们今天讲的是朴素贝叶斯法。这个一”打球“还是“不打球”是个两类分类问题，实际上朴素贝叶斯可以没有任何改变地解决多类分类问题。决策树也一样，它们都是有导师的分类方法。

朴素贝叶斯模型有两个假设：所有变量对分类均是有用的，即输出依赖于所有的属性；这些变量是相互独立的，即不相关的。之所以称为“朴素”，就是因为这些假设从未被证实过。

注意上面每项属性（或称指标）的取值都是离散的，称为“标称变量”。

step1.对每项指标分别统计：在不同的取值下打球和不打球的次数。

table 2
|**outlook**|**temperature**|**humidity**|**windy**|**play**| | | | | | | | | |
|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
||yes|no||yes|no||yes|no||yes|no|yes|no|
|sunny|2|3|hot|2|2|high|3|4|FALSE|6|2|9|5|
|overcast|4|0|mild|4|2|normal|6|1|TRUR|3|3|||
|rainy|3|2|cool|3|1|||||||||

step2.分别计算在给定“证据”下打球和不打球的概率。

这里我们的“证据”就是sunny,cool,high,TRUE，记为E，E1=sunny,E2=cool,E3=high,E4=TRUE。

A、B相互独立时，由：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}P(A\cap{B})=P(A)*P(B|A)=P(B)*P(A|B))

得贝叶斯定理：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}P(A|B)=\frac{P(B|A)P(A)}{P(B)})

得：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}P(yes|E)=\frac{P(E|yes)P(yes)}{P(E)}\cdots\cdots(1))

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}P(no|E)=\frac{P(E|no)P(no)}{P(E)})

又因为4个指标是相互独立的，所以

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}P(E|yes)=P(E1|yes)P(E2|yes)P(E3|yes)P(E4|yes))

我们只需要比较P(yes|E)和P(no|E)的大小，就可以决定打不打球了。所以分母P(E)实际上是不需要计算的。

P(yes|E)*P(E)=2/9×3/9×3/9×3/9×9/14=0.0053

P(no|E)*P(E)=3/5×1/5×4/5×3/5×5/14=0.0206

所以不打球的概率更大。

### 零频问题

注意table 2中有一个数据为0，这意味着在outlook为overcast的情况下，不打球和概率为0，即只要为overcast就一定打球，这违背了朴素贝叶斯的基本假设：输出依赖于所有的属性。

数据平滑的方法很多，最简单最古老的是拉普拉斯估计（Laplace estimator）--即为table2中的每个计数都加1。它的一种演变是每个计数都u（0<u<1）。

Good-Turing是平滑算法中的佼佼者，有兴趣的可以了解下。我在作[基于隐马尔可夫的词性标](http://www.cnblogs.com/zhangchaoyang/articles/2567610.html)注时发现Good-Turing的效果非常不错。
对于任何发生r次的事件，都假设它发生了r*次：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}r^*=(r+1)\frac{n_{r+1}}{n_r})

nr是历史数据中发生了r次的事件的个数。

### 数值属性

当属性的取值为连续的变量时，称这种属性为“数值属性“。通常我们假设数值属性的取值服从正态分布。
|**outlook**|**temperature**|**humidity**|**windy**|**play**| | | | | | | | | |
|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
||yes|no||yes|no||yes|no||yes|no|yes|no|
|sunny|2|3||83|85||86|85|FALSE|6|2|9|5|
|overcast|4|0||70|80||96|90|TRUR|3|3|||
|rainy|3|2||68|65||80|70||||||
|||||64|72||65|95||||||
|||||69|71||70|91||||||
|||||75|||80|||||||
|||||75|||70|||||||
|||||72|||90|||||||
|||||81|||75|||||||
|sunny|2/9|3/5|mean value|73|74.6|mean value|79.1|86.2|FALSE|6/9|2/5|9/15|5/14|
|overcast|4/9|0/5|deviation|6.2|7.9|deviation|10.2|9.7|TRUR|3/9|3/5|||

正态分布的概率密度函数为：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-u)^2}{2\sigma^2}}\qquad\cdots\cdots(2))

现在已知天气为：outlook=overcast，temperature=66，humidity=90，windy=TRUE。问是否打球？

f(温度=66|yes)=0.0340

f(湿度=90|yes)=0.0221

yes的似然=2/9×0.0340×0.0221×3/9×9/14=0.000036

no的似然=3/5×0.0291×0.0380×3/5×9/14=0.000136

不打球的概率更大一些。

### 用于文本分类

朴素贝叶斯分类是一种基于概率的有导师分类器。

词条集合W，文档集合D，类别集合C。

 根据（1）式（去掉分母）得文档d属于类别cj的概率为：

![](http://www.forkosh.com/mathtex.cgi?\dpi{150}p(c_j|d)\propto{p(c_j)\prod^{|d|}_{k=1}{p(w_{d,k}|c_j)}}\qquad\cdots\cdots(3))

p(cj)表示类别j出现的概率，让属于类别j的文档数量除以总文档数量即可。

而已知类别cj的情况下词条wt出现的后验概率为：类别cj中包含wt的文档数目  除以 类别cj中包含的文档总数目 。

### 结束语

实践已多次证明，朴素贝叶斯在许多数据集上不逊于甚至优于一些更复杂的分类方法。这里的原则是：优先尝试简单的方法。

机器学习的研究者尝试用更复杂的学习模型来得到良好的结果，许多年后发现简单的方法仍可取得同样甚至更好的结果。












