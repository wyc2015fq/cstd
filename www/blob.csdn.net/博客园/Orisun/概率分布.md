# 概率分布 - Orisun - 博客园







# [概率分布](https://www.cnblogs.com/zhangchaoyang/articles/3405093.html)





**期望**

介绍各个分布之前先给出期望的定义。如果$\int_{-\infty}^{\infty}|x|f(x)dx<\infty$，那么$E(x)=\int_{-\infty}^{\infty}xf(x)dx$；如果积分发散，则期望不存在（无意义）。

函数的期望。如果$Y=g(X)$，对于离散变量$E(Y)=\sum_x{g(x)p(x)}$，对于连续变量$E(Y)=\int_{-\infty}^{\infty}g(x)f(x)dx$。注意函数的期望不一定等于期望的函数，即$E[g(x)]\ne{g[E(x)]}$。如果X和Y是相互独立的随机变量，g和h是固定的函数，那么\begin{equation}E[g(X)h(Y)]=E[g(X)]E[h(Y)],\;if\;g(X)和h(Y)的期望存在\label{exp_two}\end{equation}作为公式$\eqref{exp_two}$的特例，$E(XY)=E(X)E(Y)$。

方差是一种特殊的期望\begin{equation}Var(X)=E{[X-E(X)]^2}=E(X^2)-[E(X)]^2\label{var}\end{equation}

对\ref{var}式作一下说明，由于$E(x)$已经是常数，常数的期望是它本身，所以$E(E(x))=E(x)$

**伯努利分布**

伯努利随机变量的取值只有两个：0和1。 \begin{equation}p(1)=p\label{bernolli}\end{equation}

## 二项分布

令$x_1,x_2,...,x_n$是相互独立的伯努得随机变量，那么\begin{equation}y=x_1+x_2+...+x_n\label{binomial}\end{equation}是一个二项随机变量。\begin{equation}p(y=k)={n \choose k}p^k(1-p)^{n-k}\label{binomial=k}\end{equation}其中$p$就是公式\eqref{bernolli}中的$p$，所以公式\eqref{bernolli}表示一次试验成功的概率，而公式\eqref{binomial=k}表示k次试验成功的概率。

## 多项分布

二项分布每次实验结果只有2种，如果有多种那就变成了多项分布。设一共有r种结果，每种结果出现的概率依次是$p_1,p_2,...p_r$，进行发n次实验，第i种结果出现的次数为$n_i$，这样的概率是\begin{equation}p(n_1,n_2,\cdots{n_r})=\frac{n!}{n_1!n_2!\cdots{n_r!}}p_1^{n_1}p_2^{n_2}\cdots{p_r^{n_r}}\label{multinomial}\end{equation}n个对象分成r个类别，第i类有$n_i$个对象，这种分类方式共有\begin{equation}\frac{n!}{n_1!n_2!\cdots{n_r!}}\end{equation}种，这个式子正是多项系数\begin{equation}(X_1+X_2+\cdots+X_r)^n=\sum{(\frac{n!}{n_1!n_2!\cdots{n_r!}})X_1^{n_1}X_2^{n_2}\cdots{X_r^{n_r}}}\end{equation}

## 几何分布

连续若干次相互独立的伯努利试验，第g次才成功。则\begin{equation}p(g=k)=(1-p)^{k-1}p\label{geometric}\end{equation}期望是$\frac{1}{p}$

## 负二项分布

负二项分布是几何分布的一般化。连续若干次相互独立的伯努利试验，直到成功了r次为止，共进行了k次试验。\begin{equation}p(n=k)={k-1 \choose r-1}p^{r-1}(1-p)^{k-r}p\label{negative_binomial}\end{equation}负二项分布也可以看成是r次独立的几何随机变量的和：第1次成功时经历的试验次数$g_1$加上第1次成功后第2次成功又经历的试验次数$g_2$加上……所以\begin{equation}n=g_1+g_2+...+g_r\end{equation}

## 超几何分布

共有n个球，其中黑球r个，白球n-r个。从中取出m个球，X表示抽到黑球的个数。\begin{equation}p(X=k)=\frac{{r \choose k}{n-r \choose m-k}}{n \choose m}\label{hyper_geometric}\end{equation}在估计野生动物数量时经常采用标记重捕法：捕获r只动物，将它们作上标记后释放。这之后再捕获m个动物，发现其中有k个带有标记，请估计动物的总数n。这里我们采用极大似然估计法，它将使观测结果出现可能性最大的n作为其估计值。根据超几何分布我们知道出现观测结果的概率为$$L_n=\frac{{r \choose k}{n-r \choose m-k}}{n \choose m}$$"显然易见”，该似然函数随着n的增长先单调上长再单调下降，为求得似然函数的极大值点很容易想到的是令一阶导数为0。然而一阶导数并不好求，我们转把似然函数转换成对数函数后再来求一阶导数，不幸的是这种方法仍然不便于计算。我们考虑似然函数的连续项比值$$\frac{L_n}{L_{n-1}}=\frac{(n-m)(n-r)}{n(n+k-m-r)}$$该比值项为1时似然函数取得最大值，得$$n=\frac{rm}{k}$$

## 自然常数e

下面的几种概率密度函数中都包含e，所以我们先来剖析一下e到底是什么。

自然常数e和圆周率$\pi$是常见的超越数。

来看几个跟e有关的公式。

\begin{equation}e=\lim_{x\rightarrow\infty}{(1+\frac{1}{x})^x}\label{e}\end{equation}

\begin{equation}e=\sum_{x=0}^{\infty}{\frac{1}{x!}}\end{equation}

\begin{equation}(a^x)'=a^xlna\end{equation}

\begin{equation}(log_{a}{x})'=\frac{log_{a}{e}}{x}\end{equation}

利用公式\eqref{e}我们来具体说下e到底是什么。假设一个细胞经过1个单位时间分裂成两个细胞。即经过1个单位时间后细胞数目比原先多了1倍，经过1/2个单位时间后细胞数目比原先多了1/2倍，经过1/3个单位时间后细胞数目比原先多了1/3倍，经过1/n个单位时间后细胞数目比原先多了1/n倍。则我们用下面的公式计算单位时间后的细胞数目是当前的几倍：

$(1+\frac{1}{1})^1$

现在假设一个细胞还是需要1个单位时间才能分裂成两个细胞，只是经过1/2单位时间后，正在分裂中的细胞又开始新的分裂过程。1个单位时间可以分成前后两个阶段，每个阶段末的细胞数目都是阶段初的$1+\frac{1}{2}$倍。我们用下面的公式计算单位时间后的细胞数目是当前的几倍：

$(1+\frac{1}{2})^2$

如果经过1/n个单位时间后细胞就具有分裂能力，则我们用下面的公式计算单位时间后的细胞数目是当前的几倍：

\begin{equation}(1+\frac{1}{n})^n\label{e_lim}\end{equation}

当细胞具有分裂能力的时间间隔足够短，即$n\rightarrow\infty$时，公式\eqref{e_lim}就等于e。由此得出：e是单位时间内持续的翻番增长所能达到的极限值。

## 泊松分布

当满足以下前提条件时，泊松变量表示单位时间内发生的次数。
- 不同子区间内了生与否相互独立
- 每个子区间发生的概率相同
- 事件不会同时发生

\begin{equation}P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},k=0,1,2......\label{poisson}\end{equation}注意到\begin{equation}e^{\lambda}=\sum_{k=0}^{\infty}{\frac{\lambda^k}{k!}}\end{equation}

泊松分布的期望和方差都是$\lambda$。

泊松过程：$S_1,S_2,...S_N$是S的互不相交的子集，这些子集上发生的事件数$N_1,N_2,...N_3$是相互独立的随机变量，且服从参数为$\lambda|S_1|,\lambda|S_2|...\lambda|S_N|$的泊松分布，即期望与区间大小成正比例。

如果X服从参数为$\lambda$的泊松分布，Y服从参数为$\mu$的泊松分布，且X和Y相互独立，那么X+Y服从参数为$\lambda+\mu$的泊松分布。

$Poisson(\lambda)$分布可以看成是二项分布$B(n,p)$在$np=\lambda,n\rightarrow\infty$条件下的极限分布。

## 指数分布

指数分布常用来描述生命周期或等待时间，变量一般用t表示。

密度函数$f(t)=\begin{cases}\lambda{e}^{-\lambda{t}},&\mathrm{if}\;t\ge{0}\\0,&\mathrm{if}\;t<0\end{cases}$

$\lambda$越大，密度函数下降得越快。

密度积累函数$F(t)=P(T<t)=1-e^{-\lambda{t}}$，即\begin{equation}P(T>t)=e^{-\lambda{t}}\label{power}\end{equation}一般地，泊松过程两次事件发生的时间间隔是独立同分布的指数随机变量。这里我们可以简单推导一下，令泊松过程两次事件发生的时间间隔是T，$P(T>t)=P((t_0,t_0+t)内没有事件发生)$，因为在长度为$(t_0,t_0+t)$的时长内事件发生的个数服从参数为$\lambda{t}$的泊松分布，由公式\eqref{poisson}发生次数为0的概率是$e^{-\lambda{t}}$，即$P(T>t)=e^{-\lambda{t}}$，这和公式\eqref{power}是吻合的。

指数分布的期望是$\frac{1}{\lambda}$。

## 正态分布

密度函数\begin{equation}f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\label{gauss}\end{equation}独立正态随机变量的和还是正态随机变量。

这里给出一种生成正态随机变量的方法。首先独立生成[0,1]上的均匀随机变量$U_1$和$U_2$，则$X=\sqrt{-2log{U_1}}cos(2\pi{U_2})和Y=\sqrt{-2log{U_1}}sin(2\pi{U_2})$是相互独立的标准正态随机变量，这种方法叫做极化方法(polar method)。

## 中心极限定理

令$X_1,X_2,\cdots$是均值为0方差为$\sigma^2$的独立随机变量序列，具有相同的分布函数F，矩生成函数M在零点附近有定义，令\begin{equation}S_n=\sum_{i=1}^{n}X_i\end{equation}那么\begin{equation}\lim_{n\rightarrow\infty}P(\frac{S_n}{\sigma\sqrt{n}}\le{x})=\Phi(x),-\infty<x<\infty\end{equation}其中$\Phi(x)$是正态分布的累积密度函数。暂且不论矩生成函数是什么。

粗略来看中心极限定理是说，如果一个随机变量是许多独立同分布的随机变量之和，那么它就近似服从正态分布。所以说正态分布是分布之王。

因为二项随机变量是独立的伯努力随机变量之和，由中心极限定理得，二项分布可用正态分布来近似。当$p=\frac{1}{2}$时近似得最好。常用的经验方法是np>5且n(1-p)>5时，近似比较合理。

## 柯西分布

如果X和Y是独立的标正态随机变量，则$Z=\frac{Y}{X}$服从柯西分布。\begin{equation}f(z)=\frac{1}{\pi(z^2+1)},-\infty<z<\infty\label{ksi}\end{equation}柯西密度与标准正态密度相似，也关于0点对称，似乎表明E(Z)=0，然而$\int_{-\infty}^{\infty}\frac{|z|}{\pi(1+z^2)}dz=\infty$，期望不存在，究其原因在于柯西密度衰减得太慢，以至于z取较大值时的概率不能忽略不计。柯西密度尾部以速度$x^{-2}$衰减，正态密度尾部以速度$e^{-x^2}$衰减，正态密度衰减得快一些。

## 伽马分布

先介绍下伽马函数：$\Gamma(x)=(x-1)!=\int_{0}^{\infty}\mu^{x-1}e^{-\mu}d\mu,x>0$

伽马函数把阶乘运算从整数拓展到了实数。

不仅如此，利用伽马函数还可以求一般函数的分数阶导数。我们看一下$x^n$的各阶导数：

1阶导数--$nx^{n-1}$

2阶导数--$n(n-1)x^{n-2}$

k阶导数--$n(n-1)\cdots{(n-k+1)}x^{n-k}=\frac{n!}{(n-k)!}x^{n-k}=\frac{\Gamma(n+1)}{\Gamma(n-k+1)}x^{n-k}$

$x^n$的分数阶导数就可以用伽马函数来计算。对于一般函数f(x)可以通过Taylor展开式把它表示成幂级数的形式，借助于$x^n$的分数阶导数就可以求出任意函数的分数阶导数。

伽马密度函数\begin{equation}g(t)=\frac{\lambda^{\alpha}}{\Gamma(\alpha)}t^{\alpha-1}e^{-\lambda{t}},t\ge0\label{gamma}\end{equation}参数$\alpha$为形状参数，$\lambda$为尺度参数。变动$\alpha$改变改变密度函数的形状，改变$\lambda$改变测量单位。

任何非负随机变量的密度函数都可以用伽马密度函数来模拟，就看$\alpha$和$\lambda$怎么拟合了。

$\alpha=1$时伽马密度为指数密度，伽马密度的期望是$\frac{\alpha}{\lambda}$，所以指数分布的期望是$\frac{1}{\lambda}$。

参数为$\lambda$的n个独立指数随机变量的和服从参数为n和$\lambda$的伽马分布，又因为泊松过程中两个连续随机变量发生的时间间隔服从指数分布，因此在泊松过程中，n个连续事件发生的时间间隔服从伽马分布。

## 贝塔分布

\begin{equation}f(u)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\mu^{\alpha-1}(1-\mu)^{\beta-1},0\le\mu\le1\end{equation}

Beta分布的概率密度图像也是个百变星君，调整$\alpha$和$\beta$它可以变成凸的、凹的、单调上升的、单调下降的，可以是曲线，也可以是直线。均匀分布也是一种特殊的Beta分布。

设x的密度函数为f(x)，累积密度函数为F(x)，$X_{(1)}<X_{(2)}<X\cdots<X_{(n)}$为顺序统计量，则由概率的乘法定理很容易得出$X_{(k)}$的密度是:\begin{equation}f_k(x)=\frac{n!}{(k-1)!(n-k)!}f(x)F(x)^{k-1}(x)[1-F(x)]^{n-k}\end{equation}特别地，当x是[0,1]上的均匀分布时，f(x)=1,F(x)=x，则\begin{equation}f_k(x)=\frac{n!}{(k-1)!(n-k)!}x^{k-1}(x)[1-x]^{n-k}\end{equation}这就是一个贝塔密度。$R=X_{(n)}-X_{(1)}$称为极差。

## 卡方分布

 $X_1,X_2,\cdots,X_n$是独立的标准正态随机变量，则$X_1^2+X_2^2+\cdots+X_n^2$是自由度为n的卡方分布，记为$\chi_n^2$。

如果U、V独立，且$U\sim\;\chi_n^2,V\sim\;\chi_m^2$，那么$U+Y\sim\;\chi_{m+n}^2$

自由度为n的卡方分布是$\alpha=\frac{n}{2}$和$\lambda=\frac{1}{2}$的伽马分布，由公式$\eqref{gamma}$可推出卡方密度\begin{equation}f(x)=\frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2},x\ge0\label{chi}\end{equation}

## t分布

如果$Z\sim\;N(0,1),U\sim\;\chi_n^2$，且Z和U独立，则$\frac{Z}{\sqrt{U/n}}$是自由度为n的t分布。\begin{equation}f(t)=\frac{\Gamma(\frac{n+1}{2})}{\sqrt{n\pi}\Gamma(\frac{n}{2})}(1+\frac{t^2}{n})^{-\frac{n+1}{2}}\label{t}\end{equation}t分布关于0点对称。当自由度趋于无穷大时，t分布趋于标准正态分布。事实上，自由度超过20或30时，两个分布就非常接近。

## F分布

如果U和V是自由度分别为m和n的独立卡方随机变量，

\begin{equation}W=\frac{U/m}{V/n}\label{f}\end{equation}为自由度为m和n的F分布，记作$F_{m,n}$

由t分布的定义易证：$t_n^2\sim\;F_{1,n}$












