# 对偶传播神经网络 - Orisun - 博客园







# [对偶传播神经网络](https://www.cnblogs.com/zhangchaoyang/articles/2591232.html)





对偶传播神经网络（Counter-Propagation Network,CPN）能存储二进制或模拟值的模式对，因此这种网络模型也可用于联想存储、模式分类、函数逼近、统计分析和数据压缩等功能。

对偶传播神经网络的拓扑结构跟误差反向传播（BP）网络的一样，不同之处在于，CPN采用两个阶段来分别训练竞争层的内星权向量和外星权向量，即第一阶段完全不顾输出层，采用SOFM的方法来训练竞争层的内星权向量，第二阶段采用有导师的Widrow-Hoff规则（最小均方规则LMS）来训练竞争层的外星权向量。

CPN算法步骤

第一阶段采用竞争学习算法对输入层到竞争层的权向量进行训练。
- 将内星权值随机赋予0~1上的值，归一化；对输入向量也进行归一化。
- 根据输入向量得到获胜神经元。
- CPN不设优胜领域，只有获胜神经元的内星权向量可以调整![](https://pic002.cnblogs.com/images/2012/103496/2012071309322136.png)。获胜神经元的输出为1,其他为0.学习率是随时间下降的退火函数。
- 如果学习率不为0则回到第1步。

第二阶段采用外星学习算法（由于竞争层的输出为1,所以Widrow-Hoff学习算法退化为外星学习算法），对竞争层到输出层的权向量进行训练。
- 随机初始化竞争层到输出层的权向量。
- 根据输入得到输出，又有期望输出，可以调整外星权向量：

![](https://pic002.cnblogs.com/images/2012/103496/2012071410541558.png)
又因为Yj为1,所以Widrow-Hoff学习算法退化为外星学习算法：

![](https://pic002.cnblogs.com/images/2012/103496/2012071410560186.png)


两阶段学习的结果，是使内星权向量向当前的输入模式靠拢，外星权向量向期望输出靠拢。

双获胜神经元CPN网

对标准CPN网中竞争层上只允许有一个神经元获胜。作为一种改进，在完成训练后的运行阶段允许隐藏层有两个神经元同时获胜，这两个神经元的输出均为1,其他为0。这实际上相当于在标准CPN网中两个输入模式得到的输出叠加后的效果。因此双获胜神经元CPN网能对复合输入模式包含的所有训练样本对应的输出进行线性叠加，这种能力对于图像的叠加等应用是十分合适的。

双向CPN网

将CPN网的输入层和输出层各自分为两组（X1,X2和Y1,Y2），训练时还按照一组来训练。这样可以得到两个映射函数：Y1=f(X1)，Y2=f(X2)。当输入(X1,0)时，得到(Y1,0)；当输入(0,X2)时得到(0,Y2)。当两个映射函数互逆时，双向CPN网络可用于压缩和解压缩，也可以用它实现互联想。












