# 推荐本博客博文 - LeftNotEasy - 博客园







# [推荐本博客博文](https://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/recommended-blogspots.html)





**在我的博客中，推荐以下专题**

**机器学习中的****数学****系列：**

1) [回归(regression)、梯度下降(gradient descent)](http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html)

2) [线性回归，偏差、方差权衡](http://www.cnblogs.com/LeftNotEasy/archive/2010/12/19/mathmatic_in_machine_learning_2_regression_and_bias_variance_trade_off.html)

3) [模型组合(Model Combining)之Boosting与Gradient Boosting](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/02/machine-learning-boosting-and-gradient-boosting.html)

4) [线性判别分析（LDA）, 主成分分析(PCA)](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html)

5) [强大的矩阵奇异值分解(SVD)及其应用](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html)



**机器学习中的****算法****系列：**

1) [决策树 - 随机森林与GBDT](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html)

2) [SVM基础](http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html)




**Hadoop科普****系列：**


1) [为什么Hadoop将一定会是分布式计算的未来](http://www.cnblogs.com/LeftNotEasy/archive/2011/08/27/why-map-reduce-must-be-future-of-distributed-computing.html)

2) [为什么会有Map-reduce v2 (YARN)](http://www.cnblogs.com/LeftNotEasy/archive/2012/02/18/why-yarn.html)

3) [从Hadoop Summit 2016看大数据与Hadoop的发展](http://www.cnblogs.com/LeftNotEasy/p/my-thoughts-from-hadoop-summit-2016.html)





**其他：**

- [关于我](http://www.cnblogs.com/LeftNotEasy/p/about-me-wangda-tan.html)












