# [CareerCup] 10.5 Web Crawler 网络爬虫 - Grandyang - 博客园







# [[CareerCup] 10.5 Web Crawler 网络爬虫](https://www.cnblogs.com/grandyang/p/4862606.html)







10.5 If you were designing a web crawler, how would you avoid getting into infinite loops?



这道题问如果让我们设计一个网络爬虫，怎么样才能避免进入无限循环。那么何谓无限循环呢，如果我们将网络看做一个图Graph，无限循环就是当存在环Circle时可能发生的情况。当我们用BFS来进行搜索时，每当我们访问过一个网站，我们将其标记为已访问过，下次再遇到直接跳过。那么如何定义访问过呢，是根据其内容还是根据其URL链接呢，根据URL链接更能会有多个链接指向同一个网站的情况，根据内容可能某个网站会有随机生成内容的模块，所以一个比较好的解决方案是根据相似度来确定，即既包括内容又包括URL链接，下面我们来看具体如何实现：

1. 打开网页并根据特定的子模块和URL链接生成一个页面签名

2. 访问数据库看这个页面签名是否最近被访问过

3. 如果最近被访问过，将这个网页添加到数据库中低优先级的位置

4. 如果没有，则访问此网站并将连接加入数据库

如果是对于一个小型系统，比如局域网，我们可以对每个页面设一个让页面接受访问的最小优先级。












