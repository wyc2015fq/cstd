# 模拟用户行为高匿爬虫的设计开发 - =朝晖= - 博客园
# [模拟用户行为高匿爬虫的设计开发](https://www.cnblogs.com/dhcn/p/7124710.html)
      模拟用户行为一是为了爬取数据异步加载页面方面，二也是为了爬虫行为高度模仿用户行为，最终目的还是为了高匿，写高匿爬虫做什么，我就不说了，反正现在用爬虫做事的公司太多了，很多公司应该都有这方面的需求。我在本文中主要使用之前博客介绍过的pyspider，偶尔也会谈谈一些其他手段。不会谈及Scrapy，因为已经基本忘了它的特性内容了。
       先谈谈用户行为模拟，这个东西最常见的方法应该是Selenium WebDriver技术，这个东西是做Web自动化[测试](http://lib.csdn.net/base/softwaretest)的，用Django的同学用StaticLiveServerTestCase也可以，当然这东西里面内部是依靠Selenium，在Django用testcase做这个事，主要是可以使用Django的models等设施方便做其他事。不能瞎扯了，谈正题：Pyspider这方面，可以使用pyspider集成的phantomjs，代码里具体怎么用法，看pyspider文档吧。后面会讲一些配置的问题。
下面讲怎么做高匿：
1、IP隐藏，现在网上有很多高匿http代理，所谓高匿代理，就是代理对被访问服务器完全隐藏其被代理的客户端，具体细节见此文(http://www.aikaiyuan.com/9477.html)，注意：使用网上的高匿代理时，一定要先在自己的服务器上试一下，防止伪高匿发生,在Pyspider的Phantomjs中使用代理服务器，需要单独启动phantomjs服务，启动命令：
- pyspider phantomjs -- --proxy=address:port  
使用上面这个命令，必须是pyspider0.37及其以后版本。对于Selenium webdriver，怎么用代理，看Selenium文档吧。
2、user-agent：这也是一个比较重要的数据特征，要做在爬虫里面灵活设置，最好和目前主流浏览器环境的user-agent一模一样，随着浏览器的版本变化，你的user-agent也会变化。pyspider的user-agent是在一个爬虫项目里面做爬取全局设置
3、cookie：这个东西可能会被很多爬虫开发者所忽视，实际上它是非常重要的，cookie行为的仿真不但涉及到用户行为模拟，而且会直接导致某些访问请求碰到权限或者其他方面的错误。pyspider的cookie可以直接在爬取请求里面设置。
4、登录session问题：session问题在客户端主要是cookie问题，如果你能做到cookie全局仿真，session肯定不是问题。
5、如何高度模仿浏览器请求，有个简便方法：看chrome网络请求，然后copy as cURL，pyspider的crawl接口的URL字段可以直接支持curl，这种方式发送的请求和浏览器请求完全一致，如果爬取方设定一些针对请求参数特征的反爬措施，这种方式一般就足够了，不过爬取方如何做了基于数据挖掘的反爬机制，那在请求参数的构造设计上还得下更大功夫。

