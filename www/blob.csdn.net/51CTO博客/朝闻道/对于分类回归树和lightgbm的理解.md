# 对于分类回归树和lightgbm的理解-朝闻道-51CTO博客
在分类回归树中之所以要先分类后回归的原因是， 对于一般的线性回归是基于全部的数据集。这种全局的数据建模对于一些复杂的数据来说，其建模的难度会很大。所以我们改进为局部加权线性回归，其只利用数据点周围的局部数据进行建模，这样就简化了建模的难度，提高了模型的准确性。树回归也是一种局部建模的方法，其通过构建决策点将数据切分，在切分后的局部数据集上做回归操作。
比如在前面博客中提到的风险预测问题，其实就是在特征层面对于不同类型的用户分到了不同的叶子节点上。
例如我们用了时间作为特征，就将晚上开车多的用户分到了一类 白天开车多的分成了另外一类，在危险区域开车比例高的分为一类，比例低分为另外一类。
分类的切割点用作直方图的方法来确定。
例如以速度均值为例：（图中数据为假设）
![对于分类回归树和lightgbm的理解](https://s1.51cto.com/images/blog/201806/15/3da83aca529c36d77e03ccf199350b4e.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)
这样很清楚就能找到一个切割点来划分哪些用户经常超速开车，超速和相对不超速的用户的区分速度在哪里。
