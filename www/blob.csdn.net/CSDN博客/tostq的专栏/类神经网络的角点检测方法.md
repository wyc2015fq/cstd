# 类神经网络的角点检测方法 - tostq的专栏 - CSDN博客





2015年10月13日 20:36:37[tostq](https://me.csdn.net/tostq)阅读数：1254








今天阅读了一篇论文里面提到一种类神经网络模型Connectionist Model的角点检测方法，非常有意思，虽然说这篇论文里面介绍的方法结构特征复杂（图像的每个点都需要一对神经元的表示），而且只能针对于结构简单二值或灰度图像，但这个方法非常有启发性。

如今提到角点检测，大概不外乎两种思路。第一种方法就是通过一阶或二阶梯度，获得局部角程度描述，包括了Harris算子等，这种思路最容易理解，研究也多，应用也广泛，效果也比较出色。第二种方法就是从边缘曲线出发，找到边缘曲度变化最大的地方，这种方法需要依赖于边缘曲线提取精度，所以非常不稳定。

我所读的这篇文章利用神经网络的方法也并不稀奇，早在90年代初，就有人用过这样的方法，不过一般都是先建立一系列的角点模板，然后通过神经网络去匹配，计算量较大，而效果也并不突出（主要是由于角点出现的可能情况，远比人工建立的模板多）

![](https://img-blog.csdn.net/20151013222453890?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


JayantaBasak这篇文章的思路就是有这么几点：

（1）图像的尺度越粗糙（被平滑后，或放大），角点的角程度就越不明显（实际上表现为你在较大尺度上看物体，一些角点会看不到），反之图像尺度越精细，会带来更多细小角点，而这个尺度粗细描述也可以角点的视察邻域的大小变化。

（2）在小邻域里面，角点周围的点也会受到角点影响，带有一定的角程度，而角点拥有局部最大值。

![](https://img-blog.csdn.net/20151013222543315?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


（3）角点的角程度用一个角度向量表示，角度向量是由角点与其邻域上边界点向量的和，将其分解为x,y方向上的两个标量，分别各作为一组神经网络的输入

![](https://img-blog.csdn.net/20151013222616574?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


（4）对于M*N大小图像共有2M*2N个神经元，每个像素点都有一对神经元，分别表示其角度向量的x,y分量，这两个分量的神经元没有互连，每个神经元同其邻域的点都相连，每个神经元另外还有一个自我负反馈（为了排除噪声的影响）

![](https://img-blog.csdn.net/20151013222649761?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


下面正题——大概的算法思路

（1）角度向量的初始化：找到点其3*3邻域的两个边界点![](https://img-blog.csdn.net/20151013222725672?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)（论文里用的主要是二值图，这里的边缘点实际上指像素不为0点），计算其角度向量，其x,y分量分别作为两组神经网络的输入，两者都没有互连。

![](https://img-blog.csdn.net/20151013222805294?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


（2）之后，经由神经网络自学习过程，不用再进行额外的输入了，以下是神经元的自我更新公式：

![](https://img-blog.csdn.net/20151013222923582?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20151013222950989?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20151013223005398?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20151013223018806?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


这里的j是当前神经元，i是属于其邻域N(j)的神经元，wij是神经元之间的连接权值，cxi是神经元i给j的输入（这里是个斜坡函数，也可以理解为经过一个激活函数），uj是指神经元j的当前时间的输出，其关于时间的t的变化等于其邻域神经元的输入权值和减去自身反馈。（这里可能有点难以理解，直观的讲，一是其邻域的角度正反馈会提高当前点的角程度，二是如果没有周围邻域的角度正反馈，自身的负反馈会减少自身从而达到排除噪声的目的，因为噪声一般都是孤立的。这里可以结合思路（2）里好好想想）

![](https://img-blog.csdn.net/20151013223100986?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20151013223113097?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


神经元的连接权值实际上是与邻域的半径有关的，我们先前已经知道了，思路（1）里说图像的尺度越粗糙，角点的角程度就越不明显，这时需要较大权值，而随着尺度越精细，角程度就越明显，权值也在变小。那么问题就是为什么我们需要让邻域的半径随着时间缩小呢？因为在大的尺度下，我们可以排除小的毛刺角点影响（被尺度平滑了），而随着尺度的缩小，我们又可以进一步精化角点位置，这好像又是另一种多尺度的思想了。

（3）收敛性考虑，当r<1.5时，那么停止，此时可以得到每个点的最终角向量值，找到局部最大值即为角点，这里还需要设置一个阈值，把小的局部点变化排除。对于给定的半径r，神经网络整体能量：

![](https://img-blog.csdn.net/20151014084037585?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

其关于时间变化的导数如下，可以分析出，它是随时间变化，慢慢接近于0的：




参考文献：

[A Connectionist Model for Corner Detectionin Binary and Gray Images](http://download.csdn.net/detail/tostq/9178571)



