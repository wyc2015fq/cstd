# 机器学习错题集 - YZXnuaa的博客 - CSDN博客
2018年09月27日 16:52:10[YZXnuaa](https://me.csdn.net/YZXnuaa)阅读数：128

1.线性分类器有三大类：感知器准则函数、SVM、Fisher准则，而贝叶斯分类器不是线性分类器。
感知器准则函数：代价函数J=-(W*X+w0)，分类的准则是最小化代价函数。感知器是神经网络（NN）的基础，网上有很多介绍。
SVM：支持向量机也是很经典的算法，优化目标是最大化间隔（margin），又称最大间隔分类器，是一种典型的线性分类器。（使用核函数可解决非线性问题）
Fisher准则：更广泛的称呼是线性判别分析（LDA），将所有样本投影到一条远点出发的直线，使得同类样本距离尽可能小，不同类样本距离尽可能大，具体为最大化“广义瑞利商”。
贝叶斯分类器：一种基于统计方法的分类器，要求先了解样本的分布特点（高斯、指数等），所以使用起来限制很多。在满足一些特定条件下，其优化目标与线性分类器有相同结构（同方差高斯分布等），其余条件下不是线性分类
2.类概率密度与先验概率的乘积
所谓判别式模型，需要把正负样本区分开，那势必会遇到区分不开的情形，这时就要用到核函数了，那所以我认为判别式模型都要用核函数的。
Radial Basis Function
Linear Discrimimate Analysis
Support Vector Machine
HMM三大问题
A、B：前向、后向算法解决的是一个评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型。
C：Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；
D：维特比算法解决的是给定 一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题。
对于二类分类问题常用的评价指标是精准度（precision）与召回率（recall）。通常以关注的类为正类，其他类为负类，分类器在测试数据集上的预测或正确或不正确，4种情况出现的总数分别记作：
    TP——将正类预测为正类数
    FN——将正类预测为负类数
    FP——将负类预测为正类数
    TN——将负类预测为负类数
由此：
    精准率定义为：P = TP / (TP + FP)
    召回率定义为：R = TP / (TP + FN)
    F1值定义为： F1 = 2 P R / (P + R)
精准率和召回率和F1取值都在0和1之间，精准率和召回率高，F1值也会高，不存在数值越接近0越高的说法，应该是数值越接近1越高。
