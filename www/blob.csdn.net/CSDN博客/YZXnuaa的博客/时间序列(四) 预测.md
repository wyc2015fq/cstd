# 时间序列(四) 预测 - YZXnuaa的博客 - CSDN博客
2018年03月05日 16:04:11[YZXnuaa](https://me.csdn.net/YZXnuaa)阅读数：306
时间序列建模的主要目标之一就是对时间序列未来取值的预测. 而另一个最重要的目标即是对预测精确性的评估.
可以说之前的所有知识都是为预测与评估作准备的.
所谓预测就是利用已观测样本数据,对未来某时刻的取值进行估计. 对时间序列预测,基于这样一个假设: 已观测信息包含时间序列模型的所有信息,其中一部分是可读的,基于可读信息,可以构建时间序列模型,此模型在一定的精度要求下, 可以作为真实模型的近似.
### 最佳线性预测
设时间序列12
, 对未来 l 步预测,目前最通用的预测准则为**最小方差预测原则**:
12
2
一般地, 寻求的模型,大约都时间序列12
 各时间点的线性组合, 因而满足上述条件的模型,也称为(l 步)**最佳线性预测**(之前,研究时间序列的学者都将'预测'称之为''预报''(forcasting), '预测'常被使用则是最近的事).则 上式可写成:
11222112
其中
 表示(组合)系数.
则上式等价于:
1101
求期望可得:
1112
写成矩阵形:
0111021201212
是不是好象在哪里见过? 是的, 如果是一步预测, 即1时, 上式方程也称为 的第N阶Yule-walker 方程(虽然 未必是AR序列),其中12
为未知量,也就是要求参数.
但... 等等,是不是太快了?别急,在这之前,先来了解一下如何预测:
### 时间序列预测
时间序列预测, 基本上可以分**四大步**:
- 确定模型阶数, 经过前几讲,可知,目前的所有模型都可认为是ARIMA(p,d,q)模型, 因此, 确定模型阶数,即为确定p, d,q,此过程也被称为**模型识别**.
- 当模型阶数确定后, 那就要对模型进行**参数估计**了.
- 模型构建完成,那就要进行**模型诊断**了(或称模型评估).
- 最后,才是根据所选模型进行**预测**
以上四大步每一步都可独立成章,内容过多, 不过不用担心,模型识别部分会详细讲一下,而后面的内容,在这里简单的提两句: 参数估计很重要,那是当然的,可对于实际应用来说,谁会关注这些呢,本来想放上几个公式的,可发现没有必要, 因为这些公式很复杂,而且还是递推形式的,我都记不下来,各位也就不用记忆了, 而且其主要思想已经讲了(最佳线性预测),就够了.
对模型诊断部分, 我要说的是,实践与理论研究, 学术看问题的方式, 与实践看问题的方式是不同的,在实践应用中,我们一般不会走学术的方式对诊断模型,更多的是考查模型拟合的如何, 是否overfit, MSE(均方误差,一个模型好坏的衡量指标)是否最低,等等. 所以我都'不欲'的,就不'施于'大家了.
预测,就是以你构建好的模型,对未来时间序列的预测,其实还是有一些啰嗦事的,但知道这么多就够了,实际中才不会管你什么预测误差怎么变化呢,更不会考虑什么预测极限(因为我们有自己的更加直观的方式.).
### 自相关系数与偏自相关系数(ACF)
回顾自相关函数的定义:
−−−−−−−−−−−−−−√
但一般的, 我们会研究平稳性时间序列(不平稳则先转化成平稳的).这也就意味着, 有恒定的均值,方差也可认为不变(异方差问题,我们会单独讲, 金融市场常用的模型(当然也是处理时间序列了)). 则上式可修正成样本自相关函数() (k = t - s):
112
这个自相关函数很重要,(第一讲可以先翻翻喽,当然第二讲也可以看看喽,嘻~), 比如在MA(q)s模型中, **当 k > q 时**, 0 而上式正是的估计量啊, 也就是说也是0啊(或准确的说近似为0, 这里不做深挖(没必要),可以粗暴地认为这里的就是就可以了). 什么,不懂什么意思? 就是说,拿到数据我们可以先以此公式来验证下 0
 的k 的最小取值, 那如果是MA(q)模型, 我们就知道了 **q = k - 1** !!! 神奇吧!
### 样本偏相关函数(PACF)
MA(q) 的滞后项数(q) 可以通过ACF确定,因为当 k > q 时ACF为0, 可是AR(p) 模型可没有这个性质啊. AR(p)模型的自相关ACF不会突然截断(为0) 而是逐渐衰减的. 没办法了吗? 怎么可能! 看小标题!
那什么是偏相关函数数呢? 就是在探讨
与 之间的相关函数时,想办法把中间介入的变量(11) 的影响去掉,从而找出二者'纯洁'的相关关系. 记为
.
如果用公式表示呢,则有两种方式:
121
此种方式有个前提假设,即是时间序列是基于高斯分布的.
或者写成如下形式(此种不要求一定是高斯分布):
112211112211
对于高斯分布这两个等式是等价的, 规定 111
.
经过'简单'(真的简单,两步就可以了,所以不放进来了,汗~) 可以得到如下重要事实:
0
那问题来了,如何计算啊? 好, 不废话,直接上公式:
1111111
其中,
11121
例如:
1112221111111221121211122113332122211211222
看,根上面的递推公式,我们可以计算任何想要的. 对于某个样本来说,将公式中的替换成
就可得出样本的偏相关函数.
下面给个表出ACF,PACF 在ARMA模型中的特征:
|函数|AR(p)|MA(q)|ARMA(p,q)|
|----|----|----|----|
|ACF|拖尾|滞后q阶后截尾|拖尾|
|PACF|滞后p阶后截尾|拖尾|拖尾|
扩展的自相关函数(EACF)
AR(p)模型与MA(q)模型都有判别指标了,那对于混合ARMA模型(即一般的ARMA模型)怎么办呢,从上表可知,ACF与PACF不能够用来作为ARMA的判别标准(拖尾啊~~~).
因此EACF应运而生.不过我的理解却是这样, 时间序列的研究历史已经很久了, 但由于时间序列数据的序列相关性,致使数据的结构很复杂,因此, 诸如一些基本性质,研究起来都十分的吃力, 当上升到模型,则成熟的效果好的理论至今还没出现, 比如ARMA模型的识别, ARMA模型可是时间序列的非常基础的模型啊,可是公认的方法还没有出现. 本节介绍的方法,近几年才慢慢为人们所接受(因为EACF的方法论,看似逻辑简单,可操作起来并不太容易), 我想是因为没有其他更好的办法吧.而且在第五版的Time Series Analysis: Forecasting and Control一nnh(2016年出版的啊),在模型识别部分仍然没有加入EACF, 但也没有更好的办法提出来.
EACF其实更准确地说是一个方法:
如果ARMA模型的AR部分是已知的,那从观测序列中剔掉AR部分, 将会得到一个'纯'的MA过程. 该过程的MA的ACF具有截尾特征. 而自回归的系数则可以通过有限次的回归估计得到.
呃,呃,呃… 算啦, EACF就讲这么多吧,就这么任性地决定啦~. 大家对EACF有了个了解就可以了.反正我的理解是,与其用EACF,还不如备选几个模型(不同参数组合),逐个尝试来得痛快~.
### 非平稳模型的识别
之前讲过'差分+ARMA'模型即为ARIMA模型. 所以当遇到ARIMA模型就可以先差分再应用以上方法,就可以识别模型了~.差分阶数的选择,可参见第三讲.注意,不要过度差分.
至于如何判断时间序列是否为非平稳的. 一般认为,样本ACF的近似线性衰减是时间序列非平稳的标志.定量的可使用Dickey - FullerF单位根检验.这应用到一个事实: 对差分序列的检验,即检验时间序列AR特征多项式是否存在单位根. 这里还不展开讨论, 因为实践中差分阶数一t般不大,然后… 你懂的~ /坏笑...
### 其他识别方法
还有一些其他的模型识别方法, 如BIC, AIC等等, 以上都没展开谈,这里就不展开讨论了.
### 再吐槽~
综上,时间序列的预测就告一段落了. 你会发现今天我有好多地方没有展开(至于原因,每个位置都有讲到). 至于更深层次的原因,是它们不好用,更加直白的说法是, 太复杂,理论性太强, 实际应用中,不会自己去实现某一个方法; 太陈旧,太刻板,实践中不会使用; 太不完善,没有形成普遍认同(时间序列真的很难, 想想这几讲可都是时间序列的最基础知识,但我想你早已发现所得出的结果,性质都不是那的容易~).
以后有机会,可以来实例比如: '手把手时间序列建模.'.下一讲可能不行, 因为会分享一个更令人兴奋的话题,敬请期待~
