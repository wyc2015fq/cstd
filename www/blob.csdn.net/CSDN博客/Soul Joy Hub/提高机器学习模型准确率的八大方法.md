# 提高机器学习模型准确率的八大方法 - Soul Joy Hub - CSDN博客

2016年11月28日 15:25:43[卓寿杰_SoulJoy](https://me.csdn.net/u011239443)阅读数：5473


想要提高模型的性能有时会是一件难度不小的事情。如果你也遇到过类似的情况，相信一定会认同我这一看法。在一一尝试毕生所学的对策和算法之后，依然没能够提高模型的准确率，这时，一种陷入困境的无助感就会涌上心头。事实上，百分之九十的数据科学家就是在这一阶段选择了放弃。

但是，好戏这才开始！正是这一点划清了平凡的数据科学家与非凡的数据科学家的界限。你是不是也梦想着成为一名卓越的数据科学家呢？

如果是的话，你就需要有这八种可靠的方式来重构你的模型方法了。建立可预测模型的途径有多种多样，没有定法，但是，如果你按照我的方式（分享如下）进行，你的模型准确率一定可以得到提高（条件是你的数据足以对其做出预测）。

通过以前的经验，我掌握了这些方法。相比钻研理论，我是一直都更喜欢在实践中学习的，而这些方法也不断地给我以鼓励。本文中我分享了八种可靠的方法，你们可以借此建立起一个强有效的机器学习模型。希望我的分享能够帮助你们攀登事业的更高峰。

模型开发周期要经历不同的阶段，始于数据收集，终于模型建立。


然而，在探索数据变量关系之前，我强烈建议你最好先进行假设生成，这是预测建模中最被忽视的一个步骤。

行业信息一直是很重要的，那么，它们是如何发挥作用的呢？

如果后期想要构建更好的特征，思考和获取信息是很有帮助的，它会使特征不因为数据组中现有的数据而产生偏差。通常，正是这关键的一步使模型的准确率大大提高了。

这一阶段，你要针对具体的问题采取结构化思考的方式，也就是在思考过程中考虑到某个特定问题里所有可能的方面。

好的，那么现在让我们再深入一点，探寻一下提高模型准确性的有效办法。

1**获取更多数据**

拥有更多的数据在任何时候都不坏，更多的数据就能让其“为自己代言”，而不是仅仅依赖于作的假设和弱小的相互关系。获取更多数据会使模型更完善更准确。


但是我很清楚，有时候对于增加数据我们也无能为力。例如：在数据科学竞赛中，我们除了增加训练数据的规模以外别无选择。因此在进行公司项目时，只要有可能，还是建议大家尽可能获得更多的数据，这会减少因数据组有限而带来的麻烦。

2**处理缺失值和异常值**

训练数据中意外的缺失值和异常值通常会降低模型的准确率，或使模型产生的结果出现偏差，最终导致预测不准。这是因为我们没能够准确地分析这一行为以及它与其他变量的关系。因此，认真对待缺失值和异常值非常重要。


请仔细看下面的图表。它表明，如果出现缺失数据，女性打板球的几率就和男性的基本持平。但是，看一下第二行（姓名称谓是“小姐”后的处理缺失数据），我们就可以看到女性与男性相比打板球的成功率更高。



由上，我们可以看到，缺失数据对模型准确率会产生反作用。幸运的是，我们有很多方法处理缺失值和异常值：
- 
**缺失值**：如果出现了持续变量，你可以用平均值、中位数和众数来填补丢失值。对于分类变量，你可以把变量看成单独一类，也可以建立一个模型来预测丢失值。KNN插补方法就提供了一种处理丢失值的手段。想更多地了解以上方法，请参考文章《处理丢失值的几种方法》。

- 
**异常值**：你可以用删除观察值，转换、分箱和填补数值的方法，或者（和缺失值一样）你也可以单独处理缺失值。可以参考文章《如何检测并处理数据组中的异常值》来了解更多类似方法。

3**特征工程**
这一步骤有利于从现有数据中提炼出更多信息，新的信息会根据新特征得以提炼出来，这些信息更能够解释训练数据的变化。因此，一定会使模型准确率更高。

特征工程受到假设生成的重要影响，合理的假设可以产生显著的特征。所以，我通常建议将黄金时间投入于假设生成的过程。特征工程流程可分为以下两步：
- 
**特征转换**：很多情形都需要进行特征转换。

a） 将一个变量的范围从原始范围变为从零到一，这叫做数据规范化。例如：如果一个数据组第一个变量以米计算，第二个变量以厘米计算，第三个变量以千米计算，这时，我们在应用任何算法之前，必须以同样的单位来规范这些变量。

b） 一些算法很适合处理正态分布的数据，因此，我们必须消除变量的偏差值。消除偏差值的方法有取对数, 做平方根，或者取倒数。

c）有时，对数字数据进行分箱也是很奏效的方法，这种方法也能处理异常值。数值数据通过分组为箱会变得更加离散。这叫做数据的离散化。
- 
**创建特征**：从现有的变量中推出新的变量就是创建特征，它有助于揭示数据组的隐藏关系。比如说：我们想通过某商店的交易日期预测其交易量。虽然交易日期可能与交易量没有直接的关系，但是我们观察一周内某天的数据，可能会发现两者的相关性很高。在这种情况下，一周当中某天的信息就是隐藏的信息，我们关注这些就是希望模型能够运行得更好。

4**特征选择**
特征选择是一个找到属性的最佳子集的过程，它更好地解释了目标变量与变量间的关系。

你可以基于很多类似的标准来选择有用的特征，例如：
- 
**行业知识**：基于行业经验，选择那些对目标变量有更大影响的特征。

- 
**可视化**：就像它的名字，可视化有助于使变量之间的关系更加直观，使变量选择过程更加便捷。

- 
**统计参数**：我们也考虑P值、信息值和其他统计参数来选择正确的特征。

- 
**PCA**：这种方法有助于在更低维的空间表现训练数据，同时也表现出数据的内在关系。这是一种降维技术。很多方法都能降低训练数据的维度（特征），例如要素分析、降低方差、提高相关性、后向/前向特征选择和其他等。

5**多种算法**
使用正确的机器学习算法是实现更高准确率的理想方法。然而，说起来容易做起来却难。

直觉是基于经验和不懈的实践得到的，一些算法相比其他的算法会更适合某种数据组。因此，我们应该尽可能应用所有的相关模型去检查其运行情况。
6**算法调试**
我们知道机器学习算法主要靠参数，参数影响机器学习过程的结果。

调试参量的目标就是发现每个参数的最佳值来提高模型的准确性。要想调试这些参数，你就一定要深入理解参数的意义和它们对模型的影响，你可以通过一系列运行良好的模型来重复这一过程。

例如：在随机森林算法中，我们有很多参数例如max_features, number_trees, random_state, oob_score等等。直觉性的优化这些参数值会使模型更好、更准确。

你可以参考文章《调试随机森林模型的参量》来进一步学习参量调试的影响。以下列出随机森林scikit learn算法中的所有参数：


7**集成方法**
这是在数据科学竞赛中最常用的方法，通过结合多种弱模型的结果以产生更佳结果。可以通过很多方式实现，如：

Bagging (Bootstrap Aggregating)

Boosting

想要了解这种方法的更多信息，可以参考文章《集成学习简介》。

将集成方法应用于提高模型的准确度一直都是很好的想法。原因有二：
- 
集成方法比传统的方法更加复杂；

- 
传统方法提供给你一个好的基础，从中你可以提取信息来建立你自己的集成模型。

**注意：**

到此，我们已经了解到一些可以提高模型准确性的一些方法。然而，模型准确率更高运行结果却不一定更好（由于有看不见的数据点）。有时，模型准确率的提升也会是由过度拟合产生的。

8**交叉验证**
为了找到问题的最佳答案，我们必须使用交叉验证的方法。交叉验证是数据建模中最重要的一个概念。它指的是保留一个不用于训练的模型样本，检测该样本的模型然后再最终确定模型。



这种方法有助于我们形成更有概括性的关系。想更多了解交叉验证方法，请参考文章《通过交叉验证提高模型运行》。

8**尾注**

预测建模的过程很繁琐。然而， 如果你能灵活思考，你就可以轻易超越你的对手。简单来说，多思考这八个步骤。一旦得到数据组就遵循这些方法，你就一定会形成一个可靠的机器学习模型。然而，只有在你能单独掌握这些步骤之后这八个步骤才能对你有所裨益。例如：了解多种机器学习算法才能建成一个集成模型。

本文中，我分享了八种可提高预测模型准确率的方法。这些方法广为人知，但未必要按如上描述进行逐一使用。

