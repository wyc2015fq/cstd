# 基于神经网络的智能对话系统（一）——介绍 - Soul Joy Hub - CSDN博客

2018年11月27日 17:03:12[卓寿杰_SoulJoy](https://me.csdn.net/u011239443)阅读数：776
所属专栏：[基于神经网络的智能对话系统](https://blog.csdn.net/column/details/18953.html)



# 1. 介绍

> 
1 “对话系统”和“对话AI”在科学文献中经常互换使用。差异反映了不同的传统。前一个术语更为笼统，因为对话系统可能纯粹基于规则，而不是基于人工智能。

> 
2 我们未涉及的会话AI的一个重要主题是口语理解（SLU）。 SLU系统旨在从语音话语中提取其含义，​​其应用范围很广，从移动设备中的语音搜索到会议摘要。尽管本文中回顾的许多神经方法都适用于改进SLU系统，但这不是本文的重点。我们将读者推荐给Tur和De Mori（2011）进行SLU调查。然而，目前的工作确实涵盖了许多口语对话系统 - 例如Young等。 （2013） - 但不关注与言语相关的组成部分。

开发一个智能对话系统1，不仅模仿人类对话，而且回答有关电影明星的最新新闻到爱因斯坦相对论等主题的问题，并完成旅行计划等复杂任务，是目前运行时间最长的目标之一。 AI。直到最近，目标一直难以捉摸。然而，现在，我们正在学术研究界和行业中观察到有希望的结果，因为大量的会话数据可用于培训，并且深度学习（DL）和强化学习（RL）的突破应用于会话AI。

会话AI是自然用户界面的基础。它是一个快速发展的领域，吸引了自然语言处理（NLP），信息检索（IR）和机器学习（ML）社区的许多研究人员。例如，SIGIR 2018创建了人工智能，语义学和对话的新轨道，以桥接AI和IR的研究，特别是针对问答（QA），深度语义和与智能代理的对话。

近年来，有关深度学习和对话系统的小型教学和调查论文的兴起。 Yih等。 （2015b，2016）; Gao（2017）回顾了针对各种IR和NLP任务的深度学习方法，包括对话。陈等人。 （2017d）提出了关于对话的教程，重点是面向任务的代理。 Serban等人。 （2015）调查了可用于开发会话代理的公共对话数据集。陈等人。 （2017b）回顾了流行的对话深度神经网络模型，重点是监督学习方法。目前的工作大大扩展了陈等人的范围。 （2017b）; Serban等人。 （2015）通过超越数据和监督学习提供我们认为是第一次针对会话AI的神经方法调查，针对NLP和IR受众.2其贡献是：

•我们提供了对过去几年开发的会话AI神经方法的全面调查，包括QA，面向任务和社交机器人，以及最佳决策的统一视图。

•我们在现代神经方法和传统方法之间建立联系，使我们能够更好地理解研究的原因和方式，并阐明我们如何向前发展。

•我们提供最先进的方法，使用监督和强化学习培训对话代理。

•我们勾勒出研究社区开发并在行业中发布的会话系统的情况，通过案例研究展示已经取得的进展以及我们仍然面临的挑战。

## 1.1谁应该阅读本文？

本文基于2018年SIGIR和ACL会议上提供的教程（Gao et al。，2018a，b），IR和NLP社区作为主要目标受众。然而，具有其他背景的观众（例如机器学习）也会发现它是一个易于理解的会话AI介绍，尤其是最近开发的神经方法。

我们希望本文能够为学生，研究人员和软件开发人员提供宝贵的资源。它提供了统一的视图，并详细介绍了理解和创建现代对话代理所需的重要思想和见解，这些代理有助于以看似自然和直观的方式使数百万用户能够访问世界知识和服务。

该调查的结构如下：

•本章的其余部分介绍了对话任务，并提出了一个统一的视图，其中开放域对话被制定为最佳决策过程。

•第2章介绍了基本的数学工具和机器学习概念，并回顾了深入学习和强化学习技术的最新进展，这些技术是开发神经对话代理的基础。

•第3章描述了问答（QA）代理，侧重于基于知识库的QA和机器阅读理解（MRC）的神经模型。

•第4章描述了面向任务的对话代理，侧重于将深度强化学习应用于对话管理。

•第5章描述了社交聊天机器人，侧重于完全数据驱动的神经方法，以端到端生成会话响应。

•第6章简要回顾了工业中的几个会话系统。

•第7章总结了本文，讨论了研究趋势。

## 1.2 对话：有哪些问题？

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181127144712934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

表1.1显示了在做出业务决策过程中的人 - 代理对话。这个例子说明了对话系统有望解决的各种问题：

•问题回答：代理需要基于从各种数据源（包括Web文档和预编译知识库，如销售和营销数据集）等文本集合中提取的丰富知识，为用户查询提供简明，直接的答案。

•任务完成：代理需要完成从餐馆保留到会议安排以及商务旅行计划的用户任务。

•社交聊天：代理需要与用户无缝和适当地交谈 - 就像通过图灵测试所测量的人一样 - 并提供有用的建议。

可以设想，上述对话可以由一组代理（也称为机器人）共同完成，每个代理被设计用于解决特定类型的任务，例如QA机器人，任务完成机器人，社交聊天机器人。这些机器人可以分为两类，面向任务和聊天，取决于是否进行对话以帮助用户实现特定目标，例如，获得对查询的答案或安排会议。

今天市场上大多数流行的个人助理，如亚马逊Alexa，Apple Siri，谷歌主页和微软Cortana，都是面向任务的机器人。这些只能处理相对简单的任务，例如报告天气和请求歌曲。微软对话机器人的一个例子是Microsoft SmallIce。构建对话代理以完成表1.1中的复杂任务仍然是IR和NLP社区以及AI的最基本挑战之一。

典型的面向任务的对话代理由四个模块组成，如图1.1（上）所示：（1）自然语言理解（NLU）模块，用于识别用户意图和提取相关信息; （2）用于跟踪对话状态的状态跟踪器，其捕获到目前为止在对话中的所有基本信息; （3）基于当前状态选择下一个动作的对话策略; （4）自然语言生成（NLG）模块，用于将代理动作转换为自然语言响应。近年来，通过使用将用户输入直接映射到代理输出的深度神经网络统一这些模块，开发出完全数据驱动系统的趋势，如图1.1（下图）所示。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2018112715100189.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

大多数面向任务的机器人都是使用模块化系统实现的，其中机器人通常可以访问外部数据库，在该数据库上查询完成任务的信息（Young et al。，2013; Tur and De Mori，2011）。另一方面，社交聊天机器人通常使用（非模块化）单一系统来实现。由于社交聊天机器人的主要目标是成为具有情感联系而不是完成特定任务的人类的AI伴侣，因此通常通过在大量人 - 人对话数据上训练基于DNN的响应生成模型来开发模仿人类对话（ Ritter等，2011; Sordoni等，2015b; Vinyals和Le，2015; Shang等，2015）。直到最近，研究人员才开始探索如何在世界知识（Ghazvininejad et al。，2018）和图像（Mostafazadeh等，2017）中引入闲聊，以使对话更加内容和有趣。

> 
3 [https://sounding-board.github.io/](https://sounding-board.github.io/)

4 [https://www.msxiaobing.com/](https://www.msxiaobing.com/)

## 1.3 统一观点：对话作为最优决策

表1.1中的示例对话可以表述为顺序决策过程。它具有自然的层次结构：顶级流程选择为特定子任务激活的代理（例如，回答问题，安排会议，提供推荐或只是偶尔聊天），以及低级流程，受控制通过选定的代理，选择原始动作来完成子任务。

这种分层决策过程可以在马尔可夫决策过程（MDP）的选项的数学框架中制定（Sutton等，1999b），其中选项将原始动作概括为更高级别的动作。这是传统MDP设置的扩展，其中代理只能在每个时间步骤选择基本动作，代理可以选择“多步”动作，例如可以是用于完成子任务的一系列原始动作。

如果我们将每个选项视为一个动作，则强化学习框架可以自然地捕获顶级和低级流程。对话代理在MDP中导航，通过一系列离散步骤与其环境交互。在每个步骤中，代理会观察当前状态，并根据策略选择操作。然后，代理接收奖励并观察新状态，继续循环直到情节终止。对话学习的目标是找到最优化的政策，以最大化预期的奖励。表1.2总结了使用RL统一视图的所有对话代理。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181127152716912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

统一的分层MDP观已经应用于指导一些大规模开放域对话系统的发展。最近的例子包括Sounding Board 3，一个赢得2017年亚马逊Alexa奖的社交聊天机器人，以及Microsoft SmallIce 4，可以说是自2014年发布以来吸引全球超过6.6亿用户的最受欢迎的商业社交聊天机器人。两个系统都使用分级对话管理器：管理整个会话过程的主人（顶级），以及处理不同类型的会话段（子任务）的技能（低级）。这些社交聊天机器人旨在最大限度地提高用户参与度，通过会话转换每次会话（CPS）的预期奖励功能来衡量。

尽管RL为构建对话代理提供了统一的ML框架，但应用RL需要通过与真实用户交互来培训对话代理，这在许多情况下可能非常昂贵。因此，在实践中，我们经常使用混合方法，结合不同ML方法的优势。例如，我们可以使用模仿和/或监督学习方法（如果有大量的人 - 人对话语料库）在应用RL继续改进之前获得相当好的代理。在本文的其余部分，我们将调查这些用于培训对话系统的ML方法。

## 1.4 NLP向神经方法的转变

神经方法现在正在改变NLP和IR领域，其中符号方法已经占据了数十年的主导地位。

NLP应用程序与其他数据处理系统的不同之处在于它们使用各种级别的语言知识，包括语音，形态，语法，语义和话语（Jurafsky和Hartin，2009）。从历史上看，NLP领域的大部分都围绕着图1.2的架构进行组织，研究人员将他们的工作与一个或另一个组件任务对齐，例如形态分析或解析。这些组件任务可以被视为通过将自然语言句子映射（或生成）到一系列人类定义的，明确的，象征性的表示来解决（或实现）不同级别的自然语言歧义（或多样性），例如作为词性（POS）标签，无上下文语法，一阶谓词演算。随着数据驱动和统计方法的兴起，这些组件仍然存在并且已经被调整为工程特征的丰富来源，可以被输入到各种机器学习模型中（Manning等，2014）。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181127164433120.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

神经方法不回复任何人类定义的符号表示，而是学习任务特定的神经空间，其中任务特定知识使用低维连续向量隐式表示为语义概念。如图1.3所示，神经方法通常分三步执行NLP任务（例如，机器阅读理解和对话）：（1）将符号用户输入和知识编码到其神经语义表示中，其中语义相关或相似的概念是表示为彼此接近的向量; （2）在神经空间中推理基于输入和系统状态生成系统响应; （3）将系统响应解码为符号空间中的自然语言输出。编码，推理和解码使用神经网络（不同架构）实现，神经网络可以堆叠到通过反向传播和随机梯度下降以端到端方式训练的深度神经网络中。

端到端训练导致最终应用与神经网络架构之间更紧密的耦合，减少了对形态分析和解析等传统NLP组件边界的需求。这极大地平坦化了图1.2的技术堆栈，并大大减少了对特征工程的需求。相反，重点已经转移到精心定制神经网络的日益复杂的架构到最终应用。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181127165653965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

尽管神经方法已经在许多AI任务中被广泛采用，包括图像处理，语音识别和机器翻译（参见Goodfellow等人的综述（2016）），但它们对会话AI的影响有些缓慢。直到最近，我们才开始观察神经方法在组件任务和最终应用程序的一系列会话基准上建立最先进的结果，并在此过程中撇开已定义的传统基于组件的边界几十年的研究领域。这种符号到神经的转变也通过开辟旧技术无法实现的新任务和用户体验来重塑对话AI环境。其中一个原因是神经方法为许多模态提供了一致的表示，在同一建模框架中捕获语言和非语言（例如，图像和视频（Mostafazadeh等，2017））特征。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181127171010511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEyMzk0NDM=,size_16,color_FFFFFF,t_70)

