# AAAI 2019 论文解读 | 基于区域分解集成的目标检测 - Paper weekly - CSDN博客





2019年03月04日 12:05:39[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：92









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgm9RFr5icmiaj0bibJxUeIGdAFHNM4G6PJEiccw293RuVnOiadQ4zcdibdJa5FFfn0ZMgpbKib4AAKD8dm2w/640)




作者丨文永亮

学校丨哈尔滨工业大学（深圳）

研究方向丨目标检测、GAN




本文解读的是一篇发表于 AAAI 2019 的 paper，**文章提出了一种 R-DAD 的方法来对 RCNN 系列的目标检测方法进行改进。**



![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWonxp2dcwkEsbJv3K3lsbKQbonhrjER1OvEa7pX76GYL1lJwcVRlqIvQ/640?wx_fmt=png)



# 研究动机



目前主流的目标检测算法分为 1 stage 和 2 stage 的，而 2 stage 的目标检测方法以 Faster-RCNN 为代表是需要 RPN（Region Proposals Network）生成 RoI（Region of Interests，感兴趣区域）的，文章认为正是因为被遮挡了的或者不精确的 Region Proposals 导致目标检测算法的不准确。




作者的想法动机其实很简单，就是假如一辆车的左边被人遮挡了，那么这辆车的右边带来的信息其实才是更可信的。基于这个想法，文章提出 R-DAD（Region Decomposition and Assembly Detector），即区域分解组装检测器，来改善生成的 Region Proposals。




# R-DAD的网络结构




文章以 Faster-RCNN 的网络结构为例，修改成它提出的 R-DAD 结构：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoElJCwYyuCWZjcRq1b6dsVguuD1KPrKd1VgCj54RgYYQZ1m6icYgdlXg/640?wx_fmt=png)




R-DAD 网络架构主要分成两个模块 MRP 和 RDA：




**1. MRP（Multi-Scale Region Proposal）模块**，用来改善 RPN 生成的 Region Proposals 的准确率。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo1xrWBsC8icciam53yEBoJH3V7VWsRn4wX4fricUJt4MOlBzkghIReemibw/640?wx_fmt=png)

**▲**图1.MRP模块，框内分别对应S=0.7,1,1.2的Region Proposals




MRP 表面意思就是生成多尺度的 Region Proposal，方法很简单，就是使用传统的 RPN 生成一些建议框，然后用不同的缩放因子（文章使用了 5 种缩放因子作为一组 s=[0.5,0.7,1,1.2,1.5]）对生成出的建议框进行不同比例的缩小放大，从而提高 Region Proposals 的多样性。




如图一，生成了不同尺度的区域，有一些仅仅是局部有一些是大于目标本身的，但是这也带来了一个问题，就是原来的 Region Proposals 已经可以说是极大的数量了，再乘以五倍，想要网络能够完全利用这些建议框是不切实际的，作者最后还添加了 RoI 的采样层，对分数低的和跟 ground truth 重叠率低的进行了筛选。 




由 MRP 网络生成的各种 Region Proposals 可以进一步适应目标之间因为空间变化所导致的特征变化，提高结构的鲁棒性。 




**2. RDA（Region Decomposition and Assembly）模块**，作者也称它为 mutil-region-based appearance model，即基于多区域的外观模型，它可以同时描述一个物体的全局外观和局部外观，RDA 分为目标分解和目标区域集成的两部分，目标分解如图二所示，把一个目标分为上下左右四个方向的分解部分。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoPcNGhzvOGQArsxXfj8g4AgnhHGvWia2wm85Tefa7zpboSfpGibXPN4Hw/640?wx_fmt=png)




一般会先用线性插值两倍上采样之后再分解，后面作者给出了表格表示这样效果更好。左右刚好是特征图的左右一半，上下也同理，都会送入 RAB 模块，RAB 模块如图三所示：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo3icXVC3TKUZPA6prgONUtZicMR5ibJ40LjQYsCibyjic44ZQZIKOvPEStpQ/640?wx_fmt=png)

**▲**图3. RAB模块




其实就是下面这个函数：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWos1BTJFV0atox7kgbyq5GjI2TU4g6alrVhib9HX04ryS9NuADib1vX6oQ/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWovJbzu02RyTBniagm025nIewaIm5yXicXTG0dTcIiaSCfAAML2ukdskib6w/640?wx_fmt=png)




其中 p 代表着上下左右的每一个部分或者组合后的部分如左-右 (l/r)、下-上 (b/u) 和 comb（l/r 与 b/u 的组合），*是卷积操作，f() 是 ReLU 单元。最后再取 max，是为了融合![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoyLNI1nRMzmsUoMU5k5DBdeY8m2UubmU2rP87xyjb5ia5dNgOWplwcGw/640?wx_fmt=png)和![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWohY7Lq02ia1bNpwl1wE1l8hsRtkGsIqN8drXRFTFkoZq1ibXibDzTCI9pA/640?wx_fmt=png)的信息，生成同样大小的![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoNz60qpERx8gKhbeYcn5zOadxfE9Zl3xoD4M83Aol8yeLhheGtI27Zw/640?wx_fmt=png)。




最后![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoyc2dkbeKZK8dm5G58wv9H4z1tLN0jmNQvEQ2ribY4MkicwTgJL0NudsA/640?wx_fmt=png)就是代表着全局信息的 scale 为 1 生成的 Region Proposals，一起送进 RAB 模块。这样整个网络结构就可以做到既捕捉到局部信息的同时，也不丢失全局信息。 




RAB 模块是一个类似 maxout 的单元，理论上它可以逼近任何连续的函数，所以我们使用 RAB 而不是直接使用 ReLU。这表明可以通过配置不同的分层地组合 RAB 模块来表示各种各样的目标特征。




# 损失函数




对每一个框 (box) d，我们都会通过 IoU 筛选出跟 GT (ground truth) 最匹配的 d*，如果 d 跟任何的 d* 的 IoU 超过 0.5，给予正标签![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoZBN7ZrKP9AFVm6HHgqHjsbeX5zPcL7aFQP8dmFl8fMBbmianG6pzelQ/640?wx_fmt=png)，若在 0.1 到 0.5 之间的，给予负标签。R-DAD 的输出层对每一个框 d 都有四个参数化坐标和一个分类标签![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWor4MlGOcsBGSHJUiaXV8AhNUcq1XJNsWo6hicANZUwbDayOqOZPN4Sd2w/640?wx_fmt=png)。对于 box regression 来说，我们与以往目标检测的参数化一致如下：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo1rU7PibVfg7icAhsU6rMkKONJuXOiaqFib9x5tJLzQHicNuQZpgp4ZfyaLw/640?wx_fmt=png)




同理，![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoKmD4BxIAms5PMoiccRE66gIjU0EVAgDpEn2CflGWrM2ic0s17neSQP3g/640?wx_fmt=png)是用来评估预测框和 GT 的差距的。 




跟训练 RPN 网络相似，R-DAD 也需要最小化分类损失和回归损失，如下：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo2iaSiaPnerBZZMp9rMeAUkezxpOZ5WOciblOgRiazgJDbDO7lOs2HTl1Pg/640?wx_fmt=png)




# 实验结果




文章中做了各种设置的组合，关于 MRP 里缩放因子的组合、是否有 RDA 模块以及是否上采样，得分如下表所示：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo9XNCia6xibKV14TXcuWzsrsBlRypjc3vBTpljPDaKXCSCibC7SRicG63Hw/640?wx_fmt=png)




与 Faster-RCNN 对比，作者使用了 VOC07trainval 和 VOC12trainval 数据集训练，再在 VOC07test 上测试，并且用了不同的特征提取器（VGG、ZF、Res101），得分均比 Faster-RCNN 高。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo7eCLYRjUsf9dSDrQ2aBnjkgEib7yibXPBtrKDYBkxib6wBUOPk22YqSUA/640?wx_fmt=png)




在速度方面均比 Faster-RCNN 慢。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoQdkM4gIfFicyrmicPMibouI7f33eUXTQZ8BcSVtLme4VNrybDOrWKqZ5Q/640?wx_fmt=png)




与没有上下区域分解集成的 R-DAD 对比，有上下分解集成的误判率低很多，因为它在复杂情形下被遮挡物体会更有选择地相信得到的信息。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWo6NliaKRS7y20szOIXRfoPXqiczD8snCwzsKls3otN8PXrGica2l8HuHVQ/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmgJo4tUzibw4mStnbicw7QWoCrfnyp9GFxNAjPstjVe2jQHeDjL5z4XHP6ECflPFniafY47QZvCBgcQ/640?wx_fmt=png)




# R-DAD的优点




1. 文章提出因为我们最大化目标在横向空间位置上局部特征的语义响应，与使用支持小区域的最大池化相比，在没有深层次结构的情况下，我们可以改善特征位置的空间不变性。我的理解就是作者取了上下左右四个方向的特征模板，最后对四个方向进行了融合语义信息，利用了横向空间上的空间不变性，揭示了不同方向上的语义关系。 




2. 在复杂场景下，如有目标对象被另一目标对象遮挡时，通过左右上下模板筛选出来的特征是更符合真实场景的，这样的 Region Proposals 也更加可信。 




3. 同时描述了全局特征和局部特征的语义信息，在 RAB 的组装上具有很强的可操作性，通过配置分层式地组装 RAB 模块，以及修改特征模板，特征的表达会更加灵活。




# 点评




这个区域分解集成的算法令我觉得跟以前传统的人脸识别算法提取 Haar-like 特征有点异曲同工之处，同样都是把特征图分成上下两部分，然后做特征提取操作，都是定义了特定的特征模板，这就很容易理解为什么作者要做 multi scale 的操作了，因为在以前使用 Haar/SIFT/HoG 的时候，往往都需要使用 muti scale 来检测。 




但是 R-DAD 为什么对特征只分成上下各一半，左右各一半这种特征模板，文章并没有给出令人信服的理由。尽管如此，这也是一个对目标检测的改进方向，通过 MRP 和 RDA 模块代替了之前的单纯的 RPN 网络，而且在不使用 FPN (Feature Pyramid Networks) 的情况下取得了不错的 mAP，这样看来 R-DAD 是 2 stage 目标检测系列的另一种技巧，综合了横向空间上的语义信息。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)







**点击以下标题查看更多往期内容：**




- 
[Airbnb实时搜索排序中的Embedding技巧](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494488&idx=1&sn=452ac80c593a9b31252031eac38d0e01&chksm=96ea34d8a19dbdce940ed25bb93507aa6c4d118f84dd0bb965b060f232fe5d41894bbc9edcb6&scene=21#wechat_redirect)

- 
[图神经网络综述：模型与应用](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493906&idx=1&sn=15c9f18a1ce6baa15dc85ecb52e799f6&chksm=96ea3692a19dbf847c1711e6e194ad60d80d11138daf0938f90489a054d77cfd523bee2dc1d2&scene=21#wechat_redirect)

- 
[近期值得读的10篇GAN进展论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493987&idx=1&sn=ce1bcdce28e78f4a307743e389f42b10&chksm=96ea36e3a19dbff5cff7f4f1c9d9fc482bb2144d80566319b3d26bce4d9ab80689d38ab2e427&scene=21#wechat_redirect)


- 
[自然语言处理中的语言模型预训练方法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492317&idx=1&sn=e823a75d9463257ed9ea7b3e4677c1ae&chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&scene=21#wechat_redirect)

- 
[从傅里叶分析角度解读深度学习的泛化能力](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491082&idx=1&sn=d7c1cb39c3be43154c658ca5a791eb4c&chksm=96e9c18aa19e489c32fe36671e4208ce42bf200e3a7adeda200fa2785462d16f85c58bb455b4&scene=21#wechat_redirect)

- 
[深度思考 | 从BERT看大规模数据的无监督利用](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494978&idx=1&sn=529b8f661b13c7b6b729e9a926b0737a&chksm=96ea32c2a19dbbd43456086a2186480fa548fa982d536564e167739ef46282eaf6fca7316ced&scene=21#wechat_redirect)


- 
[AI Challenger 2018 机器翻译参赛总结](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494103&idx=1&sn=fc372862e0369b1f6a943bf997f6fc1b&chksm=96ea3657a19dbf4108bbc4179e779aa04ef05fe84f0013fa6425b0cd7e761e9880917361c4c1&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494507&idx=1&sn=3c3cafef0fb51a7e40d9b9bbab53fd5f&chksm=96ea34eba19dbdfd31eaa760bb7cfd5e18f2e967c83c6ea6693ad9a062c55b3009211d824ca3&scene=21#wechat_redirect)[小米拍照黑科技：基于NAS的图像超分辨率算法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247495166&idx=1&sn=a158e603651bc4f26836151a9113e856&chksm=96ea327ea19dbb68b8987aca041bb21579a35b1c679e91fd2368c7f2fb7acd58508cd531bdfe&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493520&idx=1&sn=2b04c009ef75291ef3d19e8fe673aa36&chksm=96ea3810a19db10621e7a661974c796e8adeffc31625a769f8db1d87ba803cd58a30d40ad7ce&scene=21#wechat_redirect)[异构信息网络表示学习论文解读](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247495219&idx=1&sn=b3a29b833fe8438e12b600650ec0245a&chksm=96ea31b3a19db8a5a335cc445f04eb13d5b1ee5451d688544240cce27dbc953993da4e842ab6&scene=21#wechat_redirect)

- 
[不懂Photoshop如何P图？交给深度学习吧](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247495276&idx=1&sn=99a84e81ba9f9a90b323c21c8c905765&chksm=96ea31eca19db8faca5cdd6447136e34a61a8a5a2d8e01489657f791841d30e0c78901a87400&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**




总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志




**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取最新论文推荐




