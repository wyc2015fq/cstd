# 开学综合症有救了！17篇最新AI论文不容错过 - Paper weekly - CSDN博客





2019年03月01日 11:43:10[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：150









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhglryG74dIr2B1019Yibv9PAGsWGGYBiaoSGbK2kzUnbIsicCEiazKMticicR0MPtmr1ynDovFe2kGicSydcg/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **130** 篇文章

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?)


![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb5f0CoRwqWAQvzRfNasiaLgBvkOyQGofxPRQE5aSn867trUssxASpvbA/640?wx_fmt=png)

**@jingyihiter 推荐**

#Text Generation

本文来自国防科大和微软亚研院，**文章提出 pre-****training****-based 的 encoder-decoder 框架**，encoder 采用 BERT 将输入序列表示为 context 向量，decoder 分为两阶段：第一阶段采用 transformer-based 解码生成伪输出序列，第二阶段对伪输出序列进行 mask 送入 BERT 表示，将输入序列与伪输出序列联合，解码预测输出序列。

**文章首次将 BERT 应用于文本生成任务**，在 CNN/Daily Mail 和 New York Times 数据集上达到 SOTA 的结果。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb0pDLcv1fMotFRWQiaibcz6RbVhNvciaumtC8BRwbLwv7asibj77IYpiaECA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbB1ueyrk4L9mqNDZBoLOCdMZcEc4ueeooLvhE7wcwCZbcg4jYxlZlUw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbpwTGhTw7jUvNbMgmpibweXgia8Vkqfy4FN5wbtC45cap0jiaY66mOyISQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbCxjQy3ng6mpt3iaqTExTen2beQHS6vsRHjkhaTwVrnj4kkZNUB3jMWw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbWhz0hbQsTDqgIZTaLvziaVljnqg2RibDkevlbUJD8n1bgINyoaXgOXZw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2855




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbVmbZMTiasNXKyQuT08WwesPwLjbiazeOyibaW9m0t4ibYH8HGGOCNIVuvw/640?wx_fmt=png)

**@QAQ 推荐**

#Language Model

**本文介绍了来自 OpenAI 的新语言模型 GPT-2**，其在文本生成任务上达到接近人类水平，可生成论文（并编造数据与引用使论证看上去合理）、续写幻想故事。在多个数据集上碾压当前结果。在未经专门训练的情况下实现翻译与阅读理解。不足是会出现重复文本与世界建模失败（如在水下发生火灾）。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb2vJFRrrFRrpico9nxHwuiafHianz0EIT9e6MdkvWa9mUNHG0tiaeibbfDhA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb6ggWFxc04CUhjKOhassUibRwgsWoPiaiaxia8PIhpibqUFfuFK66nsWpxeg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbsvibUGHEgKm0iciaA0NL1iczCYBDhliaXiaydyuX7bric3ibVF7d8C2TQ3100g/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb1kWyibQKxdcGvick79fSZSvKtZvc4rQjqsicdS6UU2BhA8qJYXQael3Eg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbVW7Dib4jVGp7icErgrh34PctZhNEBD0Efqcp8kVXvlt0OOrSCyEh1JWQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2822




源码链接

https://github.com/openai/gpt-2




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb9rm4kplfD8l6clEW1FcNWicbhCKFDuk9JWAYtrRWZCf1O3WGQr6vyIw/640?wx_fmt=png)

**@rico93 推荐**

#Attention Mechanism

本文来自康奈尔大学和 Facebook AI Research，**论文提出的 lightweight convolution 模型相对于 transformer 来说能达到一致的水平**，但只需要更少的操作数量，运算速度比 Transformer 快 20%。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbcZGviaMIgbndWXe4bezjC1KlxwGwxzSNUgAiaB6TvyLda9luop9V9tUw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbiaT6ic4tQYjdvg2VEAkar54OEqt3jRNtSlHMuuXmvJxHV2w2tcqZ70JQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbBVDGWMNcjz25X9Q7icfBAaaY4UYicFPy4qSicn9nQsPHeqmyIU6GYsO9Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb9L7acJKpXYyum1ZI5aFlcNKt743nJjMDYKOdwPP5xCfMPOzGebUSFQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbxPxqKOZ907SAlwnvnoRWLiaX2u2ZUQLGSdaSwZkVABgIsobdBf0QgQw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2801




源码链接

https://github.com/pytorch/fairseq







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbhLMOKpuF420iaUSXg2a1KuicibLhmvxHUCvaFdXYYA5FX4R5ZkqMTtFOg/640?wx_fmt=png)

****@Ttssxuan** 推荐**

#Auto ML

本文来自 Google Brain，**论文提出了 progressive dynamic hurdles (PDH) 神经网络架构搜索方法**，此方法能够动态的把资源分配到相对优秀的候选者，最终得到“Evolved Transformer”，其在几个翻译任务（WMT 2014 English-German, WMT 2014 English-French, WMT 2014 English-Czech, LM1B）相对原始 Transformer 有一致的提升，并且有更高的计算效率和更少的参数量。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb2lyBWictMktzC2udic4Kib562YIyAY2aAicv5vejJ8LorU1EFv1ibwBhhIQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbKtvKt2YFibN15GOtm0Uicoj9dk1HjdibKldXs7Yo0bp4b4rnNTMnZ5WeA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbJjjy7GPtoPCgF613omxHJ67gjNK5gyZKdcsdE9dHQhUw4swLtINnEg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbElVUDzpCCiasztSJ8LHNI8sO2iclwibYTonnhDKWJRMb28Xu7WzojiaVsQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbhCy9icpweWiciaUhxwTSRYttZ7NibHDHtIf7bMNDwAgoFfgGx2ORMoCeRg/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2817







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbLeywEPicKiauW4BiaCKvZLlPYUquKN3acBQQz9BCBzwO3Vo5fNRcSuCwA/640?wx_fmt=png)

**@paperweekly 推荐**

#Dialog System

本文是微信 AI 团队和上海交大发表于 AAAI 2019 的工作，**论文关注的任务是基于背景知识的对话生成，通过指针生成机制和注意力机制，基于对话历史和背景知识生成更有意义的回复。**作者提出了一个泛化的指针生成机制，能同时从对话历史和外部知识中复制实体。此外，作者还提出了一种 Cluster-based Beam Search 算法，能在解码时动态地将相似语义的序列分组归类，避免生成通用回复。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbZnK8jDfDFdtQmT6ESWlQgvAia0muiayEkDwY02DxvLwEFC0ZMUF7YdjQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb6QFoFpUvph8qJsMxz3Jd1Zicr6lVeo9xFszIFDJf4uicXDI1HNTiakiabw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbkdx0StqdDOEWR72PvqpmMwYtVYyIrjcRqoUZNrNzmWibqNVxlFibTUSg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbIRld32ObrUMlIg2o5HDdkeibxqWjWbscjB4mQn80QW7owqQp4RT4ciag/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbHpUxfaIJ6bPibkQXib63owtz32lPibVt2FUdfOxIm4gyJcqw1SoZ6y6KA/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2845










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbI3ZFPicfbePWWaGo8zvOBuxzDCAJEdN0nXQiaSBVtpDskl3j8JVJRU0A/640?wx_fmt=png)

**@VanceChen 推荐**

#Multimodal Sentiment Analysis

本文是 CMU 的 MultiComp Lab 发表在 AAAI 2019 上的工作。**多模态情感分析是 NLP 的一个新的核心研究领域**，研究从语言、视觉和声学模态表达的说话人情绪。多模式学习的核心挑战涉及可以处理和关联这些模态信息的推断联合表示。然而，现有工作通过要求所有模态作为输入来学习联合表示，因此，学习的表示可能对测试时的噪声或丢失模态敏感。

随着机器翻译中 Seq2Seq 模型的成功，有机会探索在测试时可能不需要所有输入模态的联合表示的新方法。**论文提出了一种通过在模态之间进行转换来学习鲁棒联合表示的方法。**论文的方法基于 Key Insight，即从源到目标模态的转换提供了仅使用源模态作为输入来学习联合表示的方法。

论文使用周期一致性损失来增加模态转换，以确保联合表示保留所有模态的最大信息。一旦翻译模型使用配对的多模态数据进行训练，我们只需要在测试时从源模态获得最终情绪预测的数据。这确保了我们的模型在其他模态中不受扰动或缺失信息的影响。

我们使用耦合的翻译预测目标训练我们的模型，并在多模态情绪分析数据集上实现新的最新结果：CMU-MOSI，ICT-MMMO 和 YouTube。 另外的实验表明，我们的模型学习越来越多的判别性联合表示，具有更多的输入模态，同时保持对丢失或扰动模态的鲁棒性。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbTtdA7DFRUREMlMWgreoUmNOmMITyOD305gicJlnUO9f548hed2P92dg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbic7TQDR0rlMYIRribtoticy32cHhnv8vUcV3K5S53x8icg2zHbgibibjgaJA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb3EonlJJRppbj68AT4VT6lyI0DvXQMg1oib3Eic1r0FiaWziaxZ3ic83icSDQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb5sbVaFlAsmFDaaFM4Zniax8l3574LuFpSNYCQwqyQYcPHG4Nxiaibibv3w/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbyJeQWGu9xCqUvQQ8OL8IgsTptGZmOTmXtNFO4ufYnDSDH6pSk4MUrQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2789




源码链接

https://github.com/hainow/MCTN







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbIjlYiaiaNtf2xbpSoVXjqqO33cQdtxODo16sYj0dvKEG349KhTJdT9dA/640?wx_fmt=png)

**@paperweekly 推荐**

#Object Detection

本文来自中国科学院大学和图森未来。检测任务中存在目标尺寸多样化的问题，为了解决这一问题，涌现了很多包含 SSD、FPN、SNIP 等在内的经典算法。**基于感受野对不同尺度目标的检测影响，作者提出了一个全新的三叉戟网络（TridentNet）。**

为了使模型对不同尺寸目标的“表达能力”近似，作者借鉴了 SNIP 的特征提取网络，采用了“scale-aware”的并行结构。为了加快模型的推理速度，作者采用了 dilated convolution 得到不同感受野的特征图，从而实现检测不同尺度目标的目的，取代了 SNIP 中的特征金字塔生成不同尺度目标的做法。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb7ia3bZdiaMMO0viaOCQiaiccLK3PBed0Pibto9fXbT0HgFY6tnZgiaXGL5tQQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbCEjt5KicUFH8iaFDq2EiaJVzSwbMliaHb4ynpptq8N4KWLzHMdmRIxJYJA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbARwDdIibCQcHqvGbqjY7PUKofkic60cKaVE8MMxzdevduDHZ0fiaibGaicQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbqaewSCXjoicefXnO8T5Dia7UmJrnPFz6ofsLlz1tk8A2ahJM1gpc28icQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbuia6nibaXnjDp5Puc4RvaKl6xWFjCnw63D7qZfeVicJOWQicQYx3USphnw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2833










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbic9M1FRFzQ9San5N9TyrXMqlbE1rXAJDS86ftgPXzkqKHszaM0cVb3g/640?wx_fmt=png)

**@paperweekly 推荐**

#Human Pose Estimation

本文来自旷视科技，夺得 COCO Keypoints 2018 比赛冠军。**本文旨在设计出一个好的 multi-stage 的人体姿态检测方法**，随着网络 stage 数目增加，模型的预测能力能够逐步提高的网络。而不会像 Hourglass 及其它网络一样，增加 stage 数目并不会显著提高模型的预测能力。作者采用了 top-down 的解决思路，将重心放在对单人关节点的检测上。针对 multi-stage 算法存在的问题，作者分别进行了不同的探索。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNwFwfPy9euA6Z3oouYiaG2Gqt4ZI5sUTc8no687DWmyjlfGbLms468A/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb5SC9CSSbeicL4icibVyiaF0abKGSvg5tOtLxwNnrIEic7ibz4L7fhzia52ibsg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNC484gFLXWYG391FWJypGtg9eGXJ9ydry0uWf1UDVOCg8riazTIX4zw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbhSrnzg4f6o5CxlibUYSvk7orZOghm2F5KRXq1zmqicw4qBiaS86Hj6alw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbqbTPDmmer4jv1O0uZhRp3Np4WkKfqibuuA3ETtAcuY8zxyQySuIwRsw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2834










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNyAr7VDicUIicFemmDqXeKXrTjKvCmWJEAoxQmMRxzbNiafMvb8NLjnlA/640?wx_fmt=png)

**@Phil 推荐**

#Object Detection

本文来自香港中文大学、商汤科技、Amazon 和南洋理工，**论文提出了一种新的 anchor 生成方法——Guided Anchoring，即通过图像特征来指导 anchor 的生成。** 通过预测 anchor 的位置和形状，来生成稀疏而且形状任意的 anchor，并且设计了 Feature Adaption 模块来修正特征图，使之与 anchor 形状更加匹配。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbRyXQGfj6tQ2e27UtkCTictiaaZSQ7nz6vKkXszs9jnX0wicibQ4ZW1EAzQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbaTCMSIbvxHuvKsIyaUU6pueu5f1xATGdldr0ickg78qBkPicQiabg28icg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbic0LU2da3utfZOVzTBjEBKBEEIjM9HTXuWepSGAJGbtso3MPATialFkA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb9KXdhRU6Ricvlf3FXuiaGq6x0g2sStzEmct9MOFaKRjeUue8sFWsZzGA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbkQNwjh9ytXXYPYzltvsdI1d9DrQwTLdfMJN4bU6DUU24Cxb8St4m5A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2806










![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNoB9r60g1Sv4zlE4UiagCfWibWIiclssu6An5sPwPFibjs5MTftYZ8Hk4w/640?wx_fmt=png)

**@afei 推荐**


#Image Segmentation

**本文提出了一种新的分割网络——BOWDA Net。**基于此网络，作者在 MICCAI 2012 前列腺分割竞赛中排行第一，结果为 state of the art。创新点有两点：1）针对前列腺 MR 图像边界不清晰的问题，提出了边界加权分割 loss，平滑了边界；2）针对数据集小的问题，作者借鉴了迁移学习以及 GAN 的思想，解决了 source domain 和 target domain shift 的问题，值得阅读。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbuja6vkSOTW6uYWvmAtb4wUpL1kTwHfDTaoJ4zNGiakSmWjMIrFzQeFA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbRIvUIjeEOIG1erbOZIAhlyBEEWapia3lPT2TpMWMxR9LTia7VzqIBOVQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbAzyu3iaNE3ib10EgGMGHIbcRjJCJqKEiaXicXvTdeJmmFuLo4daECe0p2A/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCblDZfhuuqicslicmNjXEtHRN2AGR0WSr2XwgcSjGx6saibyD2c3Tu2qF6Q/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb1rGmF0icsdfHbemKNYK9oQ2O2XSXTZP05vaabzWmUw6mHVic7MCBL1AQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2851










![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbic9CeOxebR9VtRhvaUIq6XXiaKl5uq4SlgO3iacB5En3uEdYPqb6IezDw/640?wx_fmt=png)

**@paperweekly 推荐**

#Image Inpainting

本文来自安大略理工大学，**论文提出了一种全新图像修复方法，能重构出图像的精细细节。**具体而言，作者提出了一种两阶段的对抗模型 EdgeConnect，该模型由一个边生成器和一个图像补全网络组成。边生成器将图像确实区域的边生成，而后图像补全网络以边为先验填补图像。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbPkEpcRjgQTdjzTIBaSBonum671o3PnJySlqnQ0Fcs4WicMXiaY0XYRSw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbW2GBaOctWnk52LCTh32qxicSu6icI4ibbCY4ZPEmgOMFWQCMVa1p1Tz1w/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbla2K5BzkAxhpkoibicV4zRKOTPWWt4qRhyQuvprEuv4oibX5OecfE821g/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbCuOpRzfYKSIia09Eibj4GRcALqV6Wf5lxwJTHzdof2Y0VPRMMeHVcvzA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb0v4tJ6nToNaFONVZZUx6zjjibvwGRSiahWicspd3IdTMZ3ymFia5uFZMBQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2832




源码链接

https://github.com/knazeri/edge-connect







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbR89RiaCDib6ahfNlDm2M7l4cj96zDEnYJbCFuco2dibqhkQcKKQiaYw3PA/640?wx_fmt=png)

** @JasonZHM 推荐**

#Image Compression

利用卷积自编码器进行图像压缩需要同时优化压缩率和重构图像质量，但由于用于表征压缩率的编码比特率不可微，因此不能直接反向传播。现有研究普遍采用额外训练熵估计器的方法解决这个问题。

**该研究则引入了来自神经网络架构搜索领域的网络剪枝方法**，提出了 CAE-ADMM 模型，直接对压缩后的编码进行剪枝，在保持编码速度的情况下，SSIM 及 MS-SSIM 的表现均超越了使用熵估计器的现有模型和传统编码器（JPEG、JPEG 2000 等）。该研究同时对引入的剪枝方法在模型中的效果进行了检验。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbt8WYQtXJbF088TxdtK1XLtz06iah1xUVbZyzbnnbJebBIRypaiabXD7A/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbaQl9DhvMVh7mDicibhg2ExvBSbuQuBPibEBwL1JV8DZyoJtjhZiasNzSAg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbicbcWBX0wcficMkRib7wPQjS64kibfFvT7bDIyccsfpU8G1he3hsNW4lTQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbR2j9wKNnHjhluOojbwUU68tTAPPESWdNfp6ZYQwFGSRw4XjTbU6Hyg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbfyrs9V1cnVWfXyvicTwESsunYOcZdpNiaQ2k9TnIIMIlhPX8OrKLeDHA/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2803




源码链接

https://github.com/JasonZHM/CAE-ADMM







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUMyCvJ7nksObSLatO1UHuTLcw5KYWPhREehBpXWY0uqseRtib5rxuvBw/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbiaCL0oRHQHcf2sZzUuS7r4AkvHgRSNZhVFnbDzQJdKwSQ4uLcbb0VrA/640?wx_fmt=png)

**@zhangjun 推荐**

#Bayesian Deep Learning

DNN 的不确定性量化是当前一大研究热点，在小数据机器学习、自动驾驶、强化学习、贝叶斯优化、主动学习等领域应用广泛。一种经典的方法是将模型参数视为随机变量，用近似推断的方法（比如：MCMC 类和 VI 类）扎实地求出每个参数的后验分布，这种方法相对准确，但计算效率较差，尤其对于参数数以亿计的复杂结构网络更加困难；另一种方法是朝着实用方向的，训练还是基于传统的 SGD + Dropout，在测试时对参数后验分布进行近似，使得模型在预测时可考虑到不确定性的影响。

**本文属于第二种思路，基于一种叫做 Stochastic Weight Averaging （SWA）的方法**，即将 T 个 Epoch 中的参数作为统计数据，求平均作为参数后验分布的均值，方差作为分布的方差（仅考虑后验分布为高斯的情况，也是大多数方法的假设。）。思路比较简单，相对传统的贝叶斯推断方法，计算效率非常高。这类方法中另一个典型代表是 Oxford 的 Yarin Gal 提出的 MC Dropout。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb66EUeox3bAyiciaCQcQc9rLiaWbNr7VhNT7h2UzVRaOEzsGOJfGV5Tnrw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbZ9kpicTB4YZ5jtjPibhDZ3Hzd41uzeor3nGgawoozmVQibEfMXFZicgrvA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbYjdgpuHwudaZy8aKyxtIwt4SHOxpcPfW06d2nNNvMeJWoJhW31pd4w/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbte8xhd7HibM798oETfHg6nOQrBwlPwylm1UK0GtC5cticn9LH5386BlA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbvwPdsckOP1X1ffZN2ht6y8BsnOQk59OGNVC8Cjv1xCFF1nibkic0Xibaw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2815




源码链接

https://github.com/wjmaddox/swa_gaussian







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjiaA5bbtkAnnJ2yLicAzlwmVdnAIic0THYptctQhZJRx7QYCx8TC9zwOow/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb3ibxklY9hRLcewNh6OGGSU9U688uIYKa6Z1NMGTJtmBIfjbIP1ASdicw/640?wx_fmt=png)

**@paperweekly 推荐**

#Recommender Systems

本文是明尼苏达大学和京东发表于 WSDM 2018 的工作。当前大多数推荐系统更注重用户和商品之间的宏观交互（如用户-商品评分矩阵），很少有人会结合用户的微观行为数据（如浏览商品的时长、对商品的阅读和评论）进行推荐。

**本文从微观行为的角度对推荐系统进行改进****，作者将用户的固有数据视为用户和商品之间的宏观交互，并保留了宏观交互的顺序信息，同时，每个宏观交互都包含一系列微观行为。**具体来说，论文提出了一个全新模型——RIB，它由输入层、Embedding 层（解决数据稀疏和数据高维的问题）、RNN 层（建模时序信息）、Attention 层（捕捉各种微观行为影响）和输出层组成。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbKzhZlwuywnsk7AyHPxpgzrSIYicX0eBt2u0NUturazBhpe6oMAKeAqg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbBeicmwgn2nVxaPic0byHd7jiaQjpqmUOjb6LkDBGPWicAtbAOyBPnXvWAg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbs4K3BGXUnGu0qGnu9zjntqNW120ywKFJRv6LEAc9hfeMDYOicuFVfyw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbib0Ogr20tgDl19LruTxH5vKhsicu2ROkucUxRGmuJIMAxAWQibgWT0gIA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbn5dEAwp2vxE4GEs43Dv21uezDPzibXvzdeibsJUIhfRar43FoyX6ku8Q/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2549










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjgzGNHdv2YBVm6bUicHjY2A8tV8hwJIiapvTYDGmFIyMclC4Xy6gD7krQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbJb9GzHR5mt1vdz0MJwGp0R8nHy5jlE9T10Mf14w8SxqN2db8T4efQg/640?wx_fmt=png)

****@paperweekly** 推荐**

#Deformable Convolution

本文来自牛津大学，**论文提出了一种分布偏移卷积 DSConv，可以轻松替换标准神经网络体系结构，并实现较低的存储器使用和较高的计算速度。**DSConv 将传统的卷积内核分解为两个组件：可变量化内核（VQK）和分布偏移。通过在 VQK 中仅存储整数值来实现较低的存储器使用和较高的速度，同时，通过应用基于内核和基于通道的分布偏移来保持与原始卷积相同的输出。

作者在 ResNet50 和 34 以及 AlexNet 和 MobileNet 上对 ImageNet 数据集测试了 DSConv。通过将浮点运算替换为整数运算，本文方法在卷积内核中实现了高达 14x 的内存使用量减少，并将运算速度提高了 10 倍。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbCx6YL7215vNI6cSpJTpR3FE1AycmBkdgibETyicZBicpURthMdWQj5SEg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbLneuoNC3y8FSXoqMFfgplpu4waJnXXQDfuVTRXCMeEic9pLiabicnBEyA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbpibOwooic2kGvAQ0f78fWc9nS5z9rIE8LFepcNNXmhWXIxW05dcdkxGw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbskxj6luJV2UglgADGrjialic5qzsjWfx5vFkv2bawc9atIsiaXicA2npUQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNKB8PFIGbIlpjaYh46EK9Q0xKJB6Vgy4iayJFic6NBXdaTUaG94qTg1A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2835










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmjzJtCDOe8XLVgMWs5E3yVgicbLfFfFUq5D0tPfYTibSxD2ZvWJFMCnVZJ3UvpE3V635rO33PkQkIg/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbicicbbiciat9CTrTnb9eKPEMhxU4HkTnQndxSynicibkTsSGNIIvul4IA3Eg/640?wx_fmt=png)

****@Rcypw** 推荐**


#Network Embedding

本文是 UIUC 和 HEC Montreal 发表于 WSDM 2018 的工作，**论文开创性地将强化学习思想应用到星型异构网络节点表示学习当中 ，利用马尔科夫链去获取最优的节点之间边的序列。**作者将奖励计算作为节点表示的外部任务的性能作为特征，目标是采取一系列行动来最大化累积奖励，基于长短记忆网络利用深度强化学习模型，完成网络表示学习。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbqibZmPuf7hJLuSBRq2wYee9P1uoQetRFAgPiaqO4NuXCJoo0e3icnzZ4w/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbxIt6OuMIKhWNR7fhwfFNayDE3Osqj7sMiaYEkatkl4aZvZ8jRLPvIEQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbGibNZpXYFXDKz6kBLavdbuT5rUdia4HDS56alhfKPXFCibLEwoERkBS0w/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbjbzibdmrHniaYT5btBjO2QAc8lXaZyvyZXmd8VtsLW51BHULRj03Z1wA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCb26s1WLAwFcSDr8L0fIdMO2lFxvxt1XICruicsqsUYNaT0SBq60TcvibQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2590







![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy8gx4ZNX5Tiaeicno09TPNjSVd4zMnx9hxYcw2n350iaTFOOe6u2F7GLoA/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbo87s1PO5CsyV81d4QprTVBuCt3mibMZqZ1iaEyQrOWAFMv50kPgiaX4OA/640?wx_fmt=png)

****@Layumi** 推荐**

#Person Re-identification

现在行人重识别高准确率模型真的鲁棒么？是不是像传统分类问题一样容易被攻击呢？**本文提出的方法，将目前行人重识别上较高的 baseline Recall@1=88.56%, mAP=70.28% **（layumi/Person_reID_baseline_pytorch）** 降到 Recall@1=0.68%, mAP=0.72%。**

对抗样本存在于很多任务中，但如何在不同任务中构造对抗样本是一个问题。对于 reID 来说，攻击的方式与正常的分类不同。因为 reID 在测试的时候的类别与训练时类别不同，没有相同的类别（也就是测试的人和训练的人不是同一批，Open-set）。那么在构造对抗样本时，传统的降低预测概率回传梯度方法就受限。在实验中也有相应结果。**文章提出了一种新的方法来攻击图像检索**（reID 是图像检索的一个子问题）。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbr293miamvxH2xEKB1xzYZcsL7Wpb9r4GPV2pEiaZc2LJysnjX6jcdJJg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbNyE6ibHqAGsRzAiadGHDg3o4Dt8BVUeY6KAp6IztaC7RZichebicVZNrNw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbM6axfUWUqQHDozcXAl9zNEoS5eD60ibcs7RpqHlwAFzAblxK6QREUXw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbEFSNibYg2KMkyz6lS0NKM6YVM0pOoN6Ms0cLNZJCqWzMJWCUnI9lFXg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnKfNqjCUjPTKYafPlReUCbwRWSjbVUw0pPrBia1xsUnXS5JZUYBJYAbjKlt7a5EoFpIFibXDxXXr8A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2799










**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****推 荐 有 礼#**




本期所有入选论文的推荐人

均将获得**PaperWeekly纪念周边一份**



![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm5Wb1iaUHxx8mBh1Km3dWjfPlgYsxpxlV44icJWDVwuPorALMxCQglAC8Dx8JMeic5wHeNw29gJV8SA/640?)


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWQfATNyq8icodseL6gFjp8w4sQ1DBTuiaChXPEcQ0Q6tmRmz2jJjzic7g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUk6ibiaGfmJl0icaK5go84z9iaLysegxS06wkEIrCkuL1eV2dicVoBusY4aQ/640)


**▲ **深度学习主题行李牌/卡套 + 防水贴纸




****礼物领取方式****



推荐人请根据**论文详情页底部留言**

添加小助手领取礼物

*每位用户仅限领取一次




**想要赢取以上周边好礼？**

**点击阅读原文**即刻推荐论文吧！




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击以下标题查看往期推荐：**




- 
[5篇顶会论文带你了解知识图谱最新研究进展](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247495148&idx=1&sn=74d28719da5b4327161c3cc5f788b1e7&chksm=96ea326ca19dbb7a09a8b2df01dd3707dbabf4872a0b574f38f4ce4be83cfbde58b243b8238a&scene=21#wechat_redirect)

- 
[NLP、CV、ML方向最新论文清单](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494552&idx=1&sn=d87b44cc418294e42a34423579373825&chksm=96ea3418a19dbd0ec95716e7dbb46b18c6d3d7a71cdab5c90fb782760f2a9224427cdefc65a2&scene=21#wechat_redirect)

- 
[本周有哪些值得读的论文？不如看看这18篇](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494225&idx=1&sn=888e5b2eda5b3b64da92d2ce2fe383ff&chksm=96ea35d1a19dbcc72f19636a2686d80a87042a7028e7aa2a68efbe6010f325f19f11ee068b68&scene=21#wechat_redirect)

- 
[近期值得读的10篇GAN进展论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493987&idx=1&sn=ce1bcdce28e78f4a307743e389f42b10&chksm=96ea36e3a19dbff5cff7f4f1c9d9fc482bb2144d80566319b3d26bce4d9ab80689d38ab2e427&scene=21#wechat_redirect)


- 
[想了解推荐系统最新研究进展？请收好这份清单](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491818&idx=1&sn=311962e2e41119a565c252a19037dd76&chksm=96ea3f6aa19db67c3fbfa77fbec65797d0ccc8f2930290d57c2016a3e55a8bb18b77fd10180b&scene=21#wechat_redirect)

- 
[近期知识图谱顶会论文推荐，你都读过哪几篇？](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493627&idx=1&sn=33e2f7c787fa9f14cef581f10b7dd2f7&chksm=96ea387ba19db16dc97620e28e6a7c8605b396b53f21e3eff6cf9553762a1dbc5233c580cc53&scene=21#wechat_redirect)










**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**



总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志



**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取更多论文推荐




