# 新的一年，想发有关对话系统的paper？快关注时下最大热点：智能化与个性化... - Paper weekly - CSDN博客





2019年01月29日 08:53:00[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：137









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgm9RFr5icmiaj0bibJxUeIGdAFHNM4G6PJEiccw293RuVnOiadQ4zcdibdJa5FFfn0ZMgpbKib4AAKD8dm2w/640)




**TL;DR:** 为大家介绍和分析一个即将成为未来一年研究热点的 sub-topic: **Personalized Dialog System！**有强烈发 paper 的小伙伴们注意啦，上面这句话对你们来说翻译过来就是：**这就是 19 年最有可能 get paper accepted 的任务之一咯！**




作者丨骆梁宸

学校丨北京大学本科在读

研究方向丨Dialogue/NLP/ML Theory

个人主页丨https://www.luolc.com/




# NLP的四个Open Problems & 对话系统的重要性




相信很多 NLP 研究者都已经拜读过由 Sebastian Ruder 在 Deep Learning Indaba 2018 上的 talk 整理而来的文章：***The 4 Biggest Open Problems in NLP***。




http://ruder.io/4-biggest-open-problems-in-nlp/




这篇含金量十足的文章来自于对包括 Yoshua Bengio 在内的 20 余位领域内顶级研究者的访谈整理而来。




四个 open problems 中排名第一的是 **Natural Language Understanding（自然语言理解）**问题，解决它是许多 NLP tasks 能否顺利实现的先决条件。与此同时，非常多的研究人员同时提到 Dialogue System（对话系统），特别是 Goal-Oriented（任务型）Dialogue System 也是一个非常重要的 open problem，或者说，是检验 NLU 问题是否可解的一种终极方式。 




从大约 2016、2017 年起，针对 Dialogue System 的研究逐渐从鲜有人问津到逐渐引起 NLP 社区内的重视。在刚刚过去的一年里，相关工作的数量增长迅猛，显示出其成为 NLP 领域内新一 (hǎo) 热 (guàn) 点 (shuǐ) 方向的潜质。 




而另一方面，随着发展初期通过将 Neural Machine Translation 中的方法直接换汤不换药的迁移到 Dialogue 的快速灌水阶段逐渐结束，如今再想要在这一 track 下发表文章已经不能再像从前那样简单粗暴，而必须要想办法聚焦到 Dialogue 中更加核心、更加有价值的点。 




在上文提到的访谈中 Kevin Gimpel 提到：




> 
*We should develop systems that read and understand text the way a person does, by **forming a representation of the world of the text, with the agents, objects, settings, and the relationships, goals, desires, and beliefs of the agents, and everything else that humans create to understand a piece of text.** Until we can do that, all of our progress is in improving our systems’ ability to do pattern matching.*





从这段话其实也能推断出 Dialogue 任务为什么被认为“非常困难”。以 NMT 作为对比，我们可以发现在大部分情形下，除非涉及很高的文学技巧或极深的历史背景，通常而言 NMT 只需要聚焦在所翻译的文本本身即可，几乎没有任何外沿 —— 一个好的翻译系统，其实就是要稳定准确且还原本意即可。




而对话则大有不同，想象人类对话的场景，决定我们如何产生或回复一句话的因素来自方方面面：对话的场合、谈话的目的、双 (多) 方的身份和心理与情绪状态等。这些通通隐藏在一句句对白的背后，是同样需要 forming 的 representation. 我们需要设法构造更加**智能化**的系统以关注到这些问题。 




**其中最为重要，也即将成为未来一段时间热点之一的，是 Dialogue System 的个性化问题。**




# Personalization in Dialogue System




对话的一个显著特点，同时也是与其他 NLP 场景如翻译、摘要和阅读理解等最大的不同，是谈话者具有的身份特征。很容易理解，一句话的风格随着其说出者的不同可以有极大变化；此外，在人们日常交流中，根据对方的身份和偏好灵活调整谈话的内容、风格和策略是非常自然的行为——而这些在 conventional dialogue model 中完全无法得以体现。 




在以 **Jiwei Li** 的工作 [1] 为代表的早期研究中，研究者们对个性化问题的前一部分，即**为 chatbot 赋予特定人格**进行了一定探索。但这一类工作的实用性是有明显限制的——我们更加期望 Agent 能够根据我们每个人的自身特点对我们进行个性化服务，而并不在意面对的 Agent 是性格温和、暴躁、还是傲娇的——实际上这类模型最具前景的实用化方向大概就是游戏 NPC 构建了。 




而个性化中意义更大的另一方面，即设法让 Agent 可以感知用户身份和偏好并以此提供个性化的对话，难度要大很多。这主要是**受限于数据集的缺失**——我们长期缺少额外标注有对话者的信息的数据集。




而上段提到的赋予人格，其实非常类似于 language style transfer/assignment 任务，并不过多受限于 Dialogue 的形式，因而可以通过其他类型的带身份标注的语料进行补充。而针对对方身份进行个性化，则是无论如何无法绕过带身份信息的 dialogue dataset 的。 




**而我们之所以能推测个性化对话系统很快将成为研究热点，便是因为数据集这一关键问题已经被解决了。 **




做 Dialogue System 的同学一定都知道 FAIR 的一个组：Team PerlAI。其不仅产出了 NLP 领域近十年来最重要的成果之一 ***Memory Network***，更重要的是在近年持续的发布新鲜高质量的对话数据集。




在 2018 年初他们新 release 了名为*** Persona-Chat ***的数据集 [2]，其中每段对话都包含了对谈话双方的 natural text 形式的描述。在 NeurIPS 2018 上还进一步扩充并完善了数据集作为 shared competition task。




更近的时候，ParlAI 还发布了和 CV 结合的 **personalized image chat 数据集 **[3]。此外，除了以上基于 chitchat 的数据集，ParlAI 也收录 ***personalized bAbI dialog*** 这一个性化 goal-oriented 数据集 [4]。




# Learning Personalized End-to-End Goal-Oriented Dialog




值得一提的是，以上这些个性化对话的研究都是基于 chitchat 的。而任务型对话，例如餐馆预定服务、个人助理等，也同样非常需要针对用户进行个性化服务。**这一方向的研究数量还较少，但具有很高的实用价值和继续探索的空间，是非常适合继续深入（& 发 paper）的蓝海。**




在本文的最后，**简略介绍一篇即将于本周四（2019.1.31）在 AAAI-19 上 presenting 的文章**，有关任务型对话的个性化：




![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglH853mtS5bgg2kt9qOQGceBz0fpwm0wx8IV4ia7jIibYQXN0h2qsJFOR6DuDEUJnicSoS4Ifx41zjnA/640?wx_fmt=jpeg)




https://www.luolc.com/publications/personalized-goal-oriented-dialog/




上方链接的文章 website 中还较为详细的概况了最近一段时间有关 Personalization 的其他相关进展，比本文所述更为详尽，可以先阅读了解。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglH853mtS5bgg2kt9qOQGceKeiaiatWpicKTw3PqUECmXabbmznoZ5YQb1oqFKHRmMBYEEyuzS9Cz0VQ/640?wx_fmt=png)

**▲**Figure 1(a): Three example dialogs are chosen from the personalized bAbI dialog dataset. Personalized and content-based responses are generated by the Personalized MemN2N and a standard memory network, respectively.




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglH853mtS5bgg2kt9qOQGce9ZH6bBIMEtuorbl1tWiaB4vv1jOW1ib4fPoA1kiaWibqU11ZsJujsGgb7A/640?wx_fmt=png)

**▲**Figure 1(b): Examples of valid candidates from a knowledge base that match the user request.




我们从一个例子出发，直观感受一下 conventional model 在不考虑个性化的情况下有什么不足。 




图中的对话发生在餐馆预定的场景中。Dialogue agent 需要根据用户的请求推荐餐馆，并在必要的时候提供额外信息。在三组对话中，用户输入的请求都是完全相同的。前两组对话的用户是一位年轻男性，非素食偏好；第三组对话的用户是一位年长女性，素食偏好。Figure 1(b) 是 KB 中检索到的满足用户要求的两个餐馆。 




**可以观察到：**




1. 传统模型的回复是朴素和无趣的，且无法像个性化模型一样根据用户身份调整语气和称呼；




2. 在推荐餐馆阶段，传统模型只能按随机顺序给出推荐 (即无法判断两个可能的选择中哪个更可能受顾客青睐)，而个性化模型则可以动态的调整推荐策略，在上例中，即是正确的考虑到了用户是否有素食偏好；




3. 最后，注意到用户请求中的「contact」既可以被解读成 KB 中的「phone」也可以被解读为「social media」。个性化模型在训练中可以学习到年轻人倾向社交媒体账号而年长者倾向电话号码这一事实，从而解决歧义而给出用户更期望的信息。




**这些现象反映了目前模型中对应的三个问题：**



- 
无法灵活调整语言风格 [5] 



- 
缺少根据用户信息动态调整对话策略的能力 [4] 



- 
难以处理用户请求中的歧义项 





而个性化任务型对话系统的目标便是解决上述问题。需要注意的是，在任务型对话中的个性化与 chitchat 有显著不同。区别于给 Agent 赋予一个 consistent 的个性，任务型对话中的个性化要更多的聚焦在用户的个性并需要 Agent 拥有对不同对话者进行调整从而提升对话效率和用户满意度的能力。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglH853mtS5bgg2kt9qOQGceHXLKKdFAbVrddttLQh7SG7F7sbXOJBz1p35WARbKZLTx2cLRmU6N6A/640?wx_fmt=png)

**▲**Figure 2: Personalized MemN2N architecture.




文章提出的模型 Personalized MemN2N 基于适用任务型对话的经典模型 End-to-End Memory Network，**包含三个主要部分**：profile embedding、global memory、personalized preference。




用户输入会被 encode 为一个 query vector，模型会读取 memory（左上部分）寻找相关的对话历史并生成 attention weights，之后加权求和并做线性变换得到输出 vector，这一部分即是**原始的 MemN2N**。




** Profile Embedding**




以 K-V 对表示的用户信息在 One-Hot 编码后经过一个可学习的参数矩阵变换为 profile embedding，在每一次 memory network 的迭代中加入到 query vector 中，并且用于修正 candidate pool 中的回复（根据用户身份直接过滤掉语气不得体的一部分 candidates）。




** Global Memory**




这一部分（左下）和 MemN2N 的结构相同，区别在于 memory 中储存的并非当前对话历史，而是其他类似的用户发生的其他对话的内容。这是基于类似的用户可能具有对答案类似的倾向而设计的。




**Personalized Preference**




这一部分用于处理用户请求的歧义部分，模型可以对 KB 中的每一列学习到一个 preference term，然后基于此对 logits 进行修正，以推荐用户更偏好的信息。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglH853mtS5bgg2kt9qOQGcekKxjfOKwhYxMTaIEHAIYfbL3CmMwE1CjEu2qPCsxc6QRdia0KJ3suyg/640?wx_fmt=png)




在任务型对话个性化数据集 personalized bAbI dialog 上，文章提出的模型在完整数据集上刷新了原先 state-of-the-art 模型超过 7 个百分点。 




除此之外，文章进行了许多定量和定性分析，包括中间参量的可视化，可解释性讨论和对照实验等。同时，在人工评测中，新模型也在任务完成率和用户满意度两项指标上获得显著提升。在此不做详细阐述，具体细节可以浏览文章的 Analysis 章节。




# 总结




对话系统中的个性化无疑将成为新的一年里最值得探索的方向之一，尤其是对于希望尽快发 paper 的同学，是非常不错的一个新坑。而 Persona-Chat 和 Personalized MemN2N 则分别代表了 chitchat 和 goal-oriented 两类 dialogue 任务中的最新 state-of-the-art，后者更是填补了任务型对话中的空白。如果希望做一些这方面新的工作，这两篇文章是很重要的参考。




提前祝各位新春快乐！新的一年多发 paper 哟~ ^.^




#  参考文献




[1] Jiwei Li, Michel Galley, Chris Brockett, Georgios P. Spithourakis, Jianfeng Gao, Bill Dolan. A Persona-Based Neural Conversation Model. ACL 2016. 

[2] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston. Personalizing Dialogue Agents: I have a dog, do you have pets too?. ACL 2018. 

[3] Kurt Shuster, Samuel Humeau, Antoine Bordes, Jason Weston. Engaging Image Chat: Modeling Personality in Grounded Dialogue. arXiv:1811.00945, 2018. 

[4] Chaitanya K. Joshi, Fei Mi, Boi Faltings. Personalization in Goal-Oriented Dialog. NIPS 2017. 

[5] Jonathan Herzig, Michal Shmueli-Scheuer, Tommy Sandbank and David Konopnicki. Neural Response Generation for Customer Service based on Personality Traits. INLG 2017. 




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)







**点击以下标题查看更多往期内容：**




- 
[Airbnb实时搜索排序中的Embedding技巧](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494488&idx=1&sn=452ac80c593a9b31252031eac38d0e01&chksm=96ea34d8a19dbdce940ed25bb93507aa6c4d118f84dd0bb965b060f232fe5d41894bbc9edcb6&scene=21#wechat_redirect)

- 
[图神经网络综述：模型与应用](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493906&idx=1&sn=15c9f18a1ce6baa15dc85ecb52e799f6&chksm=96ea3692a19dbf847c1711e6e194ad60d80d11138daf0938f90489a054d77cfd523bee2dc1d2&scene=21#wechat_redirect)

- 
[近期值得读的10篇GAN进展论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493987&idx=1&sn=ce1bcdce28e78f4a307743e389f42b10&chksm=96ea36e3a19dbff5cff7f4f1c9d9fc482bb2144d80566319b3d26bce4d9ab80689d38ab2e427&scene=21#wechat_redirect)


- 
[自然语言处理中的语言模型预训练方法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492317&idx=1&sn=e823a75d9463257ed9ea7b3e4677c1ae&chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&scene=21#wechat_redirect)

- 
[从傅里叶分析角度解读深度学习的泛化能力](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491082&idx=1&sn=d7c1cb39c3be43154c658ca5a791eb4c&chksm=96e9c18aa19e489c32fe36671e4208ce42bf200e3a7adeda200fa2785462d16f85c58bb455b4&scene=21#wechat_redirect)

- 
[两行代码玩转Google BERT句向量词向量](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493033&idx=1&sn=1ae1cd347126b10d6a857cd9bba7b601&chksm=96ea3a29a19db33f3c07723ed6e5ecbb8d2ff1b1617f1cf0d39cb3cc1e6e9c325cc29147d58d&scene=21#wechat_redirect)

- 
[AI Challenger 2018 机器翻译参赛总结](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494103&idx=1&sn=fc372862e0369b1f6a943bf997f6fc1b&chksm=96ea3657a19dbf4108bbc4179e779aa04ef05fe84f0013fa6425b0cd7e761e9880917361c4c1&scene=21#wechat_redirect)

- 
[Google BERT应用之红楼梦对话人物提取](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494507&idx=1&sn=3c3cafef0fb51a7e40d9b9bbab53fd5f&chksm=96ea34eba19dbdfd31eaa760bb7cfd5e18f2e967c83c6ea6693ad9a062c55b3009211d824ca3&scene=21#wechat_redirect)

- 
[深度长文：NLP的巨人肩膀（上）](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493520&idx=1&sn=2b04c009ef75291ef3d19e8fe673aa36&chksm=96ea3810a19db10621e7a661974c796e8adeffc31625a769f8db1d87ba803cd58a30d40ad7ce&scene=21#wechat_redirect)

- 
[NLP的巨人肩膀（下）：从CoVe到BERT](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493731&idx=1&sn=51206e4ca3983548436d889590ab5347&chksm=96ea37e3a19dbef5b6db3143eb9df822915126d3d8f61fe73ddb9f8fa329d568ec79a662acb1&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**



总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志



**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取最新论文推荐




