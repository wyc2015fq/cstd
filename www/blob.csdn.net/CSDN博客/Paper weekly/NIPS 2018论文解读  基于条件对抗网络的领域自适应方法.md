# NIPS 2018论文解读 | 基于条件对抗网络的领域自适应方法 - Paper weekly - CSDN博客





2018年11月26日 12:09:41[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：564









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgnC9iaic8hDbiadLafh7TtCZS6icEYddVmMqZBksDV7cQkKmAu95h53FxyibqmZOS1yQgHibJT0WYD2s1Zw/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **120** 篇文章

作者丨王晋东


学校丨中国科学院计算技术研究所博士生

研究方向丨迁移学习和机器学习




这篇论文即将发表于 NIPS 2018（现在应该叫 NeurIPS 了），作者是清华大学的龙明盛团队。论文研究的还是**领域自适应（Domain Adaptation）**这一热点问题，在一些公共的数据集中，本文的方法取得了当前最优的结果。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCRYbQQIoJCFcqy4licFj3Y7r1Gcb89zj94NF3IibGkpYYMjqia0cljaMibQ/640)




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCF7ZJLvmymeYia1gawMqmj7odelIYRiaP5tjRAVlyhqnTicZX0xrkCvibQQ/640)




# 论文动机




Domain Adaptation 问题一直以来是迁移学习和计算机视觉领域等的研究热点。从传统方法，到深度方法，再到最近的对抗方法，都在尝试解决此问题。作者在本文中提出，**现在的对抗方法面临两个挑战： **




一是当数据特征具有非常复杂的模态结构时，对抗方法无法捕获多模态的数据结构，容易造成负迁移。通俗点说就是，现有的方法没有抓住深度特征之间的关系，只是把它们一股脑进行对抗适配。 




二是当上面的问题存在时，domain classifier 就很容易出错，所以造成迁移效果不好。




# 论文方法




本文提出了**基于条件对抗网络的领域自适应方法**，英文名叫做 Conditional Adversarial Domain Adaptation。从题目中不难看出，**主要由 Condition + Adversarial + Adaptation 这三部分构成。**




进行 condition 的时候，用到了一个叫做 **multilinear map** 的数学工具，主要是来刻画多个特征和类别之间的关系。下面我们分别进行描述。



**对抗网络基本结构**




发表于 ICML 2015 的经典文章 ***Unsupervised domain adaptation by backpropagation***[1] 中提出了用对抗的思想进行 Domain Adaptation，该方法名叫 DANN（或 RevGrad）。核心的问题是同时学习分类器 G、特征提取器 F、以及领域判别器 D。通过最小化分类器误差，最大化判别器误差，使得学习到的特征表达具有跨领域不变性。 




作者指出，DANN 的方法只是关注了数据特征的整体分布，忽略了和类别之间的相关性。因此，**本文首先提出，要将特征和类别一起做自适应。**公式如下：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCWF8kxSwxlOYMJ0s1v7tQUjiciafDibdu8hibWiaw1dgMJGYO59EzmONDCicQ/640)




其中，f 和 g 分别是特征和类别。通过类似于 GAN 的最大最小优化方法，就可以进行 Domain Adaptation。




**条件对抗机制**




联合优化 (f,g) 的方法很多，将它们的特征向量连接起来是最直接的方法。但是这会造成它们彼此之间还是相互无关。达不到控制条件的目的。 




**作者借鉴了数学上的多线性映射（Multilinear Map）概念，来表征特征和分类器彼此之间的关系。**什么是多线性映射？通俗点说就是，f(x)→y 是单映射，f(x,y)→z 是双映射，以此类推。线性呢？当固定其他自变量时，f 对未固定的那个自变量满足线性性（就是可加性、数乘不变），维基百科上对多线性映射的解释太抽象了。




那么，如何进行多线性映射？用 f⊗g。这里的 ⊗ 表示张量乘法，就是很多维的矩阵的乘法。 




由于在深度网络中，特征维度往往很高。为了解决维度高导致的计算复杂度增加的问题，作者引入了相应的计算方法：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCAlmVcPOD953k1mjrEIGSAMUQ1eURrSjXP8BmFTXJ6jFzMXu9rYfPibQ/640)




就是说，**当数据维度太高时，直接从特征里随机采样一些向量做乘法。**否则，用作者提出的方法做映射。




**条件对抗网络**




为了应对那些对迁移有负面影响的样本，作者用熵来控制它们的重要性，把熵操作加到了对抗网络中。




整个网络的优化目标如下：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCB1ffWJv3qssibLRSiadqRtZiauXPiagzGu241ER8iaX2W2MicTFDysk1vXzw/640)




作者还在文章中分析了方法的理论误差上界。




# 实验




实验部分与传统的 Domain Adaptation 相同，在 Office-31，ImageCLEF-DA，Office-Home，MNIST，USPS，以及 SVHN 这些公开数据集上都进行了实验。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCXy6uPzer4dmQXgu2POiaCw9dXDaAM3RZsx1UiaWJqcicw3KbxWkLPYIIQ/640)




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgllBpB6N8rD2XXBHiaX6mQdCBL2HebXG39DhaLBibHGAwMtQYXRiaRfM4vXZCFhJnepics2toRCMxcfrA/640)




实验比较充分，详细结果可以看原文。从结果上来说，取得了比作者之前的 JAN 更好的结果，不过提升幅度有限，这可能是深度网络"挤牙膏"式的增长。




# 参考文献




[1] Ganin, Y. and Lempitsky, V. Unsupervised domain adaptation by backpropagation. In International Conference on Machine Learning (ICML), 2015.

**本文由 AI 学术社区 PaperWeekly 精选推荐，社区目前已覆盖自然语言处理、计算机视觉、人工智能、机器学习、数据挖掘和信息检索等研究方向，点击「****阅读原文****」即刻加入社区！**

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击标题查看往期内容推荐：**




- 
[自动机器学习（AutoML）最新综述](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492654&idx=1&sn=b9047d5cca7657f02dc7f6685ef04037&chksm=96ea3baea19db2b8dc1c1267801d0c585b3cf072531af86abdeb73c6fb4c07dc3325c2d13d57&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492002&idx=1&sn=2d2c8551cd44ee5506cac3ff38a438f3&chksm=96ea3e22a19db73404bc9af4de8b3c406cbc1097f305b63da82efd1d07915500f4042927ee22&scene=21#wechat_redirect)[自然语言处理中的语言模型预训练方法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492317&idx=1&sn=e823a75d9463257ed9ea7b3e4677c1ae&chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492226&idx=1&sn=eafb23c1658f487f47254128bcc6e1b2&chksm=96ea3d02a19db4149215378b7c18d6a92dcd6bbacbbeb73e9bfa2d1594073528adab03ccd031&scene=21#wechat_redirect)[从傅里叶分析角度解读深度学习的泛化能力](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491082&idx=1&sn=d7c1cb39c3be43154c658ca5a791eb4c&chksm=96e9c18aa19e489c32fe36671e4208ce42bf200e3a7adeda200fa2785462d16f85c58bb455b4&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487949&idx=1&sn=e09391933f3c4493cfb737b0ea2cf0af&chksm=96e9ce4da19e475b0c789088d403a0f49449b8ba0c43734aa835c5d2a7cb69c3d839c7ce056c&scene=21#wechat_redirect)[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492415&idx=1&sn=a359e72ee99555f7a2fb4e21b2ad51db&chksm=96ea3cbfa19db5a913b9ed01490df6e902abfeb36856bb5be946527a070d399ee37a3ff6c750&scene=21#wechat_redirect)[深度](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492065&idx=1&sn=a91d7ae724eed652ca87f647910bf666&chksm=96ea3e61a19db777c615d64abf564110ee4d1c32ecca2a629a7c0158a98bf6ccb2ec0fc05814&scene=21#wechat_redirect)[解读DeepMind新作：史上最强GAN图像生成器](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492065&idx=1&sn=a91d7ae724eed652ca87f647910bf666&chksm=96ea3e61a19db777c615d64abf564110ee4d1c32ecca2a629a7c0158a98bf6ccb2ec0fc05814&scene=21#wechat_redirect)

- 
[两行代码玩转Google BERT句向量词向量](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493033&idx=1&sn=1ae1cd347126b10d6a857cd9bba7b601&chksm=96ea3a29a19db33f3c07723ed6e5ecbb8d2ff1b1617f1cf0d39cb3cc1e6e9c325cc29147d58d&scene=21#wechat_redirect)

- 
[这16篇最新论文，帮你轻松积攒知识点](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492912&idx=1&sn=e223b0bf570148493313ea8780cef2fc&chksm=96ea3ab0a19db3a6eb87b8c8d6cb41d1a4ae0d85b5fd7b616baa970234124c320fda1cdcc7d9&scene=21#wechat_redirect)

- 
[TensorSpace：超酷炫3D神经网络可视化框架](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492746&idx=1&sn=921d7315a973b85dd4e802cb5fd456fb&chksm=96ea3b0aa19db21c48841ddcee38592a3c086ae8fa1a9893cf46ff974f0f38fb350bcd528265&scene=21#wechat_redirect)












**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**



总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志



**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**



PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)

▽ 点击 | 阅读原文| 下载论文




