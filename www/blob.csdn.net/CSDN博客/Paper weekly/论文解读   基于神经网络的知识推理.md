
# 论文解读 | 基于神经网络的知识推理 - Paper weekly - CSDN博客


2018年03月08日 00:00:00[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：416



![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?wxfrom=5&wx_lazy=1)

在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。

在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。

点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第**49**篇文章
本期推荐的论文笔记来自 PaperWeekly 社区用户**@britin**。**本文对基于 RNN 的从大规模知识库中进行推理进行了精度和可操作性的改善**，提出的模型使用单个 RNN 就可以在多种 relation types 之间进行推理。
如果你对本文工作感兴趣，点击底部的**阅读原文**即可查看原论文。
# 关于作者：Britin，中科院物理学硕士，研究方向为自然语言处理和计算机视觉。

■ 论文 | Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks
■ 链接 | https://www.paperweekly.site/papers/1521
■ 源码 | https://rajarshd.github.io/ChainsofReasoning

# 论文动机

使用神经网络进行更为复杂的推理以增加 KB 中的条目正在引起广泛关注，这么做的一个重要原因是**为了同时支持 look-up 类型的问答系统以及从 entity 和 relation 中间接推理到答案的问答系统**。

KB 通常是非常不完整的，推理可以完善那些缺失的信息。见下图：

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglnVv5PV2ZFPGLQpVdX4SQY2UsZmf7gW3iaXRKSybXYSU9LosKl17fZc8B0nG5iayeAtav8Bib7bpwEw/640)

**已有的方法大多是基于 symbolic 和 logical 的推理系统**，比如 Universal Schema，它学习 relation type 的向量表示，包括结构化 KB 中的以及自然语言文本中的关系表示，其中的 matrix completion 机制可以进行简单的推理，但只能对单条 evidence 进行操作，比如从 microsoft-located-in-seattle 推理出 microsoft-HQ-in-seattle。

**更高级的推理是从从句中得到包含三个或更多实体的 multi-hop 的知识库图路径**。比如可以从 Melinda–spouse–Bill–chairman–Microsoft–HQ-in–Seattle 得到 Melinda–lives-in–Seattle。

**这种推理通常用 path ranking algorithm 进行**。RNN 沿着任意长度的路径组成了每条边关系的 embeddings，输出一个表示路径两端实体之间关系的向量表示。但是这些方法只能用于小型或人造数据库上，并且对于许多情况下来说还是不准确不实际。

**本文提出的方法则可以对大型的多语义 KB 进行推理，****本文对基于 RNN 的从大规模 KB 中进行推理进行了精度和可操作性的改善：**

之前的工作只推理了 relation，没有推理组成路径上节点的 entities，本文对关系类型，实体和实体类型进行了联合学习和推理。

本文使用了 neural attention 机制对多条路径进行推理。

之前的方法最大的问题是要为每一个需要预测的 relation-type 单独训练模型。而本文只训练一个 RNN 来预测所有的 relation type。另外，由于训练的 multi-task 特性，共享了 RNN 参数，精度也显著提高了。


# 模型介绍
**本文首先介绍了基本的 Path-RNN 的架构，本文的一切改进都是基于该模型的**。
Path-RNN 的输入是两个实体之间的路径，输出推理出的二者之间的新关系。通过将关系之间的连接用 RNN 表示来进行推理。路径的表示是在处理完路径中所有的关系之后由 RNN 的最后的隐状态给出的。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglnVv5PV2ZFPGLQpVdX4SQY92nJfEtTAibcyLErwI9QLMiaA7ezoVqwaRAukBr1RbQ92sfTX5oZPepg/640)
架构如图所示，对每一条可能的路径用一个 RNN 来表示，将改路径每一个节点上的 entity 和连接的 relation 进行向量化后输入一个 RNN 单元，整条路径的最终向量表示就是 RNN 最后一个单元输出的 Hidden state，将改路径的向量表示和要预测的关系的向量表示求相似度，相似度最高的就是目标路径。
**这个模型的缺点是每一个 relation type 都要训练一个新的模型，变量无法共享，数量巨大**。另外只选择相似度最高的那一个路径可能会忽略掉其他路径所隐含的信息，还造成了计算浪费。
**本文对这个模型做出的改进有：**
本文共享了 relation type 的表示以及 RNN 的 composition matrices，这样同样的训练数据变量就大大减少了。训练模型的损失函数用的是 negative log-likelihood。
分别用 Top-k，average 和 LogSumExp 方法为每一条路径的相似度评分加上权重，这样就考虑了每一条路径包含的信息，而不仅仅是评分最高的那条。

# 实验结果

本文在一个大型的 freebase 实体和关系数据集以及 clueweb 文本数据集上做了验证。

和先前最好的结果相比，本文在 MAP 上提高了 25%。另外本文还单独设计了一个验证来验证在同一个 RNN 中共享 strength 的效果，结果证明在训练过程中一些出现频率较小的关系也提高了 54% 的精度。

本文还在另一个数据集上做了验证：chains of resoning in WordNet。和目前最好的结果相比，在平均分位数上的错误率减少了 84%。

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglnVv5PV2ZFPGLQpVdX4SQYIE0FARbMEDAMwsJOnfChFm910p4ibSicsrJdgmeXbAsjLM2icu9T9C7ibA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglnVv5PV2ZFPGLQpVdX4SQYGiaB1QxaMGdCwPzPTfGlmB2HZUxdxauHP4hkwiagME9F7INlpurh94kQ/640)

# 文章评价

**本文提出的模型使用单个 RNN 就可以在多种 relation types 之间进行推理**。并且利用了多条可能路径以及路径间所有实体和关系的综合信息，这些信息在之前的方法中都是忽略的，极大程度的提高了精度。但是由于数据的稀疏性，在处理较长的文本特征时性能就会减弱。

**本文由 AI 学术社区 PaperWeekly 精选推荐，社区目前已覆盖自然语言处理、计算机视觉、人工智能、机器学习、数据挖掘和信息检索等研究方向，点击「****阅读原文****」即刻加入社区！**

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkvSxCRgqK914dI363k7VWmXJBVCNtexC0iaXJXUohTRgBpX4wGrDNYNpPB6SrZHiccz24zYcN2th2Q/640?)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)**\#****榜 单 公 布****\#**

**[2017年度最值得读的AI论文 | NLP篇 · 评选结果公布](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487348&idx=1&sn=8ee8bf57418342a419fe73829cb14e75&chksm=96e9d0f4a19e59e288dcb105bd90b1e13f419ee7268ac69eba7cd6dac12e2e64aa84c56e5c07&scene=21#wechat_redirect)**
**[2017年度最值得读的AI论文 | CV篇 · 评选结果公布](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487362&idx=1&sn=980153481f88ba5d6ba2929fd08240f3&chksm=96e9d002a19e5914f845973111b7056d24a28a8f7932479178c9cfcdb10c05c3284d5c0eb602&scene=21#wechat_redirect)**

我是彩蛋

**解锁新功能：热门职位推荐！**

PaperWeekly小程序升级啦

**今日arXiv√猜你喜欢√****热门职位****√**

找全职找实习都不是问题
**解锁方式**
1. 识别下方二维码打开小程序
2. 用PaperWeekly社区账号进行登陆
3. 登陆后即可解锁所有功能

**职位发布**
请添加小助手微信（**pwbot01**）进行咨询

**长按识别二维码，使用小程序**
*点击阅读原文即可注册

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnwLopkg177jgoQCbq2j2UJqSZOScYnsaSZf7ibXORdFOUEicycYycARG6V9pvHMyY7jYpdZFKpxcSQ/640?)


**关于PaperWeekly**

PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)
▽ 点击 |阅读原文| 查看原论文


