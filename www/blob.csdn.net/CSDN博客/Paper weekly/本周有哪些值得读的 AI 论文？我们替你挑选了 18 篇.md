# 本周有哪些值得读的 AI 论文？我们替你挑选了 18 篇 - Paper weekly - CSDN博客





2019年01月11日 18:45:06[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：65









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhglryG74dIr2B1019Yibv9PAGsWGGYBiaoSGbK2kzUnbIsicCEiazKMticicR0MPtmr1ynDovFe2kGicSydcg/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **127** 篇文章

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?)


![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyAQnnnQiab5kKbOBpM8gZAFLeV2RgkHVo0z8jcKxswibbE6ce2J0FlvMg/640?wx_fmt=png)

**@hauturier 推荐**

#Dialog Systems

本文是一篇来自微软和 Google Brain 的**对话系统综述文章**，论文针对问答型、任务型和聊天机器人这三类对话系统，回顾了各自当前最优的方法，并将它们与传统方法加以结合。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSydacMLGyFu7K5BGHUYJYOc0C6DkymrjmLDsMmQtHoUVps0m0cm43clQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyo3Oqe6JtPKEvf6NomEcxGV1pcMxxYCibrZgwK0fKOfoYL2UAKM3XTAQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSytnWia4UxL3n0GKh1jt3EfwzhEUYn8tY1ThJodhEQ2re4oxC0qIXNBtg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyiacgZePxCyJe73EFebsZRL1RCova3oJz6m2DooLnibKHhqrIJIJQhpPQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyXMFYPfeibbzGpzZfXNL3sNibpmKbWOicca0LbKDibvgV3KgUGsYSxAPDQQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2676




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy0x9W7DVHl1bGnJ2hBV9ibSiaIyuATqghSHAEibTXcoXRibicJKW9oqVxwOw/640?wx_fmt=png)

**@paperweekly 推荐**

#Response Generation

本文来自阿尔伯塔大学。Seq2Seq 模型在提高会话代理性能方面取得了重大突破，它虽然能生成句法良好的回复，但回复缺乏对上下文的感知及多样性，大部分都是没有营养的通用回复。

针对该问题，**本文提出了一个完全数据驱动的神经交互模型THRED，通过层次化的联合 attention 机制，在回复生成中利用对话历史和主题信息，使对话更加多样化。**此外，论文还引入了两种新的自动化评价指标：语义相似度和回复回声指数。实验表明，本文模型能产生更具多样性并且上下文相关的回复。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyr4moLw5Okl8fjnle9KicFh8r0EROBVYDfrXjHZBMeOxVGf7QYT5Memw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyfI5W7lCdp7EYemXTG8iaFDibvBVUXI7iahrOGQmDJrtE2x9VMekic5EWXQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSywj3oibIWoMBoFRQBhQsVxiaQftnuYdaBT8eAGz8t2pQZK47C68U074Tg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyiatNkX7FySPyGSSibHzibcw0Ge3gQE0JqdpUibfbicDYNoOWb6CO3U8sz5A/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyaDG7g0XAZUnXMmOlFNpII1b3ia6RWhrJANQfKVBXt8wT9QoaJk3m7qA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyumP418RvNZ98bUK4IJ3ozsRVMbTngrlWRfIWYfRf7Okx3DjlmdP85A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2743




源码链接

https://github.com/nouhadziri/THRED




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyibmDwiaickdqtPansYpfrbqURYTH9vSmnFDA0ErgNRdRagNibRoiak4CpDw/640?wx_fmt=png)

**@zkt18 推荐**

#Question Answering

本文是北京大学、腾讯和中科院发表于 AAAI 2019 的工作。Answer Selection 和 KBQA 是 QA 中的两个重要任务，现有方法通常会将二者分开做。**论文使用 multi-task 将二者同时进行，提出了新颖的 multi-view attention 多任务模型。**首先，两个任务都可视为 ranking 任务，一个在 text-level，另一个在 knowledge-level；其次两个任务可以互相提升，一个利用上下文信息，一个利用外部信息。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy1HoPxU9pjiaFTutibgl6PEWAcERCL6ukWwOIYQgLsGaz4JmGI5bAhxTQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyZibOjsON0QVGUiaFZGVVGCJribY9TtLgUd0Jyf63fWIVkticJ0pjkHWa5g/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy4bEebohkVrN5IVtkajkH9aia6XwtybTJ26l9tgNG7ShGxIjicnzciclhA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyLZvmN3ZpZBvxVfGNleyZO3gUD9X9yVTP0CGtetcBoCHKSFBjXiaT8Vw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy7Ca64psF7epib8Qw4PD1qHyfUBnqUzVOcAGOS6NnV9ia5gQS8YrnobDw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyRPo8JXwM3gt7xVgWkiaOQaiacOcXXm9mrm6CpQ3NP78pyCKiacgKXuMJw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2637










![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyCBZZVDoU9K3xdEw92Q02HZd7BTDTmbC8hyUknXx1hdn6qq7uviaiaUFg/640?wx_fmt=png)

****@paperweekly** 推荐**

#Machine Comprehension

本文是浙江大学发表于 NeurIPS 2018 的工作。机器理解是 NLP 中一个非常重要的任务，**论文提出了一个用机器理解作为补充结构来提升端到端生成任务表现的模型。**作者将机器理解任务中的编码器和模型层作为迁移对象，将其用于 Seq2Seq 模型编码和解码阶段来提升 Seq2Seq 的生成效果，让生成过程可以对语义进行更深层次的理解。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyvwuTjjk1Zu0mgFonctQgAuE99v7fq1bDCVEaEM7VGAAzfBoHojicKGA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy9maMKcotvgBU5mMS0GTlcywCuayFEbJhHlYHzIz4UAw2fkMvL3coLA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSywHBbGTsrWawtpXnQzXhlle5pfw45PbicezYialiax79cKnX4p77n8kqyA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyDQia19K1ibD2lVibYrPLcEXnib6DibiauR1MGhtLZrn0IniaxNdjJLCfz5nRQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSymZETLzL6zQUZiaCR0KyHpvdQemdvumzIt21M1zp6KJemJ6cssQNYEiaw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSykdRmJblHprncTcE7xLaIIOM9vAaHAwYkTef3Yb4yprWiczlhN9X29rQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2693










![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy5mKrAic9l8mCL6mfefaQ9erHvP9MvbAUWb7icChkdclB9DbIvQNhoicvA/640?wx_fmt=png)

**@paperweekly 推荐**

#Sentiment Classification

本文是香港科技大学杨强组发表于 AAAI 2019 的工作，**该文提出了一个新的跨 aspect 粒度的迁移问题**，从更容易获取大量标签数据的粗粒度的aspect类别任务迁移到数据匮乏的细粒度 aspect 实体任务。

在该问题设置中，需要同时解决任务间 aspect 粒度差异与领域特征分布差异的问题。**论文模型提出了一个自监督的由粗到细的注意力模块来减少任务间粒度的差异**，并且采用了对比特征对齐方法来语义上的对齐 aspect 特定的特征表达。

实验结果表明，通过利用源 aspect 类别任务提炼出的有用知识，即使对于目标 aspect 实体任务采用简单 attention-based RNN 模型也能取得优秀的性能。并且该论文提供了用于迁移的，大规模，多领域，aspect 类别的语料。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyR7xllF7tzOFoPt67KH0ymiaIfKKrtJ3a63icoBdKOkicdPMicKRWKRjCIg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyud5KNxIvIJMicocmczjs3jPMAzNlbsF8fqUicRvom0sg0ibEzhBLuLzNA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyeRXx0Oza8ANIt1t0ejKva66MrcJuwXS1sZ6dwZ4bggH8uqwK392vaw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyg13msERpic209rBOwiaV6d16RN5BwAu511yqiarMibYIdJLadjRYQDTPicQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyt4PKeC3WIibsugpOIobSiaWJMPsyDic70sRTKSeLVXVeh9DjicbSJ4Am2w/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyG6h4TcoJyVuGXwiaFIIdesGlAAj73GE9O49PHCI032Ph6Y42nUcfWuw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2717










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyDbGCEWGpibDBlyWK9xWlvKeIViaWo5U8b7YpDmFJzGHQztq6auMBH4Iw/640?wx_fmt=png)

**@guohao916 推荐**

#Conversational Question Answering

本文来自微软，**论文作者提出了一种全新的基于上下文注意力机制的深度神经网络模型 SDNet 以解决对话问答任务。**通过利用内部注意力机制和自注意力机制，对篇章和对话内容历史信息进行建模从而理解对话流程。

作者融合了 NLP 上的最新的突破性模型 BERT，并且在该预训练模型的基础上进行改进微调。实验结果表明，SDNet 取得了好于之前一系列模型的结果。在 CoQA 数据集上，F1 指标上相比于最新模型提升了 1.6%。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyFxBzOAJEFgCAXo0B0iakXdLibt1cNibG5zVHXjb1vaMHv5sBZz2QRiatfA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyVC2GJ9SbD9VXdFCOXrOywllO2Bdu2jz23E6CeKB2d0sDT8VVB7S8nw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyYPMTByxjCJXnvhBhQTTJGfVDTicDjfpLibte1p4k1t3DULA2L5ToG5xA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyFbI9SZTYgicsW7lIvHYl89XyBiamKFmL8DXrqQD8L7ej3dVNkYJUCsbg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyYKUnnwjj57EDKU8D0ru5PMicibdWZtNydbWgkC3v5htBFY08qqaEXpNw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2628










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy7bib7vMnz9ibxTRQh1xzCxibyhBRkkCG3Cdneorxztp7qhBLGUdlO9FJw/640?wx_fmt=png)

**@IndexFziQ 推荐**

#Language Model

本文是 Samuel R. Bowman 等人的最新工作，**论文关注的是语境化词语表示问题**。最近的一些预训练语言模型的工作（ELMo、BERT 等）表明，预训练句子编码器可以在 NLP 任务上获得非常强的性能。

然而，每篇论文都使用自己的评估方法，不清楚哪个预训练任务最有效，或者是否可以有效地组合多个预训练任务。并且，在句子到向量编码的相关设置中，使用多个标注数据集的多任务学习已经产生了鲁棒的当前最佳结果，也不清楚是不是多任务学习的作用。 

**本文根据 GLUE 基准测试中的 9 个语言理解任务，评估了由不同的预训练任务和这些任务的几种组合而成训练可重用的 Sentence Encoder。**实验结果表明语言建模是其中最有效的一个预训练任务，多任务学习可以进一步提高模型效果。

然而，**ELMo 预训练也存在脆弱性和限制：**1）在一些任务上，ELMo 的效果并不是很明显；2）可能对特定的任务 ELMo 才会很有效果，并且现有的多任务学习方法也无法提高句子编码器的泛化能力致通用的地步。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyvOuNygEAEAibJAS1ZGujUmqq5tL96e1RWo0QiadiczknKSicroh7Wyt0Gw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyH5WKtHCUwqYMFhfAC065OZRjppNF1aYicS4BG5a3ApWr7iaojbc8cy6A/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyQD0yC77e1hljXJXW6Wt3hgKkibsQub7vjAiakWJIwrBh3e3FmsXKibQHQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyMRibBRbEysU81GRKfUttG92Mhj541DY8V3hN1KQLFMJSo11scYyQniaA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSymdlaqp6q42Jv1cqr4KZKdAu2ib2iaWRDEgJNgB9tsJAwtu141SeYQepw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyac45RMbJacOCzVdEVWBkgMfPPGkNuO4XYxIlQ6J1JEfNhaibviaj2N9w/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2728




源码链接

https://github.com/jsalt18-sentence-repl/jiant










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyYyqqUXhuuxgpNKiaDq35O0qKkJiaWtlfa0CJonc6NrrUa2YzDFicWE5zg/640?wx_fmt=png)

**@paperweekly 推荐**

#Object Detection

本文是旷视科技和复旦大学发表于 NeurIPS 2018 的工作。近年来，深度神经网络对于目标检测任务的提升取得了巨大突破。通常做法是运用目标检测算法为一张给定图像生成一系列边界框，同时分类标注每个目标。但对于卷积神经网络而言，直接无序生成任意数量的预测框并非无足轻重，Anchor 的思想也正因此应运而生，并在目标检测任务上得到广泛应用。

**本文提出了一个全新灵活的锚点框机制 MetaAnchor，其锚点框函数可由任意自定义的先验框动态生成。**加上权重预测，MetaAnchor 可与大多数基于锚点框的目标检测系统（如当前最优的单步检测器 RetinaNet）协同工作。相较于预定义锚点框方法，实验证明 MetaAnchor 对于锚点框设置和边界框分布更为鲁棒，并在迁移任务上深具潜力。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy6icjiaNvo5LNBgDg9FnuibPDOa2Z3jR9tNwhYDpUSlPH8fkxuHYaEUMCA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyNYQYkWpde7Rho4mqfmiaX12hcQF8L94UpkSHiaJld7IicDiaWdw9cibsCIw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyTiaUq1Uiahxiaw1Ra8ibUbDFze14M1dGF1rJY1vaDaP8WC8dKdINA36guQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy03OXNETIxAh5rnSnJiaHhPryI5fKAh60wCZcxgOzTrD0iatWib8lxex2Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyNiaYZcMOxZic9icvJLpCt0Gcz5HN47fib1am6f4PeFQvqriaojljPZFGsicA/640?wx_fmt=png)



**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSykHp4I9NxD4X0NVfKVLQQCC4zNiaULRW80vnichaI7qmktILfazV7KS7A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2670










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyqLzOSVPtkc47ZPBVVRVn5DpfTMibN7phZ9XCBG7lpichmGP7icqPMlKQA/640?wx_fmt=png)

**@QAQ 推荐**

#Data Augmentation

本文来自 Google Brain，论文关注的问题是图像领域的数据增强。**作者提出了一种名为 AutoAugment 的自动数据增强的方法，可以有效降低误差率。**实验表明，本文方法在 CIFAR-10、CIFAR-100、SVHN 和 ImageNet 上实现了最先进的准确率（无需额外数据）。此外，本文方法还可以直接迁移到其他数据集上而无需进行微调。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyMFPQW3gWvFfs2SNGEOme1yb7EKjWgFctzdRoIPM6f131Fd04sYMStg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyeonwSCACas3wpZCzZvAkvmzicLH1ic9Ygyy08DuQoiaa7Ep6eVNjxCnXw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyibJ0VD0HpMwibgd1l548fGyjqeMZVsq3iaHtwzZXRLjwgNzPibSZS01vkQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyib27moHWhQsDz9UcAgExdPyomdEYtXqlFicuHPLWP2HKbjrLhXzurfzA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyP9DfLdofFJH6HgRM4mcSpxbIicpwAA9ePUicy3cmtDSdicr3w8O8zU7EQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy9lmtekqiamcVU0TA3p032Cwj8ibdSiavhSur0u0T2gKrHMnvOZqeh5TZg/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2706




源码链接

https://github.com/tensorflow/models/tree/master/research/autoaugment










![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyRcO7ruxAydWXm59GuXqbV95A950ib5tr6iaE7F35nFjTpEhicQLNJib4Qw/640?wx_fmt=png)

**@zl1994 推荐**

#Object Detection

本文来自 UIUC 和 IBM，**论文重点解决目标检测中分类错误的问题**。作者指出了当前目标检测框架对于目标分类任务存在的三个问题：1. 分类分支和回归分支共享特征不是最优的；2.多任务训练也不是最优的；3.对于小目标来说，大的感受野会导致小目标冗余的 context。**论文主要思路是对分类和回归这两大任务解耦，并借鉴 R-CNN 中的机制使得不同大小的目标有自适应的 context 信息。**
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyu0p8Mw9lpJMz1E2E9kiaPIJVTkWXFPtaqNTlsxsw1owqKNO3zcvSX8Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyC0ugeB1nomXjUzHGaXVOO95NkduQ8edcP1EAsTOG6ccsVlnE8BYmlQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyuiakHGfmf1PH5ibB4ge3dLNNzEmQtniciaQDOZJod13wW3mn4iaXqMrvgBQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyaO1QM5EL6AhEdY2PXoEwCea4lYXPwJPEGfvx5tJkadHqtfiaGmUVIMA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyibJcbkN9dcIQFIicXGGicH12Gw9UHLm3gshE5slkMzBsDK2R8e4gdxPEg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSygibGpUlRZ0icAmOVnR6Kv6xDiciat449AJvJdV9LzrnTDFobspjUf3gAAw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2688




源码链接

https://github.com/bowenc0221/Decoupled-Classification-Refinement













![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyzX0SjdKVr95a1NFNia0vcNeRQ8aT6cyT3tQa5c4YemzSpkLW87MibUGQ/640?wx_fmt=png)

**@paperweekly 推荐**

#Image Classification

本文是东京大学发表于 CVPR 2018 的工作，**论文尝试将在音频上的方法应用于图像领域，并提出了一种将图像作为波形处理的混合方法。**具体来说，作者认为人类无法识别图形波长融合，但这些信息对机器而言却是有意义的。CNN 有将输入数据作为波形处理的操作，作者提出的 BC Learning 方法是将两个不同类的图像进行混合，然后训练模型输出混合比，靠近哪个就分为哪类。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyqlvxDIQbhSCApm9BicIMDZatGaXQ4aeZtd4pUtbvLjTmWa4IgSHsfow/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSycia9zgc8oeeGobSsnzxhPINH34xXwg6Rv6eMzHE89wmZnFnpOKX0hCg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyRXmvALbgnna4JPoIdXviaH977lUtibwg4KkaMVicMbtvWlUldH00ibtKaA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyExAK6uOu9pmrLTXwZjxNDIlu3Jibg2f8HYnIqYJuT1chnYcIP1suicJA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyD0u0npRU2aIqT7ic8cZiaRmmYT0qeLyjvpfDic6dg94K32aN2GYbFQ26g/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyPK3NGxntBO1JNgYPwzNEzT4R4QMLjqcUUibMGAYrwoGgPHss7p3cNoQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2687




源码链接

https://github.com/mil-tokyo/bc_learning_image/










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSykZ8ZyibLQ9wD0Y79jpxda7QRn7PJ3RUibUBPbBVPYmmDcBswaVoyajMg/640?wx_fmt=png)

** @Kralkatorrik 推荐**

#Face Recognition

**本文提出了一个轻量级的网络来做人脸识别**， 比 MobileFaceNet 的 size 大一倍， 精度提高一些。主要看文章设计网络思路，作者使用 BottleNeck 和快速降采样策略减少参数量，从而使这个网络能够运行在移动设备上。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyicjBlzdFfSxBq1ea1Vr2CSU4Rb6C7k6VyFr0cKp7sW8p07LaISCicBHw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy2pQQ6Y7zEicWGVDY3lhwv2E5P0XLGm0gYCq2Q3IZE3ib9Aae9tsfe9ew/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy4XAshcm48aNCpq7ownibVwnE2f5vlD85bJY3zGIh7sdrHPzbicnYlcDw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSya8HravfsLO8DBORRWfCOGDo8ibvZwEnHPicYxmsDrnCUnk3fBpXPLGNQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2710










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUMyCvJ7nksObSLatO1UHuTLcw5KYWPhREehBpXWY0uqseRtib5rxuvBw/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyzwGicG5U2tZsaPrlq0t6icYIh3xN345z3zLQd9Yp5sOnxajGiaVB27KzQ/640?wx_fmt=png)

**@vimjian 推荐**

#Pose Estimation

本文来自浙江大学，**论文研究的问题是基于 RGB 的姿态估计，作者引入一个逐像素投票的网络来定位 2D keypoints。**本文方法在 LINEMOD、Occlusion LINEMOD 和 YCBVideo 数据集上均取得了 SOTA 结果。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy5aJJUumiaB4HHT51Myx0UN2I4gTzRqHicWpc1DuAWybgDiakOY4uZdIkQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyvAXcjkiaxhypj1Rru6pdcoQ0dtialHCzicJrx18SicSSay3p5eMBnLPI4Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSylKvMDUxOFpds5rkuQ0ZkCq9oJOkFotZwX96nTT5Y0U6VTgzOr1C0kg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyD4rSf4Dr0ic24p9HqPMQSkYkGl0ngDPUQ17ic7hBMzWlPJ0nB5pKjTVA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSygN1qGlFePicerhDX0ec3wT9icS03ia8ndFX5f969LqMe8n1VyBHkrdngQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2739










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjiaA5bbtkAnnJ2yLicAzlwmVdnAIic0THYptctQhZJRx7QYCx8TC9zwOow/640)

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyibtzxWYYIfBHz7mt11jEZOKzXhic7zLvxiajJB0nicfDEha45nKjbSrgyw/640?wx_fmt=png)

**@IndexFziQ 推荐**

#Multi-task Learning

这是一篇来自爱尔兰学者 Ruder 的综述文章。**论文整理了 Multi-task Learning 的相关工作，重点介绍在深度学习上的应用。**多任务学习在很多任务上都可以获得比较不错的效果，如何选择合适的辅助任务帮助主任务获得更好的效果也是值得关注的地方。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSySs766V02mnnic0HicPMshXqq86rJiaV1SnDHAx0pO3u47ibUic9v3DKdMrQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy3chialu3OOr2TX1PBiaG4a52bxnZxXg1s3QaA7K4lLS4QhIhKmyaGsFA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyVlobjtXysppVM05Ed6JfIWeX12rWVoL5E0I6BdUibOBOPK7WbJEfo7w/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyVicrGRCptWRmwfrRJ3Gv490siabqt0BQa5m5FL78qPd6LQLhibBJn7cCA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyib1RswBZ1K8bmHknBy0WiaJh1jZZMlazsXaxgnuIsiajOO4WCg6bqj9kQ/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSymPGr8AyX4HpmpStnu0aZ6UjFnRta3fraGjXDGuGqgzpibxlC899QR3A/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2708










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjgzGNHdv2YBVm6bUicHjY2A8tV8hwJIiapvTYDGmFIyMclC4Xy6gD7krQ/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy6j4cJqTVb5zKgNv3cAQgZL5XB4Y7ut1ltfibyQM6Pp6BRlrtvlJCMGg/640?wx_fmt=png)

****@Yerrick** 推荐**

#Learning to Rank

本文是 Google 发表于 CIKM 2018 的工作，**论文形式化地将 Learning to Rank 领域经典的 LambdaMart 方法的 loss 表示出来，并提出了对于 NDCG 更紧的 bound，能够更好地在训练时提升 NDCG。**同时基于他们的方法可以设计更多基于 Listwise 的 metric 直接进行优化。推导并不特别复杂，很有启发意义。方法也被TensorFlow/ranking所实现。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSytG0GSOvZL13KBB8JnhX55gKEO32AHtGcqCn6shhTq3NWMWWcnTScQg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyaLnF5GsUMPgBoYPgYA5LN3wZRpn2CIfXNrblPTZmjynphZGH3gjTEg/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSymSwkaM6UZnzo5FU1lfGichGbIiasZeuUVajWO9da8EPFCU79wkeuMZLw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSycb6VmiaZicvYXwGiajkGq1ibWeCzJ8U4LEU3aF3xjGrnzDfow2xXuNUbJw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyMjfRhx0fOY8miaW0Xx5ibhu78h08soGSBNgy0ZaibgzDicNQJjTHKu6yNA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSygVibhibuTZtJxejgmXTs40JTiaUiaRhznDPGxibjRHhRNwicDqPK9t6S2iaMw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2667










![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmjzJtCDOe8XLVgMWs5E3yVgicbLfFfFUq5D0tPfYTibSxD2ZvWJFMCnVZJ3UvpE3V635rO33PkQkIg/640)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSypicOwOJ28EXJvMrlTSwRj9Q9w0WkDrAA2WMQwdCe2h6dW7Elu5SByhQ/640?wx_fmt=png)

****@NeoTheSunshine** 推荐**

#Graph Neural Networks

本文是麻省理工和斯坦福发表于 ICLR 2019 的工作，**论文证明了 GNNs 至多可以和 WL test 在区分图结构方面同样有效。**此外，作者还证明了 GNN 和 WL test 同样有效情况下的对 neighbor aggregation 和 graph pooling functions 的条件，并且提出一种简洁但有效的模型架构 GIN。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy033ic47qxTN88Alyos1f3tz5mm220IbxiaZf8GJdNZccT5HgTTqAMjGA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyXHGA1sIPRFJAwvia2fjD39OGBjmBDXjqdxctowIDb1UYRVr8FAv1ULA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy7OT3ZyrStTTT5EAgOibicuXrxGDqXS58HeQfMtnttqsPokicHqPf1NiaBQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy2X8icIOeq0HQzm1QQFfYvibk8jdxY8fL0evjlz1LTMEH9HBEV7WQ1Znw/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyyp5ic4abFyjvMlLfichEg1UcVwaEFXblZvWIPWX8g7hfHiaOiaLKDxNdYw/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyAEdy5Z78bYuV8TV9OCJbNLD923rLzvgiaSx7BnnEHribGnNiaibVRMesnQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2730







![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSy8gx4ZNX5Tiaeicno09TPNjSVd4zMnx9hxYcw2n350iaTFOOe6u2F7GLoA/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyhicicyIBn3kXfznBwYsF43eSgUmh51ib3RJHdPrPsJ6ib0rkfsDLSB3pcg/640?wx_fmt=png)

****@figo** 推荐**

#Neural Architecture Search

本文来自小米 AI，内容上属于目前很火的 AutoML Neural Architecture Search。**这篇论文提出了 MoreMNAS 算法，应该是多目标（EA-NSGAII）+强化学习 NAS 的首篇论文。**论文的初步试验，已经击败了 SRCNN、FSRCNN、VDSR 等单帧超分辨率领域知名网络（应该是截止到 CVPR 2016 的成果)。 

论文的想法是比较巧妙的，采用 NSGAII 作为主框架，解决强化学习由于超参、算法等导致的可能的衰退问题，同时采用强化学习变异可以更好的利用学习的经验，二者相互补充，使得方法的鲁棒性有保证。另外强化学习只用来解决那些不容易解决的目标例如超分的 PSNR，对于其他可以提前计算的目标，则用了 Roulette-wheel selection。

论文中的搜索空间直接采用 cell-block，看起来效果也不错，比较自然地完成 Cross Over 和 Natural Mutation 环节。另外，论文解决的实际上是带约束的 MOP 问题，并对最低的 PSNR 进行了约束，以保证模型的业务可用性。 

实验结果是基于一台 8GPU 机器完成（V100，1 周），实乃深度学习炼丹师的福音，对于不少公司而言，这个配置是现成的。总体这种方法有一定的通用性，感兴趣的读者可以用来试水其他领域。遗憾的是该论文没有公开源码。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyKNPH7ETwbNAwvjdy31F54LsQH1hMteM2fZxCuDCwhGEfgeMXlMB5PQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyWg57svStefzfuJRVl8LABK4SAB3hYw1icicXGcCXNtslgQyUnQrp5V5g/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSygN7cOjEAce7rXUibhyZqDwibnbI2FemicPWuGlvCug0RuBew0hFwsz3JA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyeHcVm1CAFUVQ0cS2bSibw52aPLqSmKNQGNZ5LBPHHW0JdKW4vUqXJ6Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyl3XQ7TuCGR2hPOQ6cgsTqVYOhTmlrJmcq5KHKzmhXIwsc6tEkAQQgg/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyjJf0nkrPGdKDuugsXLalaTrITRPIMxc7bxHicIGq1E8ZLKhfAJw2Inw/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2740










![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSybiasRrEgIFBc3uicFteLPN0YXZTcZ7BFibXSVVIia4JibT2wOZAGbNSW6Xg/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyHfejiajDqYoP2hhq2AeOpuwUPjpfcbFytmfVDqY5AZegBaWAj77PjQA/640?wx_fmt=png)




****@paperweekly** 推荐**

#Click-Through Rate Prediction

本文是阿里巴巴发表于 AAAI 2019 的工作，**作者提出了一种由兴趣抽取和兴趣演化两个模块共同组成的 CTR 预估模型——DIEN。**论文亮点在于作者关注隐藏在用户行为背后的潜在兴趣特征的挖掘和表示（GRU + auxiliary loss）。

淘宝平台上商品种类繁多，用户兴趣具有多样性。预测时，仅仅捕获与目标商品相关的兴趣及其演变（AUGRU）。该算法被应用于阿里妈妈定向广告各大产品中，在DIN的基础上取得了非常显著的效果提高。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyb9Dl16zap1xtF9wYHibVzfEy1fjibNST093Siasib4Iw6HAtoPTCC6014g/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyxia4ayPQexFXHUMzLMzte6vB7hNOPeOVjGJdPOdl2za27GSciaaIicn4Q/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyZ9QNvYs5aKCZyrW8A654pvNLib10BA5jtBicjjuaUgvz6xsD0u4GPrKA/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyFPUckKriaKTs7GPgkI4QtvWO4SDLctUjibnZXBmyZa22QrFlU5OibYHpQ/640?wx_fmt=png)![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSycCPR0Yllib271uicqUu0iaAibonUNQDiadVe9vLyHHlVL9ib6jAtEkxjwvAA/640?wx_fmt=png)
**▲**论文模型：点击查看大图




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnntmjtq9fdPspS4WeiaVQSyfkL0eUl0mYmR2UhODksVNFgb9CFodLJUIeziaS2QkEn2Ds9Kfxou3DQ/640?wx_fmt=png)




论文链接

https://www.paperweekly.site/papers/2692




源码链接

https://github.com/alibaba/x-deeplearning/tree/master/xdl-algorithm-solution/DIEN










**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****推 荐 有 礼#**




本期所有入选论文的推荐人

均将获得**PaperWeekly纪念周边一份**



![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm5Wb1iaUHxx8mBh1Km3dWjfPlgYsxpxlV44icJWDVwuPorALMxCQglAC8Dx8JMeic5wHeNw29gJV8SA/640?)


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWQfATNyq8icodseL6gFjp8w4sQ1DBTuiaChXPEcQ0Q6tmRmz2jJjzic7g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUk6ibiaGfmJl0icaK5go84z9iaLysegxS06wkEIrCkuL1eV2dicVoBusY4aQ/640)


**▲ **深度学习主题行李牌/卡套 + 防水贴纸




****礼物领取方式****



推荐人请根据**论文详情页底部留言**

添加小助手领取礼物

*每位用户仅限领取一次




**想要赢取以上周边好礼？**

**点击阅读原文**即刻推荐论文吧！




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击以下标题查看往期推荐：**




- 
[又为写作思路熬到秃头？16篇最新论文打包送你](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492302&idx=1&sn=1efef6309e70dedd9c5380cb644fa4ea&chksm=96ea3d4ea19db458e7ce12f066e4e37c137ec67fdd5f7e851823660f9dccbd23bbad1ce2a255&scene=21#wechat_redirect)

- 
[收下这 16 篇最新论文，周会基本不用愁](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492583&idx=1&sn=85ec5352079218745428d66ab8ee97d4&chksm=96ea3c67a19db5718f5412c64f4c11d28cab5eda2826350fd5f15ac3e888f6ae7a9137eb31bd&scene=21#wechat_redirect)

- 
[这 16 篇最新论文，帮你轻松积攒知识点](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492912&idx=1&sn=e223b0bf570148493313ea8780cef2fc&chksm=96ea3ab0a19db3a6eb87b8c8d6cb41d1a4ae0d85b5fd7b616baa970234124c320fda1cdcc7d9&scene=21#wechat_redirect)

- 
[本周NLP、CV、机器学习论文精选推荐](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493834&idx=1&sn=f5b7de713568324bf3b96742e36f5e30&chksm=96ea374aa19dbe5caf333cfa01ca77ef3e36485b9b9241a5488d47509cea5e79620a223b7932&scene=21#wechat_redirect)


- 
[想了解推荐系统最新进展？请收好这些篇论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491818&idx=1&sn=311962e2e41119a565c252a19037dd76&chksm=96ea3f6aa19db67c3fbfa77fbec65797d0ccc8f2930290d57c2016a3e55a8bb18b77fd10180b&scene=21#wechat_redirect)

- 
[论文多到读不完？不如看看我们为你精选的这15篇](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493452&idx=1&sn=93c7cc02af605e3d8b86fef6ec2cee26&chksm=96ea38cca19db1daddf658a56311c1da5448eabce36d7986598d80c5f02ed91d335fab1ba8a9&scene=21#wechat_redirect)

- 
[本周有哪些值得读的AI论文？进来告诉你答案](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493220&idx=1&sn=b4c88ecfb42d081935c6deb548c681af&chksm=96ea39e4a19db0f26aede4b9e1e57208e97edfc50f736f0d4aaedaaf363939b774ac78f9ad35&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**



总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志



**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取更多论文推荐




