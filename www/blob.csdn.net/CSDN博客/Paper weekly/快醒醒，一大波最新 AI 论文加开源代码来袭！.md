# 快醒醒，一大波最新 AI 论文加开源代码来袭！ - Paper weekly - CSDN博客





2018年04月20日 00:00:00[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：1280









![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?wxfrom=5&wx_lazy=1)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **62** 篇文章


![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?wxfrom=5&wx_lazy=1)
**ETH-DS3Lab at SemEval-2018 Task 7: Effectively Combining Recurrent and Convolutional Neural Networks for Relation Classification and Extraction**

**@theodoric008 推荐**

#Relation Extraction

本文来自苏黎世联邦理工学院 DS3Lab，文章**针对实体关系抽取任务进行了非常系统的实验**，并在第十二届国际语义评测比赛 SemEval 2018 的语义关系抽取和分类任务上获得冠军。本文思路严谨，值得国内学者们仔细研读。

论文链接

https://www.paperweekly.site/papers/1833

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)
**Personalizing Dialogue Agents: I have a dog, do you have pets too?**

**@yihongchen 推荐**

#Dialogue System

本文是 Facebook AI Research 发表于 NIPS 2018 的工作。论文**根据一个名为 PERSONA-CHAT 的对话数据集来****训练基于 Profile 的聊天机器人**，该数据集包含超过 16 万条对话。

**本文致力于解决以下问题：**
- 
聊天机器人缺乏一致性格特征 

- 
聊天机器人缺乏长期记忆 

- 
聊天机器人经常给出模糊的回应，例如 I don't know


论文链接

https://www.paperweekly.site/papers/1802



数据集链接

https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/personachat




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)

**DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding**

**@zhkun 推荐**

#Natural Language Understanding

本文是悉尼科技大学发表于 AAAI 2018 的工作，这篇文章是对 Self-Attention 的另一种应用，作者**提出一种新的方向性的 Attention，从而能****更加有效地理解语义**。

论文链接

https://www.paperweekly.site/papers/1822




代码链接

https://github.com/shaohua0116/Group-Normalization-Tensorflow







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)
**DetNet: A Backbone network for Object Detection**

**@chlr1995 推荐**

#Object Detection

本文来自清华大学和 Face++，文章分析了使用 ImageNet 预训练网络调优检测器的缺陷，研究通过保持空间分辨率和扩大感受野，**提出了一种新的为检测任务设计的骨干网络 DetNet**。

实验结果表明，基于低复杂度的 DetNet59 骨干网络，**在 MSCOCO 目标检测和实例分割追踪任务上都取得当前最佳的成绩**。

论文链接

https://www.paperweekly.site/papers/1844







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)
**Imagine This! Scripts to Compositions to Videos**

**@chlr1995 推荐**

#Video Caption

本文以《摩登原始人》的动画片段作为训练数据，对每个片段进行详细的文本标注，最终**训练得到一个可以通过给定脚本或文字描述生成动画片段的模型**。

模型称为 Craft，分为布局、实体、背景，三个部分。虽然现阶段模型存在着很多问题，但是这个研究在理解文本和视频图像高层语义方面有着很大的意义。

论文链接

https://www.paperweekly.site/papers/1838







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)
**Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning**

**@Aidon 推荐**

#Image Caption

本文来自华盛顿大学和微软，文章**提出一个基于 GAN 的 Image Caption 框架**，亮点如下：

1. 提出用 comparative relevance score 来衡量 image-text 的质量从而指导模型的训练，并且在训练过程中引入 unrelated captions；

2. 利用 human evaluations 评估 caption 的 accuracy，给出了和传统的六个评价指标的结果对比；

3. 提出通过比较 caption feature vectors 的 variance 来评估 caption 的 diversity。

论文链接

https://www.paperweekly.site/papers/1842









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)
**Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction**

**@robertdlut 推荐**

#Self-Attention

本文是 Andrew McCallum 团队应用 Self-Attention 在生物医学关系抽取任务上的一个工作。这篇论文作者**提出了一个文档级别的生物关系抽取模型**，作者使用 Google 提出包含 Self-Attention 的 transformer 来对输入文本进行表示学习，和原始的 transformer 略有不同在于他们使用了窗口大小为 5 的 CNN 代替了原始 FNN。

论文链接

https://www.paperweekly.site/papers/1787




代码链接

https://github.com/patverga/bran







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)
**Evaluation of Session-based Recommendation Algorithms**

**@Ttssxuan 推荐**

#Recommender System

**本文系统地介绍了 Session-based Recommendation**，主要针对 baseline methods, nearest-neighbor techniques, recurrent neural networks 和 (hybrid) factorization-based methods 等 4 大类算法进行介绍。

此外，本文使用 RSC15、TMALL、ZALANDO、RETAILROCKET、8TRACKS 、AOTM、30MUSIC、NOWPLAYING、CLEF 等 7 个数据集进行分析，在 Mean Reciprocal Rank (MRR)、Coverage、Popularity bias、Cold start、Scalability、Precision、Recall 等指标上进行比较。


论文链接

https://www.paperweekly.site/papers/1809




代码链接

https://www.dropbox.com/sh/7qdquluflk032ot/AACoz2Go49q1mTpXYGe0gaANa?dl=0







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)
**On the Convergence of Adam and Beyond**

**@chlr1995 推荐**

#Neural Network

**本文是 ****ICLR 2018 最佳论文之一**。在神经网络优化方法中，有很多类似 Adam、RMSprop 这一类的自适应学习率的方法，但是在实际应用中，虽然这一类方法在初期下降的很快，但是往往存在着最终收敛效果不如 SGD+Momentum 的问题。

作者发现，导致这样问题的其中一个原因是因为使用了指数滑动平均，这使得学习率在某些点会出现激增。在实验中，作者给出了一个简单的凸优化问题，结果显示 Adam 并不能收敛到最优点。

在此基础上，作者**提出了一种改进方案，使得 Adam 具有长期记忆能力**，来解决这个问题，同时没有增加太多的额外开销。

论文链接

https://www.paperweekly.site/papers/1841







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)
**Neural Baby Talk**

**@jamiechoi 推荐**

#Image Captioning

 本文是佐治亚理工学院发表于 CVPR 2018 的工作，**文章结合了 image captioning 的两种做法**：以前**基于 template 的生成方法**（baby talk）和近年来主流的 **encoder-decoder 方法**（neural talk）。

论文主要做法其实跟作者以前的工作"Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning"类似：在每一个 timestep，模型决定生成到底是生成 textual word（不包含视觉信息的连接词），还是生成 visual word。其中 visual word 的生成是一个自由的接口，可以与不同的 object detector 对接。

论文链接

https://www.paperweekly.site/papers/1801



代码链接

https://github.com/jiasenlu/NeuralBabyTalk







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)
**Context Encoding for Semantic Segmentation**

**@wanzysky 推荐**

#Semantic Segmentation

**本文提出了一种与类别预测相关的网络结构，使得在一定程度上降低了分割任务的难度**。Channel attention 和空间 attention 形成互补，Global contextual loss 增强 context 信息，同时提高了小物体的分割精度。

论文链接

https://www.paperweekly.site/papers/1814




代码链接

https://github.com/zhanghang1989/PyTorch-Encoding







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)
**Adaptive Graph Convolutional Neural Networks**

**@VIPSP 推荐**

#Convolutional Neural Network

图卷积神经网络（Graph CNN）是经典 CNN 的推广方法，可用于处理分子数据、点云和社交网络等图数据。Graph CNN 中的的滤波器大多是为固定和共享的图结构而构建的。但是，对于大多数真实数据而言，图结构的大小和连接性都是不同的。

**本论文提出了一种有泛化能力且灵活的 Graph CNN，其可以使用任意图结构的数据作为输入**。通过这种方式，可以在训练时为每个图数据构建一个任务驱动的自适应图（adaptive graph）。

为了有效地学习这种图，作者提出了一种距离度量学习方法。并且在九个图结构数据集上进行了大量实验，结果表明本文方法在收敛速度和预测准确度方面都有更优的表现。

论文链接

https://www.paperweekly.site/papers/1837




****本文由 AI 学术社区 PaperWeekly 精选推荐，社区目前已覆盖自然语言处理、计算机视觉、人工智能、机器学习、数据挖掘和信息检索等研究方向，点击「阅读原文」即刻加入社区！****

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击以下标题查看往期推荐：**




- 
[来不及想标题了，我要去打包收藏了 | 本周值得读](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488060&idx=1&sn=8214e778bfc381bf684ab634a34dbf34&chksm=96e9cdbca19e44aac9ffb5bb402861e3295bb3e42b98fe7d964c422995b06875f92333fd85d1&scene=21#wechat_redirect)


- 
[选对论文，效率提升50% | 本周值得读](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487741&idx=1&sn=b61741b47e602626a236f5984a0b1cb4&chksm=96e9cf7da19e466b953b4f0fb4e0003b868045fd1a4eb1b38a2b6cfe5316c60bcd368f4ee985&scene=21#wechat_redirect)

- 
[好看的论文千篇一律，有趣的Github项目万里挑一！](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488055&idx=1&sn=5d19768e3cb2754b2e2a93cef8e61f2c&chksm=96e9cdb7a19e44a146dc12b11b1770a65bc98e4f841e58eb4f4ef22b0e46491e6fefba9cd6ca&scene=21#wechat_redirect)









![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmsvubgibQtWV5t7M3ETKt3bbXiaAothCErMicibic9QCUBpxkuibuht62MGcCTcLyAxqGrsUXbv254InDA/640?)




**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****作 者 招 募#**



****[让你的文字被很多很多人看到，喜欢我们不如加入我们](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487954&idx=1&sn=d247e5b99ecb2c37e85d962d7f93d7d7&chksm=96e9ce52a19e474457e04affae41dc6b6fe521154f95ae7122260b46ec91f55ae7c8fb472c3c&scene=21#wechat_redirect)****









我是彩蛋




** 解锁新功能：热门职位推荐！**




PaperWeekly小程序升级啦




**今日arXiv√猜你喜欢√**热门职位****√****




找全职找实习都不是问题



** 解锁方式 **

1. 识别下方二维码打开小程序

2. 用PaperWeekly社区账号进行登陆

3. 登陆后即可解锁所有功能




** 职位发布 **

请添加小助手微信（**pwbot02**）进行咨询




**长按识别二维码，使用小程序**

*点击阅读原文即可注册







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnwLopkg177jgoQCbq2j2UJqSZOScYnsaSZf7ibXORdFOUEicycYycARG6V9pvHMyY7jYpdZFKpxcSQ/640?)










******关于PaperWeekly******




PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)




▽ 点击 | 阅读原文| 加入社区刷论文




