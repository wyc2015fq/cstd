
# 快醒醒，一大波最新 AI 论文加开源代码来袭！ - Paper weekly - CSDN博客


2018年04月20日 00:00:00[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：1274


![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?wxfrom=5&wx_lazy=1)

在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。

在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。

点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第**62**篇文章
![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?wxfrom=5&wx_lazy=1)
**ETH-DS3Lab at SemEval-2018 Task 7: Effectively Combining Recurrent and Convolutional Neural Networks for Relation Classification and Extraction**
**@theodoric008 推荐**
\#Relation Extraction
本文来自苏黎世联邦理工学院 DS3Lab，文章**针对****实体关系抽取任务****进行了非常系统的实验**，并在第十二届国际语义评测比赛 SemEval 2018 的语义关系抽取和分类任务上获得冠军。本文思路严谨，值得国内学者们仔细研读。
论文链接
https://www.paperweekly.site/papers/1833
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)
**Personalizing Dialogue Agents: I have a dog, do you have pets too?**
**@yihongchen 推荐**
\#Dialogue System
本文是 Facebook AI Research 发表于 NIPS 2018 的工作。论文**根据一个名为 PERSONA-CHAT 的对话数据集来****训练基于 Profile 的聊天机器人**，该数据集包含超过 16 万条对话。
**本文致力于解决以下问题：**
聊天机器人缺乏一致性格特征
聊天机器人缺乏长期记忆
聊天机器人经常给出模糊的回应，例如 I don't know
论文链接
https://www.paperweekly.site/papers/1802
数据集链接
https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/personachat

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)
**DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding**
**@zhkun 推荐**
\#Natural Language Understanding
本文是悉尼科技大学发表于 AAAI 2018 的工作，这篇文章是对 Self-Attention 的另一种应用，作者**提出一种新的方向性的 Attention，从而能****更加有效地理解语义**。
论文链接
https://www.paperweekly.site/papers/1822

代码链接
https://github.com/shaohua0116/Group-Normalization-Tensorflow


![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)
**DetNet: A Backbone network for Object Detection**
**@chlr1995 推荐**
\#Object Detection
本文来自清华大学和 Face++，文章分析了使用 ImageNet 预训练网络调优检测器的缺陷，研究通过保持空间分辨率和扩大感受野，**提出了一种新的为检测任务设计的骨干网络 DetNet**。
实验结果表明，基于低复杂度的 DetNet59 骨干网络，**在 MSCOCO 目标检测和实例分割追踪任务上都取得当前最佳的成绩**。
论文链接
https://www.paperweekly.site/papers/1844


![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)
**Imagine This! Scripts to Compositions to Videos**
**@chlr1995 推荐**
\#Video Caption
本文以《摩登原始人》的动画片段作为训练数据，对每个片段进行详细的文本标注，最终**训练得到一个可以通过给定脚本或文字描述生成动画片段的模型**。
模型称为 Craft，分为布局、实体、背景，三个部分。虽然现阶段模型存在着很多问题，但是这个研究在理解文本和视频图像高层语义方面有着很大的意义。
论文链接
https://www.paperweekly.site/papers/1838


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)
**Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning**
**@Aidon 推荐**
\#Image Caption
本文来自华盛顿大学和微软，文章**提出一个基于 GAN 的 Image Caption 框架**，亮点如下：
1. 提出用 comparative relevance score 来衡量 image-text 的质量从而指导模型的训练，并且在训练过程中引入 unrelated captions；
2. 利用 human evaluations 评估 caption 的 accuracy，给出了和传统的六个评价指标的结果对比；
3. 提出通过比较 caption feature vectors 的 variance 来评估 caption 的 diversity。
论文链接
https://www.paperweekly.site/papers/1842


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)
**Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction**
**@robertdlut 推荐**
\#Self-Attention
本文是 Andrew McCallum 团队应用 Self-Attention 在生物医学关系抽取任务上的一个工作。这篇论文作者**提出了一个文档级别的生物关系抽取模型**，作者使用 Google 提出包含Self-Attention的 transformer 来对输入文本进行表示学习，和原始的 transformer 略有不同在于他们使用了窗口大小为 5 的 CNN 代替了原始 FNN。
论文链接
https://www.paperweekly.site/papers/1787

代码链接
https://github.com/patverga/bran


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)
**Evaluation of Session-based Recommendation Algorithms**
**@Ttssxuan 推荐**
\#Recommender System
**本文系统地介绍了 Session-based Recommendation**，主要针对 baseline methods, nearest-neighbor techniques, recurrent neural networks 和 (hybrid) factorization-based methods 等 4 大类算法进行介绍。
此外，本文使用 RSC15、TMALL、ZALANDO、RETAILROCKET、8TRACKS 、AOTM、30MUSIC、NOWPLAYING、CLEF 等 7 个数据集进行分析，在 Mean Reciprocal Rank (MRR)、Coverage、Popularity bias、Cold start、Scalability、Precision、Recall 等指标上进行比较。
论文链接
https://www.paperweekly.site/papers/1809

代码链接
https://www.dropbox.com/sh/7qdquluflk032ot/AACoz2Go49q1mTpXYGe0gaANa?dl=0


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)
**On the Convergence of Adam and Beyond**
**@chlr1995 推荐**
\#Neural Network
**本文是****ICLR 2018 最佳论文之一**。在神经网络优化方法中，有很多类似 Adam、RMSprop 这一类的自适应学习率的方法，但是在实际应用中，虽然这一类方法在初期下降的很快，但是往往存在着最终收敛效果不如 SGD+Momentum 的问题。
作者发现，导致这样问题的其中一个原因是因为使用了指数滑动平均，这使得学习率在某些点会出现激增。在实验中，作者给出了一个简单的凸优化问题，结果显示 Adam 并不能收敛到最优点。
在此基础上，作者**提出了一种改进方案，使得 Adam 具有长期记忆能力**，来解决这个问题，同时没有增加太多的额外开销。
论文链接
https://www.paperweekly.site/papers/1841


![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)
**Neural Baby Talk**
**@jamiechoi 推荐**
\#Image Captioning
本文是佐治亚理工学院发表于 CVPR 2018 的工作，**文章结合了 image captioning 的两种做法**：以前**基于 template 的生成方法**（baby talk）和近年来主流的**encoder-decoder 方法**（neural talk）。
论文主要做法其实跟作者以前的工作"Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning"类似：在每一个 timestep，模型决定生成到底是生成 textual word（不包含视觉信息的连接词），还是生成 visual word。其中 visual word 的生成是一个自由的接口，可以与不同的 object detector 对接。
论文链接
https://www.paperweekly.site/papers/1801
代码链接
https://github.com/jiasenlu/NeuralBabyTalk


![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)
**Context Encoding for Semantic Segmentation**
**@wanzysky 推荐**
\#Semantic Segmentation
**本文提出了一种与类别预测相关的网络结构，使得在一定程度上降低了分割任务的难度**。Channel attention 和空间 attention 形成互补，Global contextual loss 增强 context 信息，同时提高了小物体的分割精度。
论文链接
https://www.paperweekly.site/papers/1814

代码链接
https://github.com/zhanghang1989/PyTorch-Encoding


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)
**Adaptive Graph Convolutional Neural Networks**
**@VIPSP 推荐**
\#Convolutional Neural Network
图卷积神经网络（Graph CNN）是经典 CNN 的推广方法，可用于处理分子数据、点云和社交网络等图数据。Graph CNN 中的的滤波器大多是为固定和共享的图结构而构建的。但是，对于大多数真实数据而言，图结构的大小和连接性都是不同的。
**本论文提出了一种有泛化能力且灵活的 Graph CNN，其可以使用任意图结构的数据作为输入**。通过这种方式，可以在训练时为每个图数据构建一个任务驱动的自适应图（adaptive graph）。
为了有效地学习这种图，作者提出了一种距离度量学习方法。并且在九个图结构数据集上进行了大量实验，结果表明本文方法在收敛速度和预测准确度方面都有更优的表现。
论文链接
https://www.paperweekly.site/papers/1837

**本文由 AI 学术社区 PaperWeekly 精选推荐，社区目前已覆盖自然语言处理、计算机视觉、人工智能、机器学习、数据挖掘和信息检索等研究方向，点击「****阅读原文****」即刻加入社区！**
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)

**点击以下标题查看往期推荐：**

来不及想标题了，我要去打包收藏了 | 本周值得读

[选对论文，效率提升50% | 本周值得读](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487741&idx=1&sn=b61741b47e602626a236f5984a0b1cb4&chksm=96e9cf7da19e466b953b4f0fb4e0003b868045fd1a4eb1b38a2b6cfe5316c60bcd368f4ee985&scene=21#wechat_redirect)
[好看的论文千篇一律，有趣的Github项目万里挑一！](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488055&idx=1&sn=5d19768e3cb2754b2e2a93cef8e61f2c&chksm=96e9cdb7a19e44a146dc12b11b1770a65bc98e4f841e58eb4f4ef22b0e46491e6fefba9cd6ca&scene=21#wechat_redirect)



![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmsvubgibQtWV5t7M3ETKt3bbXiaAothCErMicibic9QCUBpxkuibuht62MGcCTcLyAxqGrsUXbv254InDA/640?)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)**\#****作 者 招 募****\#**

**[让你的文字被很多很多人看到，喜欢我们不如加入我们](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487954&idx=1&sn=d247e5b99ecb2c37e85d962d7f93d7d7&chksm=96e9ce52a19e474457e04affae41dc6b6fe521154f95ae7122260b46ec91f55ae7c8fb472c3c&scene=21#wechat_redirect)**


我是彩蛋

**解锁新功能：热门职位推荐！**

PaperWeekly小程序升级啦

**今日arXiv√猜你喜欢√****热门职位****√**

找全职找实习都不是问题
**解锁方式**
1. 识别下方二维码打开小程序
2. 用PaperWeekly社区账号进行登陆
3. 登陆后即可解锁所有功能

**职位发布**
请添加小助手微信（**pwbot02**）进行咨询

**长按识别二维码，使用小程序**
*点击阅读原文即可注册


![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnwLopkg177jgoQCbq2j2UJqSZOScYnsaSZf7ibXORdFOUEicycYycARG6V9pvHMyY7jYpdZFKpxcSQ/640?)



**关于PaperWeekly**

PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)

▽ 点击 |阅读原文| 加入社区刷论文


