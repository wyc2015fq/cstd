# 还在为周会发愁？你需要这13篇最新论文 | 本周值得读 - Paper weekly - CSDN博客





2018年06月13日 14:31:09[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：1412









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhglryG74dIr2B1019Yibv9PAGsWGGYBiaoSGbK2kzUnbIsicCEiazKMticicR0MPtmr1ynDovFe2kGicSydcg/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **81** 篇文章

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?)

**FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension**

**@shaness 推荐**

#Attention Mechanism

本文是微软和台湾大学发表于 ICLR 2018 的工作，**论文最大的价值是融合了当前主流的 Attention 模型的各个层次表示**，并且一一作了介绍，**可以通过本文了解当前主流 Attention 模型所用到的信息都是怎么得到的**。文章使用了 GloVe 表示单词，CoVe 表示上下文。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUfuXEiafq8oCrsrEBICw0iak3ggHG4lDVpBhZQiaQyJacEiciaEkUwxiar5Gg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUQTAIibHAwdxpapIVl1nZSy7uFxleNZzPicyPicRJ0kTkYOG5kic66vodqQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUlrSx5dTYxibH8Azr9WDM1txTBGMSomGJdYUP1gxSnnUgYgPMwGRRoGA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUEj6a616LzygJNZ67XzSIvEBwBljMiaqXFWtI5eZbicIzPQnohKYuBB3Q/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpl4b8cZckjp2aia27dLHMnSOyL8AzPxV6qNhc8nEohL9WGQK44OJoJg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU2LVHmKjXgvWDSEBq6Nria3WnHLaOjCib4nuHDI2ewnZxwaRIIKic9FGKg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUIGmNuYK1nNhdxTMFJmrpRp9NTTBxOnDAWpkwRUPic574lsxkupm3M1g/640)




论文链接

https://www.paperweekly.site/papers/2005



代码链接

https://github.com/momohuang/FusionNet-NLI




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)
**From Word to Sense Embeddings: A Survey on Vector Representations of Meaning**

**@qqfly1to19 推荐**

#Word Embedding

众所周知，Word Embedding 这种从语言结构中学习出来的低维表示存在着很多问题，诸如将原本的多义词 Embedding 进了一个向量里，具有相同语言结构的 Word（如反义词）具有相近的向量，这些问题在实际的工程领域往往是致命的。本篇长文总共 40 页，篇幅较长。**主要是从 Word Embedding 的工作出发去讲Sense Embedding**，内容很厚，建议好好阅读。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUF804U13BJsZZHLxiaIBaaxnfaDB0ZrDwICgzBEgZYoCyhMw84F3NgZw/640)
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPURYHveYxPIicANYHwmzYYjBSxteVenPBFE5EKdTXOHe3OEhlqdwW1lBA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUAZ5vV0XeFzzUx7rapeFLftYD2YSPz1AMIZutm0JWr9wh6Hyz7e9BHg/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUoEBkv0cQaGOFp4MSVq5J4UGkiaAD6GibdbD951rfNiarDkB8QRQnOO5Zw/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5iaNHAnsKPOolIXvnhV1P0PW6tMy1B343ics1y4BsqLA0boUe1L96TyA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUgykGwC0uRjDicfrGJvrFJogbY22x4MPelaiaAplvqflibhERtoBCfw6qA/640)
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPURYHveYxPIicANYHwmzYYjBSxteVenPBFE5EKdTXOHe3OEhlqdwW1lBA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUAZ5vV0XeFzzUx7rapeFLftYD2YSPz1AMIZutm0JWr9wh6Hyz7e9BHg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUoEBkv0cQaGOFp4MSVq5J4UGkiaAD6GibdbD951rfNiarDkB8QRQnOO5Zw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5iaNHAnsKPOolIXvnhV1P0PW6tMy1B343ics1y4BsqLA0boUe1L96TyA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUgykGwC0uRjDicfrGJvrFJogbY22x4MPelaiaAplvqflibhERtoBCfw6qA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUFVia68ibF4ibWkZAOyfdkEpG44bBibhKSK402pV9EpMPPjBWnusOV2CBdQ/640)




论文链接

https://www.paperweekly.site/papers/1999




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)

**Hybrid semi-Markov CRF for Neural Sequence Labeling**

**@zxye 推荐**

#CRF

本文是中科大发表于 ACL 2018 的工作，这篇文章**联合使用 CRF 和改进的 Semi-CRF 在 CoNLL 2003 命名实体识别任务上达到了 state-of-the-art 的性能**。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUX5XbDhO4eU1dYI6fLs7yH0rFf4gBX74oMAgia2hTdiaGR500APKeAHPA/640)
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUXuYpS9lfOic0iafYXznlgsiaIROQexic1ldwnib4F2yl6hp2Pp66BNLuwPA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUC9VEibm7SDcibk0O9Zb0Qot8KPdqR6qPseia6CnUibqINW18CMMHO9MSKQ/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpaQAXyxcSH1kxBSjOichJmlnd0q6vNicCicKuDcrZ9TorVmHRhQUB7m8Q/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUbmW6Os1armcicEDgr4ywlsiadgAc8Hsib8osGSWeeQe7iaNQCE0uQ7Ybuw/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPURYHveYxPIicANYHwmzYYjBSxteVenPBFE5EKdTXOHe3OEhlqdwW1lBA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUAZ5vV0XeFzzUx7rapeFLftYD2YSPz1AMIZutm0JWr9wh6Hyz7e9BHg/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUoEBkv0cQaGOFp4MSVq5J4UGkiaAD6GibdbD951rfNiarDkB8QRQnOO5Zw/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5iaNHAnsKPOolIXvnhV1P0PW6tMy1B343ics1y4BsqLA0boUe1L96TyA/640)

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUgykGwC0uRjDicfrGJvrFJogbY22x4MPelaiaAplvqflibhERtoBCfw6qA/640)
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUXuYpS9lfOic0iafYXznlgsiaIROQexic1ldwnib4F2yl6hp2Pp66BNLuwPA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUC9VEibm7SDcibk0O9Zb0Qot8KPdqR6qPseia6CnUibqINW18CMMHO9MSKQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpaQAXyxcSH1kxBSjOichJmlnd0q6vNicCicKuDcrZ9TorVmHRhQUB7m8Q/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUbmW6Os1armcicEDgr4ywlsiadgAc8Hsib8osGSWeeQe7iaNQCE0uQ7Ybuw/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUex9OxHsf6u1UbPZSZdrPOg0ZtkCEgMta9ic2FvR3npYe7J82icH9VmMg/640)




论文链接

https://www.paperweekly.site/papers/1998



代码链接

https://github.com/ZhixiuYe/HSCRF-pytorch







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)
**DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder**

**@guxd 推荐**

#Dialog Systems

现有的对话模型通常采用变分自编码器（VAE）实现多样化的应答生成，然而VAE模型假定对话的隐变量服从简单的高斯分布，从而限制了应答的范围（比如单模态应答）。

**本文提出一种基于 Wasserstein 自编码器的应答生成模型**，不同于 VAE 模型的单一高斯先验假设，**本文通过在隐变量上进行 GAN 训练，实现对真实数据分布的拟合。同时引入高斯混合先验网络实现多模态回答生成**。实验结果表明采用高斯混合先验的 GAN 模型在产生更连贯，信息丰富和多样化的回应方面优于现有技术。



![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUHx0kpicPp0ZCVJhf8RaJTib2tRITOX8DgMXfb3qvhmD0eE4KtqYU6JeQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUbQAVmIpPyHWftFibyXyPf8iaOcMfeBQkRHS6ic6nO4nrJuLKWMKmM36WQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWziaqroIIV5dZCqPrxlmNvZZoicYrwP2k8h2BmiaGnQ08czCkyBM4jN3A/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUjrr6MJSM1v23q3VCqIbE1QsiaCYUMoXCpvybfcO4DX2lWElWR9xr0XA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUArdFm8tur7QRwKSGcYiaFMdpMZJlKsYNMSHuwI1D15pJOibkNtI975JA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU85JyLCiaiaqFcZucickSL15cQPkGQG7mrZiaxERk9iat7tCfknicaZFWaG8w/640)




论文链接

https://www.paperweekly.site/papers/2001







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)
**Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting**

**@paperweekly 推荐**

#Abstractive Summarization

本文是 UNC Chapel Hill 发表于 ACL 2018 的工作，**论文提出了新颖的基于强化学习的句子级的文本摘要生成模型**，达到了 state-of-art 效果。

通过先抽取在生成的方式，加快了训练和测试解码速度，同时引入强化学习将抽取和生成巧妙联合起来，构成了一个整体的端到端模型而不是一个 pipeline 系统。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPULED37gMiaIcI2LChxIU7Q39Pic48sgkCEaUlEXWp7VTia9IcbJLnRRCLQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUI46jFdwdsgZw5yxDf3h3BbAkuhoeTusqhKkic1g9wPG2oPjiaibA0EWgg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWDnGRjRge9X6OOLy23BXtPB3vBBaG4XKmzZ1lDDTKo1rC2E6jia8BfA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpey8Qa0ebZzJbhJIjicTkO4xKObrYkjROE5ee8AvIIDLXLsTjzNJ1Xg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUTdic2bBNpcqMvlnnNC4JVYmfnqY4mUgAlfeh1z8BtcEGZNrsuILrIUA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUqpuYrJ2GHNsgXlSziaFqJOzfg4KbM5NnxKxUhX2MpE1aeTGhZ2e5S4g/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUBRLFndeicHTmsI0o8nIUov7Ovs8lFdTx5vNhoBhCtLlzKLiakh94uxsA/640)




论文链接

https://www.paperweekly.site/papers/2017




代码链接

https://github.com/ChenRocks/fast_abs_rl







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)
**Learning Domain-Sensitive and Sentiment-Aware Word Embeddings**

**@paperweekly 推荐**

#Word Embeddings

本文是香港中文大学与 Tencent AI Lab 联合发表于 ACL 2018 的工作。**论文提出了一种学习领域适应和情感感知的词嵌入的新方法，能够同时捕获词的情感语义和领域信息**。

与已有方法不同的是，该方法利用评论中的情感信息和上下文信息来自动确定和生成领域无关的词向量和领域相关的词向量，从而利用来自于多个领域的共同情感词的信息，并且同时捕获来自不同领域的领域相关词的不同语义。

实验结果表明，该方法能够更好的学习多领域情况下的情感词表示，提高了句子层面和词汇层面的情感分类任务的性能。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPURibKs7p3dCtE6yLYH2VOg6zmZtetI3f8Lmic7KjpYGVAib1qLNPaXHXWg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUF4eSQQNPic1I5CD1KWIml9GbT4nPTf9uabAib256OmTM0EXjUOwQib9Lw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUw37HWYyMkjc0UgRg1qWq2FqSkqXT4JxqS1S4ic8v04wXaTBtJoe5bhw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU1MyYMu7B8kcXTyiapuEVnEcFaMPUzepCiaoblt6JTqclz9JQQ2sZrX7g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU1NhCsnBylBQ4qkiapTsib41TDHiaU4Uwe1quAJGoia602asoRiaA8Ru8p8A/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUz1egUnznG8gkUvQ2ItUds2KZKn2gpSZX0Vdzgb8MPzfKogwfbzw6mg/640)




论文链接

https://www.paperweekly.site/papers/2015







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)
**Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension**

**@shaness 推荐**

#Machine Comprehension

机器阅读理解在最近的文章中，主要是针对特定数据集上的表现做模型改进。而微软的这篇文章更加贴近现实问题：**如何让机器自己从一个数据集上通过监督学习生成答案和生成问题的能力，然后无监督地应用在其他的 domain 里面，对缺少标注数据的 MRC 问题提出了迁移学习的解决思路**。

本文思路分两步合成，先根据 paragraph（后简称 p）生成答案（后简称 a），然后根据 p 和 a 生成 quenstion。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpl7G1469U0K8QHw1BO7G2Gm8ia1DUNdm6nOUII5pBdlT8Ne7YFSFchQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUhY8G1ib5US025RxDBToRFFKHFaray84fvyeoloKDV1S16yiaR2Ym4Bnw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUDd2yfL70oYeq5JM01BYDcgx5wKcN0Bf5HGxpLMZSibibIozxy2cjosrg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUKbn5XTeibWJAiad84MQeFdpARKV2qic1pl2Yu0hQ7tB3VmZRpY2R3e6Ng/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU2cbIWsayuJ0fOuMhThAicvNkOicSuHicEAPHoO1NKD5Zh3BPu6Xmf0Ydw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU50lklictltEWialMjqTFykIrTJFtqdOMmU4RvQicCcq2qx7icB3wLSUy7Q/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUSl19YpdtkrftFWtPaXyOJqzKvPA9IZq6iaOcbagZQmnCs3mY7ogUVibg/640)




论文链接

https://www.paperweekly.site/papers/2012



代码链接

https://github.com/davidgolub/QuestionGeneration







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)
**PyramidBox: A Context-assisted Single Shot Face Detector**

**@yinnxinn 推荐**

#Face Detection

**本文来自百度，论文达到了超级好的人脸检测效果。从工程角度将 FPN，RCNN，anchor 等多种结构的优势结合起来**。论文将 FPN 和 S^3^FD 的优势结合起来，主干框架采取 VGG16 进行特征提取，在 conv3_3，conv4_3，conv5_3 层使用 FPN 构建 branch 对底层 feature 的背景信息进行保留，最后将高低层的信息进行组合得到 predict_layer。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU3lD1TeoFaWdYxAcZoecO3EaAJTueVYuiae6M1qNu92a5AqGWAkocWxQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUQW4T6wKGs6nTZ0LXCtfOKfdvaD6dQAteVPtAF9bLibUdicIia0icdshGuw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUwvaIHnjWd6BibZSKqHWlAkHVXuKzduc12XBRSwb5Ql7HoXUgzABNUDw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUg0VYDBeOzAW1Dtq4NQFS21OpAqGkupZm4rg8xjicTX8OoFeDjxQrDfQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUjKOce5Lib891Fgicib73VibWylH04ZeaoroPVvGngByr2UsTpPic7VWjaYQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5LCcg6ibQ2LR9crc14ibREbZEneEkPnZUQjAD9mLlk4YhOQ93zcwEgqw/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWPsILBUlj8xrKdlzvzoDZiaI3pwWqMSCwibuBttub019yg6EmwXqRN5w/640)




论文链接

https://www.paperweekly.site/papers/2006







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)
**Quantization Mimic: Towards Very Tiny CNN for Object Detection**

**@darksoul 推荐**

#Object Detection

本文来自清华大学和商汤科技，**文章使用量化的方法加强 Mimic 的性能**，对 Mimic 的方法扩展有新的指导意义。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUQENku7HT75OWMrPbaNwFZ3nelzeGVgdibr4AzYCicMYCaCbkvGZFCiadg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUBHFeKFWicCopsFsgjfY5WDLKhFf9kUX75iaZJgJW725rUbAfXnPiblDGQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUfYJDEtiaaWzNoxhr85ibjQfKibNKAbia8G5MI8XvHGnCYdicI5cClY3KiaKQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUmkqO5dLJIr9JqiblKaeq8J4YbguJPYZyicKmhmmI2oWiaj6MQ75QZRLlA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUvqHIuDWLubR7N4W9uObJI03TT4gmJictmlAyFrxjnxXSriaC8QYykYlA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUr3Zf8lGE0uXW9Vepqg7pKUROGZiaL59goHnNNnPH16lOD4QOu4QlZfg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUBkD0FlKaeoPr2GqiaxrGYicXbSozq4yibb8uhVv5moH6QjLorpJQoqWaA/640)




论文链接

https://www.paperweekly.site/papers/2010







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)
**Towards Personalized Image Captioning via Multimodal Memory Networks**

**@born2 推荐**

#Image Caption

对于 Image Caption 任务，给出一张图，生成一句话，已经取得了长足的进步。**本文提出了 Caption 方向的一个新问题：如何产生个性化的 Caption**。因为不同的人对同样的图片会做出不同的描述，其中包含了描述者本身的用词表达习惯等特征，如何针对性的学习某个人的表达式本文提出的新问题。 

这个问题很有强的实用价值，我们日常生活中的微信朋友圈，微博等等，图片所配的问题之中，都隐藏着个人平日的用词习惯，如果能够学习到一个相应的模型，那么将会为我们节省大量的时间，我们只需要在机器生成的句子上做简单的修改，甚至不需要修改，就可以直接发布朋友圈。

存在两个问题，首先是数据库的问题，其次就是如何构建一个能够学习这种个性化的模型。

**本文构建了一个个性化的 Caption 数据库，并提出了使用记忆网络进行个人习惯用词的提取，利用卷积的方式来获取单词和图像之间的关系**，最终取得了很好的效果。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUM09iapnmReBaYmGOTjZPniaeoIABlPB9PpKBr2V8D0q41ibPXJd9beKIw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUr3tVl7T25WRB9aGiad6iammoibQed0cGZCa89NoL54oRKTWxytxTMibibHA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUI6NtSNqcbETL6zd9RZtV2L4ne8iafKqC71ncMSjputj8IbAcTqPsxSA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUSiciaI4acGkX20d83rVLnNXDCsnnol0cDEicic0asDpZRhgSZGvproy1wg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUAbE88CDgh1RHRVJXDKfuicLkOQxDTZicAibvBtNDzY4aluU56LkXtILdw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUuKAr0cEXZSgzwWj65hic73957eznmVcicfhhVFjLkDr0jMU7T6qsPvjA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUuZEhPu0CMoWhgk5libaz97700SGQzWcIqCZY0KSibzYTJl9Aib4zbzUFg/640)




论文链接

https://www.paperweekly.site/papers/2014



代码链接

https://github.com/cesc-park/attend2u







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)
**Attention to Scale: Scale-aware Semantic Image Segmentation**

**@DeepTrial 推荐**

#Image Segmentation

通过对输入图片的尺度进行放缩，构造多尺度。传统的方法是使用 average-pooling 或 max-pooling 对不同尺度的特征进行融合，而**本文通过构造 Attention model（由两个卷积层构成）从而自动地去学不同尺度的权重，进行融合**（效果提升 1 到 2 个点吧，不同的数据集不一样）。

从论文中的权重可视化的结果，能发现小尺寸输入上，对应网络关注于 small-scale objects，而在大一点的尺寸上，网络就关注于 middle-scale，large-scale 甚至 background contextual information。可视化效果感觉非常有意思。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUHLfwMFeibcT8t5FDdibxnw0p7icV0hRnHnGM0icH7peXzWMwzjp4HwAKZA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUkXKSnXLYOa8W51Rw5IKGpibcfO4wA2LyCVVPJtvRdE8wiarfmdvDz0zg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU9PaqKJmaibw7VjKZ5wuPyjBbBib97ic2QCnGN1WUxAKks4EDmvkMOr79w/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUuuB1BudDEpTCD3WmD6Wh4icGhbh3L8fDuDFH3flmXde7wuhON4FN6HQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUesTbunIMKkAReUOib27ysQt35Hd4ib2P9FTt5Ah20DIQV90VfHMr2tEw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUDibSWyhtBDSib2IlJdef783a6JJIZpfY4KibqMgt47sVNUiaziad9tMVHCg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUKzC8Nk4uBDyzcPwfqhH1drdSCA1Bicu3qwvKpfewb8Yzbdwf84BrPwQ/640)




论文链接

https://www.paperweekly.site/papers/1950




代码链接

http://liangchiehchen.com/projects/DeepLab.html







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)
**Metric Factorization: Recommendation beyond Matrix Factorization**

** @daven88 推荐**

#Recommender System

**本文提出了一种新型的推荐系统算法——Metric Factorization（距离分解）**， 该方法旨在改进传统的基于矩阵分解的推荐系统算法。矩阵分解一个很大的问题就是不符合 inequality property， 这很大程度上阻碍了其表现。

本文提出新型的解决方案，**通过把用户和商品看作是一个低纬空间里面的点，然后用他们之间的距离来表示他们的距离**。通过类似于矩阵分解的 squared loss 就能很好的从已有的历史数据中学出用户和商品在这个低维空间的位置。

**Metric Factorization 可以用在评分预测和排序两个经典的推荐场景，并且都取得了 state-of-the-art 的结果**，超过基于 deep learning 以及已有的 Metric learning 的推荐算法。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUk6VXLwUkr3no6LoWnVqZCPyQUjS1HiaBwTkKKImLRQHuuLLUWPE6ibAQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUBu1GPibcmVHwuMrepMdGm9gKZWibgbaysZJs6BxVMER1usiczvCWFcsTg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUOcF0ibog1Z348kTLicyJbLxewagaskRbX1zbltv0ibZVB0MnaIkF1RXfQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU6HS4fibTnre6E1d0XEKia0eN12UJML8I2nknH63kg2mJzcvWRlgTxOdg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU0athwSLK71c9DTcuMf3p5kMwcCnB5OYibQUsTic85sGq56t2DZX3Cxrg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5RAia1ovRLNw1fib0SHfoHjqxFw3hHwvhmSGS0OluicVQCSWRrMNJxTBg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUhvJn23TS0e8PAeasRf1Jq0OOEfcsv6U4scTYlLEcCJUXYqLR3slaSA/640)




论文链接

https://www.paperweekly.site/papers/2002







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUMyCvJ7nksObSLatO1UHuTLcw5KYWPhREehBpXWY0uqseRtib5rxuvBw/640)
**Distributed Prioritized Experience Replay**

**@Davidzhang 推荐**

#Reinforcement Learning

本文是 DeepMind 发表于 ICLR 2018 的工作。Exploration 是强化学习里面比较难的问题，这篇 paper 通过分布式，可以说**用一个最简单的做法却实现了非常好的 exploration**。同时，这篇 paper 也让我们要意识到 RL 的分布式计算是非常重要的一个环节，不仅仅是加快训练速度，还可以更好的提升效果。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUu2ygXh1dRM77ZkHYicNXqmce1br1EX79DfiaXfjeuTRajUIGOJ7OUf0w/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUpJsq2kgzDqSjxmmMeDHCFqhAMlAt7sQwh23F7FM8cWUv2QGXQiaicQlg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU0L7aiaHzmuVAIoYRFVzpCVynXBx2tgD1xxrl9ESBeFF2zlPuCF5wCow/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWyRdccO8KgQmTGBqA6OdjZLfXic4CAaGfM2qnggTk03AibKfjRDJQfnQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUgbSFToicVk4MqGvIf82SJMCkCAriatl4dmMwF9avOKf5xlLbMt9fwWbQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUrBHgzmKKAVPT5xPbPE1sREEap6qS44TSxbfxFoXkF9pw982AeIbxvg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPU5nRB81JA5Oht86EMk9ufUqm3ricqQoqvTf0kzs4zLKLicgU3x1YpDrYA/640)




论文链接

https://www.paperweekly.site/papers/1994







**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****推 荐 有 礼#**




本期所有入选论文的推荐人

均将获得**PaperWeekly纪念周边一份**



![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm5Wb1iaUHxx8mBh1Km3dWjfPlgYsxpxlV44icJWDVwuPorALMxCQglAC8Dx8JMeic5wHeNw29gJV8SA/640?)


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWQfATNyq8icodseL6gFjp8w4sQ1DBTuiaChXPEcQ0Q6tmRmz2jJjzic7g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUk6ibiaGfmJl0icaK5go84z9iaLysegxS06wkEIrCkuL1eV2dicVoBusY4aQ/640)


**▲ **深度学习主题行李牌/卡套 + 防水贴纸




****礼物领取方式****



推荐人请根据**论文详情页底部留言**

添加小助手领取礼物




**想要赢取以上周边好礼？**

**点击阅读原文**即刻加入社区吧！




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击以下标题查看往期推荐：**




- 
[来不及想标题了，我要去打包收藏了](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488060&idx=1&sn=8214e778bfc381bf684ab634a34dbf34&chksm=96e9cdbca19e44aac9ffb5bb402861e3295bb3e42b98fe7d964c422995b06875f92333fd85d1&scene=21#wechat_redirect)

- 
[快醒醒，一大波最新 AI 论文加开源代码来袭！](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488566&idx=1&sn=5af3e8b73b2d71003e9af12fb04a43b7&chksm=96e9cbb6a19e42a08722cba30ca9b663d38406f23f882fb123b5802f686391510036ad0a2da0&scene=21#wechat_redirect)


- 
[15 篇最新 AI 论文来袭！NLP、CV...人人有份](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489270&idx=1&sn=4fa88468dba51738df921da45573a927&chksm=96e9c976a19e4060c20453f9cb275966ba25522292b9b638d712963edf208822686486b2cbb7&scene=21#wechat_redirect)

- 
[还在熬夜憋思路？这12篇最新论文打包送给你](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489608&idx=1&sn=1b9384cbb3550a61901521c91aa97628&chksm=96e9c7c8a19e4ede12c934b943ef2f40df220a936bafc8e50a290f1848567412abaed8f7441d&scene=21#wechat_redirect)

- 
[本周 AI 论文良心推荐，你想 pick 谁？](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489436&idx=1&sn=111fefd080fd4459d2a80defa94880e3&chksm=96e9c81ca19e410a975df7747ea79fc9cfba4d8fa0910112e48bf66b8f2a8520f5eafe61630f&scene=21#wechat_redirect)






[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488603&idx=2&sn=7320cb23efba3e7b5a381be83b7fe3ad&chksm=96e9cbdba19e42cd5840d3d51e86da4709b3d5273b2cf2512c32d84ab2b42ac4e7f13bf9ba63&scene=21#wechat_redirect)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmsvubgibQtWV5t7M3ETKt3bbXiaAothCErMicibic9QCUBpxkuibuht62MGcCTcLyAxqGrsUXbv254InDA/640?)

**▲**戳我查看招募详情




**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****作 者 招 募#**



****[让你的文字被很多很多人看到，喜欢我们不如加入我们](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487954&idx=1&sn=d247e5b99ecb2c37e85d962d7f93d7d7&chksm=96e9ce52a19e474457e04affae41dc6b6fe521154f95ae7122260b46ec91f55ae7c8fb472c3c&scene=21#wechat_redirect)****






**关于PaperWeekly**




PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)

▽ 点击 | 阅读原文| 加入社区刷论文




