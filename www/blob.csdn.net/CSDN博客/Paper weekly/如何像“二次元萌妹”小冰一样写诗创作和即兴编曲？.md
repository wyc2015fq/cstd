# 如何像“二次元萌妹”小冰一样写诗创作和即兴编曲？ - Paper weekly - CSDN博客





2018年08月23日 14:39:03[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：272









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgm9RFr5icmiaj0bibJxUeIGdAFHNM4G6PJEiccw293RuVnOiadQ4zcdibdJa5FFfn0ZMgpbKib4AAKD8dm2w/640)




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/HSsu3xwMWBD9icVoialCRLnAvIFXqnYsKuiaqRoL4EoOMzOtj2ic9kOWsibBA7GmCwR9NcDHvCxFsq6MFxSv07udsSg/640)


作为全球首个以培养 EQ 为目标的 AI 聊天机器人，微软小冰于 2014 年诞生，当年 6 月在微博上线，因性格活泼、聊天能力强引起热烈反响，在过去的几年中，微软小冰陆续入驻微信、京东电商、QQ、Windows 10 等平台，先后解锁了主持人、唱歌、写诗创作等技能，成为无处不在的“二次元文艺少女”。

在微软小冰第五代发布的时候，沈向洋已经表示：“小冰是一个聊天机器人，但不仅仅是一个聊天机器人，聊天只是用户的一个体验，但微软设计产品理念的真正核心在于打造一个情感计算框架。”**2018 年 7 月 26 日，微软小冰正式进入第六代，这也是微软小冰历史上最大规模的一次全面升级，升级内容涉及到微软小冰情感计算框架的所有组成部分。**小冰的产品形态涉及对话式人工智能机器人、智能语音助手、人工智能创造内容提供者和一系列垂直领域解决方案，覆盖全球五个国家的 40 余个平台。

**从一个聊天机器人转化成一个完整的情感计算框架**，再从情感计算框架转化成各种各样的产品形态，与各种各样垂直领域的方向进入到人类社会生活的方方面面去，这是第六代微软小冰最为显著的特点。

这位明明可以靠颜值却非要靠才华的“水手服少女”背后，究竟隐藏着怎样的秘密？**不妨通过以下三篇来自微软的最新论文，来看看小冰是如何通过写诗创作、即兴编曲来实现养家糊口的。**

# 小冰乐队




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFhfEZjgkibzZ6ecVAyS3r3NzdR1vYnzCZse5uiaqBfS6mcXn7Ut19hibhQ/640)

**论文摘要**

随着音乐创作知识的发展和近年来需求的增加，越来越多的公司和研究机构开始研究音乐的自动生成。但以往的模型在应用于歌曲生成时存在局限性，这既需要旋律，又需要编曲。此外，许多与歌曲质量有关的关键因素没有得到很好的解决，例如和弦进行和节奏模式。特别是。如何确保多音轨音乐的和谐，这仍然是一个有待探索的问题。 

为此，我们对流行音乐的自动生成进行了重点研究，其中，我们考虑了旋律生成的和弦和节奏的影响，以及音乐编排的和声。我们提出了一种**端到端的旋律和编曲生成框架，称为“小冰乐队”（XiaoIce Band）**，该框架产生了由几种乐器演奏的几个伴奏曲目组成的旋律音轨。 

具体来说，我们设计了一种**基于和弦的节奏和旋律交叉生成模型（CRMCG）**，以生成带有和弦进行的旋律。然后，我们提出一种**基于多任务学习的多乐器协同编曲模型（ Multi-Instrument Co-Arrangement Model ，MICA）**。最后，我们在一个真实数据集上进行了广泛的实验，结果证明了 XiaoIce Band 的有效性。

**本文获得 KDD 2018 Research Track 最佳学生论文。**


**论文贡献**
- 
我们提出了一种端到端的多轨音乐生成系统，包括旋律和编曲。 

- 
基于音乐知识，我们提出用和弦进行来指导旋律和通过节奏型来学习歌曲的结构。然后，我们使用节奏和旋律交叉生成方法进行音乐生成。

- 
我们在解码器层的每一步使用其他任务状态开发多任务联合生成网络，这提高了生成质量并确保了多轨音乐的和谐。 

- 
通过提供的大量实验，我们的系统与其他模型表现更好的性能，人工评估也得到一致的结论。


**论文模型 & 效果**

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFYAdvcf2e7IB2IAObnMs94XWsnPd5yK8INvexrkOeJGDo038FyUXPeQ/640)

**▲**图1. 我们生成的歌曲示例




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFzO4AClIXuYqbRVF2iciaMSVBXqjlUWFjkN7ulpOFCHCRRXnnKP2gBx7w/640)

**▲**图2. 标有“和弦进行”的歌曲“We Don’t Talk Anymore”的旋律




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFMhmPeaibzqOoync2hTZPz9nVwrX9zRnT3gDpGTodMtFD82ArlEY56Cw/640)

**▲**图3. 流行歌曲的音轨和乐器分析




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFDn9ajaKQiaUn14nIsf1E5R7l9c5OEeicIQYCZ8SgRYOlDcy1ssx27cbg/640)

**▲**图4. 小冰乐队的流程图概述




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFgfs7R48hiaMG2hPKJAibAZPiajdrZKK2EQZuwC5B0W1zwianzIF5icpIfFg/640)

**▲**图5. CRMCG




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFaNZyGiadSdGwyziacQJNia7KeFu1GOFr1LdVrA8ylw1FXdE0NKe4MoDWA/640)

**▲**图6.  (a): MICA (b): 注意单元 (c): MLP单元




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFibxD37YkNNs3HovbnVA7UbTdPEliasEscnFv2CDqbbicp6NZeUibibc14dQ/640)

**▲**图7. 与人类研究相比的和弦的分析




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFxZahyHzMSib44oIM91PAbSB9tozxbiaHGRReWLysAkQdzic9CQajyACzA/640)

**▲**图8. 节奏分布




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFRCR1bEouz1l1XQCibLRNuiaAImOiaV2EpJApDWuqCWXVozxCeD8dHTSaw/640)

**▲**图9. 四个部分的编曲分析




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFkxsbHVVnH74FTqvbPJfQLiaIjiaTXlyrpm1WI1rEr4Pf8zfc1ib6tDXYQ/640)

**▲**图10. 编曲的和谐分析（G：吉他，S：弦乐，B：贝斯）




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFRQhOc7QZ3icuVYmY5TCqPBuT54QOBiblfCfAia0UpkxT3mrtwx32XRjkw/640)




# 图像激发诗歌生成




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFYMtLy7QCTYIQfmtgkm8OPzsAkDTZhAjBXibtjNYOJCj8QxJNPp3nRgQ/640)

**论文摘要**

诗歌的创作灵感一般来源于视觉。不同的解读者对于对象和从图像中观察到的情感印记会有各种各样的感觉。**我们在本论文中提出一个从图像生成诗歌的系统来模仿这一过程。**

给定一张图像，我们首先要从图像中提取一些呈现物体和情感的关键词。然后基于关键字在人类所作诗歌中的关联性扩展出相关关键词。最后，使用现有诗歌训练的循环神经网络模型来逐渐从关键字生成诗句。

我们的方法由人类评估人员进行评估，并与其它基准进行比较。结果表明，我们的作诗方法比其他基准方法更有艺术性。自 2017 年 7 月发行以及诗歌总集发布以来，这一体系已经为使用者创作了一千二百万的诗歌。

**论文贡献**
- 
我们介绍一种创新的应用来用图像去激发现代诗歌的创作，这是在模仿人类受到景物触动而抒发情感的创作行为。

- 
为了创作高质量的诗歌，我们结合了几种验证机制来验证文本的流畅性，诗歌的完整性以及图像的匹配度。

- 
我们利用关键词扩展来提高诗歌创作的多样性，使其更富想象力。


**论文模型 & 效果**

![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFnCnXVKCnWRA8Q6mApeIicd3nibKWoHKac7SCjZaeW0jNQxyDqzIxy7Bg/640)

**▲**图1. 诗歌框架的图像说明。该系统接受用户所提供的图像并输出语义相关的中国现代诗歌片段。对于该图左侧部分，其实关键字从物体和情感识别器获得之后，运用关键字过滤和扩展来生成关键词集。在此之后，如诗歌生成部分显示，关键词集中的每个关键词被认为是每行诗的一颗种子。提出一种多层生成模式来保持句子的流畅和连贯。另外，用自动鉴别器来选择高品质的句子。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFT1n6ybA8DJTGcnVE8qqvRjYXrmxib4JN0nY257ZCQ8lTtm9YVysyE6g/640)

**▲**图2. 我们提出的层级诗歌模式包括LSTM的两个级别。在该图的后半部分说明了诗歌水平模式，通过所有前面的句子来预测下一个句子的内容载体。此后，该图的上半部分内容载体被认作句子级别LSTM的输入。注意该图仅仅显示的是循环生成的反向生成器。正向生成的例子可以通过正序句子级别的生成模式来达到。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFPnwL8nAMe1gjLUVpSooVU9PgPicj30Yd03FbseALGcUojbEJCvqtlNw/640)

**▲**图3. 人工测评工具旨在捕捉方法之间的相对判断。对于每个图像，每种方法都会生成一首四行诗，并且所有的诗都会并排显示。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFRSk4gkm1OWdXTlXaP1cRUkWoiaR5W7xfY5x07KibUwvDR2M3Ma8wH2Aw/640)

**▲**表1. 我们的诗歌生成器在句子水平和诗歌水平上的人工测评结果。平均分数表明递归策略和层级模型都得到显著改善（p值小于0.01）。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFdQKKqUbotuOicFI7FkYiaHR90G0OibbUIZmImhqOnQ06lnt1xl4iahqREw/640)

**▲**表2. 不同关键字扩展方法的性能。虽然它们共享接近的平均分，但是通过应用基于词共现的查询扩展，关键词和句子无关性率都下降。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFbC1vwn8fCNKFznMk6xBlkust5NEfYItkft4ZhxZ8rXIwPibl52GtibpA/640)

**▲**图4. 由两个基线方法和我们提出的方法生成的示例诗。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VF5s9ialbzvPIq1K5eI8x2ibdddDgmkX7hcia3LUPvqdgm3VZr99eyiaibgNQ/640)

**▲**表3. 我们的方法和其他两个基线的人工测评结果。虽然“相关性”方面由Image2caption占优，而CTRIP在“流畅”部分更强，但我们的方法在其他方面明显优于两个基线。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFZpVDNicXXNhN4eBmpH86t1mlHk82TicNHemibicVUQllkUCdTicibwyM3qOQ/640)




# 超越叙事描述




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFjtqUJMGibO365STLEjJGHCNUPUvAqIfVkju1wl9YTpvLarxTf2ZN5ag/640)

**论文摘要**

根据图像自动生成自然语言的技术引起了广泛关注。本文中，我们更进一步，研究如何从图像生成诗歌语言，进行自动的诗歌创作。这一工作涉及多项挑战，包括发现图像中的诗歌线索（例如，绿色中蕴含的希望），以及生成诗歌——既满足于图像的相关性，又满足语言层面上的诗意。


为解决上述问题，**我们通过策略梯度将诗歌生成工作划分成了两个相关的多对抗训练子任务，从而保证跨模态相关性和诗歌语言风格。**为了从图像中提炼诗歌线索，我们提出学习深度耦合的视觉诗意嵌入，在其中，机器可以连带地学习图像中物品、情感和场景的诗意呈现。本文还介绍了两种指导诗歌生成的判别网络，包括多模态判别器和诗歌风格判别器。

为了便于研究，**我们通过人工注解者收集了两个诗歌数据集**，它们有如下性质：1）第一个是人类注解的“图像-诗歌”对数据集（共 8,292 对），以及 2）迄今为止最大的公共英文诗歌语料数据集（共有 92,265 首不同的诗歌）。

我们应用自己的模型生成了八千张图像，进行了大规模的实验，其中一千五百张图像是随机选取来进行评估的。客观评估和主管评估均显示，该方法相对于目前最先进的图像生成诗歌方法，表现优异。我们请 500 名人类受试者来进行了图灵测试，其中 30 名评估者是诗歌方面的专业人士，测试结果证明了我们方法的有效性。

**论文贡献**
- 
我们提出以自动方式从图像生成诗歌（英文自由诗）。就我们所知，这是首个尝试在整体框架中研究图像生成英文自有诗歌问题的努力，它使机器在认知工作中能够具备接近人类的能力。

- 
我们将深度耦合的视觉诗意嵌入模型与基于 RNN 的联合学习生成器结合，其中两个判别器通过多对抗训练，为跨模态相关性和诗意提供奖励。

- 
我们收集了首个人类注解的图像-诗歌对数据集，以及最大的公共诗歌语料数据集。通过应用自动和人工评价标准（包括对 500 多位人类受试者进行的图灵测试），大量实验证明，相对于几个基线方法，我们的方法更为有效。为了更好地促进图像生成诗歌的研究，我们将在不远的将来公布这些数据集。



**论文模型 & 效果**




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFU6xovwglNcQJ5Lbyt1TKEXp0mQsf6uBGrSfjSWl9hvSIVQNrWHxGhg/640)

**▲**图1. 示例-人类对相同图像写出的描述和诗歌。我们可以看到，这两种形式中相同颜色的用词有着明显差异。相对于描述图像中的事实，诗歌更倾向于捕捉图像中物体、场景和感情更深层次的含义和是个象征（例如，**骑士**与*猎鹰*，**猎**和**发**与*进食*，以及**待**与*站*）。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VF29Wcsic3M0XZicPGvibnVUtr7CqU2pwnW4d7TJLrAkhdDdu5NAKZ5sHTQ/640)

**▲**图2. 使用多对抗训练进行诗歌生成的架构。我们首先使用人类注解配对的图像-诗歌数据集（多模态诗集）中的图像-诗歌对 (a) 来训练深度耦合的视觉诗意嵌入模型 (e)。词性分析器（斯坦福大学 NLP 工具）从诗歌中提取诗歌象征（例如物品、场景和情感），图像特征 (b) 即为使用提取的这些象征对 CNN 进行微调后取得的诗歌多 CNN 特征。诗歌的语句特征 (d) 是从受到最大公共诗歌语料库（单模态诗集）训练的 skip-thought 模型 (c) 中提取得到的。基于 RNN 的语句生成器 (f) 作为智能体得到训练，两种判别器（评判根据给定图像生成的诗歌的多模态 (g) 和诗歌风格 (h) ）为策略梯度 (i) 提供奖励。词性分析器从是各种提取词性词语。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFc9eRH0dFDqshO7sTpxAQ4WhZEc8wH3d6ibiczAP4fWGFoTAcRhoHWd2Q/640)

**▲**图3. 两个数据集中的示例：单模态诗集和多模态诗集




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFXhIgicdI0vonrYqMnuxY6NbKOWlw0GJiaS0vibyoYoZLO5Y1nXrL7pheA/640)

**▲**表1. 三个数据集的详细信息。前两个数据集由我们自己收集，第三个通过VPE扩展而得。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFlicQI4NB9jVVshz8oJO1aVaQtkMzB6K9BIQr3xBYuibpjfAoLcNQibiccA/640)


**▲**图4. 使用六种方法根据一幅图像生成诗歌的示例。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFjYImX5TAokWaiayEcZzUc4HHKdXamWXm5lMFS7JM2kdQjGNmnl2n86w/640)

**▲**表2. 人类创作的三种类型诗歌与图像相关性的平均得分，评分范围0-10分（0分-不相关，10分-相关）。单向方差分析显示，这些诗歌的评价具有统计学意义（F(2, 9)=130.58, p<1e-10）。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFACUZyeIAd2CvdLaq4GZtNxz5j0vibvDGF5yhLWLEJU3XwOfMdfAyLibA/640)

**▲**图5. 通过我们12P-GAN方法生成诗歌的示例。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VF43jWSPhJYSbk3tkrvyEacHTd9fwiaFCpicsXOwAPgyDkU8fzb8D6kGDw/640)

**▲**表3. 自动评价。请注意，BLEU得分是比较人类注解的真实诗歌计算出的分数（一首诗歌对应一幅图像）。总分是三种标准归一后的平均值计算得出的。所有得分都是百分比（%）。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFTjFlrFSDXickjsKwbAMqGckYswEJ7NDshuLanLFpAjplHqR3Yo0iapAw/640)

**▲**表4. 六种方法在四个标准下的人类评价结果：相关性（Rel）、连贯性（Col）、想象力（Imag）和总分。所有标准的评分范围都是0-10分（0-差，10-优）。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFnwial3ZtOlB5l5do3pR9TpBiaIHjdcIORWHSX5lhMADICLBibfnMxajmw/640)

**▲**表5. 使用诗歌搭配图像/不搭配图像、对ATM用户和专家用户进行的图灵测试的准确性。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglphI4TB3TGnaxCO34Fy0VFiaibeOZ6Mw5WaRfaYhImsIPmsCNDyzxmib3SPvAbLDMQf0psLQSjIAJnQ/640)







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)







**点击标题查看更多论文解读：**




- 
[网络表示学习综述：一文理解Network Embedding](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490862&idx=1&sn=707fe122dfc5d961a22771111514fada&chksm=96e9c2aea19e4bb8755d6759dd8e70cb44d2da2c454947395dede0268f511c140441cd1fb5ce&scene=21#wechat_redirect)

- 
[细水长flow之NICE：流模型的基本概念与实现](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490842&idx=1&sn=840d5d8038cd923af827eef497e71404&chksm=96e9c29aa19e4b8c45980b39eb28d80408632c8f9a570c9413748b2b5699260190e0d7b4ed16&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247487949&idx=1&sn=e09391933f3c4493cfb737b0ea2cf0af&chksm=96e9ce4da19e475b0c789088d403a0f49449b8ba0c43734aa835c5d2a7cb69c3d839c7ce056c&scene=21#wechat_redirect)[如何让GAN生成更高质量图像？斯坦福给你答案](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490794&idx=1&sn=bf3af5e3f53f2fa521da137b86afbb47&chksm=96e9c36aa19e4a7ca3bdacdac311dfab3d6ba41eef5993e96de1e9a2ab29ee0571fa2fbde166&scene=21#wechat_redirect)


- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488238&idx=1&sn=06ffb033332a54279e600c511e1c5c5f&chksm=96e9cd6ea19e44781ee1313b349e0e77631781a2a163e2fd845c841dc2200d988424bd73c4c7&scene=21#wechat_redirect)[哈佛NLP组论文解读：基于隐变量的注意力模型](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490536&idx=1&sn=0998c5dd4e20841f3542ee328de1f1b4&chksm=96e9c468a19e4d7e24a38f3d9c4b1b4ea48d729c7db124f2b92a2309f0eee982bb9f9bc8356e&scene=21#wechat_redirect)

- 
[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490514&idx=1&sn=c066be4f8d2ac3afa8378d180864eed0&chksm=96e9c452a19e4d44eb6a879c5eb4a1426d6de370a0f3c5b6a27c6b8dfc6a938a3851baa258e5&scene=21#wechat_redirect)[ACL2018高分论文：混合高斯隐向量文法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490152&idx=1&sn=ee9c70c701d5ba74423318865ecdb44f&chksm=96e9c5e8a19e4cfeddb4d92d86415c54f511427f8851c5f22b596c68128b85512bf7a62cf729&scene=21#wechat_redirect)

- 
[COLING 2018最佳论文：序列标注经典模型复现](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490099&idx=1&sn=2d2497999186b979dd557fe3133b7606&chksm=96e9c5b3a19e4ca550a7ae55705af84e941b1aba14cb21f3f2ffc366df837d387575f8529cf2&scene=21#wechat_redirect)

- 
[一文解析OpenAI最新流生成模型「Glow」](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490358&idx=1&sn=b4b5d6014bdd365456d500537ba5bcad&chksm=96e9c4b6a19e4da08710a55935dc2e15b00838d5395fdf2a424c50dedff9af7fa11441741b9d&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**



总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。









