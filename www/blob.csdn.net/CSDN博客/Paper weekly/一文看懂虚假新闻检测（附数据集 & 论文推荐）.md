# 一文看懂虚假新闻检测（附数据集 & 论文推荐） - Paper weekly - CSDN博客





2019年02月19日 08:37:22[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：968









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgm9RFr5icmiaj0bibJxUeIGdAFHNM4G6PJEiccw293RuVnOiadQ4zcdibdJa5FFfn0ZMgpbKib4AAKD8dm2w/640)




作者丨孙子荀

单位丨腾讯科技高级研究员

研究方向丨多模态内容质量




本人过去几年一直从事内容质量方面的算法工作，近期出于兴趣对假新闻这个问题做了一些调研，简单总结一下提供读者参考。




在某种程度上假新闻的是一个微观领域问题，它和谣言分类，事实判断，标题党检测，垃圾内容挖掘等都比较类似，在宏观上说都属于内容质量的领域，所以很多方法其实是通用的框架。




**本文主要简单介绍了我们的做法和几篇具有典型代表的假新闻论文，从不同的方法路径去了解多模态、网络游走、特征挖掘等手段在假新闻领域上的一些实践。**




# 模型构建




根据 ***[Kai Shu, 2017]*** 的划分，**模型在这里主要有两类：**1）基于内容的建模；2）基于社交网络的模型。




** 1. 基于内容建模 **




有 1.1 面向知识和事实库的和 1.2 面向行文风格的。 




**1.1 面向知识库**




事实检查系统有点类似谣言鉴别系统 ，对文章描述的观点和客观事物进行校真，类似 QA 系统是一个比较复杂的 NLP 领域，包括知识表示、知识推理。**在知识库数据集上有集中划分方式： **




**1. 专家系统：**各个领域的专家构建的知识库， 显然这种方式的效率和扩展性都非常差。 不过如果是垂直类目（生物，历史）那或许可以在某个客观事实比较多的类目下进行尝试；




**2. 集体智慧：**用户集体知识的反馈来构建的一套知识库。 




1 和 2 有了之后其实可以通过类似检索的方法，来对新的内容进行相似度判断，从而充分利用积累的历史内容提供出来的特征指示。 




**3. 基于算法分类：**使用知识图谱或者事理图谱来对内容进行真实性判断，当前主要的开放知识图谱有 DB-pedia 和 Google Relation Extraction 数据集。 




这个领域的问题，类似 NLP 的 QA 问题，有兴趣的同学可以参考 ***[Yuyu Zhang, 2017] ***的 VRN变分推理网络。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmLicFl7I32ChMBy9w9PVhOjJqnU0S60yXDXNc50VTdicqxBfQ7yFgogVhSqeHQ5WWiaDF5AEC6mmo5g/640?wx_fmt=png)




作者通过概率模型来识别问句中的实体，问答时在 KB 上做逻辑推理，且推理规则将被学习出来。即可用于做事实判断。




当前这个方向技术落地成本高，难度较大，效果也不一定理想。




**1.2 面向内容风格 **




用文章内容本身的行文风格，通过上下文无关文法得到句子的句法结构，或者 RST 修辞依赖理论等其他 NLP 深度模型去捕捉句子文法信息。 




根据捕捉文本信息描述种类的不同，作者分为两类，检测欺骗程度，检测描述的主观客观程度（越客观公正的可能性越大）两种。震惊体的标题党就属于这类。 




其中，假新闻可能用到的特征，包括普通特征和聚合特征两大类。普通特征就是页面，文本，图片，标题等单纯的特征 embedding，聚合特征就是把各个普通特征进行组合和有监督的训练成一个一个子模型问题。然后这些子模型的输出又可以作为聚合特征用在假新闻领域。




下图就是我们使用的主要特征集：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmLicFl7I32ChMBy9w9PVhOjSEosckBYW72wancmvGELnic80MbYeAibOHW5BXDFIV040JluFPpKO8kQ/640?wx_fmt=png)




**其他：基于社交网络建模**




分为两种，基于**立场**和基于**传播行为**的。 




前者主要是基于用户对内容的操作（评论，点赞 ，举报等等）构建矩阵或者图模型。 




而基于传播行为对对象建模，类似 PageRank 的行为传递。下面介绍的 ***News Verification by Exploiting Conflicting Social Viewpoints in Microblogs*** 一文就是这种类型 。 




1. 对虚假新闻的传播游走轨迹跟踪， 以及通过图模型和演化模型中针对特定假新闻的进一步调查；




2. 识别虚假新闻的关键传播者，对于减轻社交媒体的传播范围至关重要。




**假新闻研究方向**




***[Kai Shu, 2017] ***文章总结了假新闻的几个主要的研究方向。




**数据方面的研究工作：**现在还没有标准的测评数据集，这是需要去建立的。再有就是通过传播特性去更早的检测假新闻。另外一个就是从心理学角度去做假新闻的意图检测，这个角度过去往往被忽略。 




**模型特征方面的研究工作：**往往会使用用户的画像特征，内容特征（NLP、CV）结合深度学习，还有传播网络特征，比如用户和内容之间的关系构造出来的网络特征，网络本身的 embedding 表现。 




**模型方面的研究工作：**第一个就是特征之间的组合。第二是预测目标的变化。第三不论是从内容源，还是文章风格，或者内容的反馈（评论，等互动行为）都有各自的限制，组合这些模型。最后就是空间变换，把特征变换到另外的 latent 语义空间尝试解决。




# 数据集




**FakeNewsNet**



BuzzFeed 和 PolitiFact 两个平台的数据集，包括新闻内容本身（作者，标题，正文，图片视频）和社交上下文内容（用户画像，收听，关注等）。




**数据集可获取方式：**




https://github.com/KaiDMML/FakeNewsNet




**代表论文**




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5faIgULSbgoeEthUFfpB9G7AQ2NicBqvcV1FpO3GyEEr71KyOsczN9OA/640?wx_fmt=png)




**LIAR**




该数据集也是来自 PolitiFact，包括内容本身和内容的基础属性数据（来源，正文）。




**数据集可获取方式：**




http://www.cs.ucsb.edu/~william/data/liar_dataset.zip




**代表论文**



![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5r8dxHQzcJgJIKfk2ib9voyIUN9zkppiawdAtOJT6TUCdg5ia08e4DYOJw/640?wx_fmt=png)




**Twitter and Weibo DataSet**




一个比较全的数据集包括帖子 ID，发帖用户 ID，正文，回复等数据。




**数据集可获取方式：**




http://alt.qcri.org/~wgao/data/rumdect.zip




**代表论文**



![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5e6LFxTD9jFXbVAhk10Hq11VaGHHvp8t7ycrKRmvt81pQePF4iawgXxA/640?wx_fmt=png)




**Twitter15 Twitter16**




被上面的数据集使用。来自 Twitter 15、16 年的帖子，包括了帖子之间的树状收听，关注关系和帖子正文等。




**数据集可获取方式：**




https://www.dropbox.com/s/7ewzdrbelpmrnxu/rumdetect2017.zip?dl=0




**代表论文**




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5Tc2PoQKpONzTJaz15HL5Y0Vj1h5u5dtT7sKSOYKJ6LMbl0wmC2KtIw/640?wx_fmt=png)




**Buzzfeed Election Dataset & Political News Dataset**




Buzzfeed’s 2016 收集的选举假新闻，以及作者收集的 75个 新闻故事。假新闻，真新闻和讽刺新闻。




**数据集可获取方式：**




https://github.com/rpitrust/fakenewsdata1




**代表论文**




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5AQbTsibIxHJic9CcQERMjMAGYeu8ZiaBIhPnvvdW7A1frX87cS15J1M5g/640?wx_fmt=png)




# 数据挖掘




***[Benjamin D. Horne and Sibel Adalı,2017] ***通过手工构建了大量的特征，使用单因素方差分析和秩和检验对特征进行挖掘。 发现真新闻文章明显长于假新闻文章，假新闻很少使用技术词汇，更少的标点符号，更少的引号和更多的词汇是冗余的。另外标题也有明显的不同，假新闻的标题会更长，更喜欢增加名词和动词。真的新闻通过讨论来说服，假新闻通过启发来说服。 




类似的内容分析还有：***Automatic Detection of Fake News***。




***[z.zhao et, 2018]*** 发现大多数人转发（红点）真实新闻是从一个集中的来源（绿点）。而虚假新闻通过人们转发其他转发者来传播的。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmLicFl7I32ChMBy9w9PVhOjeTBu6W2B7GlzQYTTnpgNRKNQzbkMtSphPic7Liclt4X2ZJcHZn66pVBA/640?wx_fmt=png)




# 相关论文介绍




在工业界比如互联网公司解决该类问题主要还是通过构建 pipeline，融合多个模型：内容向模型集，用户向模型集，结合号主发布者特征，内容产生的用户行为特征等综合构建一套体系进行解决。





![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmLicFl7I32ChMBy9w9PVhOjibpKKf2CKuwtzgicoeInR8YaD6c1ia84ibLibMPxDbGLC1KVJF9cC7HBh6A/640?wx_fmt=png)




我们在实际控制的时候结合了几十个静态 + 动态特征模型和知识库进行召回 pop 人工验证。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmLicFl7I32ChMBy9w9PVhOjkGicw3F7tDSBicfAqxMk0T1ToHQeeays8kSISiahQGDibMVemUdibBOCFcg/640?wx_fmt=png)




然而和工业界处理问题不同的是，顶会的相关论文主要根据数据集的特点，通过单模型进行建模解决。**主要的参考的维度有：**1）内容本体 ；2）内容生产源（源，内容发布者）；3）内容阅读者（用户）及其行为（订阅，评论）三大类，多个小类的特征进行融合处理。




比如通过端到端的深度学习，基于概率分布的特征挖掘，构建新颖的综合类目标函数等大一统的方式进行尝试解决。很多模型往往只能在小规模数据集上进行实践。我们介绍几篇学术领域相关较新论文。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5miaL1yeXJ91wZGfaJwlhHxqZJtB6icd20EQ8C5TOq90jj5zqT5UyCPicA/640?wx_fmt=png)




**这篇是 CIKM 2017 的 long paper。**作者认为通过构建社交图谱并不便利，构建一些假新闻的特征也需要大量人工知识。文章认为之前的检测方法不能很好的一次整合正文（text），反馈（response），源（source）三者的特征。论文的数据集来自 twitter 和 weibo，weibo 中的正文就是讨论的某个话题，而非一般的文章，反馈就是主题参与者的回复，源就是回复的用户。 




整个架构由两个部分组成：**Capture 模块**用于提取一篇正文所有的反馈文本信息，通过 LSTM 来组装多个回复内容。** Scoure 模块**通过构建用户关系网络降纬后计算得到一对si和y^i ，si用于后续网络计算，y^i 也可用于单独的用户分析。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5WvXnNCOlFt7fwbLwXV3Eibu3OxLR8cYYhYYPHooXiakpiaoia2a9I8M4ng/640?wx_fmt=png)




如上图的 Capture 部分用来抽取文章和用户的低维度表示 ，用一个 RNN 来抽取正文（text）的向量。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib56goEPrmy9YP9QaO6xdBpkpN9g4ulXlrmF9b13fAGHFnjHHBMdEMtRQ/640?wx_fmt=png)




η 表示订阅的数量 ，Xu 表示用户的全局特征，xτ 就是所有回复评论的文本特征。




Score 部分，作者对于参与计算的用户特征构造，文中使用了用户之间共同订阅参与主题数量构建的矩阵，然后进行 SVD 降纬，获得对用户的表示 yi, 然后参与计算得到![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5L2aVf6yxPT36RdqNHCibfU0PBib9rgLXdSgItcDiazXW6AavyDhl2WDlw/640?wx_fmt=png)，之后通过一个 mj 的 mask 处理，和上一阶段得到的那些与正文 aj 产生关系的用户，对应的特征向量做求和平均之后得到文章打分向量 pj。




Capture 得到的 vj 和 Score 的 pj 进行拼接，得到 cj，![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5A09fXicb9qicODyA1ZAlZCckGL4GcWoG1Bl8ibVI7fk2flnzt1XevI7Ng/640?wx_fmt=png)最终的 Loss 函数是二分类交叉熵损失 sigmoid 加上 L2 正则约束。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5WNRBR4knpakWFntve1qV5pzwK1t8tqBNFibHBjzWggOf8mJqUoCQkcw/640?wx_fmt=png)




不得不说作者把基于用户参与的内容对文章的刻画和用户之间的行为构建的网络对文章的刻画，二者蕴含的信息都转化成文章的向量同时进行反向传递的目标学习，这点具有很大的突破性。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5XibEkuuNzgdXVFZDwNRnQ4gbicfS9Og5EyH1hDhHXib54bRyLbCAFgX7w/640?wx_fmt=png)




这篇是中科院计算机研究所的金志威和曹娟博士的研究工作，发表在 AAAI 2016。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5aXeDAAktVYBLpfCOgubfqSp3c4FG1jibu7hWVDXrCngpcbJ92yRVwxg/640?wx_fmt=png)




**Step 1：作者通过一个 Topic 模型来进行冲突的观点挖掘。**




通过对发帖的支持和反对行为构造信用网络（Credibility NetWork），作者认为每一个帖子（tweet）都是由一组混合的主题 topic，和对某个特定主题 topic 多种观点 viewpiont 组成。 每一个主题-观点（topic-viewpoint ）pair，它的分布参数来自 Dirichlet 分布![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5GVWCRvDoFmBdclOJR8cZa2de6sZceTEicHCNblPpzBUKblHweT2MH0w/640?wx_fmt=png)。k 表示 topic 维度，l 表示 viewpoint 维度。




1. 每一个帖子，组成它的所有 topic，符合一个参数为 θt 的 Dirichlet 分布![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5Fg0bKTkoM6Z6yiaXQVoVSicb9zMkr3dp6tCOQff4RhurORaa52GQMGLQ/640?wx_fmt=png)。 




2. 同样对所有可能的 topic，组成它的所有的 viewpoint 同样符合一个参数为 ψtk 的 Dirichlet 分布。




然后怎么生成文章呢，就是通过 θt 为参数的多项式分布中得到主题，从 ψtk 的多项式分布中得到观点 Vtn，由于这里已经确定了 ψtk 的 k，就是主题 k=Ztn，所以就是![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5hdpk9ib1ytY17FdRoICxYiaiatvwJRTk2icV7EibeyUSPZXbT03OufMgfxw/640?wx_fmt=png)，l 就是 Vtn。




那最终一个 tweet 的 topic-viewpoint 生成的参数 Φkl 就可以写成![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5CZSQheNAicHmPkdb7ss44EYf8UhkEZrVOB2veRgcCCNdAObDAt7paHg/640?wx_fmt=png)，就是产生自多项式分布![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5icDackiafBHUEk9EOkseGgHlayD45EUmeK3xzurlLjVjCQak20vNUAjg/640?wx_fmt=png)。




如果一个来自同一个主题下面的多个主题-观点 pair，之间距离非常大（设定值h） 。距离采用 Jensen-Shannon Distance（JSD），其实 JSD 是 KL Divergence（Dkl）的等价模式。 




**具体冲突观点挖掘如下： **




1. 对一个新闻数据集建模，生成大量的 topic-viewpoint pair；




2. 比较同一个 topic 生成的 topic-viewpoint 对的 JSD，建立链接关系； 




3. 用 Wagstaff et al 2001 提到的带限制的 K-means 算法，把某个 topic 下的 viewpoint 观点聚合成两个彼此冲突的堆。




**Step 2：构建网络迭代学习**





接下来就是信用网络的定义。根据上面的主题模型挖掘，我们已经有了参数 θt（主题）和 ψtk（观点），就可以得到一个 tweet t 在 topic k 上的 viewpoint l 观点为![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5enB3IvsPaosgFjQ6ncFkdUnVazghEfUbjfQ7dDs3PcDl73OlgIEUBg/640?wx_fmt=png)，两两 tweet 的函数值定义为：![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5xh2JdPunpL8jjK8FXiaQnYicXnmDV4PibMayp016tAf93hXlAsiajolHtQ/640?wx_fmt=png)， Djs 表示 Jensen-Shannon 距离。wij 就是 f(ti,tj) 的矩阵。




文中定义 loss function 如下：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5ZYdJr3t7qJIJsNeemiaEsZpm6GzarTJ4psu9Uc1G0zSy0FBicA1hs33g/640?wx_fmt=png)




其中![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5a9ytH11ccT8VHjWQsEDcfB2zqtARdoibx3kjjo1SJEF95hjUlsqHpHw/640?wx_fmt=png)的 C(ti) 表示 tweet ti 的信用值，是需要学习的参数。 具体求导和证明网络可收敛过程可以参考论文，最终得到每 k 轮迭代的表达式：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5S80pehdhOEzrVpKqjGpmvNLny1tzzgN1h8ic8KkGsmKiavvRTxSUiadPw/640?wx_fmt=png)




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5Z4GUM98K3DT7xsZPlkKoVfwwxenm3JWYKe81WY7I81b3okSKr7fUZQ/640?wx_fmt=png)




论文开始先通过大量数据分析挖掘，发现帖子内容，作者和主题三者和新闻的真假有很强的关联性。于是把三者放入一个深度扩散网络中 ，同时最小化三者的目标。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5G00CyRtfYmhqUeNakH6owdn8icjYC0Eo84gZBQvHIyPkE3jDYcNO4Ww/640?wx_fmt=png)




论文通过学习显式特征（Explicit）和潜在特征（Latent），潜在特征通过  GRU 的 Hidden 层和 Fusion 层得到：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5vPNxSgFyAczVRIb9HbXlFH8mAP3ArhzicuZ1yP1PgZH6ro2IvBykrGA/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5Q3S5Tx4eia1gCja1RPoaN6UowiczOF2JSlJt57yYKWPu8hcYNaIc34OA/640?wx_fmt=png)




潜在特征通过 GRU 的 Hidden 层和 Fusion 层得到：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5vPNxSgFyAczVRIb9HbXlFH8mAP3ArhzicuZ1yP1PgZH6ro2IvBykrGA/640?wx_fmt=png)




论文提出了一个 GDU 单元，不仅可以针对帖子正文，还可以对作者，主题同时进行学习。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib55Z6t4uSfCNZbSpaCZrGMLccRwNYbeKd09ENbcEUuJPCMx8libibQWYGw/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5VicBKicn45YbBvPUJK96uLwXc1rHjR5XsMN1fwmp6FnnzNdZPLBj1M2A/640?wx_fmt=png)




其中，作者的 L(Tu) 如下：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5EOfV4tJuBGbYAPS2DfTkEJpSWHNCmFJTe4MX6LFeYFdibmj0RjiaW2Vg/640?wx_fmt=png)




其他的 L(Tn) L(Ts) 是一样的形式。 




最终的网络架构三者相互连接起来如下图：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5JTgmwkdjJGdVNV39iacylvswiaicKfXakQ9pVA8ndw0icolBABUInhe3kg/640?wx_fmt=png)




论文和其他方法进行了对比。整个方法有点类似图神经网络。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib56hgicFcceFdfdbyn0JbxnmialHticZpibqtomqJ09yAhkuIia5U6ZiafiaoFw/640?wx_fmt=png)




这篇文章中了 WSDM '19 ，个人认为创新性很高。把作者（或者是发布者），新闻，社交网络的用户，和用户直接的订阅行为，构建了 5 个矩阵。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5wSFR43eQpTTEr5LnfJqIgoFDouAmxMg03icUEuRjGZtyHS6gfDiaXmlg/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5y1xNbcn3uiag8Tk41pkqFZAiaIkDYQBl3ibIdia7UFYBVvDJaL6hKv06mQ/640?wx_fmt=png)




新闻内容矩阵；用户矩阵；用户-新闻行为矩阵，作者-新闻发布关系矩阵。其中新闻内容矩阵，和用户矩阵，采用 NMF 进行分解。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5R4OO2yNGqicXNfArFCp60wvESiaDWiay4tKgG66Ar5xWoq2IiaaGY1WD3w/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib52zq5VLxicticnJOCdggb2b9caqTSQZ6OTD9FSBccMnjzBTmZUvm08VZA/640?wx_fmt=png)




用户-新闻行为矩阵分解的目标是：高信用分的用户偏好分享真实新闻，低信用分用户偏好分享假新闻。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5HT19DvaNib70uJQq2hdTS0rjeQMEK7f1d5OMqNaMUcibOv3c9AliarbicA/640?wx_fmt=png)




作者-新闻发布关系矩阵分解的目标：基于新闻发布者的潜在特征，可以通过他发布的行为得到。文章把新闻发布者分为各种党派风格 o ，然后用分解后的矩阵拟合这个特征。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib59EOGzzU7ZicFW4Fk6UdZia4fsQbrIGxLRib9NlY1bDX9KAkkbriaR1LVjA/640?wx_fmt=png)




通过和 Hadamard 正交矩阵做运算 ⊙ 来衡量误差大小。 




最后通过把刚刚几个矩阵得到的分解矩阵进行运算，最终目标是：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5S83h5ic7Gyu0tq7DQib3TBZTyRBhyAichLO2s0DYMicOA5Au3bEGmrk5bg/640?wx_fmt=png)




把所有的矩阵分解目标和最终目标拼接起来就得到的整体目标函数：




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib54ARDtndHAXC1EiaQ4CibGS15RmBpKFZYneOwphOu9BbxZRCMzM28J2PA/640?wx_fmt=png)




具体求导过程需要一定数学知识，对这篇论文有兴趣的同学可以看原文。




# 相关比赛




Dean Pomerleau 和 Delip Rao 在 2017 年举办了假新闻挑战：*Exploring how artificial intelligence technologies could be leveraged to combat fake news.*




**比赛地址：**




http://www.fakenewschallenge.org/




训练样本和预测输入都是一个长事件标题和一段正文内容。输出的目标是正文内容是对标题的：1）赞同，2）反对，3）讨论，4）不相关。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5NibYPybrVwpPyKtGicrzdasFic1ibLUXLib9iaxZ3MTeyhMBVBNrF9kSywLw/640?wx_fmt=png)




组委会认为，观点检测任务和假新闻任务场景是有强相关的，仅仅相关或不相关会比较容易。通过正文来分析观点是否赞同标题的内容陈述。第一名采用了深度卷积神经网络和 GBDT 两个模型。第二名采用了多种模型得到特征（如 NMF，LDA ，LSI，unigrams 等等）加上多层 MLP。这次比赛其实只能算假新闻领域的一个子问题的尝试。 




***[Andreas Hanselowski, 2018] ***这篇 COLING 的 Long Paper 中作者对这次比赛的前三名的方法和特征表现进行了分析，提出了自己的改进方案，取得了该任务 state-of-the-art 的表现。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglXum3JqQPeJ0J9kElWQNib5NY8WkYa6VDuw3coQX8I5uxhuZUBW4aAXNztIe1kU1tAicIhvJ8lBI9w/640?wx_fmt=png)




他们的框架把语义信息特征通过 stackLstm 表征，再加上对标题和正文的特征融合，实验表现在小样本的类别上有明显提升。




# 参考文献




[1]. Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, Le Song. "Variational Reasoning for Question Answering with Knowledge Graph". arXiv preprint arXiv:1709.04071, 2017.

[2]. Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. "News Verification by Exploiting Conflicting Social Viewpoints in Microblogs". AAAI 2016. 

[3]. Kai Shu, Suhang Wang, Huan Liu. "Beyond News Contents: The Role of Social Context for Fake News Detection". WSDM 2019.

[4]. Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, Huan Liu. "Fake News Detection on Social Media: A Data Mining Perspective". SIGKDD 2017.

[5]. William Yang Wang. “Liar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection. ACL 2017.

[6]. Natali Ruchansky, Sungyong Seo, Yan Liu. "CSI: A Hybrid Deep Model for Fake News Detection". CIKM 2017.

[7]. Andreas Hanselowski, Avinesh PVS, Benjamin Schiller, Felix Caspelherr, Debanjan Chaudhuri, Christian M. Meyer, Iryna Gurevych. "A Retrospective Analysis of the Fake News Challenge Stance Detection Task". arXiv preprint arXiv:1806.05180, 2018.

[8]. Benjamin D. Horne, Sibel Adali. "This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News". ICWSM 2017.





![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)







**点击以下标题查看更多往期内容：**




- 
[Airbnb实时搜索排序中的Embedding技巧](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494488&idx=1&sn=452ac80c593a9b31252031eac38d0e01&chksm=96ea34d8a19dbdce940ed25bb93507aa6c4d118f84dd0bb965b060f232fe5d41894bbc9edcb6&scene=21#wechat_redirect)

- 
[图神经网络综述：模型与应用](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493906&idx=1&sn=15c9f18a1ce6baa15dc85ecb52e799f6&chksm=96ea3692a19dbf847c1711e6e194ad60d80d11138daf0938f90489a054d77cfd523bee2dc1d2&scene=21#wechat_redirect)

- 
[近期值得读的10篇GAN进展论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493987&idx=1&sn=ce1bcdce28e78f4a307743e389f42b10&chksm=96ea36e3a19dbff5cff7f4f1c9d9fc482bb2144d80566319b3d26bce4d9ab80689d38ab2e427&scene=21#wechat_redirect)

- 
[F-Principle：初探理解深度学习不能做什么](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494694&idx=1&sn=7020fb834ce8307f27ce9c072047d37d&chksm=96ea33a6a19dbab0a6585daa00d5b5c65501dd633fa677c80541fad0e170d92baffe379315c3&scene=21#wechat_redirect)


- 
[自然语言处理中的语言模型预训练方法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492317&idx=1&sn=e823a75d9463257ed9ea7b3e4677c1ae&chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&scene=21#wechat_redirect)

- 
[两行代码玩转Google BERT句向量词向量](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493033&idx=1&sn=1ae1cd347126b10d6a857cd9bba7b601&chksm=96ea3a29a19db33f3c07723ed6e5ecbb8d2ff1b1617f1cf0d39cb3cc1e6e9c325cc29147d58d&scene=21#wechat_redirect)

- 
[AI Challenger 2018 机器翻译参赛总结](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494103&idx=1&sn=fc372862e0369b1f6a943bf997f6fc1b&chksm=96ea3657a19dbf4108bbc4179e779aa04ef05fe84f0013fa6425b0cd7e761e9880917361c4c1&scene=21#wechat_redirect)

- 
[Google BERT应用之红楼梦对话人物提取](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247494507&idx=1&sn=3c3cafef0fb51a7e40d9b9bbab53fd5f&chksm=96ea34eba19dbdfd31eaa760bb7cfd5e18f2e967c83c6ea6693ad9a062c55b3009211d824ca3&scene=21#wechat_redirect)

- 
[深度长文：NLP的巨人肩膀（上）](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493520&idx=1&sn=2b04c009ef75291ef3d19e8fe673aa36&chksm=96ea3810a19db10621e7a661974c796e8adeffc31625a769f8db1d87ba803cd58a30d40ad7ce&scene=21#wechat_redirect)

- 
[NLP的巨人肩膀（下）：从CoVe到BERT](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493731&idx=1&sn=51206e4ca3983548436d889590ab5347&chksm=96ea37e3a19dbef5b6db3143eb9df822915126d3d8f61fe73ddb9f8fa329d568ec79a662acb1&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**




总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志




**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取最新论文推荐




