# 暑假没人带怎么办？还有我们为你推荐论文 | 本周值得读 - Paper weekly - CSDN博客





2018年07月06日 15:45:23[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：687









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhglryG74dIr2B1019Yibv9PAGsWGGYBiaoSGbK2kzUnbIsicCEiazKMticicR0MPtmr1ynDovFe2kGicSydcg/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **87** 篇文章

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icO9FmLojPqkAkFLqO8OhZEARhJGDywtkJx945hvpibxdvtFduMhzpThQ/640?)

**Zero-Shot Dialog Gen****eration with Cross-Domain Latent Actions**

**@paperweekly 推荐**

#Dialogue Generation

本文是 CMU 发表于对话系统顶会 SIGDIAL 2018 的工作，并且**获得最佳论文提名,角逐今年 SIGDIAL 最佳论文奖**。**此文提出零资源对话生成的问题，目的让端到端神经对话系统可以在没有新的对话数据的情况下迅速的迁移到全新的领域**。作者们提出了Action Matching（AM）算法来从现有领域的对话数据和领域描述（domain description）中学习出跨领域的隐系统行动（cross-domain latent actions），以实现神经对话模型零资源迁移。

测试表明利用提出的 AM 算法，可以让配有拷贝机制的神经对话系统在全新的 domain 实现相当于有训练数据时 80% 的性能。本文研究同时也引出了多个前沿的研究课题。 

论文假设在一类对话领域中存在可以共享的对话状态跟踪和对话策略，模型只需建立来着不同领域中对话句子之间的关系，就可以继续在新的领域正常运作。作者将有对话数据的领域称为源领域（source domain），将没有对话数据的领域称为目标领域（target domain）。然后通过把近似对话功能来自 source domain 的句子和来自 target domain 句子投射到相近的隐空间上，就可以让在 source domain domain 上训练出来的对话状态跟踪和对话策略直接在 target domain 上使用。这个目标可以通过 AM 算法中交替优化两种不同的目标函数实现。

**实验数据结果表明 AM 是在所有对比模型中唯一可以实现在全新领域零资源迁移的方法**。此外，为了更加高效的验证未来的零资源对话模型，除了利用现有的多领域人人对话数据，**论文还开源了一个多领域的人机对话模拟器，可以自动生成不同领域，不同难度的对话**。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPFXpPBItr9YW4qLt2MmBY5OH5l34ibK2DfibibWFW49BI1CBvETZXyFX5w/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPhBpXXT55OanuZpSIjZ8Wicbia7J2EPvrgnDzpLw9cXiceTWPzG2AT7kibQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPC6Vy2TOmpyXDGoCUOQYEiayYJvic0tZJKDweicxl6KWpzibXhQnPeyTRqA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPicgHWp5dX7D6JqMsA19z350E9JW6iaPa49vrB4NibrmicBfibmQ601sHALA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPPSrz9cr1ErLftBFHQWIqeTiaIjjDAwjbnwA3vmwnib98vv1rIaFR9ENA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgjW9OTm2CjG9PYciagYPH2X3PRpfhicstJkeIDHjibOhfb3rw5icszUf4g/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPApjoJ6dJPHLUfXZBufEVUtsGzX2je1hJ8536hu4qglcA3wTD0wLLdg/640)




论文链接

https://www.paperweekly.site/papers/2077



源码链接

https://github.com/snakeztc/NeuralDialog-ZSDG




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icQRlrP3aP0pQfsEGbyTZKF6UDWtfZmrMzn4nY13xQ7kA1icr0N5TcRVQ/640?)
**Design Challenges and Misconceptions in Neural Sequence Labeling**

**@handsome 推荐**

#Neural Sequence Labeling

**本文是 COLING 2018 的 Most reproducible Paper**。**作者用 PyTorch 实现了一个统一的序列标注框架，重现了 CoNLL 2003 English NER、CoNLL 2000 Chunking 和 PTB POS tagging 这三个数据集上不同模型的的表现**。值得一提的是，基于这个统一的框架，作者对一些已有工作的一些不一致的结论进行了反驳，提出了一些新的看法。对于实践者而言，这篇论文还是很有借鉴意义的。

论文作者详细解读：[COLING 2018 最佳论文解读：序列标注经典模型复现](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490099&idx=1&sn=2d2497999186b979dd557fe3133b7606&chksm=96e9c5b3a19e4ca550a7ae55705af84e941b1aba14cb21f3f2ffc366df837d387575f8529cf2&scene=21#wechat_redirect)
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPOHmgzd2IiaL4UANhVtiba9kpOtwVMRyT3zcyovq4nCkVQEnAWqbeia7mg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP5uBCYyUdibDUNAibmYZLE94BaURDVlHib8feficYaYEsgBrgJ73u7El1Uw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP113zQJqsTyVMQia0KJrl5ia16lXfd1LKqEwgZ9HPs6BtibYPeu9gZ7UCA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPg3oibxbBx2AVic5NJj0TKuRMBiaO6z04LNmVuCYrcicdtkMyAuicfbujmIQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPdbojhm4fHktqicNfrq057rDar6q5j1rVM4hqI60Xq03jpACic27sMYng/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP2j9icFMcJhvexxA5sAMkCYsS7SB18e9dxCCzJK6L6MrUp8nNOz4zfqQ/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPic1kuuvxv19OQDNjNlaBGSV0SU9ibNwKRVZLlQym7LRoMF4umxJNzfZA/640)




论文链接

https://www.paperweekly.site/papers/2061



源码链接

https://github.com/jiesutd/NCRFpp




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8ichDlonfdvKXvzUPKNndGkVFic5wMs53ZjOygqDQouOASgne02AYV1yaA/640?)

**Sequicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures**

**@paperweekly 推荐**

#Dialog Systems

本文是新加坡国立大学、复旦大学和京东发表于 ACL 2018 的工作，**论文提出了一个名为 Sequicity 的框架，可将任务型对话的状态追踪和文本生成通过 Seq2Seq 模型来完成**。

此外，在此任务的基础上，作者还提出了 Two Stage CopyNet 模型。相比传统模型，该模型参数较少且训练速度更快。实验表明，本文模型在大规模语料中优于当前最新模型的 baseline，并且在处理 out-of-vocabulary 问题时，也有着出色表现。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPEuudngR1Evn7XG6ibbU2zjCZicsMRib99XkzSCeAib5W6o4PcXlCuRkcUg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPcBXz7wgQ0HJTGiaXAI5308upONzq141ey8rYkTPcdnYj6ABlG4icTgCg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPa4rLkPcJUJ6VJm0bEoV5G2licuzOzh8TFcHcXfN9UpS0icicvCaeiaeMBg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPqRZ6wnficwKKDiaP2hMm8RkB3j63CvqSZOA8GHUqsSugfgx7e5aFDAvA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPoPwbTP5iaWh0DQdBvJlFV92gP0iaiasjrR5WTX4b0yC03srh1ONFFe0wQ/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPYMw7F2FaWu2483NA6ZpibiaZGWMQadjTZXe3hialRGPDJB69Y2cv5lTYg/640)




论文链接

https://www.paperweekly.site/papers/2095







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icJ6oGKRITiaenF00wDTL2VZF5zDm4mcv4S9N18QbCuxVtibhcltkXmb0g/640?)
**Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information**

**@zhkun 推荐**

#Sentence Matching

句子匹配（Sentence Matching）是自然语言理解任务中一个非常重要的任务，例如 Natural Language Inference，Paraphrase Identification，Question Answering 等都可以归属于这个任务。这个任务主要就是理解句子语义，理解句子之间的语义关系。因此如何去表示这些内容就变得十分重要了。

为了更好的利用原始特征信息，**作者参考 DenseNet，提出了一种 densely-connected co-attentive recurrent neural network 模型，该模型最突出的地方就是可以从最底层到最顶层一直保留原始信息以及利用 co-attention 得到的交互信息**。

本文将 DenseNet 的一些想法引入到了 stack RNN 中，还是可以给人一些灵感的，比如说从残差连接到 DenseNet，比如说注意力权值的使用方法，比如说利用 AutoEncoder 来压缩向量，这些还是十分值得学习的。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPmSiandh5Fo9cHRWCqGPkXlfxgDibAftxDxZGZwblzzuasBmF818rcLdg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPoGpB5BCzpUA6f7p4R8fKwy2kNkEBmFdHLPapL35vJY8xgQrhpYOWAQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPy3zPXYsKOfGxLjWibrD0cuHa3PjruUnibaPkRvA91CID9ERicm9XRFdHQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPnmXbBUWgN2l9PnBNGRZd1VrOZUHPMUDEcsKo9QOzu9se37re6aFbzg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP7wMRjsVW51EkE0picj2AZMj9XULAlTUYO08TibtWKYqmMuHibIfI6PsQA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPqHAChZSQ2MuGrm0wbQ5rWib6ibKXClOpre2M2KW3mvflX5zSLv8wDtqA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPhiacM5DoicJupozcTHiaayQg5GJME1SRS5pkPzUxAkYfMwbUCpXRwqaIQ/640)




论文链接

https://www.paperweekly.site/papers/2082







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icEknJzstkpn6Gab1EeXF5tmGG8rGM2FibNFG9O31YIc5eib0lrZ6MloxQ/640?)
**Unsupervised Neural Machine Translation with Weight Sharing**

**@paperweekly 推荐**

#Neural Machine Translation

本文是中科大发表于 ACL 2018 的工作，**论文提出对无监督机器翻译进行权重共享约束，使模型能够为每种语言使用独立的编码器**。为了实施共享潜在空间，模型还提出了嵌入增强编码器和两个不同的 GAN。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP1ibouoAHZEGEwQfI4TjShbKIZZicEDiafULeulydg9cOMLyujTiaDx44nA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPAnnA9UEyv2yt5iaKBEZ9ZCRAm6Wfia7JkffHFVNP6txok0twHfhjrEFQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgSMYpG0dHpsL63BLicQDLiaRkrqRjJicW7jwuxCceyibNibPPQrSprwsqiaw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPXSmTZRXELUICqbQXbcGLI4qFG34Cj6qu70GpzSNPAgk1YIYBbRib9oQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPYJPxdew0tVavQ9Boic2mibloby1LJIpe6icMFLTdFKTibWzB3rBltTKr3A/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPD54ob9hia7qc9I2ZTE2VgPvnIvk5ia5icwZp5rNMrvpWEmp5cCEibW48iag/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPV3ljEevBDdTFyxv5YMk3qwGVBPtHVbZSdQLQXANxtjkrc38noR2eaw/640)




论文链接

https://www.paperweekly.site/papers/2094




源码链接

https://github.com/ZhenYangIACAS/unsupervised-NMT







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0Drvm1kKqodONJWdluKYXVSiaVksJv8JyrGzSsG6O8Nt5p6aYxkA7aFuLiaQ/640)
**Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human Action Recognition**

**@zhaoqijie 推荐**

#Action Recognition

**本文来自百度，****该论文是获得 CVPR18-ActivityNet18 视频分类（行为识别）task 第一名的比赛方法描述**。作者提出了一个 Spatial-Temporal Network (STNet)，在 TSN 的基础上，深度整合空间和时间上的特征，学习出更具行为代表性的时序表征特征。

此外，本文还提出了一个多流信息整合的方案 Improved Temporal Xception Network，将 5 种不同的输入流信息整合学习，并得到 top1 accuracy = 82.4 的单模型最高精度。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPhS2e7OxBpRaQX6f1MdyY8ewicdia8RyrRF8aW57caP0I2qsIcbntbiaWw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPDYjedibHxFVkQ8Ov8uDg875Yz6gssXIiaDp4uY40h58Us1wdOunoqzVQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP0d9cMHsTKJyoCVQB7MxFzRUVwdhQRN1JRSVm10Yibxo5mMJg4QJG5KQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPtcLP4crTiaQz0r9P2nWoWeqC9E1X5htJKyicBg45ZA1rSzrANaibdheTA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPPsqTjupHKGVSs1IUMGA5xpuWo2A2pdK6lgHTejQDK3covibjLoib6p2A/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPeKo49OpsCQHYxpFYCt3ylOj4E3RPL3xXL7YdD744UibQ850BiakjUpbA/640)




论文链接

https://www.paperweekly.site/papers/2079







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvZkYxV68zOCas9csIEy9oS6Oop2huyXBUliaHFUVHicdamRgqibegicc0aA/640)
**Performance Comparison of Convolutional AutoEncoders, Generative Adversarial Networks and Super-Resolution for Image Compression**

**@TwistedW 推荐**

#Image Compression

本文来自早稻田大学，**论文用精炼的语言对比了几类图像生成模型，将卷积自编码器（CAE）、生成对抗网络（GAN）和超分辨率（SR）在生成图像性能上做了比较**。通过提取图像紧凑的特征，文章得出 CAE 比 JPEG 具有更好的编码效率，GAN 显示出在大压缩比和高主观质量重建方面的潜在优势，超分辨率在其中实现了最佳的速率失真（RD）性能，与 BPG 相当。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPdsvzjvd7FNAHPwyElaZDEHDbnmqCaPicl0AGmk1WkH5HuRUZqtFbDxA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPLrZH9mz8kEohwTkBCp183liafUJhLERSmVw1o5OjFuoTnMzoTppL6Ow/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPdhmia50Rica14VF8XYjqR5IlcNv0ebD2wibE1VZNzWJJQ7NAawQqMgpyQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPQ3JLpULapISfPLvLicfFvAh5ZJT9lDRa5Te6gp7QOEyvpIlHY1wAOGg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPCIe75wNJQwUia0FTtSJSEqKoNn0PDrQ1EM6KYxNbATE3zxx6ibM46LZg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPKP0HrzYcHAFJyf4z1rMjTLkV7iapzeBmVq4AhGuDMsfic32DSgwVbiaMQ/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPJTEqUXnMH3k0TIibIIYKUycCYC7ZyCVufwy1KemNnp9F78NyggDQpXw/640)




论文链接

https://www.paperweekly.site/papers/2085







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvibxtiaicW0ZRIwW0Kmkj9yU90UmGicL2jnnmaBY47NYicK2d7frJAcNP09w/640)
**ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing**

**@sawako 推荐**

#Image Reconstruction

本文是 KAUST 发表于 CVPR 2018 的工作，**论文研究了图像的 CS 重建问题，并且基于经典的 ISTA 提出了 ISTA-Net**。ISTA-Net 的每一层先对输出进行编码，即卷积提取特征，然后对特征进行压缩（shrinkage），最后再进行解码。与众多传统 CS 算法以及 ADMM-Net 相比，ISTA-Net 的速度最快，重建效果最好。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPO39K1YQicjy4yCQb07I6r5CHBD1eg0LibaicAbgqudn7uDGiaUicibBVibia4A/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP1BzAA4e3hjurriapvv5m163Tx4Fr5CxpWHQMaCcxg1iab4To7xy86kRw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPqttxzt9SZpq6BFztjVDtrB0iaUN6TylVpbw0Pibmk8iadM8GUTB6BiaicBA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPZ77J2Dyk1YdK0y0ypsNUmW5nYLfGaicrfploIHdJnNvcRZIVXtywkOg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPicpqP5XECWQjTJVU2v1g30kgvl0NFUib19P3nWXpI3S8Dicm6SLCE5vDA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPVbFLysJjdRv8edErlLqCcn6oeQia0ZzlgFfEVJTAPZvt6fEPAmlTibiag/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP1yMEZXpB0YhmC8rlRIbOfrPeLBqMVAeT0kIh9HibWyOKTgfcKt0wJyQ/640)




论文链接

https://www.paperweekly.site/papers/2056



源码链接

https://github.com/jianzhangcs/ISTA-Net







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvHib5D8hcewE9gwNibrGkW1TC8v83Y89RITicqLb5N3URaM1wGsGBV27qQ/640)
**CFENet: An Accurate and Efficient Single-Shot Object Detector for Autonomous Driving**

**@zhaoqijie 推荐**

#Object Detection

本文来自北京大学和阿里巴巴，**论文为自动驾驶场景提供了一种新的单步检测器，对小目标的检测做了极大的优化**。该文章是基于 SSD 改进的方法里效果最好的版本，论文方法在 CVPR 2018 的 workshop of autonomous driving（WAD) 中获得目标检测项目的第二名，结果为本方法的单模型、多尺度预测结果。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP7IvSicFvnG8DaxMmKGtqZoFV6bBrwG3Nibfc0V0XwLUCtm2LG7nYVaSg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPzsJ0ibtMN5dGOHendKqyblXMhhULQYcopFicKnVlgY8uBQa8RjhOypsw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPvFBJKWT1CAVbBIbmvuvic2x70KPTaY5sYaQHR1EtgLmOP7T4rpl05xA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPicZXwOcClNxgmz5BUWAK5dYEAh84hmqqCic08DLAgA48aENLiaDZklfkw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgrd2Y4JfH1nGBGmBxCLbJb5ftWYhCXJy0RgFZju5hzjGibpbSnwSOkQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPADDFrPiaBMnEqicfqPJPydpwC5YZQOabfvibyic6BJcuenfjaf837uL50A/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPFpHKLAQC9VwIV5yicYmQVicEpZWr25v3iaPU7r4H4tTWVE7F8EMcNkpug/640)




论文链接

https://www.paperweekly.site/papers/2070







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8tiamiceTcrbl3UY25cTHibSgtJNZnMBCOUdcpTpSLK45Ya9RC8yDZsSEw/640?)
**Eye In-painting with Exemplar Generative Adversarial Networks**

**@zhangjichao 推荐**

#Image Inpainting

本文来自 Facebook，**论文提出了一种基于 Exemplar 的人眼修复算法，除了得到高质量的修复结果，而且能够保持修复结果的身份特征。**论文提出的框架具有一定的通用性，可以被应用到其他修复问题，以及超分辨率等问题中。论文还开源了一个新的数据集来作为 benchmark。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPDXbEertIlJRg4teBYzK84KDXVEoTg0H0eGQ3QfPzB6BpNkSuqibcHGA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPq7abVYZWvetZ5Eg43n1e9GhFYIdAKWiacZensWYvvywr2KrAm9CX0Sg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPvnDEttib01PpLuQxQvtS8PWFZm2xC9W35Gvn2KI5HTI55xU1tb2qPeA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPiaZ3UuJjXZjCL7icqdR8asibqSicFafcOkM4MCxlFEHe2Iniaajrw3kHw6g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPQreq5KfalIZNVZIESRNsDE87dwclzMoeCiburwl3ENp63xD74BGEEuQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPHRre3BRGlyAaLNxU74Pgv0U54E2aRkAr43tTiaWVk31Lanc4ETicBjnA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPESV0a4vp9NboLrPiagRhNvgicHRzRD9ycjQu5TIzJa3hV5dboibBnPianQ/640)




论文链接

https://www.paperweekly.site/papers/2058



源码链接

https://github.com/bdol/exemplar_gans







![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmqMicvB9tX4H6dEJbe0TLM8IA3BMnKpHmwoB8kAc8CQC4UOSu2G0c5vFM7xpJZOcqLdFHch97tiaGg/640?)
**Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization**

**@figo 推荐**

#Deep Reinforcement Learning

本文来自小米，**论文对标 OpenAI PPO， 提出了一种与 PPO（OpenAI, Google Brain 默认强化学习算法，也是到目前最好的 RL 算法）相比均有很强竞争力的 RL 算法**。

在与 PPO 保持相同复杂度和计算量的前提下，严格按照 OpenAI 的测试评价指标，在 Atari 49 + Mujoco 7 上取得了 state of the art  的效果，且同时可以应用在离散和连续的情形。**论文开放了源代码和实验数据，这在 RL 领域，确是为数不多的开源如此彻底的论文**。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPoaHhQMPyr88RRcvDfgh333omMlqGicwDK9S5gYh3lSJmmt6QJ2YhRyA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPfa5uYvIS5W4qkvKCETp8nuNVL1VFCot6ZXxt43EDKtMjiarj33nhIEQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPxDSd7QmC4wdDnOyQrLyTvicS5esvJJS3fibwXROcNhWMnjwEX6RKPiacw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgCKlHeicOFMn1TZkeBVRzvibLJ87JBUc6wxZaqy0QbVwCCwY4PzTdFPA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP3rK0z28c7jMQhxU4d7Qe13hhRRe7BK9ibz8JzWkQb4cpLB1Jibj6HL4g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPQQd98vYEzic9FEuAfVf2hb44UDKxtx2ufMvsaAbPRfCwd2Iicts2fvKQ/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgVO19vibL1uIgEe3pbmZXCr7ZYaM9ofyBViaAxBV11ZHLVhYbARe0nOQ/640)




论文链接

https://www.paperweekly.site/papers/2091



源码链接

https://github.com/cxxgtxy/POP3D.git







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmnj5HVR9ickEOHxUiaKM0DrvSrUEOribtWtcbc5Bs8icSOWQPFxgpHLCrooqDs1LNC02qthicqiaUiaLzeg/640)
**Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation**

** @xiaolu 推荐**

#Deep Reinforcement Learning

**本文是华东师范大学发表于 SIGKDD 2018 的工作**。近几年，许多机器学习算法致力于辅助医生更好地开展工作，例如生成医疗图像报告，辅助诊断等。其中辅助医生开药（药物推荐）的研究已经有很长历史。传统药物推荐算法主要分为监督学习（SL）和强化学习（RL）。SL 通过匹配医生的药方来训练模型，RL 通过优化病人输出进行学习。**本文尝试通过融合 SL 的指示信号和 RL 的评估信号来提升药物推荐效果**。 

早期，许多研究工作通过构建专家系统来进行药物推荐。随着近年海量电子病历的涌现，一些工作利用这些大量的个性化数据，结合人工智能算法进行基于模型的药物推荐。基于模型的药物推荐算法大致分为 SL 和 RL 两类。

SL 通过减少模型输出和指示信号（医生药方）之间的差异来训练模型。但是，在真实医疗环境中好的 label 或者指示信号是不明确的。另一方面，药物推荐的根本目的是为了优化病人的输出（减少死亡率，减少肿瘤大小等），而不仅是匹配医生的药方。

第二类方法是基于 RL 的药物推荐。RL 通过最大化评估信号（reward）即病人的输出来训练模型。此外，医生的开药过程实际是一个多步决策过程，所以 RL 能更好地反应真实的医疗场景。可是，由于缺少指示信号，RL 可能输出高风险的药物。 

**Barto 曾提出指示信号和评估信号是互补的关系，基于此，我们提出一种同时融合这两种信号的模型来解决药物推荐问题**。模型融合了 DDPG 和 RNN，其中DDPG中的 Actor 由指示信号和评估信号共同训练。通过在公开电子病历 MIMIC-3 上进行实验，验证了本文模型的有效性。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPZTnU3nPbf79QwiavZicA9GElWtP3jyuJ59WwoZJkHvKrK5uIia2w483Ng/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPEuiatcNoLR5Jh32BcPQRhEOeS6z6Xr5BjOhGOOhMI9P83icaaXkldVIg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPcmdt0HpBiaAVje0oyIvSt1fB6R5nMGlS56Zja3ia9PeGu99ahibnLywwQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPGLuJpPAIv17xWWM3zMUusUqbLMibSFHia0UzYmrL7RdFkeJ0XhKibpL5Q/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPLvBMOw893bY3rlfibPfQVOUBNexhIaMTvdwdHxt85ic5CEuYGsXztlicw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPeNTk6YyrdIwIWuZz6hPYEBZMy4xFzjkntYPOnttld25WQyES8RZBAA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPcqzOQCg7fwzO6KibPTEuWwkbuia4GJphouurvGfCibibviaS85jyR9oRLug/640)




论文链接

https://www.paperweekly.site/papers/2092







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUMyCvJ7nksObSLatO1UHuTLcw5KYWPhREehBpXWY0uqseRtib5rxuvBw/640)
**On the Spectral Bias of Deep Neural Networks**

**@herb 推荐**

#Fourier Analysis

 根据前人的工作告诉我们，过参的（over-parameterized） DNN 会对简单的光滑（smooth） 函数优先拟合，也就是说更容易破获到数据的整体结构（global structure），而不是对每个样本的过拟合。这一现象对于真实数据和随机生成的数据都是会发生的。可见，DNNs 对拟合光滑数据很有倾向性（bias）。 

**本文工作并不是研究泛化性或者优化方法的表现，而是用傅里叶分析证明 DNNs 对光滑函数的内禀倾向性**。具体来说（这里默认了一个事实：越高频，越不光滑）：

1. 对于任意有限参数值 θ，DNN 中 ReLU 函数里的相应幅度，会随着频谱中的频率分量 k 以![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPH6F3iaE7Mrx17Sb692UvaiaMKB8hKX5r8ht1lFUxUBYRzHEdr2qZ5VpA/640)衰减。对于高频特征的捕获，DNN 的宽度是 polynomially 的，深度是 exponentially 。说白了，数据的高频分量在网络中贡献很小，所以体现了对光滑低频函数的倾向性（在一定的 steps 上）。这是 paper 最重要最核心的结果。

2. 于是有了理论上的推论：对于拟合拟合类 δ 函数来说，DNN 的能力就会大大受限。

3. 论文还证明了：加入 DNN 映射的是一个低微微分流形，那么 DNN 就可以充分利用流形的几何特征去近似地拟合高频特征分量。

4. 经验上证明了：对于 CIFAR-10 数据来说，所有的样本（甚至包括对抗样本）被 DNN 分类后，相同特定类别里的样本都在某种程度上存在着线性关联（用的AutoNEB）。

5. 经验上证明了：对于高频函数分量的 DNN 参数占坑较小。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP1rQsCxxL6TicRTcf27TZphicKV3QmwCKE0SVzxXdDKGicz8BwFkk1uWjQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP8DAoFn9W6iaQGefkARuFwRdIVyvQ6FVY1MrxibJg4IEy7FkttsRMF23Q/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPUHk9Xo4TjfM4zh28uYwiaibMh1icZ8Tuuk2JibWAJRA8w1YK3pzp80PbAw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPZXLGlC2bNiarIvKjPiak1QYNTDiblokbfKzvP6ibbO6naIiaibgZVF1xZiaicw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPdNXkgjeLgsbgqrJJu2lq24zTZNkc0M3wUaSics2lQOGQ14hc8U3ia2uw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP9tfEWCxAT2xxDx4h3749CmQqMFB7qT0u2XUbe8kLYEfjDJ48hhj7PA/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPvdPDiaMyM2BDlH93FCpZbbkwyLEsaXT7yA0ibdSLaSWnQw9cJYINS4YQ/640)




论文链接

https://www.paperweekly.site/papers/2080







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjiaA5bbtkAnnJ2yLicAzlwmVdnAIic0THYptctQhZJRx7QYCx8TC9zwOow/640)
**Generative Adversarial Image Synthesis with Decision Tree Latent Controller**

**@TwistedW 推荐**

#Image Synthesis

本文是 NTT 集团发表于 CVPR 2018 的工作，**文章提出了决策树潜在控制器生成对抗网络（DTLC-GAN）模型，该模型可以在不依赖详细监督的情况下学习到图像的分层解释表示**。DTLC-GAN 以层次分解的方式捕捉图像的显着语义特征，在有限的标签信息下以粗到细的方式控制图像的语义特征，实现了同一类别下不同语义特征图像的生成。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkP3wKb1Oyic4wYnfLfETyUw4KDfBxDCz6A20ZIwGmxJ10EWKiaFDFuVaVw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPXibSyOibZXoIczibLUpY5bs8ic7Mxgj9PODSbka2icmJNH0rEpZEAKC3hCQ/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgFePyuw6olwSDX5Fotoibjicy9mOU5B2gOKeyiarkricqK6P7SCEuSj7tw/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPejC5Do4yDtMHo1qOXs5hU4CKScTic3IsmYb6PeyrW2r9RSLPhgg6yKg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPXwRibFsiaiba649eEOiaSB8nlGiaEicBfKvYq2gkJgVwlCmdoWp43rGVfypg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPDyBmjyia7SmsuDZzb2258kUs1iaInZKC9n8RYQDwias0d5JfD26rtdJvg/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPgEQic9mudeetvD4F0c41CgruicCTnNqRD65wAGViaiaNYbKPbNMXiaIJmSQ/640)




论文链接

https://www.paperweekly.site/papers/2068







![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglvE3hJ6tARHlod6ez4ATnjgzGNHdv2YBVm6bUicHjY2A8tV8hwJIiapvTYDGmFIyMclC4Xy6gD7krQ/640)
**Mixed Link Networks**

**@chlr1995 推荐**

#Scaffolding Networks

**本文从拓扑结构的角度，分析了 ResNet（Eccv版本）和 DenseNet 的结构特性，并以此提出了 Dense Topology**。从 Dense Topology 出发，对层与层之间的连接方式进行了变换，主要方式有拼接（DenseNet Concatenation）和累加（ResNet Addition）两种，最终构造了一种混合 concat 和 addition的 Mixed link 结构，两种操作的数量由 k1 和 k2 两个超参数决定。最后通过实验验证了网络结构的有效性，以及超参数的稳定性。
![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPiaXYXNrXic3WoGsUcia2qn16KpCBGPicWD5lyFWANm0mDXwncUqDvdJxRg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPwkZJKrWDmia5UKnpO2N963piayVI1xlknf1229GaiaFdDy85qrqvGOSdA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPbwfwQ3lK1NTAtP4LJeKD6SFyIqB7O0uBUibHicsnzicdZ2JcYvuawwKCA/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPkBgK6T67871tw3UdzJUB0awrJ876LiaLm3E449rsLS5ED7uib2GlZMLg/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPeaoTDuNepTib6LlsoYoEFg65BvOuFI9Lm4OkRLSibVf5y2LO9ibPsu78w/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPDVxCUYgzTkxlIBDaI233XN10EBICtLMZty6Zb9d5PZYjvjzmwMKcVQ/640)
**▲**论文模型：点击查看大图




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglJ0icRa0oJTXlibZiaLcQ1FkPic25myiatYOfmLFcBlLLgGvJX9lkQzgQSJ4qRaMoaFkFoiax9XyQiaRDtQ/640)




论文链接

https://www.paperweekly.site/papers/2062







**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****推 荐 有 礼#**




本期所有入选论文的推荐人

均将获得**PaperWeekly纪念周边一份**



![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm5Wb1iaUHxx8mBh1Km3dWjfPlgYsxpxlV44icJWDVwuPorALMxCQglAC8Dx8JMeic5wHeNw29gJV8SA/640?)


![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUWQfATNyq8icodseL6gFjp8w4sQ1DBTuiaChXPEcQ0Q6tmRmz2jJjzic7g/640)![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkZibRsNMpvxCZSoNUjqBFPUk6ibiaGfmJl0icaK5go84z9iaLysegxS06wkEIrCkuL1eV2dicVoBusY4aQ/640)


**▲ **深度学习主题行李牌/卡套 + 防水贴纸




****礼物领取方式****



推荐人请根据**论文详情页底部留言**

添加小助手领取礼物




**想要赢取以上周边好礼？**

**点击阅读原文**即刻加入社区吧！




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击以下标题查看往期推荐：**




- 
[还在为周会发愁？你需要这13篇最新论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489896&idx=1&sn=f1d00402f6da8057e98ef1b2c98d694c&chksm=96e9c6e8a19e4ffef68a8bd385638ee9761d10ab4576559ce9ad3ef0e9e71d23e426051233f9&scene=21#wechat_redirect)

- 
[快醒醒，一大波最新 AI 论文加开源代码来袭！](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488566&idx=1&sn=5af3e8b73b2d71003e9af12fb04a43b7&chksm=96e9cbb6a19e42a08722cba30ca9b663d38406f23f882fb123b5802f686391510036ad0a2da0&scene=21#wechat_redirect)


- 
[15 篇最新 AI 论文来袭！NLP、CV...人人有份](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489270&idx=1&sn=4fa88468dba51738df921da45573a927&chksm=96e9c976a19e4060c20453f9cb275966ba25522292b9b638d712963edf208822686486b2cbb7&scene=21#wechat_redirect)

- 
[还在熬夜憋思路？这12篇最新论文打包送给你](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489608&idx=1&sn=1b9384cbb3550a61901521c91aa97628&chksm=96e9c7c8a19e4ede12c934b943ef2f40df220a936bafc8e50a290f1848567412abaed8f7441d&scene=21#wechat_redirect)

- 
[本](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489436&idx=1&sn=111fefd080fd4459d2a80defa94880e3&chksm=96e9c81ca19e410a975df7747ea79fc9cfba4d8fa0910112e48bf66b8f2a8520f5eafe61630f&scene=21#wechat_redirect)[顶会论文轮番炸场，本周哪些论文最值得读？](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489991&idx=1&sn=cb1203796186a2513f9ef91b0cbf16f7&chksm=96e9c647a19e4f513e46b99f41442bc88a556e43752ababceb80334f682bd27b80582f00718f&scene=21#wechat_redirect)


[](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247488603&idx=2&sn=7320cb23efba3e7b5a381be83b7fe3ad&chksm=96e9cbdba19e42cd5840d3d51e86da4709b3d5273b2cf2512c32d84ab2b42ac4e7f13bf9ba63&scene=21#wechat_redirect)




**关于PaperWeekly**




PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)

▽ 点击 | 阅读原文| 加入社区刷论文




