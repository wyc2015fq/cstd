# 图神经网络综述：模型与应用 - Paper weekly - CSDN博客





2018年12月26日 11:01:00[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：331









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgm9RFr5icmiaj0bibJxUeIGdAFHNM4G6PJEiccw293RuVnOiadQ4zcdibdJa5FFfn0ZMgpbKib4AAKD8dm2w/640)




近年来，图神经网络的研究成为深度学习领域的热点。近日，清华大学孙茂松组在 arXiv 上发布预印版综述文章 ***Graph Neural Networks: A Review of Methods and Applications***。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaCujs6y3SrRib6klUtQEH8kqCvLicJtSqjSmCufYnoRz9iaJJmE7wNUw9Q/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaITSqyH19F47auicxbJjBsAZ8gIp3yuZ9UehE9HaUqsyVTuqFvicmyRQg/640?wx_fmt=png)




**该文总结了近年来图神经网络领域的经典模型与典型应用，并提出了四个开放性问题。**对于希望快速了解这一领域的读者，不妨先从这篇文章看起。 




除了这篇综述外，文章作者在 Github 中更新了该领域的参考文章列表（https://github.com/thunlp/GNNPapers），供各位读者参考查看。




# 引言




图是一种数据结构，它对一组对象（节点）及其关系（边）进行建模。近年来，由于图结构的强大表现力，用机器学习方法分析图的研究越来越受到重视。图神经网络（GNN）是一类基于深度学习的处理图域信息的方法。由于其较好的性能和可解释性，GNN 最近已成为一种广泛应用的图分析方法。




**GNN 的第一个动机源于卷积神经网络（CNN）。**CNN 的广泛应用带来了机器学习领域的突破并开启了深度学习的新时代。然而 CNN 只能在规则的 Euclidean 数据上运行，如图像（2 维网格）和文本（1 维序列）。如何将 CNN 应用于图结构这一非欧几里德空间，成为 GNN 模型重点解决的问题。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaa1tKVtziaAT5yP4M0DdxY2VZlZwUk1p1rJmqjk7fxVcE0eeaIhrlCpA/640?wx_fmt=png)

▲ 图1. 左：图像（欧几里得空间） 右：图（非欧几里德空间）




**GNN 的另一个动机来自图嵌入（Graph Embedding），它学习图中节点、边或子图的低维向量空间表示。**DeepWalk、LINE、SDNE 等方法在网络表示学习领域取得了很大的成功。然而，这些方法在计算上较为复杂并且在大规模上的图上并不是最优的，GNN 旨在解决这些问题。




**这篇文章对图神经网络进行了广泛的总结，并做出了以下贡献：**



- 
文章详细介绍了图神经网络的经典模型。主要包括其原始模型，不同的变体和几个通用框架。



- 
文章将图神经网络的应用系统地归类为结构化场景、非结构化场景和其他场景中，并介绍了不同场景中的主要应用。



- 
本文为未来的研究提出四个未解决的问题。文章对每个问题进行了详细分析，并提出未来的研究方向。





# 模型




在模型这一部分中，文章首先介绍了最经典的图神经网络模型 GNN，具体阐述了 GNN 的模型与计算方式，然而 GNN 模型仍然存在一定的限制，比如较高的计算复杂度以及表示能力不足等等。




后续的很多工作致力于解决 GNN 存在的种种问题，在 2.2 一节中文章详细介绍了 GNN 的不同变体。具体来说，**文章分别介绍了适应于不同图类型、采用不同的信息传递方式以及采用了不同的训练方法的变体。**



![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaz5WGogtTMvP8uhEg3F0uaTT7PseUQIYcdhcvlq86SOlW9nicqVjomDQ/640?wx_fmt=png)

▲ 图2. 不同的GNN变体




在 2.2.1 节中，文章介绍了处理不同图类型的 GNN 变体，包括有向图、异质图和具有边信息的图。在 2.2.2 节中，**文章对于采用不同信息传递方式的变体进行了总结与概括。主要分为以下四个类别：**




**卷积。**Graph Convolutional Network（GCN）希望将卷积操作应用在图结构数据上，主要分为Spectral Method和Spatial Method（Non-spectral Method）两类。Spectral Method希望使用谱分解的方法，应用图的拉普拉斯矩阵分解进行节点的信息收集。Spatial Method直接使用图的拓扑结构，根据图的邻居信息进行信息收集。




**注意力机制。**Graph Attention Network 致力于将注意力机制应用在图中的信息收集阶段。




**门机制。**这些变体将门机制应用于节点更新阶段。Gated graph neural network 将 GRU 机制应用于节点更新。很多工作致力于将 LSTM 应用于不同类型的图上，根据具体情境的不同，可以分为 Tree LSTM、Graph LSTM 和 Sentence LSTM 等。



**残差连接。**注意到堆叠多层图神经网络可能引起信息平滑的问题，很多工作将残差机制应用于图神经网络中，文中介绍了 Highway GNN 和 Jump Knowledge Network 两种不同的处理方式。




文章还对于不同的信息传递方式进行了公式化总结。简单来说，**信息传递函数主要包括信息收集（agggregation）和节点信息更新（update）两个部分**，在表格中列出了每种方法的不同配置。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4ia0BRHhtVEJ79mGMHmS1rZcoqhMAdEYDBuP6wT7l2iaNKLOfgjSkpicpZQ/640?wx_fmt=png)

▲ 表1. 采用不同消息传递函数的GNN变体总结




在 2.2.3 节中，文章介绍了 GNN 的不同训练方法。譬如 GraphSAGE 从附近的邻居收集信息，并且能够应用于 inductive learning 领域；FastGCN 使用了 importance sampling 的方法，使用采样替代使用节点所有的邻居信息，加快了训练过程。 




在 2.3 节中，文章介绍了近年来文献中提出的图神经网络通用框架 MPNN（Message Passing Neural Network）、NLNN（Non-local Neural Network）以及 Deepmind 的 GN（Graph Network）。




MPNN 将模型总结为信息传递阶段和节点更新阶段，概括了多种图神经网络和图卷积神经网络方法。NLNN 总结了很多种基于自注意力机制的方法。GN 提出了更加通用的模型，能够总结概括几乎所有文中提到的框架，并且拥有更加灵活的表示能力、易于配置的块内结构以及易于组合的多模块架构。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iak6SPickqEeJLicEicydVFISJY5riaRRqMs7AH9aVibJUTQk6ibMVIxtHBBRw/640?wx_fmt=png)

▲ 图3. GN Block组合成复杂网络结构




# 应用




**GNN 被应用在众多的领域，文章具体将应用分为了结构化场景、非结构化场景以及其他三个类别。**




在结构化场景中，GNN 被广泛应用在社交网络、推荐系统、物理系统、化学分子预测、知识图谱等领域。文章中主要介绍了其在物理、化学、生物和知识图谱中的部分应用。在非结构领域，文章主要介绍了在图像和文本中的应用。在其他领域，文章介绍了图生成模型以及使用 GNN 来解决组合优化问题的场景。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4ialicEbDyguJaSWhvav1Xev3ibgXgicrjQQrTWHNdc4yx1Y13vN9xezeINg/640?wx_fmt=png)

▲ 图4. GNN的应用示例




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaMw2dD5ymsUYzMOa88NJTCs1W88ZGo96ShdicZeEuahPKG7k0eQBmBng/640?wx_fmt=png)

▲ 表2. 文章介绍的应用总结




# 开放问题




文章最后提出了图神经网络领域的四个开放问题：




**1. 浅层结构。**经验上使用更多参数的神经网络能够得到更好的实验效果，然而堆叠多层的 GNN 却会产生 over-smoothing 的问题。具体来说，堆叠层数越多，节点考虑的邻居个数也会越多，导致最终所有节点的表示会趋向于一致。




**2. 动态图。**目前大部分方法关注于在静态图上的处理，对于如何处理节点信息和边信息随着时间步动态变化的图仍是一个开放问题。




**3. 非结构化场景。**虽然很多工作应用于非结构化的场景（比如文本），然而并没有通用的方法用于处理非结构化的数据。




**4. 扩展性。**虽然已经有一些方法尝试解决这个问题，将图神经网络的方法应用于大规模数据上仍然是一个开放性问题。




截至发稿前，小编发现清华大学朱文武老师组也发布了一篇相关综述 ***Deep Learning on Graphs: A Survey***。




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4ia4zZ8WTqKkbQO3AqprVcCTWFuna1u5LUKdCwVTktOJf46uH52Y3UScg/640?wx_fmt=png)




![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgn7zY46aAqjLJkHPqmShn4iaf6H2VoUQaclfpQDc7hy6UgUBE0NeLKUENtPPm1TXqB0CFWEa5icwDVg/640?wx_fmt=png)




和本文不同，**这篇文章聚焦于图上的深度学习方法，将其分为半监督方法，无监督方法以及近期新的研究方法。**两个研究小组几乎同时发文，足见近期该领域的火热。




**小编温馨提示：两篇配合食用，效果更佳。**




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)







**点击以下标题查看更多往期内容：**




- 
[自动机器学习（AutoML）最新综述](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492654&idx=1&sn=b9047d5cca7657f02dc7f6685ef04037&chksm=96ea3baea19db2b8dc1c1267801d0c585b3cf072531af86abdeb73c6fb4c07dc3325c2d13d57&scene=21#wechat_redirect)

- 
[自然语言处理中的语言模型预训练方法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492317&idx=1&sn=e823a75d9463257ed9ea7b3e4677c1ae&chksm=96ea3d5da19db44be0872ff4e29043aa72c7a624a116196bfeeca092a15f9209d7cf8ce46eb5&scene=21#wechat_redirect)

- 
[从傅里叶分析角度解读深度学习的泛化能力](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247491082&idx=1&sn=d7c1cb39c3be43154c658ca5a791eb4c&chksm=96e9c18aa19e489c32fe36671e4208ce42bf200e3a7adeda200fa2785462d16f85c58bb455b4&scene=21#wechat_redirect)

- 
[两行代码玩转Google BERT句向量词向量](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493033&idx=1&sn=1ae1cd347126b10d6a857cd9bba7b601&chksm=96ea3a29a19db33f3c07723ed6e5ecbb8d2ff1b1617f1cf0d39cb3cc1e6e9c325cc29147d58d&scene=21#wechat_redirect)

- 
[近期知识图谱顶会论文推荐，你都读过哪几篇？](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493627&idx=1&sn=33e2f7c787fa9f14cef581f10b7dd2f7&chksm=96ea387ba19db16dc97620e28e6a7c8605b396b53f21e3eff6cf9553762a1dbc5233c580cc53&scene=21#wechat_redirect)

- 
[TensorSpace：超酷炫3D神经网络可视化框架](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247492746&idx=1&sn=921d7315a973b85dd4e802cb5fd456fb&chksm=96ea3b0aa19db21c48841ddcee38592a3c086ae8fa1a9893cf46ff974f0f38fb350bcd528265&scene=21#wechat_redirect)

- 
[深度长文：NLP的巨人肩膀（上）](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493520&idx=1&sn=2b04c009ef75291ef3d19e8fe673aa36&chksm=96ea3810a19db10621e7a661974c796e8adeffc31625a769f8db1d87ba803cd58a30d40ad7ce&scene=21#wechat_redirect)

- 
[NLP的巨人肩膀（下）：从CoVe到BERT](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247493731&idx=1&sn=51206e4ca3983548436d889590ab5347&chksm=96ea37e3a19dbef5b6db3143eb9df822915126d3d8f61fe73ddb9f8fa329d568ec79a662acb1&scene=21#wechat_redirect)











**![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/xuKyIMVqtF2cO2WSmiccOqL8YlIwp5Xv2cqdDp6ANbUt8yibCc1cgQQrPHLKhf73icQGHves57M2XMZLJxIhF0e7g/640?)****#****投 稿 通 道#**

** 让你的论文被更多人看到 **





如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？ **答案就是：你不认识的人。**




总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 




PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是**最新论文解读**，也可以是**学习心得**或**技术干货**。我们的目的只有一个，让知识真正流动起来。




📝 **来稿标准：**

• 稿件确系个人**原创作品**，来稿需注明作者个人信息（姓名+学校/工作单位+学历/职位+研究方向） 

• 如果文章并非首发，请在投稿时提醒并附上所有已发布链接 

• PaperWeekly 默认每篇文章都是首发，均会添加“原创”标志




**📬 投稿邮箱：**

• 投稿邮箱：hr@paperweekly.site

• 所有文章配图，请单独在附件中发送 

• 请留下即时联系方式（微信或手机），以便我们在编辑发布时和作者沟通










🔍




现在，在**「知乎」**也能找到我们了

进入知乎首页搜索**「PaperWeekly」**

点击**「关注」**订阅我们的专栏吧







**关于PaperWeekly**





PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgkXb8A1kiafKxib8NXiaPMU8mQvRWVBtFNic4G5b5GDD7YdwrsCAicOc8kp5tdEOU3x7ufnleSbKkiaj5Dg/640?)

▽ 点击 | 阅读原文| 获取最新论文推荐




