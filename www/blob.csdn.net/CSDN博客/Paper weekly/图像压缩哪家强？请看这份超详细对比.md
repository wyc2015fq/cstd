# 图像压缩哪家强？请看这份超详细对比 - Paper weekly - CSDN博客





2018年07月10日 13:47:34[Paper_weekly](https://me.csdn.net/c9Yv2cf9I06K2A9E)阅读数：983









![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgnC9iaic8hDbiadLafh7TtCZS6icEYddVmMqZBksDV7cQkKmAu95h53FxyibqmZOS1yQgHibJT0WYD2s1Zw/640)

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7VHx00TkzicBMAfz1dFT8icD4HwmJZpt0Jiccw6ns7c3co7MpZslIia8VAuZicUTSuoPaq6hE4KbxWPg/640?)





在碎片化阅读充斥眼球的时代，越来越少的人会去关注每篇论文背后的探索和思考。





在这个栏目里，你会快速 get 每篇精选论文的亮点和痛点，时刻紧跟 AI 前沿成果。




点击本文底部的「**阅读原文**」即刻加入社区，查看更多最新论文推荐。
这是 PaperDaily 的第 **88** 篇文章


本期推荐的论文笔记来自 PaperWeekly 社区用户 **@TwistedW**。本文来自早稻田大学，**论文用精炼的语言对比了几类图像生成模型，将卷积自编码器（CAE）、生成对抗网络（GAN）和超分辨率（SR）在生成图像性能上做了比较**。通过提取图像紧凑的特征，文章得出 CAE 比 JPEG 具有更好的编码效率，GAN 显示出在大压缩比和高主观质量重建方面的潜在优势，超分辨率在其中实现了最佳的速率失真（RD）性能，与 BPG 相当。

 如果你对本文工作感兴趣，点击底部**阅读原文**即可查看原论文。

# 关于作者：武广，合肥工业大学硕士生，研究方向为图像生成。

■ 论文 | Performance Comparison of Convolutional AutoEncoders, Generative Adversarial Networks and Super-Resolution for Image Compression

■ 链接 | https://www.paperweekly.site/papers/2085

■ 作者 | Zhengxue Cheng / Heming Sun / Masaru Takeuchi / Jiro Katto




图像压缩在计算机视觉领域占据着比较重要的位置，随着 GAN，VAE 和超分辨率图像让生成模型得到了很大的进步。不同的模型有着不同的性能优势，**本文用精炼的语言加上较为严谨的实验对比了 GAN，CAE 和 super-resolution 在图像压缩性能上的优势**。




# 论文引入




图像压缩一直是图像处理领域的一个基础和重要的研究课题。传统的图像压缩算法，如 JPEG，JPEG2000 和 BPG，依赖于手工制作的编码器。深度学习方法的发展提高了图像压缩的性能，其中比较有突破的图像压缩是在 Autoencoder，GAN 和超分辨率方面。




**这篇论文提出了三种架构，分别使用卷积自动编码器（CAE），GAN 和超分辨率（SR）进行有损图像压缩**。此外，还对它们的编码性能并进行了全面的比较。 




实验结果表明，由于 Autoencoder 可以紧凑表示特性，CAE 可以实现比 JPEG 更高的编码效率；GAN 显示出在大压缩比和高主观质量重建方面的潜在优势；超分辨率在三种方法中实现了最佳的速率失真（RD）性能。 




**总结一下论文的贡献：**



- 
基于 CAE，GAN，SR 提出了三种整体压缩体系结构 



- 
对这三种框架做了全面的性能比较





# CAE用于图像压缩




文中将图像压缩中的 DCT 和小波变换换成了 CAE（卷积自编码器），整体架构如下图所示：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPHhql3j1POBKkxqXPfTqe1IGGoErHo046lhKbBuibcD8H36hJhNqW1nQ/640)




上图比较符合传统的图像压缩的流程，不过主要的框架是在 CAE 的基础上建立的。连续的下采样操作会破坏重建图像的质量，所以 Autoencoder 采用卷积滤波器执行上下采样，**CAE 的内部结构如下图：**




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPWOFfCxnejbYdj7NEiaaH4ic2iapvVpdqsPnwG5aRPHPsjBwCMUP3iaa1pQ/640)




内部卷积层之后的激活函数采用的是参数整流线性单元（PReLU）函数，而不是相关工作中常用的 ReLU，因为我们发现 PReLU 可以与 ReLU 相比时，提高了重建图像的质量，尤其是在高比特率。整体的损失函数定义为：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPV2IEQbXg6qTfWmEsuiaJ6hibd1ssN7xYeQrN40BZKVRCFJ0Y927dSkbg/640)




其中![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPuA6IH0T918ia9EroUib3TOkr08oeLJXt9bIBHSST3icjXFP1JrsTicGFeA/640)为 MSE 损失，x 是原始图像 x̂ 是重构图像，μ 是均值噪声，fθ(x) 是 x 经过 encoder 得到的编码函数，gϕ(y) 为解码得到的解码函数。




# GAN用于图像压缩




我们都知道 GAN 多用于图像的生成，图像的压缩也需要在 GAN 的基础上做一些小小的改变，那就是在生成器前面加上一个编码器，这样就可以把图像 encode 到适合 G 生成即可，这个编码器的结构和判别器类似，GAN 做图像压缩的整体框架如下：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRP4RwnlSPk20MNzkHGEU37iccGoVeRlZiaLrqEiaicmibVopBLFOiaNetevLibg/640)




这个模型框架结构很清晰，不需要太多的解释，判别器可以提高输出图像的真实性，损失函数为：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPjFogRsMyp65zKV0ZDSBU0oFZicwAGwkvKfjsq8gVD0o5mbduCHgB1ibw/640)




这里只写非对抗损失函数部分，对抗损失函数和原始 GAN 是一致的。JG(x) 包含两部分，前半部分是 MSE 损失，后半部分是减小特征层的损失可有利于图像的高质量重建。




**基于 GAN 的体系结构与基于 CAE 的体系结构在图像压缩中有三个不同之处**。首先，直接输入 RGB 分量，因此不应用从 RGB 到 YCbCr 的色彩空间转换；其次，不在训练过程中添加统一的噪音，因为 GAN 会从噪音中继承重建图像。第三，使用范围编码器，而不是 JPEG2000 熵编码器。





# SR用于图像压缩




超分辨率压缩结构如下图所示：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPIkmTsIrpofeCHJyODeT6ApUU1uhkLqwN7b7pja9yRYnwEwopyfdsUA/640)




 对于具有复杂纹理或小分辨率的图像，SR 将成为高质量重建的瓶颈。因此，在编码器中构建重建循环且为自适应策略，该循环计算仅由 SR 引起的失真，即上图中的 Pre PSNR。




当 Pre PSNR 大于预定阈值时，图像被下采样到（0.5W，0.5H）并且在解码之后进行 SRCNN 滤波。否则，将图像下采样到（0.7W，0.7H），自适应策略的效果如下表。实验中阈值设置为 33.0 dB，并且选择约 30％ 的图像以使用 SRCNN 滤波器。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPfWMUEFGBgoP5BoVrsQmpF1bQ0kt8ubsoyvUWMTiaWuOQjdH0wQMeQDw/640)




# 性能比较




为了测量编码效率，通过每像素比特（bpp）来测量速率。PSNR（dB）和 MS-SSIM 分别用于测量客观和主观质量。




**CAE **




由于 CAE 生成的特征图不是能量紧凑的，所以还要用 PCA 进一步去相关特征图。PCA 生成的特征映射和旋转特征映射的示例如下图所示。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPwicJRzJxSDLTgzQFOMomUiaZXPULlKGpPTjCg2rbZyxzFiaRvxv1HcZlA/640)




可以看到，在右下角生成了更多的零，在旋转的特征映射中，大值居中于左上角，这有利于熵编码器降低速率。与 JPEG2000 相比，基于 CAE 的方法优于 JPEG，并且在 Kodak 数据集图像上实现了 13.7％ 的 BD 率减少。




**GAN**




GAN 的图像压缩在 CLIC 验证数据集上进行了性能比较实验：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPgU2H1SRibCI6gWUucsB6CTBVHpmQricFxBhLVrovT6lPjRuz9ibamNgZg/640)




其中 bpp 越小越好，PSNR 越大越好，MS-SSIM 越大越好！可以看出 GAN 的一定优势。 




**对比结果 **




实验在 CLIC 验证数据集进行公平评估。具有 MS-SSIM 和 PSNR 的 RD 曲线如下图。超分辨率的 RD 曲线很短，因为它是通过用 BPG 编解码器中的固定量化参数（QP） 值改变自适应策略中的阈值来进行的。通过改变 QP，超分辨率还可以实现广泛的 RD 曲线。




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRPPXxCQvYricMXufF7RMG81Kwwf5LK1XVUMutzngrRneqHzCsv0Qr0Uag/640)




**从 RD 曲线总结了几个观察结果：**




1. 由于自动编码器的固有特性，在有损压缩的情况下，CAE 优于 JPEG。自动编码器可以减少尺寸以从图像中提取压缩的演示文稿，因此 CAE 优于 JPEG 和 JPEG2000。




2. GAN 在低比特率下比在高比特率下表现更好，因此 GAN 倾向于实现大的压缩比。同时，GAN 在 MS-SSIM 上的性能优于 PSNR，因为 GAN 的重建是基于图像数据的分布，肉眼更加认同。特别是对于 MS-SSIM，GAN 具有从 0.2bpp 到 0.8bpp 的稳定性能。




3. SR 在这三种方法中实现了最佳性能，因为它具有新兴算法 BPG 和基于机器学习的超分辨率滤波器的优点。如果可以提供更多的计算资源，那么通过添加更好的超分辨率滤波器，可以预期有希望的结果将超过 BPG。




下表是在速率约为 0.15bpp 的三种方法的比较：




![640](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgkF2L3afFJyicOO3e5zJjdRP86oBYGoicgH13PNqLGtYplSpdHS9ZQzrf9cD4FXXtu3Pp58InIKbTtQ/640)




可以看出基于 SR 的方法与 BPG 非常接近，基于 GAN 和 CAE 的体系结构优于 JPEG，特别是 GAN 和 CAE 具有相似的 PSNR，但就相对主观的 MS-SSIM 而言，GAN 比 CAE 更好。



# 总结




论文提出了三种使用 CAE，GAN 和 SR 进行压缩的体系结构，并讨论了它们的性能。**结果表明：**



- 
CAE 比传统的有限压缩变换更好，并且有望用作特征提取器；



- 
GAN 显示出对大压缩比和主观质量重建的潜在优势；



- 
基于 SR 的压缩实现了其中最佳的编码性能。



**本文由 AI 学术社区 PaperWeekly 精选推荐，社区目前已覆盖自然语言处理、计算机视觉、人工智能、机器学习、数据挖掘和信息检索等研究方向，点击「阅读原文」即刻加入社区！**

![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmPEF4lW0pL5weJia5y4xhJbog2pIZZ3ZCgVUDynvus6rCzNKGAAAI6R8jaXTpYPISCMicpFegVdG0g/640?)




**点击标题查看更多论文解读：**




- 
[ACL2018高分论文：混合高斯隐向量文法](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490152&idx=1&sn=ee9c70c701d5ba74423318865ecdb44f&chksm=96e9c5e8a19e4cfeddb4d92d86415c54f511427f8851c5f22b596c68128b85512bf7a62cf729&scene=21#wechat_redirect)

- 
[基于词向量的简单模型 | ACL 2018论文解读](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490031&idx=1&sn=e307230ffbffb648b213b1a775372d06&chksm=96e9c66fa19e4f7996bb13ed2d944d5e49bd538174bd192e41abaf4d2a8863d29135b034cf9c&scene=21#wechat_redirect)

- 
[COLING 2018最佳论文：序列标注经典模型复现](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490099&idx=1&sn=2d2497999186b979dd557fe3133b7606&chksm=96e9c5b3a19e4ca550a7ae55705af84e941b1aba14cb21f3f2ffc366df837d387575f8529cf2&scene=21#wechat_redirect)

- 
[综述：图像风格化算法最全盘点](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489172&idx=1&sn=42f567fb57d2886da71a07dd16388022&chksm=96e9c914a19e40025bf88e89514d5c6f575ee94545bd5d854c01de2ca333d4738b433d37d1f5&scene=21#wechat_redirect)

- 
[CVPR 2018 最佳论文解读：探秘任务迁移学习](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247490012&idx=1&sn=a9a58fd4f1816932bb6944e7c174adb5&chksm=96e9c65ca19e4f4a6ab7d83cd6e57c2603b6d39ee08b9958b71c1aef209f7a731a0c2ee9d472&scene=21#wechat_redirect)

- 
[深度学习模型复现难？句子对模型复现论文](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247489955&idx=1&sn=cabe28465e40ba2b2bc0d1aab0c752ec&chksm=96e9c623a19e4f3526303ea05db1b1d6e9c2cf50a4815568e6c074fe76285888b6ab1a2b9b39&scene=21#wechat_redirect)








**关于PaperWeekly**



PaperWeekly 是一个推荐、解读、讨论、报道人工智能前沿论文成果的学术平台。如果你研究或从事 AI 领域，欢迎在公众号后台点击**「交流群」**，小助手将把你带入 PaperWeekly 的交流群里。




![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/VBcD02jFhgl9qrwuXS7D8F2ZLyZNmqfWibCVlSbGBVCrd80blia0iaiaKuVk5p1tWP8tCaIiaYxiaQwiacIOlu9yOw6Mg/640?)

▽ 点击 | 阅读原文| 查看原论文




