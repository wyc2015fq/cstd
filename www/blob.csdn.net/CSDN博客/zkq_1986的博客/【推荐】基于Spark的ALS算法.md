# 【推荐】基于Spark的ALS算法 - zkq_1986的博客 - CSDN博客





2017年08月30日 09:55:00[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：216








ALS(alternating least squares ):交替最小二乘法






## 1 含义




在现实中用户-物品-评分矩阵是及其大的，用户消费有限，对单个用户来说，消费的物品的非常有限的，产生的评分也是比较少的，这样就造成了用户-物品矩阵有大量的空值。 

假定用户的兴趣只受少数因素的影响，所以用户-物品矩阵可以分解为用户的特征向量矩阵和物品的特征向量矩阵（降维了）。用户的特征向量距离表示用户的兴趣(U)，物品的特征向量矩阵代表用户的特点(V)，合起来（内积）表示用户对物品的特点的兴趣，也就是喜好程度。 

M=U*V

## 2协同过滤矩阵分解算法

### 2.1奇异值分解（SVD）


矩阵的奇异值分解是最简单的一种矩阵分解算法，主要是在U*V中间加了个一个奇异值矩阵，公式如下： 

M=U*(奇异值矩阵)*(V的共轭) 

奇异值矩阵是对角矩阵，奇异值分解的缺点（没试过不知道，书上说的），1不允许分解矩阵有null值，需要进行填分，2如果填分，又有两个问题：1增加数据量，增加算法复杂度，2简单粗暴的填分方式会导致数据失真，如果将null值设置为0，那么会导致过度学习问题。 

奇异值分解方式，感觉用的不多，我自己接触的话。




**原理**

下面从文献1中取材，来讲解这个交替最小二乘法在推荐系统中应用的问题。如下图，对于一个R（观众对电影

的一个评价矩阵）可以分解为U（观众的特征矩阵）和V（电影的特征矩阵）

![](https://img-blog.csdn.net/20160523103701786)


**现在假如观众有5个人，电影有5部，那么R就是一个5*5的矩阵。假设评分如下：**

**![](https://img-blog.csdn.net/20160523110941941)**

**假设d是三个属性（性格，文化程度，兴趣爱好）那么U的矩阵如下：**



**![](https://img-blog.csdn.net/20160523112421700)**

**V的矩阵如下：**

**![](https://img-blog.csdn.net/20160523114759278)**







## 3 为什么叫“交替”





为什么是交替，从处理步骤来看就是确定V，来优化U，再来优化V，再来优化U，。。。。直到收敛

因为采用梯度下降和最小二乘都可以解决這个问题，在此不写代码来讲如何决定参数，可以看前面的最小二乘或者梯度下降[算法](http://lib.csdn.net/base/datastructure)。







