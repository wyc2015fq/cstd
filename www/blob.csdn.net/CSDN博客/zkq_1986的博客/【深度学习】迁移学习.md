# 【深度学习】迁移学习 - zkq_1986的博客 - CSDN博客





2017年09月13日 14:22:32[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：408








# **迁移学习（Transfer Learning）**

        在传统的机器学习的框架下，学习的任务就是在给定充分训练数据的基础上来学习一个分类模型；然后利用这个学习到的模型来对测试文档进行分类与预测。然而，我们看到机器学习算法在当前的Web挖掘研究中存在着一个关键的问题：一些新出现的领域中的大量训练数据非常难得到。我们看到Web应用领域的发展非常快速。大量新的领域不断涌现，从传统的新闻，到网页，到图片,再到博客、播客等等。传统的机器学习需要对每个领域都标定大量训练数据，这将会耗费大量的人力与物力。而没有大量的标注数据，会使得很多与学习相关研究与应用无法开展。其次，传统的机器学习假设训练数据与测试数据服从相同的数据分布。然而，在许多情况下，这种同分布假设并不满足。通常可能发生的情况如训练数据过期。这往往需要我们去重新标注大量的训练数据以满足我们训练的需要，但标注新数据是非常昂贵的，需要大量的人力与物力。从另外一个角度上看，如果我们有了大量的、在不同分布下的训练数据，完全丢弃这些数据也是非常浪费的。如何合理的利用这些数据就是迁移学习主要解决的问题。迁移学习可以从现有的数据中迁移知识，用来帮助将来的学习。迁移学习（Transfer
 Learning）的目标就是将从一个环境中学到的知识用来帮助新环境中的学习任务。因此，迁移学习不会像传统机器学习那样作同分布假设。举一个通俗的例子，一个会下象棋的人可以更容易的学会下围棋；一个认识桌子的人可以更加容易的认识椅子；


        在迁移学习方面的工作目前可以分为以下三个部分：同构空间下基于实例的迁移学习，同构空间下基于特征的迁移学习与异构空间下的迁移学习。基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广泛的知识迁移能力，而异构空间的迁移具有广泛的学习与扩展能力。


        迁移学习即一种学习对另一种学习的影响，它广泛地存在于知识、技能、态度和行为规范的学习中。任何一种学习都要受到学习者已有知识经验、技能、态度等的影响，只要有学习，就有迁移。迁移是学习的继续和巩固，又是提高和深化学习的条件，学习与迁移不可分割。

        对于人工智能的发展路径，很多人可能对基于大数据的人工智能很熟悉，但其实还有基于小样本的尝试和迁移，这也是人工智能的一种路径。


        数据需求量太大正是目前人工智能的一个显著缺点。拥有大数据的人毕竟是少数，这样发展下去，拥有数据越多的人，就能做出越好的人工智能产品，反过来，因为能提供更加便捷的服务，这些人又能吸引更多的用户贡献数据。如此循环，就会形成一些“数据寡头”，进而成为“人工智能寡头”。这会带来复杂的社会问题，从技术上来讲，小样本的迁移学习提供了一个缓解问题的方案，可以让初创公司在数据较少的领域也能提供人工智能的创新服务。就像深度学习必须具备大数据，而经过学习训练后的知识又很难迁移到新的领域，这也导致了计算机学习效率不高。有网友曾开玩笑，要和alphago比拼麻将，这恰恰戳中了它的软肋。alphago要学会打麻将，必须输入新的数据从头学起！迁移学习，可以让计算机把大数据领域习得的知识和方法迁移到数据不那么多的领域，这样，计算机也可以“举一反三”“触类旁通”，而不必在每个领域都依赖大数据从头学起。







 我们在迁移学习方面的工作目前可以分为以下三个部分：同构空间下基于实例的迁移学习，同构空间下基于特征的迁移学习与异构空间下的迁移学习。我们的研究指出，基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广泛的知识迁移能力，而异构空间的迁移具有广泛的学习与扩展能力。这几种方法各有千秋。


1.同构空间下基于实例的迁移学习


        基于实例的迁移学习的基本思想是，尽管辅助训练数据和源训练数据或多或少会有些不同，但是辅助训练数据中应该还是会存在一部分比较适合用来训练一个有效的分类模型，并且适应测试数据。于是，我们的目标就是从辅助训练数据中找出那些适合测试数据的实例，并将这些实例迁移到源训练数据的学习中去。在基于实例的迁移学习方面，我们推广了传统的[AdaBoost](http://apex.sjtu.edu.cn/apex_wiki/AdaBoost)算法，提出一种具有迁移能力的boosting算法：Tradaboosting
 [9]，使之具有迁移学习的能力，从而能够最大限度的利用辅助训练数据来帮助目标的分类。我们的关键想法是，利用boosting的技术来过滤掉辅助数据中那些与源训练数据最不像的数据。其中，boosting的作用是建立一种自动调整权重的机制，于是重要的辅助训练数据的权重将会增加，不重要的辅助训练数据的权重将会减小。调整权重之后，这些带权重的辅助训练数据将会作为额外的训练数据，与源训练数据一起从来提高分类模型的可靠度。


        基于实例的迁移学习只能发生在源数据与辅助数据非常相近的情况下。但是，当源数据和辅助数据差别比较大的时候，基于实例的迁移学习算法往往很难找到可以迁移的知识。但是我们发现，即便有时源数据与目标数据在实例层面上并没有共享一些公共的知识，它们可能会在特征层面上有一些交集。因此我们研究了基于特征的迁移学习，它讨论的是如何利用特征层面上公共的知识进行学习的问题。


2.同构空间下基于特征的迁移学习


        在基于特征的迁移学习研究方面，我们提出了多种学习的算法，如CoCC算法[7]，TPLSA算法[4]，谱分析算法[2]与自学习算法[3]等。其中利用互聚类算法产生一个公共的特征表示，从而帮助学习算法。我们的基本思想是使用互聚类算法同时对源数据与辅助数据进行聚类，得到一个共同的特征表示，这个新的特征表示优于只基于源数据的特征表示。通过把源数据表示在这个新的空间里，以实现迁移学习。应用这个思想，我们提出了基于特征的有监督迁移学习与基于特征的无监督迁移学习。


2.1 基于特征的有监督迁移学习


        我们在基于特征的有监督迁移学习方面的工作是基于互聚类的跨领域分类[7]，这个工作考虑的问题是：当给定一个新的、不同的领域，标注数据及其稀少时，如何利用原有领域中含有的大量标注数据进行迁移学习的问题。在基于互聚类的跨领域分类这个工作中，我们为跨领域分类问题定义了一个统一的信息论形式化公式，其中基于互聚类的分类问题的转化成对目标函数的最优化问题。在我们提出的模型中，目标函数被定义为源数据实例，公共特征空间与辅助数据实例间互信息的损失。


2.2 基于特征的无监督迁移学习：自学习聚类


        我们提出的自学习聚类算法[3]属于基于特征的无监督迁移学习方面的工作。这里我们考虑的问题是：现实中可能有标记的辅助数据都难以得到，在这种情况下如何利用大量无标记数据辅助数据进行迁移学习的问题。自学习聚类 的基本思想是通过同时对源数据与辅助数据进行聚类得到一个共同的特征表示，而这个新的特征表示由于基于大量的辅助数据，所以会优于仅基于源数据而产生的特征表示，从而对聚类产生帮助。


       上面提出的两种学习策略（基于特征的有监督迁移学习与无监督迁移学习）解决的都是源数据与辅助数据在同一特征空间内的基于特征的迁移学习问题。当源数据与辅助数据所在的特征空间中不同时，我们还研究了跨特征空间的基于特征的迁移学习，它也属于基于特征的迁移学习的一种。


３　异构空间下的迁移学习：翻译学习


        我们提出的翻译学习[1][5]致力于解决源数据与测试数据分别属于两个不同的特征空间下的情况。在[1]中，我们使用大量容易得到的标注过文本数据去帮助仅有少量标注的图像分类的问题，如上图所示。我们的方法基于使用那些用有两个视角的数据来构建沟通两个特征空间的桥梁。虽然这些多视角数据可能不一定能够用来做分类用的训练数据，但是，它们可以用来构建翻译器。通过这个翻译器，我们把近邻算法和特征翻译结合在一起，将辅助数据翻译到源数据特征空间里去，用一个统一的语言模型进行学习与分类


参考文献：

[1] http://blog.csdn.net/zyazky/article/details/51942135


[2] http://www.cnblogs.com/wentingtu/archive/2012/06/12/2546376.html



