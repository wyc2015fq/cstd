# 【机器学习】GBDT算法原理 - zkq_1986的博客 - CSDN博客





2018年04月03日 17:03:57[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：67








### GBDT算法原理

GBDT是集成学习中的一种方法，它将梯度作为后一棵树的输入，来学习出多颗树。通过多棵树的协作，完成一个泛化能力很强的综合学习器。具体的GBDT算法如下。

![](https://img-blog.csdn.net/2018040317031837)


算法：

![](https://img-blog.csdn.net/20180403170333872)


算法第1步初始化，估计使损失函数极小化的常数值，它是只有一个根节点的树。第2（a）步计算损失函数的负梯度在当前模型的值，将它作为残差的估计。对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值。第2（b）步估计回归树叶节点区域，以拟合残差的近似值。第2（c）步利用线性搜索估计叶节点区域的值，使损失函数极小化。第2（d）步更新回归树。第3步得到输出的最终模型f^(x)。

其中，c_mj为预测值。





