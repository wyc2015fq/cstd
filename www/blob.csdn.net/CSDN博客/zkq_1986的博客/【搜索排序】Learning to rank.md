# 【搜索排序】Learning to rank - zkq_1986的博客 - CSDN博客





2017年09月07日 14:45:45[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：208








Learning to rank





Learning to rank根据人工标记的查询排序评分结果，训练出一个模型，预测新的查询结果的排序。训练模型的方法包括：单文档、文档对、文档列表。

1 单文档



单文档方法的处理对象是单独的一篇文档，将文档转换为特征向量后，机器学习系统根据从训练数据中学习到的分类或者回归函数对文档打分，打分结果即是搜索结果。下面我们用一个简单的例子说明这种方法。 

       图2是人工标注的训练集合，在这个例子中，我们对于每个文档采用了3个特征： 査询与文档的Cosme相似性分值、査询词的Proximity值及页面的PageRank数值，而相关性判断是二元的，即要么相关要么不相关，当然，这里的相关性判断完全可以按照相关程度扩展为多元的，本例为了方便说明做了简化。

![](https://img-my.csdn.net/uploads/201209/18/1347946810_5795.jpg)



** 图2 训练数据**

        例子中提供了5个训练实例，每个训练实例分别标出来其对应的查询，3个特征的得分情况及相关性判断。对于机器学习系统来说，根据训练数据，需要如下的线性打分函数：
Score(Q, D)=a x CS+b x PM+cx PR+d 
        这个公式中，cs代表Cosine相似度变徽，PM代表Proximity值变量，PR代表pageRank， 而a、b、c、d则是变量对应的参数。

如果得分大于设定阀值，则叫以认为是相关的， 如果小于设定闽值则可以认为不相关。通过训练实例，可以获得最优的a、b、c、d参数组合，当这些参数确定后，机器学习系统就算学习完毕，之后即可利用这个打分函数进行相关性判断。对于某个新的查询Q和文档D，系统首先获得其文档D对应的3个特 I特征值，之后利用学习到的参数组合计算两者得分，当得分大于设定的闽值，即可判断文档是相关文档，否则判断为不相关文档。


2 文档对



判断任意两个文档组成的文档对<D0C1，D0C2>是否满足顺序关系，即判断是否D0C1应该排在DOC2的前面。图3展示了一个训练实例：査询Q1对应的搜索结果列表如何转换为文档对的形式，因为从人工标注的相关性得分可以看出，D0C2得分最高，D0C3次之，D0C1得分最低，于是我们可以按照得分大小顺序关系得到3个如图3所示的文档对，将每个文档对的文档转换为特征向量后，就形成了一个具体的训练实例。

![](https://img-my.csdn.net/uploads/201209/18/1347947868_9185.jpg)

**图3  文档对的方法训练实例**

       根据转换后的训练实例，就可以利用机器学习方法进行二分类函数的学习。




3 文档列表

依赖正确排序分布，寻找一个最优的拟合排序分布。常见的算法有ListNet。



 ListNet(Z. Cao, T. Qin, T. Liu, et al. ICML 2007)使用正确排序与预测排序的排列概率分布之间的KL距离（交叉熵）作为损失函数，等等。

        以ListNet为例，其损失函数如下：

![](https://www.52ml.net/images/82845345ce57279487ecde60e38fc5a9.jpg)

![y](https://www.52ml.net/images/226a34f1eeb1fc50f05f1d950fbdcbb2.png) 和 ![z](https://www.52ml.net/images/a5ca5ea5703a9329ddf3cc950c513629.png) 分别表示正确的排序以及预测的排序。其中，概率分布由以下公式定义：

![](https://www.52ml.net/images/4f7de29d0c25b7ad591f5e940afdb9ae.jpg)

        其中 ![s_{j}](https://www.52ml.net/images/1f3c66a6c0841d480104c195b086e03f.png) 为第j个特征向量的Score。当然这个概率分布需要满足一些性质，比如，对于更佳排序，其概率值应该更高。那么，最终损失函数就可以表示为以下形式：

![](https://www.52ml.net/images/c3e97c7877ebb5cc234812fff438719c.png)




