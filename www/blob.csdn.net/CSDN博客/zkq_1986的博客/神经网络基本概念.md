# 神经网络基本概念 - zkq_1986的博客 - CSDN博客





2016年07月30日 14:25:31[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：190








# 1 起源

McCulloch （精神病学家和解剖学家）和Pitts （数学家）在**1943年**，发表第一个系统的ANN研究——阈值加权和(M-P)数学模型。

# 2 BP算法

BP（Back Propagation）神经网络，是指误差的后向传播，修正权值矩阵，达到训练模型。 

    1） **弱点：**训练速度非常慢、局部极小点的逃离问题、算法不一定收敛。 

    2） **优点：**广泛的适应性和有效性。
## 2.1 网络的构成

![这里写图片描述](https://img-blog.csdn.net/20160730164723949)

神经元的网络输入： 


$net_i=x_1w_{1i}+x_2w_{2i}+…+x_nw_{ni}$

神经元的输出： 


$o=f(net)=\frac{1}{1+e^{-net}}$

其中： 
![这里写图片描述](https://img-blog.csdn.net/20160730165003409)

对于输出函数（激活函数active function），有以下要求： 

1） 应该将net的值尽量控制在收敛比较快的范围内 

2） 可以用其它的函数作为激活函数，只要该函数是处处可导的
实验表明，增加隐藏层的层数和隐藏层神经元个数不一定总能够提高网络精度和表达能力。 

BP网一般都选用二级网络。

## 2.2 算法的主要实现步骤

```
用不同的小伪随机数初始化W，V；
初始化精度控制参数ε；学习率α ； 
循环控制参数E=ε+1；循环最大次数M；循环次数控制参数N=0； 
while E>ε & N < M do 
    N=N+1；E=0；
    对每一个样本(X,Y)，执行如下操作  
    计算：O1=F1(XV)；O2=F2(O1W)；
    计算输出层的权修改量 for  i=1 to m
        ∆o[i]= O2 [i]*(1- O2 [i])*(Y[i]-O2 [i])；
    计算输出误差：for i=1 to m 
        E=E+(Y[i]-O2 [i])^2；
    计算隐藏层的权修改量：for i=1 to H
        Z=0；
        for j=1 to m do Z=Z+W[i,j]* ∆o[j]；
            Δh[i]=Z* O1 [i](1- O1 [i]) ；
    修改输出层权矩阵：for k=1 to H & i=1 to m
        W[k,i]= W[k,i]+ α*O1[k]*∆o[i]；
    修改隐藏层权矩阵：for k=1 to n & i=1 to H
        V[k,i]= V[k,i]+ α*X[k]* ∆h[i]；
end
```





