# L1和L2正则化 - zkq_1986的博客 - CSDN博客





2017年05月24日 14:50:39[zkq_1986](https://me.csdn.net/zkq_1986)阅读数：301
个人分类：[Machine Learning](https://blog.csdn.net/zkq_1986/article/category/6374102)









**L1和L2正则化**

L1与L2正则化都是防止模型过拟合，其方式略有不同。具体请见下文。

**1 L1正则化**

L1正则化（1范数）是指，各权值（变量、特征）绝对值之和。其作用是产生权值的稀疏模型，也就是让大部分权值为0.

为什么能产生权值稀疏模型？因为如下图所示，各权值绝对值之和后得到一个矩阵，很容易在矩阵的顶点位置使得目标函数为极值，此时大部分权值就为0。

适用场景：线性回归

![](https://img-blog.csdn.net/20170524144932311)



**2 L2正则化**

L1正则化（2范数）是指，各权值（变量、特征）平方和开根。其作用是让大部分权值接近0，防止模型过拟合。

![](https://img-blog.csdn.net/20170524144937093)

二维平面下L2正则化的函数图形是个圆，与方形相比，在权值接近0，而不是完全0时，使得目标函数为极值，这就是为什么L2正则化不具有稀疏性的原因，但又能达到防止模型过拟合。

适用场景：大部分模型










