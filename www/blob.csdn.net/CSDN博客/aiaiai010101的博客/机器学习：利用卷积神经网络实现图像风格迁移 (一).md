# 机器学习：利用卷积神经网络实现图像风格迁移 (一) - aiaiai010101的博客 - CSDN博客

2017年03月03日 21:47:37[aiaiai010101](https://me.csdn.net/aiaiai010101)阅读数：2348



相信很多人都对之前大名鼎鼎的 Prisma 早有耳闻，Prisma 能够将一张普通的图像转换成各种艺术风格的图像，今天，我们将要介绍一下Prisma 这款软件背后的[算法](http://lib.csdn.net/base/31)原理。就是发表于 2016 CVPR
 一篇文章，

“ Image Style Transfer Using Convolutional Neural Networks”

算法的流程图主要如下：

![这里写图片描述](https://img-blog.csdn.net/20170109093842637?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWF0cml4X3NwYWNl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

总得来说，就是利用一个训练好的卷积神经网络 VGG-19，这个网络在ImageNet 上已经训练过了。

给定一张风格图像 
 和一张普通图像 ，风格图像经过VGG-19
 的时候在每个卷积层会得到很多 feature maps, 这些feature maps 组成一个集合 ，同样的，普通图像
 通过 VGG-19 的时候也会得到很多 feature maps，这些feature maps 组成一个集合 ，然后生成一张随机噪声图像,
 随机噪声图像 
 通过VGG-19 的时候也会生成很多feature maps，这些 feature maps 构成集合 
 和 
 分别对应集合 
 和 ,
 最终的优化函数是希望调整 
 让 随机噪声图像 
 最后看起来既保持普通图像 
 的内容, 又有一定的风格图像 
 的风格。

#### content representation

在建立目标函数之前，我们需要先给出一些定义: 在CNN 中, 假设某一 layer 含有 
 个 filters, 那么将会生成 
 个 feature maps，每个 feature map 的维度为 
 , 
 是 feature map 的 高与宽的乘积。所以每一层 feature maps 的集合可以表示为 
 , 
 表示第 个
 filter在 position 
 上的 activation。

所以，我们可以给出 content 的 cost function:


#### style representation

为了建立风格的representation，我们先利用 Gram matrix 去表示每一层各个 feature maps 之间的关系，
 , 
 是 feature maps 
 的内积：


利用 Gram matrix，我们可以建立每一层的关于 style 的 cost :


结合所有层，可以得到总的cost 


最后将 content 和 style 的 cost 相结合，最终可以得到:


 表示权值，在建立 
 的时候，用到了 VGG-19 的 conv4_2 层，而在建立 
 的时候，用到了VGG-19 的 conv1_1, conv2_1, conv3_1, conv4_1 以及 conv5_1。 

下一篇博客里，我们将介绍基于 TensorFlow 的代码实现。

本文转自：http://blog.csdn.net/matrix_space/article/details/54286086

**个人阅读理解：**

**这里用了两个代价函数，第一个代价函数衡量我们想要的图像x与输入的普通图像p之间的内容相似程度，第二个代价函数衡量x与输入的艺术图像a之间的风格相似度。**

**内容相似程度并没有直接用两个图像之间的欧氏距离求和来表示，而是用了它们经过同一个已经训练好的神经网络(我认为整个过程中该卷积网络参数一直固定，我们并不对这些参数进行调节，我们只是调节x来最小化两个代价函数)得出的一系列特征图之间的相似度来衡量图像内容相似度，我认为这样做有助于x的平滑。基于这样一个假设：两个相似图像的高级特征也应该是相似的。反过来，两个图像的高级特征相似，那么这两个图像也应该相似，至少反映的是同一种事物。**

**图片的风格，听起来很抽象。但我们必须把这种抽象的东西量化才能进行比较，如何量化一张图片的风格，这里采用的方式：某个层中两个特征图的内积作为该层的某种风格，依次类推，如果某层有4个特征图，则应该有10种风格(4个特征图两两求内积，另外四个特征图还要各自求内积)。**

**换句话说，这里认为，风格即是两个特征之间的关系(即两个矩阵之间的关系，因为特征图即是矩阵)。这里用内积来求表达这种数量关系。**

**求内容相似度只用了比较深的一层，求风格相似度则用了每一层，我认为这是因为考虑内容相似度时倾向于全局特征(可以理解成宏观上看比较像)，所以用了比较深的某一层。而考虑风格相似度时则既考虑全局风格相似，也考虑局部风格相似。**

本文转自：http://blog.csdn.net/matrix_space/article/details/54286086


