# 流形正则化学习笔记 - zhuchengzhang的专栏 - CSDN博客





2013年12月10日 10:13:00[无声云泪](https://me.csdn.net/zhuchengzhang)阅读数：6577








     早就听说流形正则化能将有监督学习和无监督学习融合成半监督学习，听上去威武霸气，但真正一看就只能高山仰止了。今天硬着头皮学习了一下，浅浅品味往圣先哲的思维魅力。
     半监督学习（semi-supervise learning）初一听觉得很迷惑，什么是半监督学习？为什么要半监督学习？平时我们做机器学习的时候，大多数都是人为给定label的有监督学习，大家也都很向往人们毫不费力的无监督学习。但细细一想，这两类情况都有点先天缺陷的感觉，有监督学习虽然精度较高，但是人们得手工标注，太累，离人们理想中的“智能”太远；无监督学习虽然很轻松，计算机自动的就把所有工作一步到位了，但是往往精度低于人们的预期。于是乎，大牛们又开始进行哲学的思考了，如果一个婴儿（暂且把我们可爱的不懂事的计算机当成小宝宝吧）要学习一个东西，他会怎么学呢？终于有一天，善于思考的大家们发现，小婴儿会根据自己的好奇心观察探索一个东西很久，期间会有人告诉他这是什么，然后聪明的宝宝从此就学认识了这个东西。于是乎，半监督学习就应运而生了，用大量的无标签样本结合部分有标签样本进行训练。细细想来，生活中大多数情况都是如此。自从有了半监督学习，研究机器学习的人们从此进入了崭新的时代，既可以偷懒，又可以达到理想的效果。

     如何进行半监督学习型呢？在浩瀚的历史长河之中，半监督学习的方法也有很多。有兴趣的大家可以到网上搜一下。今天这里仅仅品尝一下流形正则化的美味。

     今天看的是《Manifold Regularization： A Geometric Framework for Learning from Labeled and Unlabeled Examples》，由Mikhail Belkin,Partha Niyogi,Vikas Sindhwani在2006年所做，是流形正则化的开山之作。暂且不管流形这种高深的几何概念，我们先看看文章到底做了什么。文中提出了一种将有监督数据和无监督数据结合结合起来学习的半监督学习方法，使用了一种新的正则化形式来进行这种结合。（这种方法貌似也可以将无监督学习完全转换成有监督学习，不过在这儿咱们暂且只关注加入了有监督数据的半监督学习）按照文中的说法这个正则化的作用是挖掘边缘分布的几何形状（exploit
 the geometry of marginal distribution）。这么高大上的方法，到底内部有何玄机呢？这个方法说白了就干了一件事——挖掘了数据分布的几何形状然后将其作为一个增加的正则化项。可以先有一个这样的概念，原来我们的分类器一般是有一个控制分类器复杂度的正则化项，现在按照这个方法我们增加了一个正则化项，这个正则化项就是用来控制样本分布的几何形状的。看到了这里，估计各位看官都会对他是如何融合有监督和无监督的数据来进行半监督学习有一个直观的想法了。没错，这个方法的**精髓**就是用了有监督和无监督样本共同来挖掘这一个数据分布的几何结构。说了这么多，对于只是想用流行学习方法来将有监督变成半监督学习的玩家来说已经足够了，直接在自己已有方法的目标函数后加入这一项吧（怎么加？直接Google这篇论文，里面有公式，还有解法，这儿就不多说了）。对于还想对这个方法一探究竟的勇士们，我们接着往下看。

    想一想，如果我只用有监督学习的话，在拿到较少样本的时候，只是在几类数据点间找到了一个分类面，但是这个分类面不一定是包含了数据真实的分布信息的。也就是说这样的一个分类面只是在就事论事，精度是不高的。可以看看下图，在这个图中我们只是在两个样本点中，找到了一个分类面，让你们再找一个测试样本来检验一下，这个正确率估计就和掷硬币差不多了。




![](https://img-blog.csdn.net/20131210101100375?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemh1Y2hlbmd6aGFuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)




     但是如果加入了数据分布的信息，也就是说我们只要让电脑知道我们的样本是一个什么样子的分布，而不一定要把每一个分布的点都打上标签，这样得到的分类面就比较精确了。大家看看下面这幅图




![](https://img-blog.csdn.net/20131210101132781?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemh1Y2hlbmd6aGFuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)






     再想想，这样的分布如果直接按照最开始的一刀切方法来做，能好吗？好了，又啰啰嗦嗦说了一大堆，其实想表达的意思只有一个，就是我们要是能为有监督的样本给出足够的样本分布信息，那么分类能力就可以得到提升和保证了。可能有的看官已经明白了，找出分布信息就是无监督学习最擅长做的事。换句话说，我们给无监督学习学到的分布信息帖上少量有监督的标签，这个分类工作就能漂亮的完成了。这也就是半监督学习要做的主要工作。在流形正则化中，就是通过流形正则化项来达到结合有监督和无监督样本来找出分布特征的目的。

     在流形正则化中，用到的是谱方法来表示几何信息的。这儿有个前提假设，就是我们的数据是分布于嵌入在高位空间中的低维流形之上。有了这个假设，我们就可以根据谱得到一个平滑的正则化项了。至于谱又是何方神圣了，在此咱们先打住，后面我们再慢慢揭开这层貌似神秘的面纱。




