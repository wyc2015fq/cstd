# 【面经笔记】红云融通电话二面 - xiaxzhou的博客 - CSDN博客





2017年07月30日 16:48:24[xiaxzhou](https://me.csdn.net/xiaxzhou)阅读数：244







- 问到各种深度学习的参数 ，需要了解参数的含义及在实际工程应用中大概值如

1、lr 学习率：0.0001

2、层数：VGG本身是13卷积层+3全连接层 

    取VGG的前 13层卷积层+1层全连接层 ，后面接7层反卷积层

3、batch_size,：1，每次处理一张

4、loss 损失：20000多收敛到6000

5、损失函数：

交叉熵损失函数/logistics loss

> 
[http://blog.csdn.net/lanchunhui/article/details/50970625](http://blog.csdn.net/lanchunhui/article/details/50970625)


sigmoid梯度



$-\frac{1}{n}\sum_{i=0}^n \widehat y_ilog(y_i)$

```
function [loss, delta] = loss_crossentropy_paired_sigmoid_grad(pred, output, penalty)

[h,w,c,n] = size(pred);

act = 1 ./ (1 + exp(-pred)); //sigomid

if nargin > 2,
    loss = -log(act).*output.*penalty;
    loss = sum(loss(:));
    delta = (act - output).*penalty;
else
    loss = -log(act).*output;//交叉熵
    loss = sum(loss(:));
    delta = act - output;
end
```

6、迭代次数，样本量，

7、梯度下降：

Adam = 动量更新+AdaGrad
- CUDA的优化措施有哪些

纹理内存，全局内存，共享内存，线程束，大核，小核 

还说了一个名词，忘记了叫啥，大概含义是：内存访问延迟可以被并行计算掩盖
- 解释一下OpenMP

OpenMP是一种API，用于编写可移植的多线程应用程序，无需程序员进行复杂的线程创建、同步、负载平衡和销毁工作。
- 什么是脏读，脏写



