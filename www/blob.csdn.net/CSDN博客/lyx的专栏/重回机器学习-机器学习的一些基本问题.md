# 重回机器学习-机器学习的一些基本问题 - lyx的专栏 - CSDN博客





2019年04月11日 20:12:50[钱塘小甲子](https://me.csdn.net/qtlyx)阅读数：21








## 1.样本偏差问题

        所谓样本偏差问题，以二分类问题来说，就是两个类别的样本个数存在很大的区别。比如，我们识别违约的问题，我们知道，一般违约都是小概率的，要不然放贷款的就都玩完了。那么这个时候，训练模型就会有样本偏差的问题，可能一百个样本中只有一个是违约的，如果不做处理，模型肯定更加习惯于判定不违约，因为随便来一个样本，判断不违约的准确率都是99%。

        这个问题要分情况来解决，比如如果两者的样本都很大。比如你的数据足够多，上亿级别的，那么一个亿的百分之一是百万，这个级别的数据量其实可以进行下采样。也就是丢掉不违约的样本，让两者样本平衡。

        如果发现不行，你的样本量是在是太小了，那么只能进行所谓的上采样。比如，违约样本多重复几次、如果是图片的识别，那么可以进行镜像或者旋转变换。此外，除了在样本上下功夫外，也可以改变损失函数，让损失函数对样本少的情况加大惩罚。

## 2、连续数据和离散数据

        连续数据和离散数据不是按照数据本身来看的。比如同样的变量，价格，在有些场景下可以是连续变量，有些场景下可以是离散变量。这种看起来连续的变量离散化背后的原因是非线性。

## 3、类别特征的Hash技巧

        一般用在自然语言处理上。比如一句话按照词库进行离散化，也就是变成一个很长的0、1向量。我们知道，词库中的词是有意义的，那么把一个主题的词汇放在一起，成为一个袋子，然后统计一下向量中属于这个袋子中的词汇的数目，这样就变成了一系列袋子和数目的特征了。这就是所谓的Hash技巧。

## 4、交叉验证集的作用

       交叉验证集做参数/模型选择，测试集只做模型效果评估。

其中有一个方法叫做k交叉验证，这个就是把训练集变成k份，然后每次选k-1份训练模型，剩下一份评估。然后获得k个评估结果，做均值，就获得了训练集的效果。不断变换模型，最后获得一个比较好的模型和参数。

        最后外面的测试集合则是最后用来评估模型的。但是，有一点注意，金融数据大部分都是不能用这个方法的，因为金融数据天然就不是稳态的。

## 5、模型bias和variance验证的方法

        所谓的bias就是模型的偏差，variance就是模型的方差。

![](https://img-blog.csdnimg.cn/20190411195302706.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9sdXlpeGlhby5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

        上面的横轴是样本的数量。如果随着样本的数量增加，在测试集合验证集上面的准确率是趋同的，那么这个模型就是variance比较小的。如果趋同到一个比较满意的准确度，那么这个模型是比较完美的，就像上面的右下角的图一样；如果趋同到一个较低的准确度，就像上面的左上角的图一样，这种情况就叫做有bias。那么如果训练集和测试集准确度不会收敛到一致，最后总有一个较大的准确度的差距，即使两者准确度都比较高，那么这样的情况就是有variance，就像右上角这张图这样。

        理论上，我们在进行模型训练的时候是可以把上面这样的图给绘制出来的，然后就可以知道我们的模型是一个怎么样的状态了。

## 6、过拟合和欠拟合怎么办

        过拟合则寻找更多的样本或者增大正则化系数，比如lasso就是典型的一个例子。欠拟合则可以寻找更多的特征。

## 7、bad-case分析

        模型个构建过程中，需要进行bad-case分析，也就是查看哪些样本模型搞错了，然后看看能不能从业务上来分析原因，然后修正模型。但是，金融数据又有这个问题，就是没有办法进行bad-case分析，本身就很不讲道理的金融市场，很难通过人的主观的bad-case分析来对模型有什么进步，毕竟人类自己都不知道。





