# 巴氏距离 Bhattacharyya - lyx的专栏 - CSDN博客





2015年11月03日 21:29:42[钱塘小甲子](https://me.csdn.net/qtlyx)阅读数：2489








[http://en.wikipedia.org/wiki/Bhattacharyya_coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_coefficient)

[http://blog.chinaunix.net/u2/61062/showart_1950751.html](http://blog.chinaunix.net/u2/61062/showart_1950751.html)


马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。

采用巴氏距离特征选择的迭代算法，可以获得最小错误率上界。当特征维数高时，为了减少巴氏距离特征选择计算时间，对样本先进行K-L变换，将特征降低到中间维数。然后进行巴氏距离特征选择，降低到结果的维数。用基于MNIST手写体数字库的试验表明，该文方法比单纯用巴氏距离特征选择计算时间大大减少，并比主分量方法(即单纯使用K-L变换)特征选择的错误率小得多




在统计学中，巴氏距离（巴塔恰里雅距离 / Bhattacharyya distance）用于测量两离散概率分布。它常在分类中测量类之间的可分离性。


在同一定义域X中，概率分布p和q的巴氏距离定义如下：其中（1）离散概率分布和（2）连续概率分 






BC是巴氏系数（Bhattacharyya coefficient）。




欧式距离和马氏距离和巴式距离（转）
|||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）||----||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）||----|----||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）| |||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）||----||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）|
|----|----|----|
||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）||----||欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）| |
|欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。我们熟悉的欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中，经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：①当且仅当i=j时，dij=0②dij＞0③dij＝dji（对称性）④dij≤dik＋dkj（三角不等式）显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。第i个样品与第j个样品的马氏距离dij用下式计算：dij=(xi一xj)'S-1(xi一xj)其中，xi和xj分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。马氏距离有很多优点。它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。它的缺点是夸大了变化微小的变量的作用。In [statistics](http://en.wikipedia.org/wiki/Statistics), the Bhattacharyya distance measures the similarity of two discrete [probability distributions](http://en.wikipedia.org/wiki/Probability_distribution). It is normally used to measure the separability of classes in [classification](http://en.wikipedia.org/wiki/Statistical_classification).For discrete probability distributions p and q over the same domain X, it is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png)where:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png)is the [Bhattacharyya coefficient](http://en.wikipedia.org/wiki/Bhattacharyya_distance#Bhattacharyya_coefficient). For continuous distributions, the Bhattacharyya coefficient is defined as:![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png)In either case, ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/f/1/6/f16a22527f777255955360c96549de6f.png) and ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/b/d/6/bd6f70026f3492e3b16316c04b813282.png) . *DB* need not obey the triangle inequality, but ![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/1/d/6/1d60ce798461f94203eec11516fbfd3f.png) does obey the triangle inequality.For multivariate Gaussian distributions *pi* = *N*(*mi*,*Pi*),![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png),where *mi* and *Pi* are the means and covariances of the distributions, and![巴氏距离（Bhattacharyya distance, Bhattacharyya 系数） - fhqdddddd - 流浪云南](http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png).Note that the first term in the Bhattacharyya distance is related to the Mahalanobis distance.（巴式距离和马氏距离之间的关系）| | |



