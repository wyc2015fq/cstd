# 多因子模型之因子（信号）测试平台----因子值的处理（一） - lyx的专栏 - CSDN博客





2017年08月16日 22:58:33[钱塘小甲子](https://me.csdn.net/qtlyx)阅读数：3239








在前面一节，我们成功计算出来了因子值。

在开始今天的内容前，我们要先了解几个概念。许多书本上，可能不会这样讲，这个仅仅是笔者的一些感悟。

# 0.几种factor

        先来弄清楚笔者自己总结的factor的生命周期

1）raw facto

        raw factor就是上一次我们计算出来的factor，没有什么可以更多的解释的。


2）Winsorized-raw factor

        我们知道，金融数据充满了噪音，也就是意味着，有很多异常值，所以我们要对这些股票的存货周转率值做一个处理。比如说，对于异常值，我们可以用Winsorized或者直接剔除的方法。Winsorized方法比较常用，但是也不一定有效。Winsorized方法说白了，就是让所有的raw
 factor有一个上下限，大于这个上限的，就等于上限的值，小于下限的，就等于下限值。通常，上下限可以用分位数或者标准差来体现。


3）raw z-score

        这一步其实就是factor的标准化，也就是，减去均值，然后除以标准差。相对而言好理解。把因子值都做标准化后，是为了以后很多因子可以相互combine。如果不做标准化，量纲就不一样，组合在一起就不会有什么意义。

4）neut-score

        我们做完标准化后，需要对因子值做中性化处理。包括行业中性和风格中性。

        行业中性比较简单，只要满足行业内因子值均值为0，标准差为1，也就是，行业内部再做一次标准化就可以了。而风格中性则需要和风格因子的secore，或者说，exposure做回归，然后取残差作为最后的neut-score。

这里，前面三步还是比较容易实现的，但是第四部我们需要一个风格因子的score，这就很尴尬了，因为我们并不知道有哪些风格因子。有一个神一般的存在，叫做barra，读者可以自己去百度一下。总而言之，这个数据供应商给了我们十个风格因子以及每一个因子的score（exposure）。当然，我们也可以自己去建立这个。

        这一小节，我们先尝试前面三步，后续，我们自己建立一两个风格因子来neut。

# 1.数据整合

        为了能够实现上面这些功能，我们首先要有一个把所有数据放在一起的数据集。


```python
def data_df_get(stock_file_name):
    df = pd.read_csv('./price_data/%s' % stock_file_name, index_col=0, parse_dates=True)
    df['sec_id'] = stock_file_name[:-4]
    return df

pd.concat([data_df_get(stock_file_name) for stock_file_name in univers]).to_csv('total_data.csv')
```
        然后，我们可以获得我们universe中所有股票的集合，同时加了一个sec_id字段。


![](https://img-blog.csdn.net/20170816222958240?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXRseXg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)





# 2.去极值与标准化


```python
import datetime
def winsorize_series(se):
    q = se.quantile([0.025, 0.975])
    if isinstance(q, pd.Series) and len(q) == 2:
        se[se < q.iloc[0]] = q.iloc[0]
        se[se > q.iloc[1]] = q.iloc[1]
    return se

def standardize_series(se):
    se_std = se.std()
    se_mean = se.mean()
    return (se - se_mean)/se_std

paser = lambda x: datetime.datetime.strptime(x, "%Y-%m-%d %H:%M:%S.%f").strftime('%Y-%m-%d')
all_data = pd.read_csv('total_data.csv')
all_data.rename(columns={all_data.columns[0]: 'date'}, inplace=True)
all_data['date'] = all_data['date'].apply(paser)
all_data.sort_values(['date', 'sec_id'], inplace=True)
all_data['win_secore'] = all_data.groupby('date')['raw_factor'].apply(winsorize_series)
all_data['z-score'] = all_data.groupby('date')['win_secore'].apply(standardize_series)
all_data.to_csv('total_data.csv')
```
         上面这段代码，让我们读入了刚才的total_data，然后计算出去极值后的score和标准化后的score。读者运行后，大概csv文件是下面这样的。

        当然，上面的代码中，由于要对date分组，所以，需要一些时间的操作，但都是很基础的。




![](https://img-blog.csdn.net/20170816225739636?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXRseXg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)










