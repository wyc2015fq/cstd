# 爬虫介绍及原理 - Alex_McAvoy的博客 - CSDN博客





2018年08月20日 20:35:29[Alex_McAvoy](https://me.csdn.net/u011815404)阅读数：158








# 【爬虫】

爬虫，是按照一定的规则，自动地抓取万维网信息的程序或者脚本，实质就是通过程序自动去获取 Web 页面上想要获取的数据，即自动抓取数据。

浏览器的所有结果都是由代码组成，爬虫就是为了获取这些内容，通过过滤、分析代码，从中获取我们想要的数据。

# 【基本流程】

爬虫首先通过 HTTP 库向目标站点发起请求，即发送一个 Request，等待服务器响应。

如果服务器能正常响应，则会得到一个 Response，其内容便是要获取的页面内容，类型可能是 HTML、Json 字符串等等。

如果得到的内容类型是 HTML，可以使用正则表达式，通过页面解析库进行解析；如果得到的内容类型是 Json 字符串，可以直接转换为 Json 对象进行解析。

解析后，要将数据保存，可根据需求存为文本、数据库、特定格式的文件等。

关于 HTTP 协议：[点击这里](https://blog.csdn.net/u011815404/article/details/81748842)

# 【解析方式】

为什么要解析：很多网站中的数据都是通过 js、ajax 等动态加载而成，直接通过爬虫获取的内容与浏览器显示的不同，因此需要进行解析。

解析方式大体分为以下几种：
- 直接处理
- 正则表达式处理
- Json 解析
- BeautifulSoup 解析
- PyQuery 解析
- Xpath 解析

# 【保存数据的方式】

保存数据的方式大体分为以下三种：
- 文本：保存为纯文本，Json、Xml 等
- 关系型数据库：MySQL、Oracle、SQL Server 等结构化数据库
- 非关系型数据库：MongoDB、Redis 等 key-value 形式存储



