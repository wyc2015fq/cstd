# 动态规划 —— 概率 DP 与期望 DP - Alex_McAvoy的博客 - CSDN博客





2019年04月02日 15:28:37[Alex_McAvoy](https://me.csdn.net/u011815404)阅读数：27








# 【概述】

由于概率和期望具有线性性质，使得可以在概率和期望之间建立一定的递推关系，这样就可以通过动态规划来解决一些概率问题，例如概率和期望的最值问题就常常使用概率 DP、期望 DP 来解决。

与其他的动态规划一样，合理的选择状态以及高效的状态转移方程是关键，选择合适的状态不仅可以提高效率，而且可以保证动态规划所必须的无后效性。

一般来说，**将问题直接作为状态**是最好的，当找到正确的状态定义后，转移是较容易想到的，**一般的递推即可确定转移**。

例如：n 个人做 XX 的期望次数，可以设计状态 f[i] 表示 i 个人做完事的期望。

# 【概率 DP】

概率 DP 通常已知初始的状态，然后求解最终达到目标的概率，因此概率 DP 需要顺序求解。

其相较于期望 DP较为简单，当前状态只需加上所有上一状态乘上转移概率即可，即：**f[i]=f[i-1]*p[i]**

# 【期望 DP】

期望 DP 与概率 DP 不同，其需要倒序求解。

当求解达到某一目标的期望花费时，由于最终的花费无从知晓（无法从无穷推起），因此期望 DP 需要倒序求解。

设 f[i] 为 i 状态下实现目标的期望值，即到了 f[i] 这个状态的差距是多少。

初始时，令 f[n]=0，即在目标状态期望值为 0，然后进行状态转移，新的状态为上一状态与转移概率的乘积再加上转移的花费

即：**f[i-1]=f[i]*p[i]+w**

最后初始位置 f[0] 即为所求的期望值

需要注意的是，当转移关系不成环时，期望 DP 可以进行线性递推，但当转移关系成环时，期望 DP 的最终状态相当于一个已知量，而转移关系相当于一个个方程，此时需要使用高斯消元法来解决。

# 【例题】
- Discovering Gold（LightOJ-1030）**(期望DP)**：[点击这里](https://blog.csdn.net/u011815404/article/details/88977925)
- Dice (III)（LightOJ-1248）**(期望DP)**：[点击这里](https://blog.csdn.net/u011815404/article/details/88987205)
- Just another Robbery（LightOJ-1079）**(概率DP+01背包)**：[点击这里](https://blog.csdn.net/u011815404/article/details/88980854)



