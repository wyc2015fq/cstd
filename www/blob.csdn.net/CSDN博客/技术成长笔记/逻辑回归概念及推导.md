# 逻辑回归概念及推导 - 技术成长笔记 - CSDN博客





2017年02月26日 21:29:27[zhixuhao](https://me.csdn.net/u012931582)阅读数：2063标签：[逻辑回归																[线性分类器																[预测函数																[梯度下降																[推导](https://so.csdn.net/so/search/s.do?q=推导&t=blog)
个人分类：[机器学习](https://blog.csdn.net/u012931582/article/category/6749542)





# 逻辑回归

## 逻辑回归概念

逻辑回归属于线性模型,虽然名字是回归,但是实际上是用来解决分类问题,主要是二分类问题. 

之所以叫逻辑回归,是因为预测函数用到了逻辑函数,也叫作sigmoid函数:

$g(z) = \frac{1}{1+e^{-z}}$

逻辑函数如下图所示:

![sigmoid](https://img-blog.csdn.net/20170226211921979?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

可以看出逻辑函数能够把所有输入映射到[0-1]之间. 

之所以引入逻辑函数,是因为线性回归的输出可能超出1,如果用来解决二分类问题显然是不太合适的,所以需要用逻辑函数把输入映射到[0-1]之间.

## 预测函数

构造逻辑回归模型的预测函数如下:

$h_\theta (x) = g(\theta ^{T}x) = \frac{1}{1 + e^{-\theta ^{T}x}}$

预测函数有着特殊的意义,就是结果取1的概率,因此对于输入x分类结果为1和0的概率分别为:

![gailv](https://img-blog.csdn.net/20170226212944477?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 损失函数

下面就是构造Cost函数和损失函数J,是基于最大似然估计推导的.

Cost函数和损失函数如下所示:

![cost](https://img-blog.csdn.net/20170226212716834?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

下面详细说明推导的过程：

![tuidao](https://img-blog.csdn.net/20170226213132492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 梯度下降优化过程

![youhua](https://img-blog.csdn.net/20170226213250763?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 过拟合问题

对于线性回归或逻辑回归的损失函数构成的模型，可能会有些权重很大，有些权重很小，导致过拟合（就是过分拟合了训练数据），使得模型的复杂度提高，泛化能力较差（对未知数据的预测能力）。

下面左图即为欠拟合，中图为合适的拟合，右图为过拟合。

![guonihe](https://img-blog.csdn.net/20170226213553509?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjkzMTU4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

问题的主因

过拟合问题往往源自过多的特征。

解决方法

1）减少特征数量（减少特征会失去一些信息，即使特征选的很好）

```
可用人工选择要保留的特征；
模型选择算法；
```

2）正则化（特征较多时比较有效）

```
保留所有特征，但减少θ的大小
```

正则化方法

正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化项就越大。

## 多分类问题

对于多类分类问题，可以将其看做成二类分类问题：保留其中的一类，剩下的作为另一类。

对于每一个类 i 训练一个逻辑回归模型的分类器$h_{\theta}^{(i)}(x)$，并且预测y = i时的概率；对于一个新的输入变量x, 分别对每一个类进行预测，取概率最大的那个类作为分类结果.](https://so.csdn.net/so/search/s.do?q=梯度下降&t=blog)](https://so.csdn.net/so/search/s.do?q=预测函数&t=blog)](https://so.csdn.net/so/search/s.do?q=线性分类器&t=blog)](https://so.csdn.net/so/search/s.do?q=逻辑回归&t=blog)




