# PCA降维求特征值的原因 - 苝花向暖丨楠枝向寒 - CSDN博客

2019年01月20日 17:44:38[苝花向暖丨楠枝向寒](https://me.csdn.net/weixin_40247263)阅读数：65


我看了几篇文章，知道了PCA降维思路，但始终不能理解，为什么通过求其特征值，然后去掉较小的特征值，再根据特征值求出特征向量最终能达到降维的目的。 如果你有相同的困惑，看下面的内容一定会有帮助。

看之前你需要了解协方差矩阵。了解特征值的求解方式。

# PCA做的事情：

**去噪声和冗余**

**噪声**: 样本中某个主要维度A，能够代表原始数据，但是由于维度A与其他维度有联系，而其他维度又给我们造成干扰，此时可以通过PCA处理，使维度A与其他维度的相关性减弱。
**冗余**：冗余就是有一些没有用的维度，这些维度在所有样本上变化不明显，即通过它对区分不同样本不起作用。就可以通过PCA去掉这些维度。

**PCA降维过程**：

首先我们拿到样本数据求出其协方差矩阵(网上很多，不具体写了)，协方差矩阵的对角线上是方差，非对角线元素是协方差。我们应使协方差尽可能小(因为协方差代表维度之间的相关性，去噪声就是使其相关性变的尽可能小)，应使方差尽可能大(因为方差大说明该维度在不同样本中的变化大，能体现出样本的特点)。要达到这个目的实际上就是将协方差矩阵的非对角线元素(协方差)全变为0(协方差为0意味着维度之间没有联系)。即转换成一个对角矩阵，此时该矩阵的对角线上的元素被称为特征值(也是各个维度上的新的方差)。对角线上较小的新方差就是去掉该去掉的维度，根据特征值求出来的其对应的特征向量就是该样本的新的坐标系。

