# 大数据学习笔记(十六)-- 完全分布式版 - 苝花向暖丨楠枝向寒 - CSDN博客

2018年10月10日 23:46:15[苝花向暖丨楠枝向寒](https://me.csdn.net/weixin_40247263)阅读数：31标签：[完全分布式HDFS搭建](https://so.csdn.net/so/search/s.do?q=完全分布式HDFS搭建&t=blog)
个人分类：[大数据](https://blog.csdn.net/weixin_40247263/article/category/8073779)



**本博客是基于 伪分布式版继续搭建的，所以如果想跟着本篇博客进行搭建的话，必须先按照我上一篇博客搭建好伪分布式版**，**详情可参考**[这里](https://blog.csdn.net/weixin_40247263/article/details/82897698)

节点配置如下 
||NN|SNN|DN|
|----|----|----|----|
|node001|*|||
|node002||*|*|
|node003|||*|
|node004|||*|



**正题**

首先统一每个节点的系统时间，date -s "2018-10-10 21:18:00"。

分别在每个节点里安装好jdk

分别在每一个节点中  执行   ssh localhost   ， 目的是在 ~ 目录下 生成 .ssh 文件

回到node001 

```bash
[root@node001 /]# cd ~/.ssh/
[root@node001 .ssh]# scp id_dsa.pub root@node002:`pwd`/node001.pub
```

切换到node002

```bash
[root@node002 .ssh]# cat node001.pub >> authorized_keys
```

回到node001 测试免密登录

```bash
[root@node001 .ssh]# ssh node002
Last login: Wed Oct 10 21:25:40 2018 from localhost
```

继续对node003 和 node004 进行免密设置

```bash
[root@node001 .ssh]# scp id_dsa.pub root@node003:`pwd`/node001.pub
[root@node001 .ssh]# scp id_dsa.pub root@node004:`pwd`/node001.pub
```

分别在 node003和node004 执行如下命令，注意要在.ssh 目录下

```bash
[root@node003 .ssh]# cat node001.pub >> authorized_keys
[root@node004 .ssh]# cat node001.pub >> authorized_keys
```

返回node001进行测试

```bash
[root@node003 ~]# logout
Connection to node003 closed.
[root@node001 .ssh]# ssh node004
Last login: Wed Oct 10 21:54:13 2018 from localhost
[root@node004 ~]# logout
Connection to node004 closed.
```

将node001 在搭建伪分布式版时 配置过的profile文件 拷贝到 其它节点下，然后分别执行

```bash
[root@node001 .ssh]# scp /etc/profile node002:/etc
profile                                                100% 1953     1.9KB/s   00:00    
[root@node001 .ssh]# scp /etc/profile node003:/etc
profile                                                100% 1953     1.9KB/s   00:00    
[root@node001 .ssh]# scp /etc/profile node004:/etc
profile                                                100% 1953     1.9KB/s   00:00
```

```bash
. /etc/profile
```

进入 hadoop 根目录的上一层目录，然后将hadoop做一份备份，备份的是伪分布式版本配置的信息

```bash
[root@node001 hadoop]# cd /opt/hadoop
[root@node001 hadoop]# cp -r hadoop-2.6.5 hadoop-local
```

修改hadoop配置文件

先指定 namenode ， 需要修改 NN 源文件所存放的目录，目的是不与之前的伪分布式版冲突

```bash
[root@node001 hadoop]# cd /opt/hadoop/hadoop-2.6.5/etc/hadoop
[root@node001 hadoop]# vi core-site.xml
```

 更改配置如下

```bash
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node001:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/zzh/hadoop/full</value>
    </property>
</configuration>
```

再指定DN(datenode)

```bash
[root@node001 hadoop]# vi slaves 
[root@node001 hadoop]# cat slaves 
node002
node003
node004
```

再指定SNN(secondnamenode)

```bash
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>2</value>         # 这里有3个副本，但为了看效果设置成了2个
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node002:50090</value>  # 这里代表 SNN 所在节点，端口号固定的
    </property>
</configuration>
```

将node001 /opt/hadoop目录拷贝到其他节点的opt目录下

```bash
[root@node001 opt]# scp -r hadoop node002:`pwd`
[root@node001 opt]# scp -r hadoop node003:`pwd`
[root@node001 opt]# scp -r hadoop node004:`pwd`
```

hadoop目录中的内容如下 

```bash
[root@node001 opt]# cd hadoop/
[root@node001 hadoop]# ll
total 8
drwxrwxr-x. 10 1000 1000 4096 Sep 30 05:37 hadoop-2.6.5
drwxr-xr-x. 10 root root 4096 Oct 10 22:32 hadoop-local
```

即备份伪分布式版的hadoop和刚刚配置的

回到node001 进行格式化

```bash
[root@node001 opt]# hdfs namenode -format
```

启动服务 

```bash
[root@node001 hadoop]# start-dfs.sh
```

然后分别在每一个节点进行验证

```bash
[root@node001 hadoop]# jps
5506 Jps
5289 NameNode
[root@node002 linux-basic]# jps
1700 Jps
1578 DataNode
1662 SecondaryNameNode
[root@node003 linux-basic]# jps
1623 Jps
1554 DataNode
[root@node004 linux-basic]# jps
1612 Jps
1543 DataNode
```

测试

输入   [http://node001的ip:50070](http://192.168.46.21:50070)

页面下拉有个live node ，点进去可以看到 节点信息

![](https://img-blog.csdn.net/20181010233244568?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDI0NzI2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

页面最上面的导航栏最后一个Utilities 中有一个 Browes the file system 可以查看目录下所上传的文件，刚启动的服务所以没有目录

通过hdfs dfs -mkdir -p 目录名   创建目录，

通过

 hdfs dfs -put 文件名 目录名    上传文件

更多的相关命令 上网搜素


