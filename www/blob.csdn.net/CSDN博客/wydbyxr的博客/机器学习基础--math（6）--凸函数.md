# 机器学习基础--math（6）--凸函数 - wydbyxr的博客 - CSDN博客
2018年06月20日 15:35:02[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：79
# 凸函数 (convex function)
　　一种函数，函数图像以上的区域为凸集。典型凸函数的形状类似于字母U。 严格凸函数只有一个局部最低点，该点也是全局最低点。经典的 U 形函数都是严格凸函数。不过，有些凸函数（例如直线）则不是这样。 
　　例如很多常见的损失函数（包括下列函数）都是凸函数：L2 损失函数、对数损失函数、L1 正则化、L2 正则化。 
　　两个凸函数的和（例如 L2 损失函数 + L1 正则化）也是凸函数。
### 与DL的关系，梯度下降
　　梯度下降法的很多变体都一定能找到一个接近严格凸函数最小值的点。同样，随机梯度下降法的很多变体都有很高的可能性能够找到接近严格凸函数最小值的点（但并非一定能找到）。 
　　深度模型绝不会是凸函数。值得注意的是，专门针对凸优化设计的算法往往总能在深度网络上找到非常好的解决方案，虽然这些解决方案并不一定对应于全局最小值。
# 凸优化 (convex optimization)
　　使用数学方法（例如梯度下降法）寻找凸函数最小值的过程。机器学习方面的大量研究都是专注于如何通过公式将各种问题表示成凸优化问题，以及如何更高效地解决这些问题。        
# 凸集 (convex set)
　　欧几里得空间的一个子集，其中任意两点之间的连线仍完全落在该子集内。     
