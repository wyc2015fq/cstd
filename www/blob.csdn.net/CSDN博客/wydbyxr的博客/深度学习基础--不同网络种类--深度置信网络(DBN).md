# 深度学习基础--不同网络种类--深度置信网络(DBN) - wydbyxr的博客 - CSDN博客
2018年11月09日 10:45:50[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：418
# 深度置信网络(DBN)
  RBM的作用就是用来生成似然分布的互补先验分布，使得其后验分布具有因子形式。
  因此，DBN算法解决了Wake-Sleep算法表示分布难以匹配生成分布的难题，通过RBM使得训练数据的生成分布具有因子形式，从而提高了学习效率。
  深度置信网络（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。
## 应用领域
  通常，DBN主要用于对一维数据的建模比较有效，例如语音。而通过级联多层卷积网络组成深度网络的模型主要用于二维数据，例如图像等。
  基于深度信念网络的资源检索与推荐系统
  之前微软的语音识别就是基于DBN
## 研究现状
  1）CNN和RNN流行之后就很少有人用DBN和SAE了。那么DBN和SAE真的过时了吗？
  答：DBN之流，在理论上还有人在做，但是从效果看好像用处不大。
  DBN与RBM在训练数据量变的越来越大之后，到现在，所有的深度学习这一块基本上都不用当时所用的 RBM/DBN pretraining的方法。为了保证我们这么做是有比较好的理论根据，我们当时还做了非常强的分析，从理论上看出来大数据确实可以不需要那么复杂的pretraining。
  你们看文献的时候，你们要注意在2012年之前的文献常常把DBN和DNN混合在一起。我们微软同多伦多大学在2012年合写的文章中其实才把DBN和DNN正确地分开。"
  2）pretraining除了在DBN和SAE这两个模型中用，是不是几乎没用处了（比如CNN/RNN中会用pre training吗）？
  答：有预训练才能利用大量没有标籤的资料集作半监督学习, 防止只有少数标籤的资料集过拟合或拟合不足。
  stacked denoised autoencoder (SDA)，和DBN类似，都是使用无监督的网络“堆叠”起来的，他有分层预训练来寻找更好的参数，最后使用BP来微调网络。
  比dnn利用各种算法来初始化权值矩阵，从经验上来看是有帮助的。但是缺点也很明显，每层的贪婪学习权值矩阵，也带来了过长的训练时间。在大量的数据面前 dnn(relu)的效果已经不差于预训练的深度学习结构了。
  最终DBN也是看成是“生成模型”。CNN 也没有pre-train过程，训练算法也是用BP。
  因为加入卷积 可以更好的处理2D数据，例如图像和语音。并且目前看来 相比其它网络有更好的表现。dnn/dbn/sda 等都是处理1D的数据。
## DBN与CNN两者异同
  1）同：无论是DBN还是CNN，这种多隐层堆叠，每层对上一层的输出进行处理的机制，可看作是在对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不大的输入表示，转化成与输出目标联系密切的表示。即：通过多层处理，逐渐将初始的低层特征表示转化成高层的特征表示后，用“简单模型”就可以完成复杂的分类等学习任务。
  2）异：网络结构和训练过程不同。
  DBN：全连接，有pre-train过程；
  CNN：局部连接，没有预训练过程，但加了卷积。
