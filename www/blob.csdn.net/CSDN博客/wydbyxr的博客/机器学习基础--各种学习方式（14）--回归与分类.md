# 机器学习基础--各种学习方式（14）--回归与分类 - wydbyxr的博客 - CSDN博客
2018年07月14日 21:24:43[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：120
个人分类：[机器学习基础](https://blog.csdn.net/wydbyxr/article/category/7151096)
# 回归与分类
　　回归和分类的区别：总的来说两个问题本质上都是一致的，就是模型的拟合（匹配）。 
　　分类指的是预测值是有限个离散值的情况；而回归指的是预测值是连续值的情况。
### 使用流程
　　线性回归和分类问题都有以下几个步骤, 
1）如何选取一个合理的模型(线性的，or 非线性的(e.g. 阶跃函数， 高斯函数)). 
2）制造一个”“美好”“的误差函数 (可以评估拟合程度，而且还是convex函数)； 
3）采取一切可能的技术(e.g. 导数下降法，解极值方程法) 求出最好的模型参数。
### 使用分类还是回归？
　　回归问题一般都可以转换成为分类问题，另外分类问题一般更简单，效果更好，但也损失了更多的信息。 
　　一般在下面情况下，会将回归转换成分类： 
　　1）数据限制太大(数据量少),做回归的效果很差； 
　　2）对精度的要求较低。例如：做股票预测不需要知道跌多少或者涨多少，只需要知道跌或者涨就可以了，这样就转换成了二分类问题。
### 分类
　　多标签分类：预测非互斥分类的任务 
　　想象一下，人们可能会把多个标签同时标注在自己的某篇技术类博客文章上，例如“机器学习”、“科技”、“编程语言”、“云计算”、“安全与隐私”和“AWS”。 
　　这里面的标签其实有时候相互关联，比如“云计算”和“安全与隐私”。当一篇文章可能被标注的数量很大时，人力标注就显得很吃力。这就需要使用机器学习了。
### 回归（Regression）
　　回归是在自变量和需要预测的变量之间构建一个模型，并使用迭代的方法逐渐降低预测值和真实值之间的误差。回归方法是统计机器学习的一种。 
　　常用的回归算法如下：
> 
决策林回归 
  神经网络回归 
  贝叶斯回归 
  Ordinary Least Squares（最小二乘法） 
  Logistic Regression（逻辑斯底回归） 
  Stepwise Regression（逐步回归） 
  Multivariate Adaptive Regression Splines（多元自适应回归样条法）  
  Locally Estimated Scatterplot Smoothing（局部加权散点平滑法）
