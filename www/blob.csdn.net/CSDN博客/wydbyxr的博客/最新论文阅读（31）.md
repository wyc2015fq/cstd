# 最新论文阅读（31） - wydbyxr的博客 - CSDN博客
2018年06月10日 20:57:27[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：287
# L1-Norm Batch Normalization for Efficient Training of Deep Neural Networks
```
- 2018年2月   
- L1-BN
- 中国人
```
　　BN中的平方和根运算对低比特量化不友好。 
　　我们提出在训练期中只有线性运算的L1范数BN（L1BN）。L1-BN被证明与原始的BN乘以比例因子(π/2的根号)近似相等。 
　　对各种CNN和GAN的实验表明，与L2BN相比，L1BN保持几乎相同的准确度和收敛速度，但具有更高的计算效率。 
　　在FPGA平台上，L1BN的提议符号和绝对操作可以达到1.5×与原始昂贵的平方和根操作相比，加速并节省50％的功耗。这种硬件友好的标准化方法不仅在速度上超过L2BN，而且还简化了ASIC加速器的硬件设计，并且能源效率更高。 
　　最后，L1BN承诺对DNN进行全量化培训，这对于未来的自适应终端设备至关重要。
# HENet: A Highly Efficient Convolutional Neural Networks Optimized for Accuracy, Speed and Storage
```
- 2018年3月
- 高效的HENet
- 上海大学
```
　　在对ResNet，DenseNet，ShuffleNet等CNN体系结构进行分析的基础上，提出了一种非常有效的高效网络模型（HENet）。 
　　新的架构采用了一种不寻常的方式将ShuffleNet中提到的群组卷积和通道混洗相结合。受ResNet和DenseNet的启发，我们还提出了一种新的方法，使用每个块的元素方式添加和串联连接。为了更好地使用功能映射，汇集操作从HENet中移除。 
　　实验表明，我们模型的效率比许多开源数据集上的ShuffleNet高出1倍以上。
# Invisible Mask: Practical Attacks on Face Recognition with Infrared
```
- 2018年3月
- 第一个揭示红外对抗人脸识别能造成的威胁的严重性。
- 复旦大学；CUHK；阿里
```
　　从论文的实验来看，就是一道光打在人脸上，然后NN就识别不出来了。当公共安全严重依赖这种人脸识别系统时，设计人员应该有意识地考虑新出现的攻击。 
　　我们提出了一种针对人脸识别系统的全新攻击方法，该方法利用红外线照射对象来实现，因此人脸识别系统可以被忽略或误导，同时不能观察到红外扰动由原始的眼睛。 
　　通过发起这种攻击，攻击者不仅可以躲避监视摄像机。更重要的是，如果只有受害者的照片被攻击者获取，他可以冒充他的目标受害者并通过脸部认证系统。而且，攻击是完全不可见的附近的人，因为不仅光是看不见的，而且我们发起攻击的设备足够小。 
　　根据我们对大数据集的研究，攻击者有很高的成功率，以超过70％的成功率找到这样一个可以通过红外线实施的对抗性例子。
# Incremental Training of Deep Convolutional Neural Networks
```
- 2018年3月   
- 一种增量训练方法
- IBM
```
　　一种增量训练方法，将原始网络划分为子网络，然后在训练过程中逐渐将其纳入运行网络。 
　　为了实现网络的平稳动态增长，我们引入了一个超前的初始化，它优于随机初始化。 
　　在ResNet和VGGNet上报告CIFAR-10的训练的结果。
# A Quantization-Friendly Separable Convolution for MobileNets
```
- 2018年3月
- 改进mobilenet的可分离(separable)卷积，这种卷积是量化友好
- 加拿大高通
```
　　MobileNetV1虽然通过可分离(separable)卷积成功降低了参数大小和计算延迟，但我们的实验显示其量化模型与浮点模型相比具有较大的精度差距。为了解决这个问题，我们分析了量化损失的根本原因并提出了一种量化友好的可分离卷积结构。
# Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks
```
- 2018年5月
- 防御后门攻击，使用pruning和fineturn
- 纽约大学
```
　　DNN训练需要很大的计算资源并且通常会外包给第三方。但给外包进行训练会引入了一种风险，即恶意培训师会返回一个后备DNN，该DNN在大多数输入上行为正常，但当仅存在攻击者知道的触发器时会导致目标错误分类或降低网络的准确性。 
　　在本文中，我们提供了第一个针对DNN后门攻击的有效防御措施。防御的方法是修剪和微调。 
　　实验表明它成功地削弱甚至消除了后门，即在某些情况下将攻击成功率降低到0％，而干净（非触发）输入的精确度仅下降0.4％ 。我们的工作为防御深度神经网络中的后门攻击提供了第一步。
# Retraining-Based Iterative Weight Quantization for Deep Neural Networks
```
- 2018年5月
- 量化；pruning
- 三星研究院
```
　　在这项工作中，我们引入了迭代技术来应用量化，呈现高压缩比，而不对训练算法做任何修改。 
　　在所提出的技术中，重量量化之后是以全精度重量重新训练模型。我们表明，迭代再训练产生新的权重集合，可以在每次迭代时减少量化损失量化。我们还表明，量化能够有效地利用修剪。还讨论了结合这两种方法的实施问题。 
　　我们的实验结果表明，使用1比特量化权重的LSTM模型足够用于PTB数据集而没有任何精度下降，而先前的方法需要至少2-4个比特用于量化权重。
