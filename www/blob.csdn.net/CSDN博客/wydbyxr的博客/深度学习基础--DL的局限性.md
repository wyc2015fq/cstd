# 深度学习基础--DL的局限性 - wydbyxr的博客 - CSDN博客
2018年11月07日 10:02:41[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：78
# DL的局限性
  1）当数据量偏少，效果不好
  2）数据不具有局部相关特性。
  而对于不具有局部相关特性的数据，没法用特点的网络拓扑来捕捉了他的信息，在深度学习中就只能用 MLP 来完成模型的训练，而 MLP 的效果，一般要弱于 GDBT，RandomForest 等传统模型。
  3）从输入到输出的几何变化大必须光滑且连续。
  在深度学习中，所有的东西都可以矢量化，所有的东西都是几何空间中的一个点。模型的输入和输出首先被矢量化，被转换到输入矢量空间和目标矢量空间中去。网络中的每一层都对通过它的数据进行简单的几何变化。而模型中的不同层链接起来便构成的复杂的几何变化，将这一复杂的变换简化成一系列简单操作的组合变构成了深度学习的过程。
  这一复杂的变换操作试图将输入空间映射到目标空间去。利用参数化的层间权重来实现之一变换，同时基于模型的表现来迭代地更新这些参数的取值。
  这意味着深度学习需要遵循一个十分重要的约束条件，从输入到输出的几何变化大必须光滑且连续。
  目前，深度学习还不能自然处理层级结构。乔姆斯基不断地强调，语言有着层级结构，大的结构部件是由小部件递归构成的。但是，当前大多数基于深度学习的语言模型都将句子视为词的序列。在遇到陌生的句子结构时，循环神经网络（RNN）无法系统地展示、扩展句子的递归结构。这种情况在其他需要复杂层级结构的领域也是一样，比如规划和电机控制。而深度学习学到的各组特征之间的关联是平面的，没有层级关系，是一个核心问题。
  4）任何需要推理（类似编程）或者是需要科学方法（例如长期规划，算法类的数据操作等）相关的工作，都已经超出了目前深度学习技术的能力范畴。
  举个很实际的例子，你可能能创建一个产品经理对于软件描述的巨量文本库，同时也拥有一大堆工程师为了满足这些产品要求的巨量代码，但是即使在这样的条件下，你也不能训练出一个神经网络来阅读产品需求，随后就能够生成合适的代码和软件。
  这仅仅是其中的一个例子，普遍意义上来说，任何需要推理（类似编程）或者是需要科学方法（例如长期规划，算法类的数据操作等）相关的工作，都已经超出了目前深度学习技术的能力范畴，无论多少的数据都无法实现完成的工作。甚至利用深度学习去学习一个简单的排序算法都是十分复杂和困难的工作。
  深度学习的能力受到模型所能表示范围的限制，同时还受限于所希望学习的内容不能表示为数据流形到目标空间的连续的几何变换！
  5）深度学习模型只具有"局域泛化"的能力，同时只能处理与训练数据非常相近的新情况，而人类则拥有"极致的泛化"能力，能迅速适应完全不同的状况，同时能为长期状况作出有效的安排。
  6）“可解释性”差
  "机器学习系统通常具有较低的“可解释性”，这意味着人类很难弄清楚系统是如何做出决定的。具有讽刺意味的是，即使我们已经开始克服Polanyi的悖论，我们也面临着另一个版本：机器知道的比它们能告诉我们的更多。
  最后一个甚至仍有可能被低估的好消息是，有效使用机器学习算法所需要的数据可能没有你想象的那么多。
  首先，机器可能有隐藏的偏见，不是来自设计者的任何意图，而是来自提供给系统的数据。举个例子，如果一个系统了解到哪些求职者在面试中使用了过去招聘人员所做的一系列决定来接受面试，那么它可能会无意中学会将他们的种族、性别、种族或其他偏见延续下去。
  第二个风险是，与传统的基于显式逻辑规则的系统不同，神经网络系统处理的是统计学上的真理，而不是真实的事实。尤其是在没有在培训数据中表示的情况下工作很难，甚至不可能。缺乏可验证性对于任务型的应用场景是一个问题，例如控制核电站，或者涉及生死抉择。
  第三，当机器学习系统确实出现错误时，几乎不可避免地会出现错误诊断和纠正错误。导致解决方案的底层结构可能是难以想象的复杂，如果系统被培训的条件发生变化，那么解决方案可能会远远不够理想。
  7）和以前的机器学习方法相比，DNN的劣势：
  在分类时容易受到对抗样例（adversarial examples）的影响；
  在强化学习中容易出现灾难性遗忘（catastrophic forgetting）；
  在生成建模中容易发生模式崩溃（mode collapse）。
