# 朴素贝叶斯（Naive Bayes）分类和Gaussian naive Bayes - wydbyxr的博客 - CSDN博客
2018年10月22日 13:25:38[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：502
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 朴素贝叶斯（Naive Bayes）
  参考资料：[https://www.cnblogs.com/pinard/p/6069267.html](https://www.cnblogs.com/pinard/p/6069267.html)
  朴素贝叶斯最关键的就是 （强制认为每种指标都是独立的）。
  不同于其它分类器，朴素贝叶斯是一种基于概率理论的分类算法；总体上来说，朴素贝叶斯原理和实现都比较简单，学习和预测的效率都很高，是一种经典而常用的分类算法。朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。其中 naive（朴素）是指的对于模型中各个 feature（特征） 有强独立性的假设，并未将 feature 间的相关性纳入考虑中。
## 基本概念
  朴素贝叶斯分类器基于一个简单的假定：给定目标值时属性之间相互条件独立。
  朴素贝叶斯是生成方法，也就是直接找出特征输出Y和特征X的联合分布P(X,Y)P(X,Y),然后用P(Y|X)=P(X,Y)/P(X)P(Y|X)=P(X,Y)/P(X)得出。
## 优点
  1） 算法逻辑简单,易于实现（算法思路很简单，只要使用贝叶斯公式转化医学即可！）
  2）分类过程中时空开销小（假设特征相互独立，只会涉及到二维存储）,朴素贝叶斯很快。
## 缺点：
  朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。
  而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。
## 具体使用
  1）特征之间的条件独立性假设，显然这种假设显得“粗鲁”而不符合实际，这也是名称中“朴素”的由来。然而事实证明，朴素贝叶斯在有些领域很有用，比如垃圾邮件过滤；
  2）在具体的算法实施中，要考虑很多实际问题。比如因为“下溢”问题，需要对概率乘积取对数；再比如词集模型和词袋模型，还有停用词和无意义的高频词的剔除，以及大量的数据预处理问题，等等；"
## 应用
  1）多类预测：这个算法以多类别预测功能闻名，因此可以用来预测多类目标变量的概率。
  2）文本分类/垃圾邮件过滤/情感分析：相比较其他算法，朴素贝叶斯的应用主要集中在文本分类（变量类型多，且更独立），具有较高的成功率。因此被广泛应用于垃圾邮件过滤（识别垃圾邮件）和情感分析（在社交媒体平台分辨积极情绪和消极情绪的用户）。
  3）推荐系统：朴素贝叶斯分类器和协同过滤结合使用可以过滤出用户想看到的和不想看到的东西。
# Gaussian naive Bayes（高斯朴素贝叶斯）
  处理连续数据的时候，一个比较典型的假设是与每个分类相关的连续值是按照高斯分布分布的。
## 公式
![在这里插入图片描述](https://img-blog.csdn.net/20181022132803227?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
  假设训练集中包含连续值 x，我们按照类别将数据分类，并计算每个分类的均值和偏差。
  μk是对应类别 Ck 下 x 值的均值，σk2是方差。
  假设我们已经收集到一些观测值 v。在给定分类 Ck 下 v 的概率分布 p(x = v | Ck） 可以通过将 v 带入到由 μk 和 σk2 决定的高斯分布公式中得到。
