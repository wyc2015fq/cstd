# 生成模型--GAN与NLP - wydbyxr的博客 - CSDN博客
2018年10月29日 10:46:53[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：173
# GAN与NLP
  GAN是否可以应用到NLP上?
  Yoshua Bengio 的得意门生 Ian Goodfellow 博士回答了这个问题：
  GANs 目前并没有应用到自然语言处理（NLP）中，因为 GANs 仅仅定义在真值数据中，GANs 通过训练出的生成器来产生合成数据，然后在合成数据上运行判别器，判别器的输出梯度将会告诉你，如何通过略微改变合成数据而使其更加现实。
**只有在数据连续（输入连续）的情况下，你才可以略微改变合成的数据，而如果数据是离散的，绝对不可以改变合成数据，一点都不可以。**
  例如，如果你输出了一张图片，其像素值是1.0，那么接下来你可以将这个值改为1.0001。如果你输出了一个单词“penguin”，那么接下来就不能将其改变为“penguin + .001”，因为没有“penguin +.001”这个单词。如果想改的话，你必须将“penguin”变为“ostrich”或其他。因为所有的自然语言处理（NLP）的基础都是离散值，如“单词”、“字母”或者“音节”，没有人真正知道怎样才能在 NLP 中应用 GANs。"
  我看到有人说， GANs 在递归神经网络（RNN）方面并不奏效。这是不对的。从理论上来看，GANs 和 RNN 的生成器或判别器之间，并没有什么矛盾。但是，对于这一点，目前并没有人严肃而又认真的测试过。因此，在实际应用中还是存在一定的困难的。
## 生成文本的话，用VAE就行
**VAEs 对可见的离散单元是有效的，但是对隐藏的离散单元却并不奏效（除非你在运用增强算法，比如 DARN 或者 NVIL）。而另一方面，GANs 对隐藏的离散单元奏效，对可见的离散单元却并不奏效（从理论上来讲，除非是运用增强算法）。因此，这两种方法可以说是各有利弊，相辅相成。**
