# 算法选择--数据与特征工程 - wydbyxr的博客 - CSDN博客
2018年12月03日 10:09:16[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：48
# 数据与特征工程（如何选择与处理数据）
  1）在处理数据上，数据并非越多越好，多余的无关特征会因为伪相关、巧合而影响模型。
  2）对数据做相关性分析的时候，善用可视化可以一目了然发现问题。
  3）对于高度相关的特征，移除或者合并前要三思，可能并不会提高模型能力。
  3）如果选用了线性模型，可能需要对特征进行离散化
  4）对于大部分模型来说，归一化或者标准化是必不可少的步骤，至少”无害“
  5）如果问题较为复杂，尽量选择非线性的鲁棒性强的模型
  数据不是越多越好，要根据领域经验挑选相关特征。有一个误区就是信息越多越好。其实不然，无关信息可能与预测值存在某种巧合，导致对检测结果造成负面影响。所以只选择与预测值可能有关联的信息。
## 相关性分析
  做相关性分析，可以发现数据中的问题，发现数据中有意思的部分，评估模型的能力。如果多个特征高度相关，那可能模型预测能力效果有限。
  方法：可视化；相关性矩阵；互信息
## 去相关性
  总结来看，如果不存在特别严重的相关性，去相关性不是必要步骤。从理论和实验角度来看，去掉或者合并相关性特征不一定会提高模型的预测能力。
  从实践角度来看，树模型对于相关性的鲁棒性强，如果可能，可以先使用未处理的特征在树模型进行尝试。
  如果有必要移除相关性，下面是移除相关性的方法：特征选择；设定阈值，去除高线性相关的特征组。
# 特征提取
  你提到在数据挖掘比赛上面，胜负更多在特征上，为什么这么说呢？在特征上有什么套路？
  基本上大家都会用同样的一些工具去训练同样的模型，在模型方面差别很小。所以，模型没那么重要。融合是基于单模型来的，要是单模型不好，那么很大概率上融合也好不了。此外，融合的套路应该也基本上都固定了，但凡常玩的人也都知道。所以，融合基本上达不到创新，很难出现别人不知道的招。
  因此，机会还是在特征上，现在只有特征还没有一个通用的标准，大家自己做自己的，有可能做出点不一样的东西。
  其实特征工程主要分两点：
  1）你可能需要了解业务，从业务本身出发，找到一些对预测有帮助的信息和线索。这是基于你对业务的熟悉，对业务的理解出发的。
  2）需要想办法把这种信息转化成适用于模型的特征。
# 特征工程与数据集大小
  一般来说，数据量够的话深度学习自动抽取的特征表示能力更好，小数据集上人工特征工程效果更好。不幸的是，特征工程没太多窍门，唯手熟尔。
  1）在数据量不够的时候，自动特征抽取的方法往往不如人为的特征工程；
  2）当使用者对于数据和问题有深刻的理解时，人工的特征工程往往效果更好。一个极端的例子是，在kaggle比赛中的特征工程总能带来一些提升；
  3）当数据量较大或者我们的人为先验理解很有限时，可以尝试表征学习。
# 特征的选择（维度灾难）
  一些情况下原始数据维度非常高，维度越高，数据在每个特征维度上的分布就越稀疏，这对机器学习算法基本都是灾难性（维度灾难）。
  当我们又没有办法挑选出有效的特征时，需要使用PCA等算法来降低数据维度，使得数据可以用于统计学习的算法。但是，如果能够挑选出少而精的特征了，那么PCA等降维算法没有很大必要。
# 什麽样的数据集不适合用深度学习?
  1）数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。
  2）数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。
  图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。
