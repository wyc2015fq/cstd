# 生成模型--生成式对抗网络(GAN，Generative Adversarial Networks)综述 - wydbyxr的博客 - CSDN博客
2018年10月26日 10:10:06[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：792
# 生成式对抗网络(GAN，Generative Adversarial Networks)
  无监督深度学习，除了强化学习，主要包括BM、自动编码器AE和GAN领域。
  是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。
  它由两个成对的网络协同运作，即生成模型（Generative Model）和判别模型（Discriminative Model），两者的的互相博弈学习产生相当好的输出。虽然GAN里面同时包含了生成网络和判别网络，但本质来说GAN的目的还是生成模型。
  原始 GAN 理论中，并不要求 G 和 D 都是神经网络，只需要是能拟合相应生成和判别的函数即可。但实用中一般均使用深度神经网络作为 G 和 D 。一个优秀的GAN应用需要有良好的训练方法，否则可能由于神经网络模型的自由性而导致输出不理想。
  判别网络的输入是训练数据或者生成网络产生的内容，它正确区分数据来源的能力构成了生成网络错误水平的表现的一部分。这样就形成了一种竞争形式：判别器越来越擅长区分真实数据和生成数据，与此同时生成器不断学习从而让判别器更难区分。有时候，这样的机制效果还不错，因为即便是相当复杂的类噪声模式最终都是可预测的，但与输入数据特征相似的生成数据更难区分。
  参考资料：[http://geek.csdn.net/news/detail/230599](http://geek.csdn.net/news/detail/230599)
## 发展历史
  2014年Ian Goodfellow提出的
## 基本原理
  这里以生成图片为例进行说明。假设我们有两个网络，G（Generator）和D（Discriminator）。正如它的名字所暗示的那样，它们的功能分别是：
  G是一个生成图片的网络，它的输入时一个随机的噪声z，通过这个噪声生成图片，记做G(z)。
  D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片。
  在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。
  最后博弈的结果是什么？在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。
## 训练的原理
  下面这幅图片很好地描述了这个过程：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181026100154453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=,size_27,color_FFFFFF,t_70)
  第一步，假设G已经训练好了，只训练D，D是希望V(G, D)越大越好，所以是加上梯度(ascending)。
  第二步，假设D已经训练好了，只训练G，V(G, D)越小越好，所以是减去梯度(descending)。
  两步训练过程交替进行。
### 公式如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181026100030987.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=,size_27,color_FFFFFF,t_70)
  1.整个式子由两项构成。x表示真实图片，z表示输入G网络的噪声，而G(z)表示G网络生成的图片。
  2.D(x)表示D网络判断真实图片是否真实的概率（因为x就是真实的，所以对于D来说，这个值越接近1越好）。而D(G(z))是D网络判断G生成的图片的是否真实的概率。
  3.G的目的：上面提到过，D(G(z))是D网络判断G生成的图片是否真实的概率，G应该希望自己生成的图片“越接近真实越好”。也就是说，G希望D(G(z))尽可能得大，这时V(D, G)会变小。因此我们看到式子的最前面的记号是min_G。
  4.D的目的：D的能力越强，D(x)应该越大，D(G(x))应该越小。这时V(D,G)会变大。因此式子对于D来说是求最大(max_D)。
## GAN在训练遇到的困难
  1）GAN 很难训练——你不仅需要训练两个网络（它们可能都有自己的问题），还要很好地平衡它们的动态情况。如果预测或者生成任意一方比另一方更强，这个 GAN 就不会收敛，而是直接发散掉了。
  2）生成器和判别器的loss无法指示训练进程。训练过程不稳定。
  3）模式崩溃的（collapse mode）问题，即生成样本缺乏多样性。
## 如何解决难以训练的困难
  1）GAN难以训练，但对目标函数进行了修改。原来Jensen-Shannon散度目标的简单修改：最小二乘法，absolute deviation with margin，还有Wasserstein距离；
  2）Leaky ReLU, popular for DCGAN networks and for small datasets,
  3）Cycle GAN的D用了其中的方法，将Loss改为L2 Loss，训练稳定性提高了，好于传统的cross-entropy loss。
  4）在训练 GAN 上有很多 trick，比如如何衡量生成器和判别器的强弱从而控制一方的能力；在判别器中加入 minibatch，用于衡量更多的样本，从而丰富生成的多样性；合理的设计网络深度和参数等等。这些 trick 确实提高了 GAN 的训练稳定性和生成上的多样性，但是仍无法避免 GAN 的问题。
## 应用
  1）图像生成：目前GAN最常使用的地方就是图像生成，如超分辨率任务，语义分割等等。
  2）数据增强：用GAN生成的图像来做数据增强。对于小数据集，数据量不足， 如果能生成一些就好了。
#### 如果GAN生成了图片？怎么给这些数据label呢？因为他们相比原始数据也不属于预定义的类别。
  先用原始数据（即使只有2000张图）训练一个GAN，然后生成图片，加入到训练集中。 总结一下就是：
  1）GAN 生成数据是可以用在实际的图像问题上，且性能都有提升。
  2）GAN 数据有三种给pseudo label的方式（假设我们做五分类）：
a)把生成的数据都当成新的一类, 六分类，那么生成图像的 label 就可以是 （0, 0, 0, 0, 0, 1） 这样给。
b)按照置信度最高的 动态去分配，那个概率高就给谁 比如第三类概率高（0, 0, 1, 0, 0）
c)既然所有类都不是，那么可以参考inceptionv3，搞label smooth，每一类置信度相同（0.2, 0.2, 0.2, 0.2, 0.2）。
  3）虽然得出的结论是没有明显的证据说明其他GAN比原始GAN好，但就生成高清图像来说，还是BEGAN和wgan-gp用的更多一些。
## 与VAE的比较
  1）AE中生成的loss是基于重建误差的。而只基于重建误差的图像生成，都或多或少会有图像模糊的缺点，因为误差通常都是针对全局。
  例如：真实数据分布在一个U形的流形上，而MSE系的方法因为loss的形式往往会得到一个接近平均值所在的位置。
  2）GAN在这方面则完爆其他方法，因为目标分布在流形上。所以只要大概收敛了，就算生成的图像都看不出是个啥，清晰度常常是有保证的。
