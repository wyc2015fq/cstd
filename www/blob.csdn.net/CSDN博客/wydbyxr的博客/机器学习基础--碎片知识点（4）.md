# 机器学习基础--碎片知识点（4） - wydbyxr的博客 - CSDN博客
2018年08月17日 11:12:02[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：76
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 对这些比赛的分类，主要分为挖掘、图像、语音、NLP 四类
　　这四类问题需要用到的一些技术或者技巧，彼此之间可以相对独立，每类问题都有各自的套路。 
　　1）对于数据挖掘类问题来说的话，具体是广告、交通、金融还是教育，其实影响不大。主要的共性就是理解数据，理解问题，从数据中找到有用的信息用来预测，这类问题胜负更多的是在特征上。
　　2）对于图像问题，可能就较少涉及到特征了。图像问题现在主要用到深度学习的相关技术，基于深度学习做了很多改进或者演绎，已经完全不需要在特征层面上去做什么了。 
　　像图像、语音类比赛，其实我目前接触的还比较少，这种比赛这两年才开始兴起。
# 人工智能的学派分类
　　1）用逻辑的方法做人工智能，通常我们把它叫做逻辑主义学派，或者叫做符号主义学派。 
　　2）以连接主义为基本工具，就是用神经元网络，今天的深度学习就是它一个典型的代表。 
　　3）从搞控制论的人，比较主张的一个学派，更多的是做这种自适应和进化、计算。
# 各种应用中的传统算法
　　语音识别采用高斯混合模型（GMM）和隐马尔可夫模型（HMM）， 
　　物体匹配和识别采用SIFT特征， 
　　人脸检测采用Haar-like特征， 
　　人脸识别采用LBP特征， 
　　行人检测采用HOG特征等。
# 二元处理机制理论
　　「二元处理机制」认为，人类的推理包括两种不同种类的思考方法。 
　　系统 1 是一个快速的、无意识的、自动化的思考模式，它也被称为直觉。 
　　系统 2 是一个慢速的、有意识的、显式的、基于规则的推理模式，它被认为是一种进化上的最新进展。 
　　在学习完成某项具有挑战性的规划任务（例如棋牌类游戏）时，人类会同时运用这两种处理方式：准确的直觉可以快速地选择有利路线，这使我们慢速的分析推理更加高效。而持续的深入学习又能逐渐提升直觉，从而使更准确的直觉回馈到更强大的分析中，这就形成了一个闭合的学习回路。换言之，人类是通过既快又慢的思考方式来学习的。   
## 专家迭代
　　是一种新的强化学习算法，它受启发于人类思维的二元处理机制理论。 
　　ExIt 将强化学习分解为两个独立的子问题：泛化和规划。规划在具体分析的基础上执行，并且在找到了强大的策略之后将之泛化。这将允许智能体做长期规划，并进行更快速的学习，即使在极具挑战的问题也能达到高水平表现。这个训练策略在棋牌类人工智能玩家中是非常强大的，不需要任何人类专家的棋谱就能达到当前最佳性能。
# 背包优化/背包问题
　　背包优化是一个经典的算法问题。你有两样东西：一个容量为固定重量的背包和一系列不同重量和价值的盒子。目标是装满这个背包使其价值最大化却又不超出它的最大承载重量。 
　　自 1972 年以来，这一直是一个著名的数学问题。遗传算法可以很好地解决这一问题，因为它本质上是一个具有大量可能答案的优化问题。 
　　为了亲自测试这一算法的工作原理，我们用它解决一个简单的问题：如何破解同事的密码。
# 标注任务
　　正如你所见，上图里既有猫又有狗。其实还没完呢，里面还有草啊、轮胎啊、石头啊等等。与其将上图仅仅分类为其中一类，倒不如把这张图里面我们所关心的类别都标注出来。比如，给定一张图片，我们希望知道里面是否有猫、是否有狗、是否有草等。给定一个输入，输出不定量的类别，这个就叫做标注任务。
# model-free和model-based的区别
　　model-free是指在训练中没有任何的先验的外观或者形状等模型，而model-based是基于人为的外观等模型     
# 迭代算法
　　我理解对于这么大的数据量级使用这种迭代算法，计算代价是非常高的，所以应用到实际场景，系统工程要求也是非常高。
# 分箱 (binning)/分桶 (bucketing)
　　连续值转换为离散值。根据值的范围将一个连续特征转换成多个称为 buckets 或者 bins 二元特征，称为 buckets 或者 bins。 
　　例如：将温度表示为单一的浮点特征，可以将温度范围切割为几个离散的 bins。假如给定的温度的敏感度为十分之一度，那么分布在 0.0 度和 15.0 度之间的温度可以放入一个 bin 中，15.1 度到 30.0 度放入第二个 bin，30.1 度到 45.0 度放入第三个 bin。
# 密集特征（dense feature）
　　大多数取值为非零的一种特征，通常用取浮点值的张量（tensor）表示。和稀疏特征（sparse feature）相反。       
# 一对多（one-vs.-all）
　　给出一个有 N 个可能解决方案的分类问题，一对多解决方案包括 N 个独立的二元分类器——每个可能的结果都有一个二元分类器。 
　　例如： 
　　一个模型将样本分为动物、蔬菜或矿物，则一对多的解决方案将提供以下三种独立的二元分类器：动物和非动物；蔬菜和非蔬菜；矿物和非矿物”。
# Distance metric learning方法在大规模图像检索中的应用?
　　在图像检索中，其基本问题是如何度量图像间的相关度，这可分解为图像表征学习和距离测度学习。 
　　直观地讲，为提高相关性度量质量，我们可以优化图像标注学习，也可以优化距离测度学习。 
　　然而，与其他视觉任务不同，图像检索面对的数据库规模大，对检索相应时间苛刻，因此一般采用简单的距离测度，比如L1距离或L2距离，这样方便通过施加稀疏性约束来引入倒排索引结构。所以，在很多图像检索方法中，相对于距离测度学习，大家一般更关注在图像表征学习上。
# 求分析一下直接回归坐标和回归heat map的优缺点（landmark/joint）以及offset上有什么可以改进的吗?
　　直接回归坐标的缺点在于难以训练，优点在于对于landmark的定位较为精确且更适合3D pose等任务；而heat map的优点在于可以利用现有的fully convolutional network的套路进行训练，缺点在于对于landmark的定位较为粗糙且整个网络的计算代价较大。 
　　对于cascading中offset的改进可以基于difficulty-aware learning，比如对于每个sample所预测出的offset还取决于这个sample所属的典型错误类型，具体细节可参见我们ECCV 2016关于fashion landmark detection的论文。
# 论文的复现
　　一般来说，得比别人多用1-2项技术才能做到paper里宣称的识别率。 
　　经验吧，很多时候跑不到一个好结果，可能是没有充分下降，learning rate收缩得过快的话，可能还没到底就几乎不动了，收缩过慢的话，可能没有耐心等待学习率降到一个比较低的数就停止了。用最常用的指数下降法的话，很容易发生以上两种现象。 
　　我现在一般使用固定学习率，如果观察到loss已经下降不动，只在一个区间内抖动的话，就停止学习，将学习率除以10继续重复这个过程。从0.01开始，一般搞到1e-6就差不多啦。
# 流程（pipeline）
　　指的是机器学习算法的基础架构。管道包括收集数据、将数据放入训练数据文件中、训练一或多个模型，以及最终输出模型。 
# 混淆矩阵 (confusion matrix)
　　一种 NxN 表格，用于总结分类模型的预测成效；即标签和模型预测的分类之间的关联。在混淆矩阵中，一个轴表示模型预测的标签，另一个轴表示实际标签。N 表示类别个数。在二元分类问题中，N=2。 
　　多类别分类问题的混淆矩阵有助于确定出错模式。例如，某个混淆矩阵可以揭示，某个经过训练以识别手写数字的模型往往会将 4 错误地预测为 9，将 7 错误地预测为 1。混淆矩阵包含计算各种效果指标（包括精确率和召回率）所需的充足信息。 
　　例如，下面显示了一个二元分类问题的混淆矩阵示例：
肿瘤（预测的标签） 非肿瘤（预测的标签） 
肿瘤（实际标签） 18 1 
非肿瘤（实际标签） 6 452 
　　上面的混淆矩阵显示，在 19 个实际有肿瘤的样本中，该模型正确地将 18 个归类为有肿瘤（18 个真正例），错误地将 1 个归类为没有肿瘤（1 个假负例）。同样，在 458 个实际没有肿瘤的样本中，模型归类正确的有 452 个（452 个真负例），归类错误的有 6 个（6 个假正例）。
# 为什么不用逻辑回归，而要用GBM？
　　答：GB是Gradient Boosting。引用知乎答主Frankenstein的话，从决策边界上看，线性回归的决策边界是一条直线，逻辑回归的决策边界是一条曲线，GBM的决策边界可能是很多条线。 
　　逻辑回归只能处理回归问题，而GBM还可以用于解决分类或排序问题。
# benchmark和baseline
　　相同点：Benchmark和baseline都有性能比较的意思。 
　　不同点：Benchmark一般是指评测指标或评测体系；Baseline指你要对比的基础方法。 
　　简而言之，benchmark一般是和同行中比较牛的算法比较，比牛算法还好，那你可以考虑发好一点的会议/期刊；baseline一般是自己算法优化和调参过程中自己和自己比较，目标是越来越好，当性能超过benchmark时，可以发表了，当性能甚至超过SOTA时，恭喜你，考虑投顶会顶刊啦。 
## Benchmark
　　通俗的讲，一个算法之所以被称为benchmark，是因为它的性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏。这里需要区别state-of-the-art（SOTA），能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法以SOTA作为benchmark，这当然是最好的了，但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。
## baseline
　　通俗的讲，一个算法被称为baseline，基本上表示比这个算法性能还差的基本上不能接受的，除非方法上有革命性的创新点，而且还有巨大的改进空间和超越benchmark的潜力，只是因为是发展初期而性能有限。所以baseline有一个自带的含义就是“性能起点”。这里还需要指出其另一个应用语境，就是在算法优化过程中，一般version1.0是作为baseline的，即这是你的算法能达到的一个基本性能，在算法继续优化和调参数的过程中，你的目标是比这个性能更好，因此需要在这个base line的基础上往上跳。
# The ground truth
　　就是参考标准，一般用来做error quantification。比方说要根据历史数据预测某一时间的温度，ground truth就是那个时间的真实温度。error就是(predicted temperature - real temprature)。例W_gt       
# train、evaluation和prediction的区别
　　predict是指结果，不包含loss、acc，只包含softmax、logit等预测值；对单张图使用。 
　　eval包含了loss，acc等损失；对测试集使用。 
　　例如： 
predict_result    =>[{‘predictions’: array([-2.99999738], dtype=float32)}] 
eval_result    =>{‘average_loss’: 0.010000505, ‘loss’: 0.010000505, ‘global_step’: 3000}
