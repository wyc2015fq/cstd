# 机器学习基础--各种学习方式（1） - wydbyxr的博客 - CSDN博客
2018年06月26日 22:04:03[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：145
个人分类：[机器学习基础](https://blog.csdn.net/wydbyxr/article/category/7151096)
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 机器学习中的各种学习方式
　　以识别猫狗图像为例，区分以下几种学习方式： 
1.监督学习：有标签的猫狗数据。 
2.无监督学习：无标签的猫狗数据。 
3.半监督学习：部分有标签的猫狗数据。 
4.Transfer Learning(迁移学习)：有标签的猫狗数据、有标签的大象老虎的数据。 
5.Self-taught Learning：有标签的猫狗数据、无标签的大象老虎美女的数据。  
## 监督学习（supervised learning）
　　输入数据都有一个类别标记或结果标记，被称作训练数据，比如垃圾邮件与非垃圾邮件、某时间点的股票价格。模型由训练过程得到，利用模型，可以对新样本做出推测，并可以计算得到这些预测的精确度等指标。训练过程往往需要在训练集上达到一定程度的精确度，不欠拟合或过拟合。 
　　监督学习一般解决的问题是分类和回归，代表算法有逻辑回归（Logistic Regression）和神经网络后向传播算法（Back Propagation Neural Network）。 
　　有监督学习：有标签、直接反馈、预测未来结果
　　监督学习算法利用训练数据集学习，并持续学习直到达到他们所期望的信息（最小化错误概率）的程度。 
　　监督算法可以分为回归、分类和异常检测或降维。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
## 半监督学习（Semi-Supervised Learning）
　　输入数据是标注数据和非标注数据的混合，它也是为了解决预测问题的，但是模型必须同时兼顾学习数据中已经存在的结构和作出预测，即上述监督学习和无监督学习的融合。该方法要解决的问题仍然是分类的回归，代表算法一般是在监督学习的算法上进行扩展，使之可以对未标注数据建模。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
　　一般性流程：首先，可以先用有标签的数据训练得到分类器C0；然后用C0去预测无标签的数据并打上标签；最后使用全部的数据训练得到分类器C1。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  
　　常用的算法：基于图模型的半监督学习是使用最多的 
半监督学习的关键步骤是构图，确定距离，以及确定标签传播的方法另外常见的半监督学习还包括self-training，transductive learning 等等 
　　self-training(自训练算法)、generative models(生成模型)、SVMs(半监督支持向量机）、graph-based methods(图论方法)、multiview learing(多视角算法)等。
## 无监督学习（Unsupervised Learning）
　　输入数据没有任何标记，通过推理数据中已有的结构来构建模型。 
　　无监督学习算法尝试从可用数据中获取价值。这意味着，在可用数据内，算法产生关系，以便检测模式或根据它们之间的相似程度将数据集划分为子组。”                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
#### 常用的算法
　　自编码（Autoencoding）、主成分分析（Principal components analysis）、随机森林（Random forests）、K均值聚类（K-means clustering）。 
　　无监督学习中最有前景的最新发展之一是Ian Goodfellow（当时在Yoshua Bengio的实验室工作时提出）的一个想法，称为“ 生成对抗网络 （generative adversarial networks）”。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
　　a）关联/规则学习(Association Rule)：就是去发觉在同一个数据集合中不同条目同时发生的概率。广泛地用于市场篮子分析。例如：如果一位顾客买了面包，那么他有 80% 的可能性购买鸡蛋。例如：Apriori 算法 
　　b）聚类：把更加相似的对象归为一类，而不是其他类别对象。例如：K-均值聚类。 
　　c）降维：顾名思义，降维就是减少数据集变量，同时要保证重要信息不丢失。降维可以通过使用特征提取和特征选择方法来完成。特征选择方法会选择原始变量的一个子集。特征提取完成了从高维空间到低维空间的数据变换。例如：主成分分析（PCA）                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
## 增强学习（Reinforcement Learning）
　　在这种学习方式中，模型先被构建，然后输入数据刺激模型，输入数据往往来自于环境中，模型得到的结果称之为反馈，使用反馈对模型进行调整。 
　　详情见“增强学习”的excel表。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             
## 迁移学习Transfer Learning
　　本质上是希望通过与目标对象不那么相关的数据（例如利用大象老虎的图片去分类猫狗的图片）发现潜在的共性特征，利用潜在的共性特征去分类识别。 
　　在图像识别中，经常使用Transfer Learning的方法。其思路是：先利用CNN训练一大堆数据，CNN的隐含层相当于特征提取层。用于新的数据时，保持原来的网络结构的前面部分不变，相当于构建了隐含特征，通过调整后面部分的网络参数实现对新数据的识别。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
## Self-talk Learning
　　Self-talk Learning与Transfer Learning很像，都有除了猫狗以外的大象老虎的数据。不同之处是：Transfer Learning的大象老虎数据是有标签的，Self-talk Learning的大象老虎数据是无标签的。 
　　乍看之下，Self-talk Learning很难，从不相关的无标签数据中可以获得什么呢？仔细思考下，以图像为例，像素空间的向量分布是很稀疏的，实际空间的维度并不需要这么高。不论是0-9还是a-z都是由不同的笔触组成的，如果可以通过无监督的a-z学习到笔触的表现形式，那么对于0-9的数据，先转化成笔触再进行识别便有可能取得较高的识别精度。 
　　Self-talk Learning的例子如下： 
识别数字0-9，有a-z的无标签的字符数据 
新闻文本分类，有网络上爬的各种文本 
汉语识别，有网络上英语、西班牙语的语料数据”                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
## 论外
　　机器学习任务可以划分为监督学习、无监督学习、和弱监督学习。 
　　弱监督学习的目的，与监督学习一致，然而其获得的样本并没有完整的标记。从标记缺失的形式和处理方式的不同，又可以分为半监督学习、主动学习、多示例学习／多标记学习、和强化学习。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
　　1）半监督学习中，只有少量的样本具有标记； 
　　2）主动学习中，机器可以询问真实的标记，但需要考虑询问的代价； 
　　3）多示例学习中，一个对象表示为一组样本的包，而标记只在包的层面上，在样本的层面上却没有标记； 
　　4）多标记学习中，一个样本对应一组标记，因此需要处理巨大的标记组合空间问题； 
　　5）强化学习中，机器需要探索环境来获得样本，并且学习的目的是长期的奖赏，因此样本的标记是延迟的
