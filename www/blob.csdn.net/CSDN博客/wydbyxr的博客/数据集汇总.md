# 数据集汇总 - wydbyxr的博客 - CSDN博客
2018年11月26日 10:57:52[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：805
# 原始数据的采集
  下面是对原始采集数据质量的评估：
  1）图像、视频：分辨率，清晰度，光照，色彩等
  2）语音：清晰度，背景音等
  3）文本：是否自然语言，是否专业，与主题相关性等
  下面是对数据标注质量的评估：
  标注正确率（类别数据）
  标注精确度（坐标、时间点、个数、文字等）
  标注完备性（是否漏，是否重复）
  标注一致性（前后规则是否一致）
  人工标记的大规模数据一般都会含有噪声，一些经典数据集也含有噪声，例如人脸LFW、MS COCO等，这是不可避免的，不过在可以接受的限度内就行。
# 经典数据集
## MNIST数据集
  深度学习领域的“Hello World!”！
  THE MNIST DATABASE of handwritten digits。MNIST是一个手写数字数据集，它有60000个训练样本集和10000个测试样本集，每个样本图像的宽高为28*28。需要注意的是，此数据集是以二进制存储的，不能直接以图像格式查看。
# 常见的用于分类的数据集
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181126104028664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=,size_16,color_FFFFFF,t_70)
## 开源数据集	[https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
## CIFAR/cifar
  用于分类算法测试的中小规模数据集。
  1）CIFAR-10包含10个类别，50,000个训练图像，彩色图像大小：32x32，10,000个测试图像。
  CIFAR-10 is an image classication benchmark dataset. It consists of a training set of size 50K and a test set of size 10K, where instances are 32 * 32 color images representing airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships and trucks.
  2）CIFAR-100与CIFAR-10类似，包含100个类，每类有600张图片，其中500张用于训练，100张用于测试；这100个类分组成20个超类。图像类别均有明确标注。
## COCO common objects Dataset(Common Objects in Context)
  COCO数据集由微软赞助，其对于图像的标注信息不仅有类别、位置信息，还有对图像的语义文本描述，COCO数据集的开源使得近两三年来图像分割语义理解取得了巨大的进展，也几乎成为了图像语义理解算法性能评价的“标准”数据集。
  它有如下特点：
1）Object segmentation
2）Recognition in Context
3）Multiple objects per image
4）More than 300,000 images
5）More than 2 Million instances
6）80 object categories
7）5 captions per image
8）Keypoints on 100,000 people
#### 三大子集
  1）目标检测（COCO Detection Challenge），包含两项比赛：用于目标检测、语义分割
  2）图像标注（COCO Captioning Challenge）
  具体说来就是一句话准确描述图片上的信息（producing image captions that are informative and accurate）。那这个怎么评分呢？目前是靠人工评分。
  3）人体关键点检测（COCO Keypoint Challenge）
  比赛要求是找到人在哪，然后定位到人体的一些关键点位置（The keypoint challenge involves simultaneously detecting people and localizing their keypoints）。
## Pascal VOC
  PASCAL VOC挑战赛是视觉对象的目标分类和目标检测的一个基准测试，提供了检测算法和学习性能的标准图像注释数据集和标准的评估系统。
  PASCAL VOC图片集包括20个目录：人类；动物（鸟、猫、牛、狗、马、羊）；交通工具（飞机、自行车、船、公共汽车、小轿车、摩托车、火车）；室内（瓶子、椅子、餐桌、盆栽植物、沙发、电视）。
  PASCAL VOC挑战赛在2012年后便不再举办，但其数据集图像质量好，标注完备，非常适合用来测试算法性能。
## ImageNet数据集
  1）Total number of non-empty synsets（同义词）: 21841
  2）Total number of images: 14,197,122
  3）Number of images with bounding box annotations: 1,034,908
  4）Number of synsets with SIFT features: 1000
  5）Number of images with SIFT features: 1.2 million
## WebVision竞赛
  超越 ILSVRC：侧重图像学习和理解的 WebVision竞赛
  超越 ILSVRC”workshop 将正式宣布ImageNet 竞赛的完结。ImageNet 之所以不再正式举办，是因为在 2016 年 ILSVRC 的图像识别错误率已经达到 2.9% 左右，远远超越人类（5.1%），今后再进行这类竞赛意义就不大了。
  未来，计算机视觉的重点在图像和视频的理解。由此，便产生了一个值得关注的问题——继 ImageNet 之后成为计算机视觉界标志性竞赛的是什么。
## The Street View House Numbers (SVHN)
  SVHN是一个真实世界的街道门牌号数字识别数据集，该数据集有两种格式：Full Numbers和Cropped Digit。
  其中，Cropped Digit，这里面是被裁剪成32*32的彩色图像，训练集有73257张，测试集有26032张，另有包含了531131张图像的extra训练集。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181126105428935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=,size_16,color_FFFFFF,t_70)
## ILSVRC-2012
  由于ILSVRC-2012测试集标签是不公开的，我们不能对试过的所有模型都报告测试误差率。在本段的其余部分，我们将验证误差率与测试误差率互换，因为根据我们的经验，它们之间相差不超过0.1%。
## LFW+
  LFW+是基于LFW构建的一个包含年龄，性别，种族标注的数据集。每张人脸图像通过至少3个 amazon mechanical turk 标注，然后通过计算年龄均值作为年龄的标注，通过投票确定性别和种族的标注。此外，因为LFW数据集中青少年的图像偏少，LFW+中增加了2000多张青少年的人脸图像。
  LFW+数据集可以用于人脸属性学习方面的研究，例如年龄估计，性别分类，种族分类。
  获取方式： [http://biometrics.cse.msu.edu/Publications/Databases/MSU_LFW+/](http://biometrics.cse.msu.edu/Publications/Databases/MSU_LFW+/)
# 各个领域的数据集
## CityScapes数据集（自动驾驶）
  自动驾驶算法公开排行榜Cityscapes，Cityscapes主要专注于像素级别的分割和识别。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181126103348328.png)
## KITTI
  KITTI由德国卡尔斯鲁厄理工学院(Karlsruhe Institute of Technology)和丰田芝加哥技术研究院(Toyota Technological Institute at Chicago)于2012年联合创办，是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集。
  用于评测3D 目标（机动车、非机动车、行人等）检测、3D 目标跟踪、道路分割等计算机视觉技术在车载环境下的性能。KITTI包含市区、乡村和高速公路等场景采集的真实图像数据，每张图像中多达15辆车和30个行人，还有各种程度的遮挡。
## Omniglot dataset
  1623个手工绘制的字符从50个字母。为每个字符只有20个实例，每一个不同的人画在分辨率105x105。
## JFT-300M
  谷歌希望利用300M的大数据集进一步检验模型的能力和提升空间。
  具体来说，我们已经构建包含300M图像的内部数据集（JFT-300M），这些图像被标注为18291个类别。图像标注算法使用了原始网络信号的复杂混合体和网页与用户反馈之间的连接，这导致300M图像拥有10亿多标签（一个图像可具备多个标签）。10亿图像标签中，谷歌通过将所选图像的标签精度最大化而获取了375M标注。然而，标签中仍然存在大量噪声：所选图像的标签中约有20%带有噪声。由于缺乏详细注释，我们无法评估标签的召回率。
  新的最优结果。我们的论文展示了在JFT-300M上训练的模型，该模型在多个基准上获得了最佳的结果。例如，单模型（没有任何附加技巧）在COCO检测基准上获得了37.4AP（相对于原来的34.3AP）
  谷歌的目标：10亿+ 规模数据集
  在模型越来越复杂的现在，谷歌的目标是——朝着 10 亿+ 的数据集前进。
  Gupta 补充强调说，由于没有搜索最佳的超参数集合（因为需要相当大的计算量），所以本次实验得出的结果很可能还不是最佳。也就是说，这次他们的实验可能还没有完全将数据对性能的影响表现出来。由此，Gupta 指出，虽然难度很大，但获取针对某一任务的大规模数据应当成为未来研究的重点。
## Common Voice
  mozilla基金会(即开发firefox浏览器的）开源语音识别模型，和世界第二大语音数据集。
  Mozilla 在今年七月份启动了 Common Voice 项目（[https://voice.mozilla.org/）。该项目的目标是使人们能轻松地将他们的语音数据贡献到一个公开数据集上。](https://voice.mozilla.org/%EF%BC%89%E3%80%82%E8%AF%A5%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%9B%AE%E6%A0%87%E6%98%AF%E4%BD%BF%E4%BA%BA%E4%BB%AC%E8%83%BD%E8%BD%BB%E6%9D%BE%E5%9C%B0%E5%B0%86%E4%BB%96%E4%BB%AC%E7%9A%84%E8%AF%AD%E9%9F%B3%E6%95%B0%E6%8D%AE%E8%B4%A1%E7%8C%AE%E5%88%B0%E4%B8%80%E4%B8%AA%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E3%80%82)
  Mozilla 公布了贡献数据集的第一部分：大约 400,000 份录音，500 个小时时长。
  所有人都可以在这里下载：[https://voice.mozilla.org/data。](https://voice.mozilla.org/data%E3%80%82)
虽然目前主要是英文数据，但是未来 Common Voice 将支持对多种语言的贡献，这个计划将从 2018 年上半年开始。
## CMU Multi-PIE Face Database
  A large (305GB) database of images for training facial recognition software. （300多G,都是花钱买的,谁能免费给你啊）
  contains more than 750,000 images of 337 people, with 15 different views and 19 lighting conditions.
  所谓“PIE”就是姿态（Pose），光照（Illumination）和表情（Expression）的缩写。CMU Multi-PIE人脸数据库是在CMU-PIE人脸数据库的基础上发展起来的。包含337位志愿者的75000多张多姿态，光照和表情的面部图像。其中的姿态和光照变化图像也是在严格控制的条件下采集的，目前已经逐渐成为人脸识别领域的一个重要的测试集合。
