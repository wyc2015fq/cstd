# 生成模型--正则自编码器 - wydbyxr的博客 - CSDN博客
2018年10月25日 13:40:43[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：182
个人分类：[生成模型(VAE,GAN,GLOW)](https://blog.csdn.net/wydbyxr/article/category/8260790)
# 正则自编码器
  除了施加一个比输入维度小的隐含层，一些其他方法也可用来约束自编码器重构，如正则自编码器。
  正则自编码器使用的损失函数可以鼓励模型学习其他特性（除了将输入复制到输出），而不必限制使用浅层的编码器和解码器以及小的编码维数来限制模型的容量。
  正则自编码器不需要使用浅层的编码器和解码器以及小的编码维数来限制模型容量，而是使用损失函数来鼓励模型学习其他特性（除了将输入复制到输出）。这些特性包括稀疏表征、小导数表征、以及对噪声或输入缺失的鲁棒性。
  即使模型容量大到足以学习一个无意义的恒等函数，非线性且过完备的正则自编码器仍然能够从数据中学到一些关于数据分布的有用信息。
  公式是由损失函数和惩罚项两部分组成：
![在这里插入图片描述](https://img-blog.csdn.net/20181025134013498?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
  在实际应用中，常用到两种正则自编码器，分别是稀疏自编码器和降噪自编码器。而收缩自编码器也属于正则自编码器。
