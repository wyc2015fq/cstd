# 人工智能追求的是满意解[转] - wydbyxr的博客 - CSDN博客
2017年07月05日 10:00:50[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：200标签：[人工智能](https://so.csdn.net/so/search/s.do?q=人工智能&t=blog)
个人分类：[深度学习基础](https://blog.csdn.net/wydbyxr/article/category/6829999)
原文入口;[http://blog.sina.com.cn/s/blog_73040b820102wwoo.html](http://blog.sina.com.cn/s/blog_73040b820102wwoo.html)
AlphaGo战胜柯洁之后，有人说AlphaGo虽然战胜了柯洁，但仍然不是最优的下法。人工智能就一定要追求最优吗？答案是否定的。印象中有位图灵奖获奖者在获奖演讲中专门讲过这个问题，人工智能往往与人一样，追求的是满意解。 
举个例子，也是我常常在课上讲过的例子。现在正是西瓜上市的季节，你打算去买一个西瓜。如果你的目标是要买一个北京市最甜的瓜，你能实现你的目标吗？先不说最甜如何测量的问题，即便假设能够测量，这个目标也几乎是无法实现的。但是如果你的目标是满意解呢？也就是说，你只想买一个吃起来还不错的西瓜，那么这件事情就简单的多了，只需到一个西瓜摊，让摊主帮你选一个就可以了。而且摊主也不需要把整个瓜摊的西瓜都挑选一边，只在三五个西瓜中挑选就可以了。 
这就是最优解与满意解的区别，人类往往追求的是满意解而非最优解，而事实上，满意解与最优解的差别，往往也不会太大。 
再回到AlphaGo，他的目标只是取胜，他的所有策略都是围绕着这个目标进行的，所以并不追求最好的下法，而在实战中，尤其是在收官阶段，还往往会走出劣手，因为对于AlphaGo来说胜1子与胜5子并没有什么区别。 
有人会说，AlphaGo把目标修改成胜子最多不就可以了？大家都知道，AlphaGo的主要框架是蒙特卡洛树搜索，搜索过程依靠的就是胜率，想修改也不是那么容易。我能想到的就是，在最后的收官阶段，对于几个胜率高的着子点，分析其得失，从中选择好的下法。当然这肯定不是最优的下法，最多是某种程度的启发式的局部满意解。 
能得到满意解就可以了，没有必要追求最佳解，因为一方面满意解与最佳解往往并没有本质的差别，另一方面，最优解往往会带来指数增长的计算量，追求最佳解也是不现实的。
