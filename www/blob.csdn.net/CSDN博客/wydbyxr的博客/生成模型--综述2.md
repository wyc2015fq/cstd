# 生成模型--综述2 - wydbyxr的博客 - CSDN博客
2018年10月29日 10:53:56[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：167
# 生成模型的本质
  本质就是希望用一个我们知道的概率模型来拟合所给的数据样本，也就是说，我们得写出一个带参数 θ 的分布 qθ(x)。然而，我们的神经网络只是“万能函数拟合器”，却不是“万能分布拟合器”，也就是它原则上能拟合任意函数，但不能随意拟合一个概率分布，因为概率分布有“非负”和“归一化”的要求。这样一来，我们能直接写出来的只有离散型的分布，或者是连续型的高斯分布。
## 两种
  1）自回归流
  图像应该是一个离散的分布，因为它是由有限个像素组成的，而每个像素的取值也是离散的、有限的，因此可以通过离散分布来描述。
  这个思路的成果就是 PixelRNN 一类的模型了，我们称之为“自回归流”，其特点就是无法并行，所以计算量特别大。所以，我们更希望用连续分布来描述图像。当然，图像只是一个场景，其他场景下我们也有很多连续型的数据，所以连续型的分布的研究是很有必要的。
  2）对于连续型的，我们也就只能写出高斯分布了，而且很多时候为了方便处理，我们只能写出各分量独立的高斯分布，这显然只是众多连续分布中极小的一部分，显然是不够用的。
  为了解决这个困境，我们通过积分来创造更多的分布：
  ** q(x)=∫q(z)*q(x|z)dz **
  这里 q(z) 一般是标准的高斯分布，而 q(x|z) 可以选择任意的条件高斯分布或者狄拉克分布。这样的积分形式可以形成很多复杂的分布。理论上来讲，它能拟合任意分布。
  故目标就是求出参数 θ，那一般就是最大似然，假设真实数据分布为 p̃(x)，那么我们就需要最大化目标：
**max【logq(x)】**
  然而 qθ(x) 是积分形式的，难以求解"	"VAE 和 GAN 在不同方向上避开了这个困难。
  a）VAE 没有直接优化目标，而是优化一个更强的上界，这使得它只能是一个近似模型，无法达到良好的生成效果。
  b）GAN 则是通过一个交替训练的方法绕开了这个困难，确实保留了模型的精确性，所以它才能有如此好的生成效果。但不管怎么样，GAN 也不能说处处让人满意了，所以探索别的解决方法是有意义的。
