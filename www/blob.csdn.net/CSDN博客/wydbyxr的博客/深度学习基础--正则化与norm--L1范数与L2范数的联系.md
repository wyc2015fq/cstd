# 深度学习基础--正则化与norm--L1范数与L2范数的联系 - wydbyxr的博客 - CSDN博客
2018年11月20日 09:37:22[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：254
# L1范数与L2范数的联系
  假设需要求解的目标函数为：E(x) = f(x) + r(x)
  其中f(x)为损失函数，用来评价模型训练损失，必须是任意的可微凸函数，r(x)为规范化约束因子，用来对模型进行限制。
  根据模型参数的概率分布不同，r(x)一般有:
  1）L1范式约束(模型服从拉普拉斯分布)，
  2）L2范式约束(模型服从高斯分布）
  3）L1范式可以产生比较稀疏的解，具备一定的特征选择的能力，在对高维特征空间进行求解的时候比较有用；L2范式主要是为了防止过拟合。
## 最小化误差的L1范数等价于对拉普拉斯噪声的MLE
  看过laplace分布的概率密度函数会发现，laplace分布是尖尖的分布，服从laplace分布的数据就是稀疏的了(只有很小的概率有值,大部分概率值都很小或为0)。
  如果取对数,剩下的是一个一次项|x-u|,这就是L1范式。所以用L1范式去正则,就假定了你的数据是laplace分布,是稀疏的。
## 最小化误差的L2范数等价于对高斯噪声的MLE
  如果你去看看高斯分布的概率密度函数P(x)，你会发现取对数后的log(P(x))就剩下一个平方项了，这就是L2范式的由来–高斯先验。
