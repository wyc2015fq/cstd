# PVANet的总结和思考 - wydbyxr的博客 - CSDN博客
2017年03月30日 20:07:44[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：1719
所属专栏：[深度学习--最新论文](https://blog.csdn.net/column/details/23683.html)
#前言
本文主要是针对《PVANet: Lightweight Deep Neural Networks for Real-time Object Detection》
的总结和思考。阅读时如有错误，你来打我。
#abstract：
APVNet是用于实时的物体发现（检测）的网络结构。
降低计算成本是同样重要的提高精度。本文提出了一种新的网络结构，这是一个数量级轻于其他最先进的网络，并保持精度。基于较少层数的基本原理通道，这种新的深度神经网络最小化，其冗余采用最近创新包括c.relu和初生结构。
#introduction：
以减少计算成本在网络设计阶段。成功的网络压缩[ 1 ]和分解的卷积内核[ 2，3 ]暗示
目前的网络架构是高度冗余的。因此，减少这些冗余是减少计算成本的直接方法。
基于“小”的基本原理用更多层的“输出通道数，我们采用c.relu [ 4 ]在初始层和Inception结构[ 5 ]在网络的后半部分。		
采用多尺度特征级联[ 6 ]也适用于最大化目标检测任务的多尺度性。
我们的这个框架也能用训练批次标准化[ 7 ]，剩余连接[ 8 ]和基于平稳检测的自主学习速率调度，来训练。
#开始正题
##2.1特征提取网络
- 
改性c.relu部分：本来c.relu可以双倍数量输出通道输出，且共享偏置；我们添加一个分离的偏置层，使两相关的过滤器可以具有不同的偏置值。
- 
初始结构部分：它是在输入图像中最具效益的部分。大的图像应该有更大的感受野，而小图像不需要这多、大的卷积核。初生结构中的1x1卷积，防止了在其他路径上的感受野的生长，这可以减少这些冗余。
- 
深层网络的训练：一般认为越深越好。解决越深越麻烦，我们使用有预激活和批次规定化的残差结构；也使用了基于“平稳检测”的动态学习率
- 
总体设计：一个5x5卷积被有两个连续的3x3的卷积层，见两个图。
##2.2目标检测网络
- 高度的特征连接：
超特征级联多尺度表示及其组合被证明是有效在许多最近的深度学习任务。但由于直接级联所有抽象层可能产生冗余信息且有更高的计算要求，我们需要设计不同的抽象层，同时小心设计抽象层层数。见图3.
网络输入（RPN）不需要以完全投入很深的全连接分类。
#4结论
在本文中，我们表明，目前的网络是高度冗余的，我们可以设计一个具有复杂视觉任务的轻便网络。
精心挑选与组合最近DL领域的技术创新，能使我们有可能设计出一个网络最大化计算效率。
我们相信我们的设计原则是广泛适用于其他任务，例如面对识别与语义分析。
我们的网络设计是完全独立的网络压缩和量化。各种最近的压缩和量化技术是适用于我们的网络，以及进一步增加实际应用中的实际性能。
