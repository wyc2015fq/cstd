# 吉布斯采样（Gibbs Sampling） - wydbyxr的博客 - CSDN博客
2018年10月20日 13:32:57[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：1447
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 吉布斯采样（Gibbs Sampling）
  常用于DBM和DBN，吉布斯采样主要用在像LDA和其它模型参数的推断上。
  要完成Gibbs抽样，需要知道条件概率。也就是说，gibbs采样是通过条件分布采样模拟联合分布，再通过模拟的联合分布直接推导出条件分布，以此循环。
## 概念解释
  吉布斯采样是特殊的Metropolis-Hastings算法，会用到马尔科夫链。
  具体地说，
  MCMC：Markov链通过转移概率矩阵可以收敛到稳定的概率分布。这意味着MCMC可以借助Markov链的平稳分布特性模拟高维概率分布；当Markov链经过burn-in阶段，消除初始参数的影响，到达平稳状态后，每一次状态转移都可以生成待模拟分布的一个样本。
  Gibbs抽样是MCMC的一个特例，它交替的固定某一维度，然后通过其他维度的值来抽样该维度的值，注意，gibbs采样只对z是高维（2维以上）（Gibbs sampling is applicable in situations where Z has at least two dimensions）情况有效。
## 吉布斯采样的通俗解释
  Gibbs Sampling就是以一定的概率分布，看发生什么事件。
### 例子
  甲只能E：吃饭、学习、打球，
  时间；T：上午、下午、晚上，
  天气；W：晴朗、刮风、下雨。
  现在要一个sample，这个sample可以是：打球+下午+晴朗。
  问题是我们不知道p(E,T,W)，或者说，不知道三件事的联合分布joint distribution。当然，如果知道的话，就没有必要用gibbs sampling了。但是，我们知道三件事的conditional distribution。也就是说，p(E|T,W),p(T|E,W),p(W|E,T)。现在要做的就是通过这三个已知的条件分布，再用gibbs sampling的方法，得到联合分布。
### 具体方法
  首先随便初始化一个组合,i.e. 学习+晚上+刮风，
  然后依条件概率改变其中的一个变量。
  具体说，假设我们知道晚上+刮风，我们给E生成一个变量，比如，学习-》吃饭。我们再依条件概率改下一个变量，根据学习+刮风，把晚上变成上午。类似地，把刮风变成刮风（当然可以变成相同的变量）。这样学习+晚上+刮风-》吃饭+上午+刮风。
  同样的方法，得到一个序列，每个单元包含三个变量，也就是一个马尔可夫链。然后跳过初始的一定数量的单元（比如100个），然后隔一定的数量取一个单元（比如隔20个取1个）。这样sample到的单元，是逼近联合分布的。
## 二维吉布斯采样算法
  吉布斯采样算法中右边的条件概率我们是知道的，例如你要采样的是二维高斯分布，那么固定xt后就是二维高斯分布固定xt后的一维高斯分布，且每次采样的坐标不同，这样这个一维高斯分布概率密度函数也就不一样了。
