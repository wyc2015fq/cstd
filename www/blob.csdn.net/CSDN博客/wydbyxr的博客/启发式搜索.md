# 启发式搜索 - wydbyxr的博客 - CSDN博客
2018年10月22日 13:34:39[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：426
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 启发式搜索
  一种最优化的算法。
  当一个问题是NP难问题时，是无法求解到最优解的，因此，用一种相对好的求解算法，去尽可能逼近最优解，得到一个相对优解，在很多实际情况中也是可以接受的。
  群体智能算法就是启发式算法；研究的重点就是如何平衡局部搜索与全局搜索；有效逃离局部最优解；
## 常用的启发算法
  蚁群算法、PSO（粒子群算法）、GA（遗传算法）、人工免疫算法、模拟退火算法、禁忌搜索算法等都可以看作是启发式算法。
### 分类
  仿动物类的算法：粒子群优化，蚂蚁优化，鱼群算法，蜂群算法等；
  仿植物类的算法：向光性算法，杂草优化算法，等等；
  仿人类的算法有：和声搜索算法是较好的算法；
## 具体使用
  用的不多，但对于神经网络，现在梯度下降玩懒了，就试试启发式算法。
  有梯度的时候，肯定是梯度方法收敛快。虽说启发式方法据说可以避免局部极值，但要我说有那么多资源还不如多跑几次梯度下降。
  实际应用时差分进化算法较有优势。关于粒子群算法，理论成熟，应用广泛。
## 各种启发式算法
- 
序列前向选择（SFS , Sequential Forward Selection）
  特征子集X从空集开始，每次选择能使得评价函数J(X)最优的一个特征x加入，其实就是贪心算法，缺点是只加不减
- 
序列后向选择(SBS , Sequential Backward Selection)
  和SFS相反，从特征全集开始，每次选择使评价函数J(X)最优的特征x剔除，也是贪心，缺点是只减不增
- 
双向搜索(BDS , Bidirectional Search)
  前向-后向贪心算法	SFS和SBS同时开始，当两者搜索到同一个特征子集时停止。
- 
增L去R选择算法（LRS , Plus-l Minus-R Selection）
  形式一：从空集开始，每次加L个特征，去除R个特征，使得J最优
  形式二：从全集开始，每次去除R个特征，加入L个特征，使J最优。
- 
序列浮动选择(Sequential Floating Selection)
  该算法由增L去R发展，不同之处在于L和R是会变化的，它结合了序列前后向选择、增L去R的特点并弥补了缺点。
   ①序列浮动前向选择（SFFS , Sequential Floating Forward Selection)：从空集开始，每轮选择子集x加入使得J最优，再选择子集z剔除使得J最优。
  ②序列浮动后向选择(SFBS , Sequential Floating Backward Selection）：与①相反，从全集开始，先剔除再加入。
- 决策树(Decision Tree Method , DTM)
  一般使用信息增益作为评价函数，待决策树生长后再进行剪枝，最后留下的叶子就是特征子集。
