# 深度学习基础--BP和训练--并行条件下的BP - wydbyxr的博客 - CSDN博客
2018年11月13日 09:41:30[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：27
# 并行条件下的BP
## 原因
  并行训练（parallel training）规模的情况下，在保证模型性能的同时实现训练速度线性增长	在增加CPU 或 GPU 数量的同时，保证训练的线性加速以及性能。但由于工人（GPU/CPU）之间存在沟通成本和资源浪费，因此无法实现工作成果随工人数量的增多呈线性增长。
## 两个评价指标
  训练速度和模型性能	如何在增加工人（卡）数量的同时，保证工人的劳动成果（训练速度）是线性增长的，同时还要保证整个施工的质量（模型性能）。
## 典型算法
  1）加速型SGD，最知名的方法是 ASGD（异步随机梯度下降，Asynchronous stochastic gradient descent）
  通过大量 GPU 做异步计算，这是 Google 从 2012 年起就在采用的方法。但这个方法的问题在于，增加 GPU 时需要的通信代价很高，增加了系统设计优化和维护成本，同时基于同样数据的两次训练结果也会不同。
  2）ASGD 加模型平均
  在对大数据做并行处理时，将数据分配给每块GPU去处理，之后把计算结果取一个平均值生成新的模型，再给GPU分配数据进行处理，以此类推。这种方法很简单，但坏处在于卡数上去时模型性能会下降。
  3）1-bit SGD
  该方法由微软一位研究员提出，通过梯度量化和压缩技术减少通信代价，实现了 Geoffrey Hinton 30 年前提出的单机训练经典方法 mini-batch SGD 的并行化。它的主要缺点是, 在保证训练模型性能的情况下，卡数增加时无法做到训练线性加速。
