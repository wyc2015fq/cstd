# 深度学习基础--传统机器学习与深度学习的区别 - wydbyxr的博客 - CSDN博客
2018年11月07日 09:52:15[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：77
# 传统机器学习与深度学习的区别
  1）传统机器学习：利用特征工程 (feature engineering)，人为对数据进行提炼清洗
  2）深度学习：利用表示学习 (representation learning)，机器学习模型自身对数据进行提炼，不需要选择特征、压缩维度、转换格式等对数据的处理。深度学习对比传统方法来说，最大的优势是自动特征的提取
  现实中遇到的绝大部分机器学习问题，基于原始特征（Input Space）无法找到分类超平面把训练数据里的正例和负例恰好分开。
  在机器学习领域，有一些通用的手段来处理线性不可分的问题，譬如可以在Input Space 寻求非线性分界面，而不再寻求线性分界面；也可以通过对特征做预处理，通过非线性映射的手段把训练数据从Input Space 映射到一个所谓的Feature Space，在原始Input Space无法线性可分的样例在Feature Space有可能线性可分。深度学习就是这种思想的一个典型应用。
## “深度模型”是手段，“特征学习”是目的
  区别于传统的浅层学习，深度学习的不同在于：
  1）强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；
  2）明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。
  与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。
  3）DL采用了与神经网络很不同的训练机制。传统神经网络中，采用的是back propagation的方式进行，简单来讲就是采用迭代的算法来训练整个网络，随机设定初值，计算当前网络的输出，然后根据当前输出和label之间的差去改变前面各层的参数，直到收敛（整体是一个梯度下降法）。而deep learning整体上是一个layer-wise（逐层）的训练机制。
  这样做的原因是因为，如果采用back propagation的机制，对于一个deep network（7层以上），残差传播到最前面的层已经变得太小，出现所谓的gradient diffusion（梯度扩散）。
## 深度学习的劣势
  另外，有人指出深度学习在面对 x 和 y 的关系是一次推理的情况时，深度学习能学到很好，如果是两层或多层的推理的时候，相比传统模型，深度学习却完全处于劣势，但深度学习结合知识图谱可以有效的解决这个问题。
  这里说到的推理应该是指在逻辑上的关系，比如你爸爸的妈妈的二叔的老婆的姐姐你应该称呼她什么这种推理，而并非数学上 y=f(x) 这种关系。
