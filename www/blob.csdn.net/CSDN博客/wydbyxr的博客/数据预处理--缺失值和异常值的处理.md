# 数据预处理--缺失值和异常值的处理 - wydbyxr的博客 - CSDN博客
2018年12月03日 11:07:07[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：1306
# 处理缺失数据的方法
  1）用平均值、中值、分位数、众数、随机值等替代。
  如果预计该变量对于学习模型效果影响不大，可以对unknown值赋众数，这里认为变量都对学习模型有较大影响，效果一般，因为等于人为增加了噪声，不建议采取此法。
  数值型的话，均值和近邻或许是更好的方法。做成哑变量更适合分类、顺序型变量。
  2）用其他变量做预测模型来算出缺失变量。
  效果比方法1略好。有一个根本缺陷，如果其他变量和缺失变量无关，则预测的结果无意义。如果预测结果相当准确，则又说明这个变量是没必要加入建模的。一般情况下，介于两者之间。
  可以使用数据完整的行作为训练集，以此来预测缺失值。又由于sklearn的模型只能处理数值变量，需要先将分类变量数值化，然后进行预测。
  一般使用KNN, Matrix completion等方法预测。
  3）最精确的做法，把变量映射到高维空间。
  比如性别，有男、女、缺失三种情况，则映射成3个变量：是否男、是否女、是否缺失。连续型变量也可以这样处理。比如Google、百度的CTR预估模型，预处理时会把所有变量都这样处理，达到几亿维。这样做的好处是完整保留了原始数据的全部信息、不用考虑缺失值、不用考虑线性不可分之类的问题。缺点是计算量大大提升。
  而且只有在样本量非常大的时候效果才好，否则会因为过于稀疏，效果很差。
  连续变量这么map岂不会产生超多纬数的data？这种也叫one hot. 把取值变成离散特征。
  4）有时还可以用特殊值标记，	引入虚拟变量(dummy variable)来表征是否有缺失，是否有补全。
  5）有时还可忽略该行数据。
  有一些模型，如随机森林，自身能够处理数据缺失的情况，在这种情况下不需要对缺失数据做任何的处理，这种做法的缺点是在模型的选择上有局限。
  6)删除。
  最简单最直接的方法，很多时候也是最有效的方法，这种做法的缺点是可能会导致信息丢失。
  对于unknown值数量较少的变量可以选择删除。
  删除有缺失数据的样本，删除有过多缺失数据的特征。
# 异常值（outlier）
  异常值往往使模型训练中出现问题。
  与大多数值差别很大的值。在机器学习中，下列都是异常值：
  1）高绝对值的权重。
  2）与实际值差距过大的预测值。
  3）比平均值多大约 3 个标准差的输入数据的值。
