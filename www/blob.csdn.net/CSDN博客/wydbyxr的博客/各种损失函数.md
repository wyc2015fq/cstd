# 各种损失函数 - wydbyxr的博客 - CSDN博客
2018年10月20日 11:59:16[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：115
所属专栏：[经典机器学习算法](https://blog.csdn.net/column/details/28812.html)
# 合页损失函数、折页损失函数（Hinge loss）
  损失函数的一个类型，用于分类模型以寻找距离每个样本的距离最大的决策边界，即最大化样本和边界之间的边缘。KSVMs 使用 hinge 损失函数（或相关的函数，比如平方 hinge 函数）。在二元分类中，hinge 损失函数按以下方式定义：
**loss=max(0,1−(y′* y))**
  其中， y’是分类器模型的列输出：y′=b+w_1*x_1+w_2*x_2+…w_n*x_n；y 是真实的标签，-1 或+1。
  因此，hinge 损失将是下图所示的样子：
![在这里插入图片描述](https://img-blog.csdn.net/20181020115848592?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
# 广义线性模型
  深度学习从统计学角度，可以看做递归的广义线性模型。广义线性模型相对于经典的线性模型(y=wx+b)，核心在于引入了连接函数g(.)，形式变为：
**y=g(wx+b)**
  深度学习时递归的广义线性模型，神经元的激活函数，即为广义线性模型的链接函数。逻辑回归（广义线性模型的一种）的Logistic函数即为神经元激活函数中的Sigmoid函数，很多类似的方法在统计学和神经网络中的名称不一样，容易引起初学者的困惑。
  下图是一个对照表：	
![在这里插入图片描述](https://img-blog.csdn.net/20181020115901764?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d5ZGJ5eHI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
