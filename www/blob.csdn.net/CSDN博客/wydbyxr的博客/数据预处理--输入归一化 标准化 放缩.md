# 数据预处理--输入归一化/标准化/放缩 - wydbyxr的博客 - CSDN博客
2018年12月03日 10:35:59[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：202
# 输入归一化/标准化
  Alex 和 Caffe中的初始化参数都是基于均值归一化的，如果不做归一化，会因为输入大了一半，导致训练失败。这也是为什么Caffe强制为样本计算图像均值的原因。
  这样，像素值[0,255]被调整成了近似[-128,128]。尽管图像数据格式规整，但是做一做归一化还是挺有用处的。
  归一化本身是一种降低特征之间差异的手段，不一定就可以增强discriminative ability，应该慎重使用。
## 一个简单策略
  训练样本均值归一化。即对训练集所有样本计算各个维度的均值（比如32x32图像，就应该有32x32个均值）并且将均值存储起来。
  训练网络时，训练集、验证集减去存起来的均值。
  测试网络时，测试集减去存起来的均值（一定要全减去训练集的均值）。
## 深度学习cnn中图片预处理方式（减去均值后，又乘以了0.0167）
  减去均值后，又乘以了0.0167。简单来说，就是减均值除以标准差。这里对应输入为0-255的情形。
  0.0167表示的是方差归一化，不同数据集用不同的值为的是Normalize Input，减去均值除以std得到均值为0std为1的数据组。
  取0.0167初衷是用它来近似代替除以标准差。在ImageNet上，输入数据的BGR三通道均值是[104,117,123]左右，而标准差在[57.1,57.4,58.4]左右，相差很小，都近似取58。然后，除以标准差，就是x/58=x*(1/58)≌x*0.017。
# 输入的尺寸很重要
  ImageNet通常将224x224x3作为输入尺寸，即具有3个颜色通道的224×224像素图像。虽然12GB内存对于ImageNet上具有112x112x3维度的类似数据集的最先进的结果至关重要，但我们可能会获得最新的结果，只有4-6GB的内存。另一方面，对于输入大小为25x75x75x3x的视频数据集，12GB的内存可能与您需要的结果相差很远。
