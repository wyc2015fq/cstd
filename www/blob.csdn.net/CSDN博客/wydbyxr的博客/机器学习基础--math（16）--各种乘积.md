# 机器学习基础--math（16）--各种乘积 - wydbyxr的博客 - CSDN博客
2018年06月22日 23:22:09[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：189
# 元素乘法
　　按元素乘法有时候被称为Hadamard 乘积，或者Schur 乘积         
# 卷积
信号与系统等学科中的 
　　卷积操作的本质，神经网络中的卷积就是乘累加； 
　　信号处理中的卷积就是加权叠加。具体点，平移（无反褶）、叠加。可以看到卷积的重要的物理意义是：一个函数（如：单位响应）在另一个函数（如：输入信号）上的加权叠加。   楼主这种做法和通常教材上的区别在于：书上先反褶再平移，把输入信号当作一个整体，一次算出一个时间点的响应值；而楼主把信号拆开，一次算出一个信号在所有时间的响应值，再把各个信号相加。两者本质上是相同的。  
　　参考资料：[http://blog.csdn.net/bitcarmanlee/article/details/54729807](http://blog.csdn.net/bitcarmanlee/article/details/54729807)
# 矩阵乘法
　　矩阵乘以列向量的话用矩阵的每一行乘以列向量；行向量乘以矩阵的话用行向量乘以矩阵的每一列, 
　　设A为m*p的矩阵，B为p*n的矩阵，那么称m*n的矩阵C为矩阵A与B的乘积，记作C=AB 
# 点乘和叉乘
### 点乘
　　点乘,也叫向量的内积、数量积.顾名思义,求下来的结果是一个数。 
　　向量a·向量b=|a||b|cos ； 
　　在物理学中,已知力与位移求功,实际上就是求向量F与向量s的内积,即要用点乘；
### 叉乘
　　在物理学中,已知力与力臂求力矩,就是向量的外积,即叉乘。 
　　向量的外积不遵守乘法交换率,因为 向量a×向量b=-向量b×向量a  
### 例子
　　将向量用坐标表示（三维向量）, 
　　若向量a=(a1,b1,c1),向量b=(a2,b2,c2),则  
　　向量a·向量b=a1a2+b1b2+c1c2  
　　向量a×向量b=  
　　　　　　　　| i j k|  
　　　　　　　　|a1 b1 c1|  
　　　　　　　　|a2 b2 c2|  
　　　　　　　=(b1c2-b2c1,c1a2-a1c2,a1b2-a2b1)  
（i、j、k分别为空间中相互垂直的三条坐标轴的单位向量）。
# 克罗内克积
　　Kronecker：上采样，如果A是一个 m x n 的矩阵，而B是一个 p x q 的矩阵，克罗内克积则是一个 mp x nq 的矩阵。
# 笛卡尔积
　　是指在数学中，两个集合X和Y的笛卡尓积（Cartesian product），又称直积，表示为X × Y，第一个对象是X的成员而第二个对象是Y的所有可能有序对的其中一个成员。 
　　例子：设A,B为集合，用A中元素为第一元素，B中元素为第二元素构成有序对，所有这样的有序对组成的集合叫做A与B的笛卡尔积，记作AxB.
### 笛卡尔积的符号化
　　A×B={(x,y)|x∈A∧y∈B} 
　　例如，A={a,b}, B={0,1,2}，则 
　　A×B={(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)} 
　　B×A={(0, a), (0, b), (1, a), (1, b), (2, a), (2, b)} 
　　可以扩展到多个集合的情况。类似的例子有，如果A表示某学校学生的集合，B表示该学校所有课程的集合，则A与B的笛卡尔积表示所有可能的选课情况。
