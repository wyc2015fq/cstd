# 深度学习基础--各种Dropout--Drop-path - wydbyxr的博客 - CSDN博客
2018年11月12日 11:37:09[whitenightwu](https://me.csdn.net/wydbyxr)阅读数：205
# Drop-path
  尽管ResNet在许多应用中已被证明很强大，但它的主要的缺点是，更深层的网络通常需要几周的时间进行训练，而这在实际应用中几乎不可行。为了解决这个问题，引入了一种在训练过程中随机丢弃图层的反直觉方法，同时使用完整的网络进行推理。
  作者使用残差块作为其网络的构建块，因此，在训练期间，当特定残差块被启用时，它的输入在身份近路和权重层流动，否则，输入只在身份近路流动。在训练时间内，每层都有“生存概率”，随机下降。在测试时间内，所有的块都保持活动状态，并在测试期间根据其生存概率进行重新校准。
  类似于Dropout，训练具有随机深度的深层网络可以被视为训练许多较小ResNets的合集。不同之处在于，该方法随机丢弃整个图层，而Dropout在训练期间仅将一部分隐藏单元下降。
  这种方法大大降低了训练时间，甚至我们可以在训练完成后，删除部分layer，同时还不影响精度。
