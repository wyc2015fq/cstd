# 机器学习习题（10） - 刘炫320的博客 - CSDN博客
2017年07月27日 09:50:43[刘炫320](https://me.csdn.net/qq_35082030)阅读数：1623
所属专栏：[机器学习习题集](https://blog.csdn.net/column/details/16442.html)
# 1. 前言
行百里者半于九十。此言末路之难也。
# 2. 习题
## 2.1 习题1（支持度）
> 
考虑如下数据集，其中Customer ID(顾客id),Transaction ID(事务id),Items Bought(购买项)。如果将每个事务id看成一个购物篮，计算项集{e}, {b, d}, {b, d, e}的支持度: 
![这里写图片描述](https://uploadfiles.nowcoder.com/images/20170701/3063430_1498890730885_0E712C6DC65FD7C1B383D9B4135BB940)
A.s({e}) =0.8s({b, d})= 0.2s({b, d, e})= 0.2
B.s({e}) =0.7s({b, d})= 0.3s({b, d, e})= 0.3
C.s({e}) =0.6s({b, d})= 0.4s({b, d, e})= 0.3
D.s({e}) =0.8s({b, d})= 0.1s({b, d, e})= 0.1
正确答案：A
解析：可以看到题目的意思是将每个事务id看成一个购物篮，因此，我们计算的值为s({e}) =$\frac{8}{10}$，s({b, d})=$\frac{2}{10}$，s({b, d, e})=$\frac{2}{10}$。
## 2.2 习题2（隐马尔可夫模型）
> 
解决隐马模型中预测问题的算法是?
A.前向算法
B.后向算法
C.Baum-Welch算法
D.维特比算法
正确答案：D
解析：
A、B：前向、后向算法解决的是一个评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型。
C：Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；
D：维特比算法解决的是给定 一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题。
## 2.3 习题3（K近邻算法）
> 
一般，k-NN最近邻方法在( )的情况下效果较好
A.样本较多但典型性不好
B.样本较少但典型性好
C.样本呈团状分布
D.样本呈链状分布
正确答案：B
解析：K近邻算法主要依靠的是周围的点，因此如果样本过多，那肯定是区分不出来的。因此应当选择B
样本呈团状颇有迷惑性，这里应该指的是整个样本都是呈团状分布，这样kNN就发挥不出其求近邻的优势了，整体样本应该具有典型性好，样本较少，比较适宜。
## 2.4 习题4（降维）
> 
下列方法中，可以用于特征降维的方法包括（）
A.主成分分析PCA
B.线性判别分析LDA
C.深度学习SparseAutoEncoder
D.矩阵奇异值分解SVD
E.最小二乘法LeastSquares
正确答案：ABCD
解析：降维的3种常见方法ABD，都是线性的。深度学习是降维的方法这个就比较新鲜了，事实上，细细想来，也是降维的一种方法，因为如果隐藏层中的神经元数目要小于输入层，那就达到了降维，但如果隐藏层中的神经元如果多余输入层，那就不是降维了。
最小二乘法是线性回归的一种解决方法，其实也是投影，但是并没有进行降维。
## 2.5 习题5（核方法）
> 
下面哪些是基于核的机器学习算法?()
A.Expectation Maximization（EM）（最大期望算法）
B.Radial Basis Function（RBF）（径向基核函数）
C.Linear Discrimimate Analysis（LDA）（主成分分析法）
D.Support Vector Machine（SVM）（支持向量机）
正确答案：BCD
解析：径向基核函数是非常常用的核函数，而主成分分析法的常规方法是线性的，但是当遇到非线性的时候，同样可以使用核方法使得非线性问题转化为线性问题。支持向量机处理非线性的问题的时候，核函数也是非常重要的。
# 3. 小结
本章中我们主要学习了支持度、隐马尔可夫模型、K近邻算法、降维和核方法的相关知识。
