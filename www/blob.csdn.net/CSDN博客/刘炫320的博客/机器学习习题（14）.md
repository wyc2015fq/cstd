# 机器学习习题（14） - 刘炫320的博客 - CSDN博客
2018年01月27日 13:09:01[刘炫320](https://me.csdn.net/qq_35082030)阅读数：967
所属专栏：[机器学习习题集](https://blog.csdn.net/column/details/16442.html)
本次习题则主要侧重于支持向量机、KNN和性能评估上。
> 
1.我们想要减少数据集中的特征数, 即降维. 选择以下适合的方案 :  
  (1)使用前向特征选择方法  
  (2)使用后向特征排除方法  
  (3)我们先把所有特征都使用, 去训练一个模型, 得到测试集上的表现. 然后我们去掉一个特征, 再去训练, 用交叉验证看看测试集上的表现. 如果表现比原来还要好, 我们可以去除这个特征  
  (4)查看相关性表, 去除相关性最高的一些特征 
  A. 1 和 2  
  B. 2, 3和4  
  C. 1, 2和4  
  D. All
参考答案: D 
解析： 
(1)前向特征选择方法和后向特征排除方法是我们特征选择的常用方法  
(2)如果前向特征选择方法和后向特征排除方法在大数据上不适用, 可以用这里第三种方法  
(3)用相关性的度量去删除多余特征, 也是一个好方法
所谓的前向特征选择法看起来很高大上，其实就是特征一个一个取，第一次取特征1，第二次取特征12，第三次取特征123…在试验中常用的方法。 
而后向特征排除法也一样，第一次取123，第二次取12，第三次取1这种。
所以D是正确的
> 
2.假如我们使用非线性可分的SVM目标函数作为最优化对象, 我们怎么保证模型线性可分？ 
  A. 设C=1  
  B. 设C=0  
  C. 设C=无穷大  
  D. 以上都不对
参考答案: C
解析：首先我们要知道C是什么，根据SVM的定义我们可以知道： 
![这里写图片描述](https://pic1.zhimg.com/80/1de6d986ed0b17cd90615544918461ec_hd.jpg)
C是作为对于误差项$\sum_{i=1}\xi_i$的关注程度。C越大对于误差的容忍度越小，也就是要保证准确度越高，容易出现过拟合现象。而C越小，则越不关注误差，只关注最大间隔的大小。这样容易欠拟合。
而题目中要保证线性可分，那么就要要求一定可以有一个界面需要完全的把两类数据分开，那么这样就要保证没有误差项，即C为无穷大。注意的是，这里我们使用的是非线性可分的SVM作为目标函数。
> - 我们想在大数据集上训练决策树, 为了使用较少时间, 我们可以 :  
  A. 增加树的深度  
  B. 增加学习率 (learning rate)  
  C. 减少树的深度  
  D. 减少树的数量
参考答案: C
解析： 
A.增加树的深度, 会导致所有节点不断分裂, 直到叶子节点是纯的为止. 所以, 增加深度, 会延长训练时间。 
B.决策树没有学习率参数可以调。(不像集成学习和其它有步长的学习方法) 
D.决策树只有一棵树, 不是随机森林。
由题目候选项的互斥性也可以知道，应当选择AC中的一项。
> 
4.使用k=1的KNN算法, 下图二类分类问题, “+” 和 “o” 分别代表两个类, 那么, 用仅拿出一个测试样本的交叉验证方法, 交叉验证的错误率是多少 : 
![这里写图片描述](https://img-blog.csdn.net/20171214144028390?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
  A. 0%  
  B. 100%  
  C. 0% 到 100%  
  D. 以上都不是
参考答案: B
解析： 
这道题为什么是100%呢？七月在线并未给出真正的解析。下面我们来深刻的了解一下为啥是100%.
首先我们先弄清楚k=1的KNN学习的结果是什么，如下图所示： 
![这里写图片描述](http://ww2.sinaimg.cn/mw690/c047247egw1f51hvumenjj20l20bugu8.jpg)
也就是说，K=1时，它是保证每个样本都是属于自己的范围。在训练样本上绝对是0误差。那么为什么对应这道题的时候错误率是100%呢？其原因有2，第一就是题目要求只使用1个测试样例，这点大家都能看到。第二个原因藏在了图里，仔细观察次可以发现，对于任意一点，距离它最近的点总是和自己的类别相反，当使用K=1的KNN时，它总是会被预测成相反的标签，这才是为什么错误率为100%的真正原因。
> 
5.”点击率问题”是这样一个预测问题, 99%的人是不会点击的, 而1%的人是会点击进去的, 所以这是一个非常不平衡的数据集. 假设, 现在我们已经建了一个模型来分类, 而且有了99%的预测准确率, 我们可以下的结论是 :  
  A. 模型预测准确率已经很高了, 我们不需要做什么了  
  B. 模型预测准确率不高, 我们需要做点什么改进模型  
  C. 无法下结论  
  D. 以上都不对
参考答案: B
解析：这道题其实也是有问题的，首先，这是一个不平衡的数据集，在之前我们讲过，对于不平衡数据集，使用准确率来作为评价指标是不合适的，因为这并不能体现模型的性能。
但是此题，给出了一个先验假设，那就是模型对于这种非常不平衡数据集的小类别是不可能学习的非常好的。因此才会说B，模型准确率不高。
> 
6.假设我们要解决一个二类分类问题, 我们已经建立好了模型, 输出是0或1, 初始时设阈值为0.5, 超过0.5概率估计, 就判别为1, 否则就判别为0 ; 如果我们现在用另一个大于0.5的阈值, 那么现在关于模型说法, 正确的是 : （C） 
  (1)模型分类的召回率会降低或不变  
  (2)模型分类的召回率会升高  
  (3)模型分类准确率会升高或不变  
  (4)模型分类准确率会降低 
  A. 1  
  B. 2  
  C.1和3  
  D. 2和4  
  E. 以上都不是
参考答案: A
解析： 
首先我们来回顾一下模型的准确率和召回率公式。
定义：TP(True-Positive)为把正例预测为正例的数目。FP则是把负例预测为正例的数目。TN则是把正例预测为负例的数目，而FN(False-Nagetive)则是把负例预测为负例的数目。
精确率：$P=\frac{TP}{TP+FP}$
准确率：$A=\frac{TP+FN}{ALL}$
召回率：$R=\frac{TP}{TP+TN}$
这里要记住的是（PRF）值其实是只能对一个类别进行评估，如果是对模型的分类效果进行评估，那么一定是对每个类别进行分别的评估后，再进行加权求和等操作才能出现最终的结果。
此题说是2分类问题，又没有给出评估类别，那么默认的均以正例来评估PRF值。
这里可以分几种情况讨论：
- 真实分布为0.5,修改后预测模型为0.7。 
在这种情况下，原来的准确率为1，修改后准确率下降。 
对于召回率来说，（TP+TN）=T不变，TP变少，TN变多，召回率降低。
- 真实分布为0.6,修改后预测模型为0.7。 
对于这种情况，准确率不好判断。 
对于召回率来说，（TP+TN）=T不变，TP变少，TN变多，召回率降低。
- 真实分布为0.7,修改后预测模型为0.7。 
在这种情况下，原来准确率不为1，修改后为1，准确率上升。 
对于召回率来说，由于TP和TN都未变，因此召回率不变。
- 真实分布为0.9,修改后预测模型为0.7。 
在这种情况下，准确率上升。 
对于召回率来说，由于TP和TN都未变，因此召回率不变。
> 
7.下图是同一个SVM模型, 但是使用了不同的径向基核函数的gamma参数, 依次是g1, g2, g3 , 下面大小比较正确的是 : 
![这里写图片描述](https://img-blog.csdn.net/20171214143727061?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzU1MTIyNDU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
  A. g1 > g2 > g3  
  B. g1 = g2 = g3  
  C. g1 < g2 < g3  
  D. g1 >= g2 >= g3  
  E. g1 <= g2 <= g3
参考答案: C
解析： gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。
RBF公式里面的sigma和gamma的关系如下： 
![这里写图片描述](https://img-blog.csdn.net/20150606105930104?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHVqaWFuZG9uZzE=/font/5a6L5L2T/fontsize/4/fill/I0JBQkFCMA==)
gamma的物理意义为RBF的幅宽，它会影响每个支持向量对应的高斯的作用范围，从而影响泛化性能。也就是gamma越大，sigmma越小， 会造成只会作用于支持向量样本附近，对于未知样本分类效果很差，存在训练准确率可以很高。也就是有可能会发生过拟合现象。
