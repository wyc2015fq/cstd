# 神经网络与深度学习（2） - 刘炫320的博客 - CSDN博客
2017年08月31日 10:34:59[刘炫320](https://me.csdn.net/qq_35082030)阅读数：767标签：[深度学习																[神经网络																[数据																[算法																[模型](https://so.csdn.net/so/search/s.do?q=模型&t=blog)](https://so.csdn.net/so/search/s.do?q=算法&t=blog)](https://so.csdn.net/so/search/s.do?q=数据&t=blog)](https://so.csdn.net/so/search/s.do?q=神经网络&t=blog)](https://so.csdn.net/so/search/s.do?q=深度学习&t=blog)
个人分类：[深度学习笔记](https://blog.csdn.net/qq_35082030/article/category/7137295)
所属专栏：[深度学习与神经网络课程笔记](https://blog.csdn.net/column/details/17134.html)
# 0. 写在前面
在这一章中，我们主要讨论的是什么让深度学习流行起来的原因，以及在这门课中，我们将会学到什么。
# 1.深度学习流行起来的原因
深度学习的理论都已经存在几十年了，包括从1982年开始的反向传播算法开始，或者是更早的感知机模型，那么为什么直到最近深度学习才开始流行起来呢。首先我们先看一个图： 
![这里写图片描述](https://img-blog.csdn.net/20170831101521500?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzUwODIwMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
这张图的x轴表示数据量的大小（这里的数据指的是有标注的数据），从左到右越来越大。y轴表示性能表现，从下到上越来越大，图中的红线表示传统的机器学习方法，可以看到，传统的机器学习算法随着数据量的增加有着性能瓶颈，而黄线则表示一个小规模的神经网络模型，蓝色的表示一个中规模的神经网络模型，绿色的表示大规模的神经网络模型。这样我们可以看到，虽然每个模型有着自己的瓶颈，但是神经网络模型是乐高积木一样，可以不断的变大，这样性能就可以不断的提升，如果你想达到右上角黑点的那个层次的性能表现（例如95%+的准确率），那基本上深度学习模型是你的首选。
这里还要提的一点是，在小规模数据集中，各个算法的性能表现都是势均力敌的，可能更多的受到特征和算法技巧上的影响。只有在大规模的数据下，神经网络模型才表现出稳定的优势。
事实上，深度学习流行的原因不仅仅是数据，还有计算力和算法。
在计算力上，我们可以看到越来越快的CPU，甚至更加适合深度学习的GPU，以及最新产物TPU，它把张量计算融入到了硬件中，这样就可以更加迅速的实现深度学习模型了。
在算法上，越来越多的算法上的创新推动着深度学习的速度越来越快。例如吴恩达举例的激活函数从Sigmoid函数转换到Relu函数，这样可以避免梯度消失问题，从而增加训练速度。
这一点是很重要的，因为训练速度意味着深度学习的迭代速度，也就是进化速度。整个深度学习的迭代周期如下： 
![这里写图片描述](https://img-blog.csdn.net/20170831102334422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzUwODIwMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
包括是三个部分：想法、编码和实验。如果实验过程很快，那么我们就可以更快的根据实验结果改进想法，从而改变编码，进行下一次实验。这样深度学习就会发展很快，从而更具有生产力。当然算法上的创新主要是为了提升训练速度（包括大名鼎鼎的1bit算法）。
# 2.未来计划
目前总共开设了5门课（4，5还未开放）。我们目前是在第一门，第一门课最后是让我们可以能够搭建一个神经网络模型。而第一门课则有4周时间。
第一周，我们进行简单的介绍，正如第一讲和这一讲的内容，能够让我们知道什么是神经网络和深度学习。
第二周，我们将介绍一些神经网络编程基础。了解神经网络的结构和算法过程，以及如何实现。接下来可能会进行自己实现算法。
第三周，将会编写含有隐含层的神经网络。这样才算一个真正的具有神经网络的特性。
第四周，将会实现一个多层的神经网络。
我想说的是，这和Keras不同之处在于，你可以更加清楚的了解整个神经网络的运行过程，而Keras只需要让你专注于模型，属于工程类，而真正要懂神经网络的话，还是需要自己从小开始搭建，尽管目前有Tensorflow、CNTK等框架供你实现，但是你还是要知道一些细节和原理。
# 3. 小结
这仅仅是一个开始，接下来才是干货。当然这仅仅是碎片式学习，我们也仅仅像正常上课一样，每次只上一点内容，这样方便大家阅读和学习。
