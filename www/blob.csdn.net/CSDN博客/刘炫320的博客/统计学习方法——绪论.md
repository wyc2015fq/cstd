# 统计学习方法——绪论 - 刘炫320的博客 - CSDN博客
2017年02月23日 16:37:11[刘炫320](https://me.csdn.net/qq_35082030)阅读数：420标签：[统计学																[机器学习																[统计学习																[经验风险																[模型](https://so.csdn.net/so/search/s.do?q=模型&t=blog)](https://so.csdn.net/so/search/s.do?q=经验风险&t=blog)](https://so.csdn.net/so/search/s.do?q=统计学习&t=blog)](https://so.csdn.net/so/search/s.do?q=机器学习&t=blog)](https://so.csdn.net/so/search/s.do?q=统计学&t=blog)
个人分类：[统计学习方法](https://blog.csdn.net/qq_35082030/article/category/6775564)
所属专栏：[统计学习方法笔记](https://blog.csdn.net/column/details/16460.html)
# 0.写在前面
这是统计学习方法的第一场讨论班。主要讨论在学习过程中的一些小问题。
# 1.统计学习和机器学习是否是等价？
在讨论班中第一个问题就是统计学习是不是机器学习。
观点1：统计学习就是机器学习
统计学习全称叫做统计机器学习，应该和机器学习是一样的，机器学习实际上也是使用的统计模型。
观点2：统计学习不是机器学习
统计学习主要是想依靠一种确切的概率分布来模拟整个模型。而机器学习更多的是追求结果的准确度，而对于模型并不需要知道的太清楚。
其实，就我个人而言，我认为，狭义的机器学习是统计学习的子集，或者说广义的机器学习不仅仅是统计机器学习。这要看你怎么理解了。
首先，例如像概念学习和基于实例的学习等等，它们其实并不考虑全局整个概率分布，也不会统计之前学过的所有数据，可能只是对于当前实例进行一个判断，这点我们之前都知道的。
另外，早在上世纪70年代80年代时，就已经有这方面的争论，但是并不是如此，它们争论的主要焦点在于机器学习是否可以使用统计的方法来进行试验。在早期，机器学习大部分是专家系统，更偏向于规则模型，而到了80年代以后，统计模型的机器学习才逐渐变为主流。就目前而言，这两种模型的机器学习都存在，只不过统计方法的机器学习占了主流，才会给我们印象中的这种统计学习=机器学习。
那么，其实统计学习主要包括：监督学习、半监督学习、非监督学习和强化学习（但是也不一定包括这最后一部分）。
统计学习方法的三要素为：模型、策略和算法。
后面介绍的许多统计学习方法，大部分是监督学习的，主要用于分类、标注、回归这三大问题。
# 2. 预测任务的类型
根据输入输出的形式不同，预测任务也分为不同的问题，下表总结了一下：
|输入格式|输出格式|预测任务类型|
|----|----|----|
|连续|连续|回归问题|
|不定|离散|分类问题|
|变量序列|变量序列|标注问题|
这样就很容易看出不同类别的不同问题类型了。
# 3. 模型的定义？
对于模型的确切定义又产生了一些歧义。在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。
但是就模型二字，我想应该选取模型的最后一种定义：
> 
对研究的实体进行必要的简化，并用适当的变现形式或规则把它的主要特征描述出来。所得到的系统模仿品称之为模型。
这里要提一下：
> 
方法=模型+策略+算法
这里模型是放在首位的。而且这里对于模型的假设空间来讲，则包含了巨册函数的集合或者是条件概率的集合。
# 4. 对于策略的选取标准
其实这一段就是告诉机器学习过程中的一种价值衡量标准，来告诉机器所运行程序的目的或者改进的方向。
通常使用损失函数和风险函数来度量，损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。但是具体应用上，其损失函数的具体表现形式也是不一致的，常用的统计学习中的损失函数有：
- 0-1损失函数
- 平方损失函数
- 绝对损失函数
- 对数损失函数
损失函数越小，则模型就越好。那怎么判别这个损失函数大小呢，使用的是预测值$f(X)$与真实值$Y$之间的差值。那么最终损失函数的期望就是
$R_exp(f)=E_p[L(Y,f(x))]=\int_{x*y}  L(y,f(x))P(x,y) dxdy $
但是实际上我们并不能得到那个准确的概率分布，因为如果我们知道这个概率分布了，就不需要再机器学习了。那现在进行评价好坏时，采用的是叫做“经验风险”的函数：
$R_{emp}(f)=\dfrac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))$
这里可以看出，其实对于经验风险的评估是基于一个个实例的误差所产生的平均错误，这也是为什么自从有了大数据以后，模型的效果成倍的提升。一旦数据量足够大，则拟合效果就会无限接近于真实模型。
这里顺便提一个小提问：
> 
学习方法对于未知数据的预测能力称为泛化能力。
# 5. 小结
就先整理一下这几个问题，再接下来的过程中，可能会有更多的疑问和答案，等待着我们去发掘。下期讨论班见。
