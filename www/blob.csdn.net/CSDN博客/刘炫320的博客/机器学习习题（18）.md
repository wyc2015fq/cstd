# 机器学习习题（18） - 刘炫320的博客 - CSDN博客
2018年11月06日 11:02:29[刘炫320](https://me.csdn.net/qq_35082030)阅读数：312
所属专栏：[机器学习习题集](https://blog.csdn.net/column/details/16442.html)
1、中文同义词替换时，常用到Word2Vec，以下说法错误的是
A. Word2Vec基于概率统计
B. Word2Vec结果符合当前语料环境
C. Word2Vec得到的都是语义上的同义词
D. Word2Vec受限于训练语料的数量和质量
参考答案：C
解析：Word2Vec是常用的词向量表示，它采用的是同等上下文环境下的词语具有相同的词向量，而并非相同的含义。例如，我使用和朋友聊天。我使用<微信>和朋友聊天。这两句话只要上下文一样，那么QQ和微信的词向量表示也相同。当然也有我爱<中国>和我爱<中华人民共和国>这两个词在语义上的表示是相同的。
2、假定你用一个线性SVM分类器求解二类分类问题，如下图所示，这些用红色圆圈起来的点表示支持向量
![在这里插入图片描述](https://julyedu-img-public.oss-cn-beijing.aliyuncs.com/Public/Image/Question/1525854173_143.png)
如果移除这些圈起来的数据，决策边界（即分离超平面）是否会发生改变？
A. 会
B. 不会
参考答案：A
解析：SVM的决策边界取决于支持向量，支持向量发生改变，其决策边界也会发生改变。
3、如果将数据中除圈起来的三个点以外的其他数据全部移除，那么决策边界是否会改变？
A.会
B.不会
参考答案：B
解析：同上题。
4、关于SVM泛化误差描述正确的是
A. 超平面与支持向量之间距离
B. SVM对未知数据的预测能力
C. SVM的误差阈值
参考答案：B
解析：统计学中的泛化误差是指对模型对未知数据的预测能力。
5、以下关于硬间隔hard margin描述正确的是
A. SVM允许分类存在微小误差
B. SVM允许分类是有大量误差
参考答案：A
解析：硬间隔的要求比较严格，只允许分类存在微小的误差。
6、训练SVM的最小时间复杂度为O(n2)，那么一下哪种数据集不适合用SVM?
A. 大数据集
B. 小数据集
C. 中等大小数据集
D. 和数据集大小无关
参考答案：A
解析：传统机器学习方法对于大数据集都具有一定的局限性，其根本原因在于多出来的数据并没有对模型有太大的性能提升。例如在SVM中，只是支持点具有分类作用。
7、SVM的效率依赖于
A. 核函数的选择
B. 核参数
C. 软间隔参数
D. 以上所有
参考答案; D
解析：分别具有够提高效率，降低误差和防止过拟合。
8、支持向量是那些最接近决策平面的数据点
A. 对
B. 错
参考答案：A
解析：支持向量就在间隔边界上。
9、SVM在下列那种情况下表现糟糕
A. 线性可分数据
B. 清洗过的数据
C. 含噪声数据与重叠数据点
参考答案：C
解析：当数据中含有噪声数据与重叠的点时，要画出干净利落且无误分类的超平面很难。
10、假定你使用了一个很大γ值的RBF核，这意味着：
A. 模型将考虑使用远离超平面的点建模
B. 模型仅使用接近超平面的点来建模
C. 模型不会被点到超平面的距离所影响
D. 以上都不正确
参考答案：B
解析：SVM调参中的γ衡量距离超平面远近的点的影响。
对于较小的γ，模型受到严格约束，会考虑训练集中的所有点。
对于较大的γ，模型仅使用接近超平面的点来建模。
