# KNN（六）--LSH算法 - 工作笔记 - CSDN博客





2016年07月22日 16:36:35[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：5473








LSH(Location Sensitive Hash),即位置敏感哈希函数。与一般哈希函数不同的是位置敏感性，也就是散列前的相似点经过哈希之后，也能够在一定程度上相似，并且具有一定的概率保证。


形式化定义：

对于任意q,p属于S，若从集合S到U的函数族H={h1,h2...hn}对距离函数D(,)，如欧式距离、曼哈顿距离等等，满足条件：

![image](http://hi.csdn.net/attachment/201005/28/0_1275042131VCyi.gif)

则称D(,)是位置敏感的。

如下图，空间上的点经位置敏感哈希函数散列之后，对于q，其rNN有可能散列到同一个桶（如第一个桶）,即散列到第一个桶的概率较大，会大于某一个概率阈值p1;而其(1+emxilong)rNN之外的对象则不太可能散列到第一个桶，即散列到第一个桶的概率很小，会小于某个阈值p2.

![image](http://hi.csdn.net/attachment/201005/28/0_1275042131m8SZ.gif)

LSH的作用

◆高维下近似查询

相似性检索在各种领域特别是在视频、音频、图像、文本等含有丰富特征信息领域中的应用变得越来越重要。丰富的特征信息一般用高维向量表示，由此相似性检索一般通过K近邻或近似近邻查询来实现。一个理想的相似性检索一般需要满足以下四个条件：

1. 高准确性。即返回的结果和线性查找的结果接近。

2. 空间复杂度低。即占用内存空间少。理想状态下，空间复杂度随数据集呈线性增长，但不会远大于数据集的大小。

3. 时间复杂度低。检索的时间复杂度最好为O（1）或O（logN)。

4. 支持高维度。能够较灵活地支持高维数据的检索。

传统主要方法是基于空间划分的算法——tree类似算法，如R-tree，Kd-tree，SR-tree。这种算法返回的结果是精确的，但是这种算法在高维数据集上的时间效率并不高。实验[1]指出维度高于10之后，基于空间划分的算法时间复杂度反而不如线性查找。LSH方法能够在保证一定程度上的准确性的前提下，时间和空间复杂度得到降低，并且能够很好地支持高维数据的检索。

◆分类和聚类

根据LSH的特性，即可将相近（相似）的对象散列到同一个桶之中，则可以对图像、音视频、文本等丰富的高维数据进行分类或聚类。

◆数据压缩。如广泛地应用于信号处理及数据压缩等领域的Vector Quantization量子化技术。 

总而言之，哪儿需要近似kNN查询，哪儿都能用上LSH.

[1] Weber R, Schek H, Blott S. A quantitative analysis and performance study for similarity search methods in high dimensional spaces Proc.of the 24th Intl.Conf.on Very Large Data Bases (VLDB).1998:194-205



