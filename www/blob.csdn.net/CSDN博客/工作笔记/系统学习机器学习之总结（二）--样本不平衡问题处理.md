# 系统学习机器学习之总结（二）--样本不平衡问题处理 - 工作笔记 - CSDN博客





2018年11月03日 10:14:08[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：5372








原文链接：[http://blog.csdn.net/heyongluoyao8/article/details/49408131](http://blog.csdn.net/heyongluoyao8/article/details/49408131)

解决这一问题的基本思路是让正负样本在训练过程中拥有相同的话语权，比如利用采样与加权等方法。为了方便起见，我们把数据集中样本较多的那一类称为“大众类”，样本较少的那一类称为“小众类”。 

解决方式分为： 

![](https://img-blog.csdnimg.cn/20181111111230433.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FwcF8xMjA2MjAxMQ==,size_16,color_FFFFFF,t_70)

一、相关方法总结

1、采样

采样方法是通过对训练集进行处理使其从不平衡的数据集变成平衡的数据集，在大部分情况下会对最终的结果带来提升。

采样分为上采样（Oversampling，过采样）和下采样（Undersampling， 欠采样），上采样是把小种类复制多份，下采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本。

随机采样最大的优点是简单，但缺点也很明显。上采样后的数据集中会反复出现一些样本，训练出来的模型会有一定的过拟合；而下采样的缺点显而易见，那就是最终的训练集丢失了数据，模型只学到了总体模式的一部分。

上采样会把小众样本复制多份，一个点会在高维空间中反复出现，这会导致一个问题，那就是运气好就能分对很多点，否则分错很多点。为了解决这一问题，可以在每次生成新数据点时加入轻微的随机扰动，经验表明这种做法非常有效。

——这一方式会加重过拟合！

因为下采样会丢失信息，如何减少信息的损失呢？

第一种方法叫做EasyEnsemble，利用模型融合的方法（Ensemble）：多次下采样（放回采样，这样产生的训练集才相互独立）产生多个不同的训练集，进而训练多个不同的分类器，通过组合多个分类器的结果得到最终的结果。简单的最佳实践是建立n个模型，每个模型使用稀有类别的所有样本和丰富类别的n个不同样本。假设想要合并10个模型，那么将保留例如1000例稀有类别，并随机抽取10000例丰富类别。然后，只需将10000个案例分成10块，并训练10个不同的模型。

第二种方法叫做BalanceCascade，利用增量训练的思想（Boosting）：先通过一次下采样产生训练集，训练一个分类器，对于那些分类正确的大众样本不放回，然后对这个更小的大众样本下采样产生训练集，训练第二个分类器，以此类推，最终组合所有分类器的结果得到最终结果。

第三种方法是利用KNN试图挑选那些最具代表性的大众样本，叫做NearMiss，这类方法计算量很大， 

感兴趣的可以参考“Learning from Imbalanced Data”这篇综述的3.2.1节。

2、 数据合成

数据合成方法是利用已有样本生成更多样本，这类方法在小数据场景下有很多成功案例，比如医学图像分析等。

其中最常见的一种方法叫做SMOTE，它利用小众样本在特征空间的相似性来生成新样本。

SMOTE为每个小众样本合成相同数量的新样本，这带来一些潜在的问题：一方面是增加了类之间重叠的可能性，另一方面是生成一些没有提供有益信息的样本。为了解决这个问题，出现两种方法：Borderline-SMOTE与ADASYN。

Borderline-SMOTE的解决思路是寻找那些应该为之合成新样本的小众样本。即为每个小众样本计算K近邻，只为那些K近邻中有一半以上大众样本的小众样本生成新样本。直观地讲，只为那些周围大部分是大众样本的小众样本生成新样本，因为这些样本往往是边界样本。确定了为哪些小众样本生成新样本后再利用SMOTE生成新样本。

ADASYN的解决思路是根据数据分布情况为不同小众样本生成不同数量的新样本。首先根据最终的平衡程度设定总共需要生成的新小众样本数量 G，然后为每个小众样本 xi 计算分布比例 

3、 加权

除了采样和生成新数据等方法，我们还可以通过加权的方式来解决数据不平衡问题，即对不同类别分错的代价不同，如下图：

![](https://img-blog.csdnimg.cn/20181111111310517.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FwcF8xMjA2MjAxMQ==,size_16,color_FFFFFF,t_70)

横向是真实分类情况，纵向是预测分类情况，C(i,j)是把真实类别为j的样本预测为i时的损失，我们需要根据实际情况来设定它的值。

这种方法的难点在于设置合理的权重，实际应用中一般让各个分类间的加权损失值近似相等。当然这并不是通用法则，还是需要具体问题具体分析。 

4、一分类

对于正负样本极不平衡的场景，我们可以换一个完全不同的角度来看待问题：把它看做一分类（One Class Learning）或异常检测（Novelty Detection）问题。这类方法的重点不在于捕捉类间的差别，而是为其中一类进行建模，经典的工作包括One-class SVM等。 

5、以正确的方式使用K-fold交叉验证

值得注意的是，使用过采样方法来解决不平衡问题时应适当地应用交叉验证。这是因为过采样会观察到罕见的样本，并根据分布函数应用自举生成新的随机数据，如果在过采样之后应用交叉验证，那么我们所做的就是将我们的模型过拟合于一个特定的人工引导结果。这就是为什么在过度采样数据之前应该始终进行交叉验证，就像实现特征选择一样。只有重复采样数据可以将随机性引入到数据集中，以确保不会出现过拟合问题。

K-fold交叉验证就是把原始数据随机分成K个部分，在这K个部分中选择一个作为测试数据，剩余的K-1个作为训练数据。交叉验证的过程实际上是将实验重复做K次，每次实验都从K个部分中选择一个不同的部分作为测试数据，剩余的数据作为训练数据进行实验，最后把得到的K个实验结果平均。 

6、基于聚类的重抽样方法

（1）首先分别对正负例进行K-means聚类

（2）聚类之后进行Oversampling等系列方法

举例说明，假设我们运行K-means方法分别对正负例进行了聚类，结果如下： 

正例三个簇，个数分别为：20 ， 5, 12 负例两个簇，个数分别为：4 ，6

可以看出，正负例簇中个数最大的为20，所以正例其他两个簇通过oversampling都提高到20个实例，负例簇都提高到（20+20+20）/2=30 个实例。

最后变为，正例三个簇：20,20,20 负例两个簇：30,30

总结下这种基于聚类的抽样算法的优点： 

该算法不仅可以解决类间不平衡问题，而且还能解决类内部不平衡问题。 

7、适应不平衡样本的模型

所有之前的方法都集中在数据上，并将模型保持为固定的组件。但事实上，如果设计的模型适用于不平衡数据，则不需要重新采样数据，著名的XGBoost已经是一个很好的起点，因此设计一个适用于不平衡数据集的模型也是很有意义的。

通过设计一个代价函数来惩罚稀有类别的错误分类而不是分类丰富类别，可以设计出许多自然泛化为稀有类别的模型。例如，调整SVM以惩罚稀有类别的错误分类。

二、如何选择

解决数据不平衡问题的方法有很多，上面只是一些最常用的方法，而最常用的方法也有这么多种，如何根据实际问题选择合适的方法呢：

在正负样本都非常之少的情况下，应该采用数据合成的方式；

在负样本足够多，正样本非常之少且比例及其悬殊的情况下，应该考虑一分类方法；

在正负样本都足够多且比例不是特别悬殊的情况下，应该考虑采样或者加权的方法。

采样和加权在数学上是等价的，但实际应用中效果却有差别。尤其是采样了诸如Random Forest等分类方法，训练过程会对训练集进行随机采样。在这种情况下，如果计算资源允许上采样往往要比加权好一些。

另外，虽然上采样和下采样都可以使数据集变得平衡，并且在数据足够多的情况下等价，但两者也是有区别的。实际应用中，我的经验是如果计算资源足够且小众类样本足够多的情况下使用上采样，否则使用下采样，因为上采样会增加训练集的大小进而增加训练时间，同时小的训练集非常容易产生过拟合。 

对于下采样，如果计算资源相对较多且有良好的并行环境，应该选择Ensemble方法。 

### 在分类中如何处理训练集中不平衡问题

  在很多机器学习任务中，训练集中可能会存在某个或某些类别下的样本数远大于另一些类别下的样本数目。即类别不平衡，为了使得学习达到更好的效果，因此需要解决该类别不平衡问题。

### [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) 的回复：

原文标题：[8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)

你在对一个类别不均衡的数据集进行分类时得到了90%的准确度（Accuracy）。当你进一步分析发现，数据集的90%的样本是属于同一个类，并且分类器将所有的样本都分类为该类。在这种情况下，显然该分类器是无效的。并且这种无效是由于训练集中类别不均衡而导致的。

  首先举几个所收到的邮件中关于类别不均衡的例子：
- 在一个二分类问题中，训练集中class 1的样本数比class 2的样本数是60:1。使用逻辑回归进行分类，最后结果是其忽略了class 2，即其将所有的训练样本都分类为class 1。
- 在分类任务的数据集中，有三个类别，分别为A，B，C。在训练集中，A类的样本占70%，B类的样本占25%，C类的样本占5%。最后我的分类器对类A的样本过拟合了，而对其它两个类别的样本欠拟合。

### 什么是类别不均衡问题

类别数据不均衡是分类任务中一个典型的存在的问题。简而言之，即数据集中，每个类别下的样本数目相差很大。例如，在一个二分类问题中，共有100个样本（100行数据，每一行数据为一个样本的表征），其中80个样本属于class 1，其余的20个样本属于class 2，class 1:class2=80:20=4:1，这便属于类别不均衡。当然，类别不均衡问同样会发生在多分类任务中。它们的解决方法是一样的。因此，为了便于讨论与理解，我们从二分类任务入手进行讲解。

### 类别不均衡问题是现实中很常见的问题

大部分分类任务中，各类别下的数据个数基本上不可能完全相等，但是一点点差异是不会产生任何影响与问题的。

  在现实中有很多类别不均衡问题，它是常见的，并且也是合理的，符合人们期望的。如，在欺诈交易识别中，属于欺诈交易的应该是很少部分，即绝大部分交易是正常的，只有极少部分的交易属于欺诈交易。这就是一个正常的类别不均衡问题。又如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）。一般而已，如果类别不平衡比例超过4:1，那么其分类器会大大地因为数据不平衡性而无法满足分类要求的。因此在构建分类模型之前，需要对分类不均衡性问题进行处理。

  在前面，我们使用准确度这个指标来评价分类质量，可以看出，在类别不均衡时，准确度这个评价指标并不能work。因为分类器将所有的样本都分类到大类下面时，该指标值仍然会很高。即，该分类器偏向了大类这个类别的数据。

### 八大解决方法
- **扩大数据集**

	当遇到类别不均衡问题时，首先应该想到，是否可能再增加数据（一定要有小类样本数据），更多的数据往往战胜更好的算法。因为机器学习是使用现有的数据多整个数据的分布进行估计，因此更多的数据往往能够得到更多的分布信息，以及更好分布估计。即使再增加小类样本数据时，又增加了大类样本数据，也可以使用放弃一部分大类数据（即对大类数据进行欠采样）来解决。
- 
**尝试其它评价指标**

	        从前面的分析可以看出，准确度这个评价指标在类别不均衡的分类任务中并不能work，甚至进行误导（分类器不work，但是从这个指标来看，该分类器有着很好的评价指标得分）。因此在类别不均衡分类任务中，需要使用更有说服力的评价指标来对分类器进行评价。如何对不同的问题选择有效的评价指标[参见这里](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)。

	  上面的超链接中的文章，讲述了如何对乳腺癌患者复发类别不均衡数据进行分类。在文中，推荐了几个比传统的准确度更有效的评价指标：

- 
混淆矩阵(Confusion Matrix)：使用一个表格对分类器所预测的类别与其真实的类别的样本统计，分别为：TP、FN、FP与TN。

- 精确度(Precision)
- 召回率(Recall)
- F1得分(F1 Score)：精确度与找召回率的加权平均。

特别是：
- Kappa ([Cohen kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa))
- 
ROC曲线(ROC Curves):见[Assessing and Comparing Classifier Performance with ROC Curves](https://machinelearningmastery.com/assessing-comparing-classifier-performance-roc-curves-2/)

- 
**对数据集进行重采样**

	 可以使用一些策略该减轻数据的不平衡程度。该策略便是采样(sampling)，主要有两种采样方法来降低数据的不平衡性。

- 
对小类的数据样本进行采样来增加小类的数据样本个数，即过采样（over-sampling ，采样的个数大于该类样本的个数）。

- 
对大类的数据样本进行采样来减少该类数据样本的个数，即欠采样（under-sampling，采样的次数少于该类样本的个素）。

        采样算法往往很容易实现，并且其运行速度快，并且效果也不错。更详细的内容参见[这里](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis)。


一些经验法则：
- 考虑对大类下的样本（超过1万、十万甚至更多）进行欠采样，即删除部分样本；
- 考虑对小类下的样本（不足1为甚至更少）进行过采样，即添加部分样本的副本；
- 考虑尝试随机采样与非随机采样两种采样方法；
- 考虑对各类别尝试不同的采样比例，比一定是1:1，有时候1:1反而不好，因为与现实情况相差甚远；
- 
考虑同时使用过采样与欠采样。

- 
**尝试产生人工数据样本**

	       一种简单的人工样本数据产生的方法便是，对该类下的所有样本每个属性特征的取值空间中随机选取一个组成新的样本，即属性值随机采样。你可以使用基于经验对属性值进行随机采样而构造新的人工样本，或者使用类似朴素贝叶斯方法假设各属性之间互相独立进行采样，这样便可得到更多的数据，但是无法保证属性之前的线性关系（如果本身是存在的）。

	  有一个系统的构造人工数据样本的方法SMOTE(Synthetic Minority Over-sampling Technique)。[SMOTE](http://blog.csdn.net/stranger_man/article/details/79055756)是一种过采样算法，它构造新的小类样本而不是产生小类中已有的样本的副本，即该算法构造的数据是新样本，原数据集中不存在的。该基于距离度量选择小类别下两个或者更多的相似样本，然后选择其中一个样本，并随机选择一定数量的邻居样本对选择的那个样本的一个属性增加噪声，每次处理一个属性。这样就构造了更多的新生数据。

- 
**尝试不同的分类算法**

	       强烈建议不要对待每一个分类都使用自己喜欢而熟悉的分类算法。应该使用不同的算法对其进行比较，因为不同的算法使用于不同的任务与数据。具体可以参见“[Why you should be Spot-Checking Algorithms on your Machine Learning Problems](https://machinelearningmastery.com/why-you-should-be-spot-checking-algorithms-on-your-machine-learning-problems/)”。

	       决策树往往在类别不均衡数据上表现不错。它使用基于类变量的划分规则去创建分类树，因此可以强制地将不同类别的样本分开。目前流行的决策树算法有：C4.5、C5.0、CART和Random Forest等。

- 
**尝试对模型进行惩罚**

       你可以使用相同的分类算法，但是使用一个不同的角度，比如你的分类任务是识别那些小类，那么可以对分类器的小类样本数据增加权值，降低大类样本的权值（这种方法其实是产生了新的数据分布，即产生了新的数据集，译者注），从而使得分类器将重点集中在小类样本身上。一个具体做法就是，在训练分类器时，若分类器将小类样本分错时额外增加分类器一个小类样本分错代价，这个额外的代价可以使得分类器更加“关心”小类样本。如penalized-SVM和penalized-LDA算法。

     Weka中有一个惩罚模型的通用框架[CostSensitiveClassifier](http://weka.sourceforge.net/doc.dev/weka/classifiers/meta/CostSensitiveClassifier.html)，它能够对任何分类器进行封装，并且使用一个自定义的惩罚矩阵对分错的样本进行惩罚。

	  如果你锁定一个具体的算法时，并且无法通过使用重采样来解决不均衡性问题而得到较差的分类结果。这样你便可以使用惩罚模型来解决不平衡性问题。但是，设置惩罚矩阵是一个复杂的事，因此你需要根据你的任务尝试不同的惩罚矩阵，并选取一个较好的惩罚矩阵。

- 
**尝试一个新的角度理解问题**

	     我们可以从不同于分类的角度去解决数据不均衡性问题，我们可以把那些小类的样本作为异常点(outliers)，因此该问题便转化为异常点检测(anomaly detection)与变化趋势检测问题(change detection)。

[异常点检测](https://en.wikipedia.org/wiki/Anomaly_detection)即是对那些罕见事件进行识别。如通过机器的部件的振动识别机器故障，又如通过系统调用序列识别恶意程序。这些事件相对于正常情况是很少见的。
[变化趋势检测](https://en.wikipedia.org/wiki/Change_detection)类似于异常点检测，不同在于其通过检测不寻常的变化趋势来识别。如通过观察用户模式或银行交易来检测用户行为的不寻常改变。

	  将小类样本作为异常点这种思维的转变，可以帮助考虑新的方法去分离或分类样本。这两种方法从不同的角度去思考，让你尝试新的方法去解决问题。

- 
**尝试创新**

	  仔细对你的问题进行分析与挖掘，是否可以将你的问题划分成多个更小的问题，而这些小问题更容易解决。你可以从这篇文章In classification, how do you handle an unbalanced training set?中得到灵感。例如：
- 将你的大类压缩成小类；
- 使用One Class分类器（将小类作为异常点）；
- 使用集成方式，训练多个分类器，然后联合这些分类器进行分类；

		….

这些想法只是冰山一角，你可以想到更多的有趣的和有创意的想法去解决问题。更多的想法参加Reddit的文章[http://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set](http://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set)。


### 选择某一种方法并使用它

  你不必成为一个精通所有算法的算法奇才或者一个建立准确而可靠的处理数据不平衡的模型的统计学家，你只需要根据你的问题的实际情况从上述算法或方法中去选择一种或两种方法去使用。希望上述的某些方法能够解决你的问题。例如使用其它评价指标或重采样算法速度快并且有效。

### 总结

  记住，其实并不知道哪种方法最适合你的任务与数据，你可以使用一些启发式规则或经验去选择某一个较优算法。当然最好的方法测试每一种算法，然后选择最好的方法。最重要的是，从点滴开始做起，根据自己现有的知识，并不断学习去一步步完善。

     这里有一些我认为有价值的可供参考的相关资料，让你进一步去认识与研究数据不平衡问题：

**相关书籍**

    Imbalanced Learning: Foundations, Algorithms, and Applications
**相关论文**

      Data Mining for Imbalanced Datasets: An Overview

      Learning from Imbalanced Data

      Addressing the Curse of Imbalanced Training Sets: One-Sided Selection (PDF)

      A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data

### [Sergey Feldman]()的回答：
- 
设超大类中样本的个数是极小类中样本个数的L倍，那么在随机梯度下降（SGD，stochastic gradient descent）算法中，每次遇到一个极小类中样本进行训练时，训练L次。

- 
将大类中样本划分到L个聚类中，然后训练L个分类器，每个分类器使用大类中的一个簇与所有的小类样本进行训练得到。最后对这L个分类器采取少数服从多数对未知类别数据进行分类，如果是连续值（预测），那么采用平均值。

- 设小类中有N个样本。将大类聚类成N个簇，然后使用每个簇的中心组成大类中的N个样本，加上小类中所有的样本进行训练。
- 
无论你使用前面的何种方法，都对某个或某些类进行了损害。为了不进行损害，那么可以使用全部的训练集采用多种分类方法分别建立分类器而得到多个分类器，采用投票的方式对未知类别的数据进行分类，如果是连续值（预测），那么采用平均值。

- 
在最近的[ICML](http://proceedings.mlr.press/v28/vandermaaten13.pdf)论文中，表明增加数据量使得已知分布的训练集的误差增加了，即破坏了原有训练集的分布，从而可以提高分类器的性能。这篇论文与类别不平衡问题不相关，因为它隐式地使用数学方式增加数据而使得数据集大小不变。但是，我认为破坏原有的分布是有益的。

- More details than you need: imho, the most interesting of the corrupting distributions is the blankout distribution, where you just zero out a random subset of features. Why is it interesting? Because you are helping your classifier be sturdier/hardier by giving it variations of your data that have essentially missing features. So it has to learn to classify correctly even in adverse conditions. 一个相关的想法是，在神经网络中，随机选择部分隐藏层单元来继续训练（即，随机去掉一部分隐藏层单元，(zeroed-out)）。具体见[http://web.stanford.edu/~sidaw/cgi-bin/home/lib/exe/fetch.php?media=papers:fastdropout.pdf](http://web.stanford.edu/~sidaw/cgi-bin/home/lib/exe/fetch.php?media=papers:fastdropout.pdf)

### [Kripa Chettiar](https://www.quora.com/profile/Kripa-Chettiar)的回答：
- 增加新数据，可以使用SMOTE或SMOTEBoost产生人造数据。
- 将大类压缩。压缩比例需要具体情况具体分析，取决于你所拥有的数据。例如，A类中有30个样本，B类中有4000个样本，那么你可以将B类压缩成1000（进行采样）。
- 可以结合1与2
- 对于那种极小类是异常点的分类任务，因此分类器需要学习到大类的决策分界面，即分类器是一个单个类分类器（One Class Classifier）。[Weka]()中有相关的库。

### Dan Levin的回答：

一个很好的方法去处理非平衡数据问题，并且在理论上证明了。这个方法便是由Robert E. Schapire于1990年在Machine Learning提出的”The strength of weak learnability” ，该方法是一个boosting算法，它递归地训练三个弱学习器，然后将这三个弱学习器结合起形成一个强的学习器。我们可以使用这个算法的第一步去解决数据不平衡问题。

  首先使用原始数据集训练第一个学习器L1。

  然后使用50%在L1学习正确和50%学习错误的的那些样本训练得到学习器L2，即从L1中学习错误的样本集与学习正确的样本集中，循环一边采样一个。

  接着，使用L1与L2不一致的那些样本去训练得到学习器L3。

  最后，使用投票方式作为最后输出。

  那么如何使用该算法来解决类别不平衡问题呢？

  假设是一个二分类问题，大部分的样本都是true类。让L1输出始终为true。使用50%在L1分类正确的与50%分类错误的样本训练得到L2，即从L1中学习错误的样本集与学习正确的样本集中，循环一边采样一个。因此，L2的训练样本是平衡的。L使用L1与L2分类不一致的那些样本训练得到L3，即在L2中分类为false的那些样本。最后，结合这三个分类器，采用投票的方式来决定分类结果，因此只有当L2与L3都分类为false时，最终结果才为false，否则true。

  自己已经在实践中使用过很多次，并且效果都不错。

### [Kaushik Kasi](https://www.quora.com/profile/Kaushik-Kasi)的回答：
- 对小类中的样本进行复制以增加该类中的样本数，但是可能会增加bias。
- 对小类中的样本通过调整特征值来人工生成样本，而使得该类中样本个数增多。如在图像中，对一幅图像进行扭曲得到另一幅图像，即改变了原图像的某些特征值。但是该方法可能会产生现实中并存在的样本。

### [Muktabh Mayank](https://www.quora.com/profile/Muktabh-Mayank)的回答：

这里有一个类似SVM的方法来处理不平衡问题。具体[参见这里](https://hal.inria.fr/hal-01087452/document)。  



