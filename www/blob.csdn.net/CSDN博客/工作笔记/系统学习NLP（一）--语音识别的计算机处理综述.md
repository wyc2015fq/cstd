# 系统学习NLP（一）--语音识别的计算机处理综述 - 工作笔记 - CSDN博客





2018年10月05日 14:16:09[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：6580








参考：[https://blog.csdn.net/u012637501/article/details/42424961](https://blog.csdn.net/u012637501/article/details/42424961)

从这个月开始，进入NLP方向，《自然语言处理综论》这本书有将近五章介绍了语音的计算机处理，作为阅读笔记又不高兴手打，所以，参考了这篇博客（因为内容差不多类似）。略删改。

另外，本书没有深度学习部分的应用，因此，这里只介绍传统语音识别算法。主要还是针对ASR的系统介绍。

语音识别技术，广泛来说是指语意识别和声纹识别；从狭义上来说指语音语义的理解识别，也称为自动语音识别(ASR)。其关键技术包括选择识别单元、语音端点检测、特征参数提取、声学模型及语音模型的建立。语音识别技术目前在桌面系统、智能手机、导航设备等嵌入式领域均有一定程度的应用。其主要技术难题是识别系统的适应性较差、受背景噪声影响较大，未来的发展方向应是无限词汇量连续语音非特定人语音识别系统。

**(1)信号处理及特征提取模块**

    该模块的主要任务是从输入信号中提取特征，供声学模型处理。同时，它一般也包括了一些信号处理技术，以尽可能降低环境噪声、信道、说话人等因素对特征造成的影响。

**(2)统计声学模型**

    典型系统多采用基于一阶隐马尔科夫模型进行建模。（这里不全对，实际上是GMM-HMM，因为GMM建模观察似然度也是很重要的一个点）

**(3)发音词典**

    发音词典包含系统所能处理的词汇集及其发音。发音词典实际提供了声学模型建模单元与语言模型建模单元间的映射。

**(4)语言模型**

    语言模型对系统所针对的语言进行建模。理论上，包括正则语言，上下文无关文法在内的各种语言模型都可以作为语言模型，但目前各种系统普遍采用的还是基于统计的N元文法及其变体。

**(5)解码器**

    解码器是语音识别系统的核心之一，其任务是对输入的信号，根据声学、语言模型及词典，寻找能够以最大概率输出该信号的词串，从数学角度可以更加清楚的了解上述模块之间的关系。

    当今语音识别技术的主流算法，主要有基于动态时间规整(DTW)算法、基于非参数模型的矢量量化(VQ)方法、基于参数模型的隐马尔可夫模型(HMM)的方法、基于人工神经网络(ANN)和支持向量机等语音识别方法.

二、非特定人、大词汇量、连续语音识别系统（LVCSR）

       连续数字语音识别系统经过训练和识别两个部分。此训练可以看作是对 HMM 建立模型的过程。通过对参数重新评估，调整模型的各种参数，得到具有较好鲁棒性的模型。对基本模型进行改进和优化，可以有效提高精确度，获得更好的识别率。识别过程则可以认为是使用现有的 HMM 模型库、数据字典和语法控制组成识别网络，运用搜索算法寻找最佳匹配过程。 首先对等待识别的语音信号进行采样，然后通过转换变成电信号。预处理这 些电信号，也就是对信号进行增加预重、帧数分离、检测端点等操作。处理过后，对语音信号提炼生成特征的矢量数据。按识别模块中的 HMM 模型和词典要求组合，形成合词模型后完成识别，将结果和语言模型进行匹配，淘汰那些不符合语法限制的句子和词组，最后输出符合规范的识别的过程，就是语音识别的全过程。特征值、HMM 模 型、语法和数据字典都是影响识别率高低的重要因素。

    语音识别过程通常包括"前段"和"后端"两部分：“前端”模块 主要的作用是进行端点检测（去除多余的静音和非说话声）、降噪、 特征提取等；“后端”模块的作用是利用训练好的声学模型和语言模型对用户说话的特征向量进行统计模式识别（又称解码），得到其包含的文字信息，此外，后端模块还存在一个自适应的反馈模块，可以对用户的语音进行自学习，从而对声学模型和语音模型进行必要的校正，进一步提高识别的准确率。一个完整的非特定人大词汇量连续语音识别系统可大致分为三部分：语音信号预处理与特征提取、声学模型训练、语言模型训练、搜索算法与识别。

**0.识别单元的选择**

   选择识别单元是[语音识别](http://lib.csdn.net/base/vras)研究的第一步，分为单词、音节、音素。

(1)单词单元：广泛应用于中小词汇语音识别系统，但不适合大词汇系统，原因在于模型库太庞大，训练模型任务繁重、模型匹配[算法](http://lib.csdn.net/base/datastructure)复杂，难以满足实时性要求。

(2)音节单元：多见于汉语语音识别，主要因为汉语是单音节结构的语言，而英语是多音节。虽然汉语大约有1300个音节，但若不考了声调只有约408个无调音节。

(3)音素单元：目前广泛被应用到大词汇量语音识别系统中，原因是在于汉语音节仅有声明和韵母构成，并且声明和韵母的声学特性相差很大。

    总结，对大词汇量语音识别系统来说，通常识别单元越小，则计算量也越小，所需的模型存储量也小，要求的训练数量也少，但对应语音段的定位和分割较困难，因此识别模型规则也变得更复杂。

**1、预处理模块**

       对输入的原始语音信号进行处理(输入的语言信号首先要进行反混叠滤波、 采样、 A/D 转换等过程进行数字化， 之后要进行预处理， 包括预加重、 加窗和 分帧、 端点检测等。)，滤除掉其中的不重要的信息以及背景噪声，并进行语音信号的端点检测（找出语音信号的始末）、语音分帧（近似认为在10-30ms内是语音信号是短时平稳的，将语音信号分割为一段一段进行分析）以及预加重（提升高频部分）等处理。

目前主流的语音信号端点检测方法：

(1)短时能量En:反应语音振幅或能量随着事件缓慢变化的规律；

(2)短时平均过零率Zn:对于离散信号而言，是样本改变符号的次数，可以粗略分别清音和浊音；

(3)双门限端点检测：短时平均能量和过零率两者结合可以起到区分语音信号中的静音与语音信息的作 用，完成端点检测。一段完整的语音信号的可以分为三段：静音段、过渡段、语音段。 在静音段，过零率或能量越过了低门限，进入过渡段。在过渡段，过零率或能量都降低至低门限以下，则恢复到静音态；过零率或能量中的其中一个越过了高门限，则为进入了语音段。在低噪声情况下，双门限端点检测简单可靠。但在噪声较大的情况下，该方法失去判断能力，所以此方法的抗噪能力较差。 

**2、声学特征提取**

       语音信号是一种典型的时变信号，然而如果把音频的参考时间控制在几十毫 秒以内，则得到一段基本稳定的信号。去除语音信号中对于语音识别无用的冗余信息，保留能够反映语音本质特征的信息，并用一定的形式表示出来。也就是提取出反映语音信号特征的关键特征参数形成特征矢量序列，去掉那些相对无关的信息如背景噪声、信道失真等，以便用于后续处理。目前的较常用的提取特征的方法还是比较多的，不过这些提取方法都是由频谱衍生出来的。

目前主流的语音信号特征提取方法：

(1)线性预测系数(LPCC)：很好的模拟语音信号，语音信号是由声带振动发出的， 声带可以不振动也可以有周期的振动，分别对应清音（consonants）和浊音（vowels），每一段声管则对应一个 LPC 模型的极点。通常极点个数在 12-16 个左右，即可清晰地描述信号的特征了。

(2)Mel频率倒谱系数（MFCC)参数

   人的听觉系统却是一种特殊的非线性系 统，它对不同频率信号的响应灵敏度有较大区别。 MFCC参数比 LPC 参数更能够充分利用人耳的感知特性提高系统的识别性能，因其良好的抗噪性和鲁棒性而应用广泛。MFCC的计算首先用FFT将时域信号转化成频域，之后对其对数能量谱用依照Mel刻度分布的三角滤波器组进行卷积，最后对各个滤波器的输出构成的向量进行离散余弦变换DCT，取前N个系数。在sphinx中也是用MFCC特征的，用帧frames去分割语音波形，每帧大概10ms，然后每帧提取可以代表该帧语音的39个数字，这39个数字也就是该帧语音的MFCC特征，用特征向量来表示。

(3)小波分析

3**、声学模型训练(模版匹配方法)**

      声学模型的训练，即为建模过程。声学模型是识别系统的底层模型，是语音识别系统中最关键的部分。声学模型表示一种语言的发音声音，可以通过训练来识别某个特定用户的语音模式和发音环境的特征。根据训练语音库的特征参数训练出声学模型参数，在识别时可以将待识别的语音的特征参数同声学模型进行匹配与比较，得到最佳识别结果。

目前主流的声学模型训练方法：

(1)动态时间规整(DTW)：现实生活中语音信号的 随机性较强，就是同一人说的话，也不太可能说出一句一模一样的话来。就算字词都一样，发音的时间长短也可能不一样。因此，需要寻找一种变换关系来削除这种时间上的距离偏差，这种结合时间变换关系求特征序列之间距离的技术算法 称为动态时间规整算法(DTW：DynamicTimeWarping)。动态时间规整(DTW)算法 的算法的思想，就是将待识别的语音信号均匀的升长或缩短，使其与参考模板的长度一致。同时，使语音信号的时间轴进行不均匀的扭曲和弯折，最终达到与模板的特征对齐。DTW 是较早的一种模式匹配和模型训练技术， 它把整个单词作为识别单元，在训练阶段将词汇表中每个词的特征矢量序列作为模板存入模板库，在识别阶段将待识别语音的特征矢量序列依次与库中的每个模板进行相似度比较，将相似度最高者作为识别结果输出。DTW 应用动态规划方法成功解决了语音信号特征参数序列比较时时长不等的难题，在小词汇量、孤立词语音识别中获得了良好性能。但因其不适合连续语音大词汇量语音识别系统， 目前已逐渐被 HMM 和 ANN模型替代。

(2)矢量量化（VQ）技术

    矢量量化(VectorQuantization)是一种适用于小词汇量、孤立词的语音识别的 信号压缩方法 。矢量量化器的设计其核心思想是：为某一个特定的信源设计一 个优化的码书，那么来自同一个信息源所产生的信号与该码书的平均量化失真就应远远小于他与其他信息的信号与该码书的平均量化失真，也就是说编码器本身存在一定的区分能力。 

(3)隐马尔可夫模型HMM 

     HMM是对语音信号的时间序列结构建立统计模型，将其看作一个数学上的双重随机过程:一个是用具有有限状态数的Markov链来模拟语音信号统计特性变化的隐含（马尔可夫模型的内部状态外界不可见）的随机过程，另一个是与Markov链的每一个状态相关联的外界可见的观测序列（通常就是从各个帧计算而得的声学特征）的随机过程。

    HMM 模型是语音信号时变特征的有参表示法。它由相 互关联的两个随机过程共同描述信号的统计特性，其中一个 是隐蔽的 （不可观测的） 具有有限状态的 Markor 链， 另一个是 与 Markor 链的每一状态相关联的观察矢量的随机过程 （可观测的） 。HMM 很好的模拟了人得语言过程， 目前应用十分广泛。目前的主流语音识别系统多采用隐马尔可夫模型HMM进行声学模型建模。声学模型的建模单元，可以是音素，音节，词等各个层次。对于小词汇量的语音识别系统，可以直接采用音节进行建模。而对于词汇量偏大的识别系统，一般选取音素，即声母，韵母进行建模。识别规模越大，识别单元选取的越小。 

        人的言语过程实际上就是一个双重随机过程，语音信号本身是一个可观测的时变序列，是由大脑根据语法知识和言语需要（不可观测的状态）发出的音素的参数流（发出的声音）。HMM合理地模仿了这一过程，是较为理想的一种语音模型。用HMM刻画语音信号需作出两个假设，一是内部状态的转移只与上一状态有关，另一是输出值只与当前状态（或当前的状态转移）有关，这两个假设大大降低了模型的复杂度。所以 HMM 可以 非常精确地描述语音信号的产生过程。 

       语音识别中使用HMM通常是用从左向右单向、带自环、带跨越的拓扑结构来对识别基元建模，一个音素就是一个三至五状态的HMM，一个词就是构成词的多个音素的HMM串行起来构成的HMM，而连续语音识别的整个模型就是词和静音组合起来的HMM。总之 HMM 模型较为完整的表达了语音的声学模型，采用统计的训练方法将 上层的语言模型和底层的声学模型融入统一的语音识别搜索算法中，并获得更好 的效果。

![](https://img-blog.csdn.net/20150105165617803?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjYzNzUwMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

(4)人工神经网络模型(ANN)

     神经网络是由许多被称为节点的简单非线性模拟处理要素密集互连配置而成的，是 一种模仿了生物神经元的系统模型。网络通过令每一个节点的输出与一些其他的节点输入连接形成，类似于真实神经元的突触连接。每个神经元表达了一种特定的输出函数，称为激励函数，每两个神经元之间的连接都包含一个连接强度，也就是作用于通过该连接的信号的加权值。经过训练之后的神经网络，具有信息特征抽取、知识概括和学习记忆的能力，而模型学习到的信息或知识则储存在每个单元节点之间的连接矩阵上。一个神经网络的表现是由节点定义，拓扑结构以及学习算法这三个特征组成的集体性质决定的。 

   ANN本质上是一个自适应非线性动力学系统，是由结点互连组成的计算网络， (优点)人工神经网络(ANN) 基本上能够模拟人类神经的活动原理，具有学习特性、容错性、并行性、自适应性和鲁棒性，是一个自适应非线性动力学系统，且具有较强的分类能力和输入输出映射能力。这些能力是 HMM 模型不具备的， 可用于处理一些环境信息十分复杂， 背景知识不清楚， 推理规则不明确的问题， 允许样品有较大的缺损、 畸变， 因此对于噪声环境下非特定人的语音识别问题来说是一种很好的解决方案。(缺点)但由于语音训练和识别时间太长，实现和应用较难等不利因素，所以到目前为止该方法停留在实验阶段，目前大部分应用神经网络的语音识别系统都采用了 BP 网并取得了较好的识别效果.将 ANN 与 HMM 结合分别利用各自优点进行识别将是今后的一条研究途径。ANN 具有 较好的区分复杂分类边界的能力，显然它十分有助于模式识别。在这些研究中，大部分 

采用基于反向传播算法(BP 算法)的多层感知网络。 

a.BP神经网络：BP 神经网络在训练的时候，正向传播之后输出层没有得到期望输出，则采用反向传 播算法，提高网络系统对样本的似然度(Likelihood)。将样本的实际输出与期望输出之间的差值即误差信号，并在逐层反向传播的过程中由误差反馈不断调整网络的权值。网络学习效果的提升可以由增加隐藏层层数实现。 在诸多神经网络中，BP 是应用较多的一种，用于语音识别时也具有较好的效果，这 是由于 BP 神经网络具有许多独特的优点：（1）它可以联想模式对，将复杂的声学信号映射为不同级别的语音学和音韵学的表示；（2）可以通过插值进行归纳，因此相关特征 

可通过训练获取（3）对不同的类，他可以在超平面中形成不相交的区域，很适合捕捉细微的规律；（4）输入可以是二值或连续值，也可以是声学属性或语音特征的任意组合； （5）对数据的分布不做先验假设，对模型使用全局约束，因此能构造光滑的类边界， 识别精度好。虽然 BP 神经网络具有强大的计算能力，能够好的应用于语音识别，但随着对识别 性能要求的提高，网络本身仍有一些问题逐渐暴露出来，以下方面亟待改进： 

（1）局部极小值问题； 

（2）增加神经网络的可理解性。人们暂时仍然无法直接理解网络学习存储在连接矩阵上的知识； 

（3）加快神经网络学习速度。目前大部分神经网络算法都无法回避的一个部分就是迭代问题，为了获得好的学习效果，迭代需要大的计算开销。 

b.神经网络训练

    神经网络的学习也称为训练，是指通过神经网络所在环境的刺激作用，调整神经网 络的自由参数。能够从环境中学习和在学习中获得系统工作效果提升，是神经网络最有意义的性质。在神经网络中，一般有两类训练算法。 

（1）有监督学习算法。不但需要训练用的输入信号，同时需要与输入相对应的表示所需输出的目标信号。网络通过计算实际输出与每组输入对应的目标输出之间的差值来调整权值，做出正确反应。 

（2）无监督学习算法。不要求有目标输出，算法提供一个关于网络学习表示方法质量的测量尺度，根据尺度将自由参数最优化，当网络与输入数据统计规律性一致，就能形成内部表示方法记忆输入特征，由此进行类别识别。 

**4、语言模型训练**

       语音识别中的语言模型主要解决两个问题，一是如何使用数学模型来描述语音中词的语音结构；二是如何结合给定的语言结构和模式识别器形成识别算法。语言模型是用来计算一个句子出现概率的概率模型。它主要用于决定哪个词序列的可能性更大，或者在出现了几个词的情况下预测下一个即将出现的词语的内容。换一个说法说，语言模型是用来约束单词搜索的。它定义了哪些词能跟在上一个已经识别的词的后面（匹配是一个顺序的处理过程），这样就可以为匹配过程排除一些不可能的单词。语言模型一般指在匹配搜索时用于字词和路径约束的语言规 则，它包括由识别语音命令构成的语法网络或由统计方法构成的语言模型， 语言处理则可以进行语法、 语义分析.

       语言建模能够有效的结合汉语语法和语义的知识，描述词之间的内在关系，从而提高识别率，减少搜索范围。语言模型分为三个层次：字典知识，语法知识，句法知识。

         对训练文本[数据库](http://lib.csdn.net/base/mysql)进行语法、语义分析，经过基于统计模型训练得到语言模型。

目前主流的语言建模方法：

(1)基于规则模型

(2)基于统计模型

    统计语言模型是用概率统计的方法来揭示语言单位内在的统计规律，其中N-Gram模型简单有效，被广泛使用。它包含了单词序列的统计。N-Gram模型基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积(即根据前面N-1个词汇的历史来决定下一个词可能出现的概率)。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。

         Sphinx中是采用二元语法和三元语法的统计语言概率模型，也就是通过前一个或两个单词来判定当前单词出现的概率P(w2| w1)，P(w3| w2, w1)。

**5、语音解码和搜索算法**

       解码器：即指语音技术中的识别过程。针对输入的语音信号，根据己经训练好的HMM声学模型、语言模型及字典建立一个识别网络，根据搜索算法在该网络(识别网络)中寻找最佳的一条路径，这个路径就是能够以最大概率输出该语音信号的词串，这样就确定这个语音样本所包含的文字了。所以解码操作即指搜索算法：是指在解码端通过搜索技术寻找最优词串的方法。连续语音识别中的搜索，就是寻找一个词模型序列以描述输入语音信号，从而得到词解码序列。搜索所依据的是对公式中的声学模型打分和语言模型打分。在实际使用中，往往要依据经验给语言模型加上一个高权重，并设置一个长词惩罚分数。当今的主流解码技术都是基于Viterbi搜索算法的，Sphinx也是。模型参数得到后可以用 Viterbi 算法来确定与观察序列对 应的最佳的状态序列。建好模型后，在识别阶段就是要计算每个模型产生观察符号序列的输出概率，输出概率最大的模型所表示的词就是我们的识别结果。

    基于动态规划的Viterbi算法在每个时间点上的各个状态，计算解码状态序列对观察序列的后验概率，保留概率最大的路径，并在每个节点记录下相应的状态信息以便最后反向获取词解码序列。Viterbi算法本质上是一种动态规划算法，该算法遍历HMM状态网络并保留每一帧语音在某个状态的最优路径得分。

    连续语音识别系统的识别结果是一个词序列。解码实际上是对词表的所有词反复搜索。词表中词的排列方式会影响搜索的速度，而词的排列方式就是字典的表示形式。Sphinx系统中采用音素作为声学训练单元，通常字典就用来记录每个单词由哪些个音素组成，也可以理解为对每个词的发音进行标注。

     N-best搜索和多遍搜索：为在搜索中利用各种知识源，通常要进行多遍搜索，第一遍使用代价低的知识源（如声学模型、语言模型和音标词典），产生一个候选列表或词候选网格，在此基础上进行使用代价高的知识源（如4阶或5阶的N-Gram、4阶或更高的上下文相关模型）的第二遍搜索得到最佳路径。



