# 人脸对齐（十）--人脸对齐综述（综述及2D人脸对齐总结2018.8） - 工作笔记 - CSDN博客





2018年08月17日 15:55:19[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：6405
所属专栏：[机器视觉](https://blog.csdn.net/column/details/33959.html)









转自：[https://blog.csdn.net/zhangjunhit/article/details/78435972](https://blog.csdn.net/zhangjunhit/article/details/78435972) 略删改（红色为个人理解，不对之处，欢迎指正）

Face Alignment In-the-Wild: A Survey

Computer Vision and Image Understanding Volume 162, September 2017, Pages 1-22
[https://www.sciencedirect.com/science/article/pii/S1077314217301455](https://www.sciencedirect.com/science/article/pii/S1077314217301455)

本文主要是这篇文章的翻译，后面增加具体的算法理解。

还有另一篇综述文献（内容好像截止2013年）

Facial feature point detection: A comprehensive survey

Neurocomputing Available online 1 June 2017
[http://www.sciencedirect.com/science/article/pii/S0925231217308202](http://www.sciencedirect.com/science/article/pii/S0925231217308202)

人脸对齐的定义： face alignment can be formulated as a problem of searching over a face image for the pre-defined facial points (also called face shape), which typically starts from a coarse initial shape, and proceeds by refining the shape estimate step by step until convergence。During the search process, two different sources of information are typically used: facial appearance and shape information. The latter aims to explicitly model the spatial relations between the locations

of facial points to ensure that the estimated facial points can form a valid face shape.

人脸对齐可以看作在一张人脸图像搜索人脸预先定义的点（也叫人脸形状），通常从一个粗估计的形状开始，然后通过迭代来细化形状的估计。在搜索的过程中，两种不同的信息被使用，一个是人脸的外观 appearance ，另一个是形状。形状提供一个搜索空间上的约束条件

在人脸检测的基础上，根据输入的人脸图像，自动定位出面部关键特征点，如眼睛、鼻尖、嘴角点、眉毛以及人脸各部件轮廓点等，输入为人脸外观图像，输出为人脸的特征点集合，见下图：

![](https://img-blog.csdn.net/20180817155843979?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FwcF8xMjA2MjAxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![这里写图片描述](https://img-blog.csdn.net/20171103151858883?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

人脸对齐是一个中间步骤，首先是人脸检测，然后是人脸对齐，人脸对齐的结果可以用于：

人脸识别、Face recognition，属性计算、Attribute computing，表情识别、Expression recognition

人脸对齐难点：姿态，遮挡，表情，光照
![这里写图片描述](https://img-blog.csdn.net/20171103152144269?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

这里我们首先将人脸对齐算法分为两大类： generative and discriminative

1） Generative methods 这类方法对人脸形状和外观都建立 generative models，将人脸对齐问题看作一个搜索 shape and appearance 参数的优化问题

2）Discriminative methods 这类方法直接分别训练特征点检测器，这些点的位置受到形状的约束

其实，生成方法，就是用你数据学习联合概率模型P（x,y）,再求出条件概率分布P（Y|X）作为预测，因为模型表示了给定数据X，生成Y的生成关系，所以，在人脸对齐里，就是用最优化方法得到全局表观模型再预测，判别模式就是用数据直接学习P（Y|X），只关心给定X预测什么样的Y输出，因此，不完全受全局模型的影响（外在约束不算）

![这里写图片描述](https://img-blog.csdn.net/20171103155222297?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![这里写图片描述](https://img-blog.csdn.net/20171103155231265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

下面我们来深入这两类方法

3 Generative methods

因为人脸的形状和外观多变性，通常我们将人脸建模为 deformable objects。用于人脸对齐的 Generative methods 对人脸外观构建 parametric models，拟合生成模型的目标是找到一组形状和外观参数可以得到一个最符合测试人脸图像的生成模型。基于人脸特征表示的类型，生成模型方法可以进一步细分为基于整体表示的 Active Appearance Models (AAMs) 和基于局部表示的 part-based generative deformable models

3.1.1. Basic AAM algorithm: modeling and fitting

基本的 Active Appearance Models (AAMs) 算法包括 modeling and fitting 两个部分：

AAM modeling包括 shape model, appearance model, and motion model

AAM fitting 这个拟合主要是寻找测试图像 test image 和 参考图像 reference image 之间的映射关系

3.1.2. Recent advances on AAMs

近年来针对AAMs的改进主要在三个方面：

(1) unconstrained training data [22], 现实场景的训练数据

(2) robust image representations [75, 76] 新的特征表示方法

(3) robust and fast fitting strategies [75, 22] 新的拟合算法

3.1.3 Discussion

AAMs 的缺点:

1）因为 holistic appearance model （也就是全局表观模型）被使用，局部遮挡情况难以被解决

2）appearance parameter 维数很高，导致难优化，容易收敛于局部极小值

3.2. Part-based generative deformable models

Part-based generative methods build generative appearance models for facial parts, typically with a shape model to govern the deformations of the face shapes

局部生成方法对人脸局部特征建立 generative appearance models，并使用一个 shape model 分析人脸形状的变形

一般来说有两类方法构建 generative part models：一个是对每个人脸局部特征构建独立的 appearance model，另一个是 对所有的人脸局部特征同时构建 generative models

Part-based generative methods 优点：

more robust to global lighting and occlusion in wild conditions， easier to optimize

随着现实场景训练数据的增加， discriminative methods 在人脸对齐中的优势比较明显

4 Discriminative methods

Discriminative face alignment methods seek to learn a (or a set of) discriminative function that directly maps the facial appearance to the target facial points

这里有分两条技术线路：

1）The first line is to follow the “divide and conquer”strategy by learning discriminative local appearance model (detector or regressor) for each facial point, and a shape model to impose global constraints on these local models（训练单点或者局部分类/检测器，这些点或者块受全局形状模型约束，如DPM,CLM，也就是分步解决）

2）The second line is to directly learn a vectorial regression function to infer the whole face shape, during which the shape constraint is implicitly encoded.（训练整个脸部形状回归向量，如ERT,ESR以及DNNs方法等）

![这里写图片描述](https://img-blog.csdn.net/20171106164153289?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![这里写图片描述](https://img-blog.csdn.net/20171106164159587?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

4.7. Summary and discussion

CLMs, constrained local regression and DPMs follow the “divide and conquer” principle to simplify the face alignment task by constructing individual local appearance model for each facial point

这类方法效果不是很好，于是有了另一条研究线路（明显很慢）

another main stream in face alignment is to jointly estimate the whole face shape from image, implicitly exploiting the spatial constraints among facial points

5 Towards the development of a robust face alignment system

这里先提出一个整体框架，然后再优化细节问题
![这里写图片描述](https://img-blog.csdn.net/20171106164702270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

5.2. Training data augmentation

数据增强还是很重要的，这里介绍了四个方法

5.3. Face preprocessing

For the task of face alignment, it is useful to remove the scaling variations of the detected faces, and enlarge the face region to ensure that all predefined facial points are enclosed

排除检测到脸的尺度差异化，扩大脸部区域，保证面部数据全在检测框内。

5.3.1. Handling scaling variations

rescaling the bounding box produced by the face detector。尺度归一化。

5.3.2. Enlarging face areas

enlarge the face bounding box by 30%。外扩。

5.4. Shape initialization

Most face alignment methods start from a rough initialization, and then refine the shape iteratively until convergence. The initialization step typically has great influence on the final result, and an initial shape far from the ground truth might lead to very bad alignment results.初始形状选择，有平均脸，有随机采样真实脸，有多次随机采样，也有估计方法等等。

5.5. Accuracy and efficiency tradeoffs

Face alignment in real time is crucial to many practical applications. The efficiency mainly depends on the feature extraction and shape prediction steps

输出点的平均对齐误差。精度与效率平衡。

6 System Evaluation

测试评估使用的数据库有：
![这里写图片描述](https://img-blog.csdn.net/20171106165854369?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](https://img-blog.csdn.net/20171106165915636?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](https://img-blog.csdn.net/20171106170007186?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](https://img-blog.csdn.net/20171106170109223?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![这里写图片描述](https://img-blog.csdn.net/20171106170115667?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![这里写图片描述](https://img-blog.csdn.net/20171106170122507?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmdqdW5oaXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

上面这篇文章讲的主要是算法研究方向，补充一点人脸对齐领域的具体算法。参考：[https://www.jianshu.com/p/e4b9317a817f](https://www.jianshu.com/p/e4b9317a817f)

从空间维度来考虑，以上这些方法又可分为2D方法，3D方法，稀疏方法和密集方法等。需要指出的是，由于深度学习方法可以很好的实现对多任务的处理，因此有很多新的算法可以同时完成对2D关键点和3D关键点的同时获取，进而可进一步支持后续的多任务分析，如人脸对齐，3D姿态分析等。

在人脸关键点定位的发展史上，具有里程碑式的有如下五种方法：
- 1995 年，Cootes 的 ASM(Active Shape Model)。
- 1998 年，Cootes 的 AAM(Active Appearance Model) 算法。
- 2006 年，Ristinacce 的 CLM（Constrained Local Model）算法。
- 2010 年，Rollar 的 cascaded Regression 算法。
- 2013 年，想港中文大学的汤晓欧和Sun Yi等开创深度学习人脸关键点检测的先河，首次将 CNN 应用到人脸关键点定位上。

## 2. 2D人脸对齐

2.1 AAM(Active Appearance Model)/ASM/Snake

参考文献：An Introduction to Active Shape Models. Constrained Local Model for FaceAlignment. Xiaoguang Yan(2011).

ASM模型起源于snake模型（作为动态边缘分割的snake模型），该方法用一条由n个控制点组成的连续闭合曲线作为snake模型，再用一个能量函数作为匹配度的评价函数，首先将模型设定在目标对象预估位置的周围，再通过不断迭代使能量函数最小化，当内外能量达到平衡时即得到目标对象的边界与特征。

1989年yuille等人此提出使用参数化的可变形模板来代替snake模型，可变形模板概念的提出为aam的产生奠定了理论基础。

1995年cootes等人提出的asm算法是aam的直接前身，asm采用参数化的采样形状来构成对象形状模型，并利用pca方法建立描述形状的控制点的运动模型，最后利用一组参数组来控制形状控制点的位置变化从而逼近当前对象的形状，该方法只单纯利用对象的形状，因此准确率不高。

1998年，cootes等人在asm算法的基础上首先提出aam，与asm的不同之处是他不仅利用了对象的形状信息而且利用了对象的纹理信息。

2.2 CLMS(Constrained Local Model)

2.3 级联回归方法(Cascaded regression)
- 
**CPR(Cascaded Pose Regression)**

	CPR通过一系列回归器将一个指定的初始预测值逐步细化，每一个回归器都依靠前一个回归器的输出来执行简单的图像操作，整个系统可自动的从训练样本中学习。

	人脸关键点检测的目的是估计向量(face shape) *S*=(x1, x2, ..., xK) ，其中K表示关键点的个数，由于每个关键点有横纵两个坐标，所以S得长度为2K。CPR检测流程一共有T个阶段，在每个阶段中首先进行特征提取f，这里使用的是shape-indexed features，也可以使用诸如HOG、SIFT等人工设计的特征，或者其他可学习特征（learning based features），然后通过训练得到的回归器R来估计增量ΔS( update vector)，把ΔS加到前一个阶段的S上得到新的S，这样通过不断的迭代即可以得到最终的S(shape)。
**CPR中主要的操作是向量相加，不仅有效而且计算复杂度较低，所以近年来在face alignment中广泛应用**

- 
**ESR**

	ESR(Explicit Shape Regression)该方法出自2012的cvpr，是微软亚洲研究院（MSRA）孙剑组的作品。该文章主要提出了3个方法：

	（1）2层级联的boost回归（two-level boosted regression）： 该方法最早是P Dollar大神在CVPR2010中Cascaded pose regression这篇论文中提出。作者这里的2层boost回归，第一层有10级，第二层有500级，这样分层的好处，比单独使用一个5000级而只有1层的效果要好很多。其中，第一层中的特征维度不固定，第二层中中的特征维度固定。

	（2）基于形状索引的特征（shape-indexed features）： 该形状索引特征，计算回归的位置和真实位置之间的像素差，类似于中心差分算梯度，从而得到最终特征向量，并且该特征向量采用了局部坐标系，相比全局坐标系具有更好的鲁棒性。

	（3）基于相关系数的特征选择方法（correlation-based feature selection method）：这里，需要从之前提取的400*400个特征中选择出最右代表性的前f个。简单的说，就是计算所有特征向量的相关系数，取前f个系数最高的作为最终的输出特征向量。

- 
**ERT(Ensemble of Regression Trees)**

	是对ESR回归器的改进，dlib实现的就是这个。由原来ESR的两级boost回归器，替换为GBDT构成的森林。

- 
**Face Alignment at 3000 FPS**

	cvpr2013, ESR是基础版本的形状回归，ERT将回归树修改为GBDT，由原始的直接回归形状，改进为回归形状残差，而LBF，是加速特征提取，由原来的像素差分特征池，改为随机选择点。

- 说点自己的理解，其实，实际工程中，生成模型在资源上不是很占优势，基本上能工程化的，都是回归的思路，所以，以上方法里，也就是ERT,LBF值得去做了。实际上，ESR也是对CPR的改进。

2.4 CNN 方法
- DCNN
**香港中文大学汤晓欧，SunYi**等人作品，首次将CNN用于人脸关键点检测。总体思想是由粗到细，实现5个人脸关键点的精确定位。网络结构分为3层：level 1、level 2、level 3。每层都包含多个独立的CNN模型，负责预测部分或全部关键点位置，在此基础上平均来得到该层最终的预测结果。虽然作者没有明确说这个问题，但是很明显的是，经过level-1,得到了一个相对较好的初始化。

在这方面，face++ 发表在ICCV-2013的paper（Extensive facial landmark localization with coarse-to-fine convolutional network cascade）同样有这么个“初始化”的操作。借鉴别的文献中的idea：局部共享权值（locally sharing weights），理论听起来挺有道理的。传统的权值共享认为某一个特征会图像的不同位置出现，所以采用全局权值共享。但是人脸是由比较规范的结构，如人眼就是在上部，鼻子就是在中部，嘴就是在下部，因此应该采用局部权值共享。
- TCNN
	- 《**[Facial Landmark Detection with Tweaked Convolutional Neural Networks](http://www.openu.ac.il/home/hassner/projects/tcnn_landmarks/)**》用了一个叫Vanilla CNN的网络模型，也是直接CNN回归，亮点在于对CNN提取的特征进行聚类，将各簇对应的样本进行分析，最后发现同一簇表现出“相同属性”（姿态，微笑，性别）的人脸。对此，设计了K个FC5和K个FC6层，用以对不同“面部属性”的人脸进行关键点检测。就是下图红圈那里。2016年，Wu等人研究了CNN在人脸关键点定位任务中到底学习到的是什么样的特征，在采用GMM（Gaussian Mixture Model, 混合高斯模型）对不同层的特征进行聚类分析，发现网络进行的是层次的，由粗到精的特征定位，越深层提取到的特征越能反应出人脸关键点的位置。针对这一发现，提出了TCNN（Tweaked Convolutional Neural Networks），其网络结构如图所示：![这里写图片描述](https://img-blog.csdn.net/20171207085939575?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTk5NTcxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)![这里写图片描述](https://img-blog.csdn.net/20171207085948950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTk5NTcxOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


上图为Vanilla CNN

测试时，图片首先经过Vanilla CNN提取特征，即FC5的输出。将FC5输出的特征与K个聚类中心进行比较，将FC5输出的特征划分至相应的类别中，然后选择与之相应的FC6进行连接，最终得到输出
- 
MTCNN

	CNN回归和检测多任务，多尺度级联，三个网络级联，由粗到精，同时完成检测和特征点定位回归。
- 
LAB (LAB-Look at Boundary A Boundary-Aware Face Alignment Algorithm )

	2018cvpr 清华&商汤作品。借鉴人体姿态估计，将边界信息引入关键点回归上。网络包含3个部分：边界热度图估计模块（Boundary heatmap estimator），基于边界的关键点定位模块（ Boundary-aware landmarks regressor ）和边界有效性判别模块（Boundary effectiveness discriminator）

![](https://img-blog.csdn.net/20180817165427888?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FwcF8xMjA2MjAxMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

LAB网络结构

- 边界热度图估计模块：采用stacked hourglass network 和 message passing layers。输入人脸图像，输出人脸边界热度图来表示面部的几何结构。人脸面部的各个器官边界共构成K个边界。每个stack结束时，特征图被分成K个分支，分别送给各个对应类型的边界热度图估计。最终生成的热度图与输入原始图像进行融合，作为关键点定位模块的输入。
- 基于边界的关键点定位模块，利用边界信息，通过4阶res-18网络来定位关键点
- 边界有效性判别模块，由于边界热度图在关键点定位中起着非常重要的作用，因此需要对生成的边界信息的准确性进行评判。该模块采用对抗网络，评判边界热度图的有效性。



