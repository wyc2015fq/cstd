# 图像局部特征（八）--斑点检测子SIFT/SURF区别总结 - 工作笔记 - CSDN博客





2016年06月13日 11:14:19[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：7424
所属专栏：[机器视觉](https://blog.csdn.net/column/details/33959.html)









原文：

[http://blog.csdn.net/cy513/article/details/4414352](http://blog.csdn.net/cy513/article/details/4414352)

[http://blog.csdn.net/jwh_bupt/article/details/6567452](http://blog.csdn.net/jwh_bupt/article/details/6567452)
`局部特征系列：`- `局部特征(1)——入门篇`
- `局部特征(2)——Harris角点 `
- `局部特征(3)——SURF特征总结 `
- `局部特征(4)——SIFT和SURF的比较 `
- `局部特征(5)——如何利用彩色信息 Color Descriptors `
- `局部特征(6)——局部特征描述汇总 `

 --------------------------------------------------------------
- **共同点：**



> 
SIFT/SURF为了实现不同图像中相同场景的匹配，主要包括三个步骤：

1、尺度空间的建立；

2、特征点的提取；

3、利用特征点周围邻域的信息生成特征描述子

4、特征点匹配。


        从博客上看到一片文章，[http://blog.csdn.net/cy513/archive/2009/08/05/4414352.aspx](http://blog.csdn.net/cy513/archive/2009/08/05/4414352.aspx)，这一段的大部分内容源于这篇文章，推荐大家去看看。

        如果两幅图像中的物体一般只是旋转和缩放的关系，加上图像的亮度及对比度的不同，要在这些条件下要实现物体之间的匹配，SIFT[算法](http://lib.csdn.net/base/31)的先驱及其发明者想到只要找到多于三对物体间的匹配点就可以通过射影几何的理论建立它们的一一对应。

        如何找到这样的匹配点呢？SIFT/SURF作者的想法是首先找到图像中的一些“稳定点”，这些点是一些特殊的点，不会因为视角的改变、光照的变化、噪音的干扰而消失，比如角点、边缘点、暗区域的亮点以及亮区域的暗点。这样如果两幅图像中有相同的景物，那么这些稳定点就会在两幅图像的相同景物上同时出现，这样就能实现匹配。因此，SIFT/SURF算法的基础是稳定点。

        SIFT/SURF提取的稳定点，首先都要求是局部极值。但是，当两个物体的大小比例不一样时，大图像的局部极值点在小图像的对应位置上有可能不是极值点。于是SIFT/SURF都采用图像金字塔的方法，每一个截面与原图像相似，这样两个金字塔中就有可能包含大小最近似的两个截面了。

        这样找到的特征点会比较多，经过一些处理后滤掉一些相对不稳定的点。

        接下来如何去匹配相同物体上对应的点呢？SIFT/SURF的作者都想到以特征点为中心，在周围邻域内统计特征，将特征附加到稳定点上，生成特征描述子。在遇到旋转的情况下，作者们都决定找出一个主方向，然后以这个方向为参考坐标进行后面的特征统计，就解决了旋转的问题。

![](https://img-my.csdn.net/uploads/201206/12/1339508536_9881.png)




- **共同的大问题有以下几个：**



*1、为什么选用高斯金字塔来作特征提取？*



      为什么是DOG的金字塔？因为它接近LOG，而LOG的极值点提供了最稳定的特征，而且DOG方便计算（只要做减法。）

      为什么LOG的极值点提供的特征最稳定，有参考文献，未看。

     (7.12补充：)直观理解：特征明显的点经过不同尺度的高斯滤波器进行滤波后，差别较大，所以用到的是DOG。

      但是直观上怎么理解？如果相邻Octave的sigma不是两倍关系还好理解：如果两幅图像只是缩放的关系，那么假设第一个Octave找到了小一倍图像的极值点，那么大一倍图像的极值点会在下一个Octave找到相似的。但是现在，如果把大一倍图像进行一次下采样（这样和小的图像就完全一样了），进行Gauss滤波时，两个图像滤波系数（sigma）是不一样的，不就找不到一样的极值点了么？不理解。

*2、Hessian矩阵为什么能用来筛选极值点？*

      SIFT先利用非极大抑制，再用到Hessian矩阵进行滤除。SURF先用Hessian矩阵，再进行非极大抑制。SURF的顺序可以加快筛选速度么？（Hessian矩阵滤除的点更多？）



      至于SURF先用Hessian矩阵，再进行非极大抑制的原因，是不管先极大值抑制还是判断Hessian矩阵的行列式，金字塔上的点的行列式都是要计算出来的。先判断是否大于0只要进行1次判断，而判断是否是极大值点或者极小值点要与周围26个点比较，只比较1次肯定快。

      而在SIFT中，构建的高斯金字塔只有一座（不想SURF是有3座），要进行非极大抑制可以直接用金字塔的结果进行比较。而如果计算Hessian矩阵的行列式，还要再计算Dxx、Dxy、Dyy。因此先进行非极大抑制。这两个步骤的先后与SIFT/SURF的实际计算情况有关的，都是当前算法下的最佳顺序，而不是说哪种先计算一定更好。

*3、为什么采用梯度特征作为局部不变特征？*

      这与人的视觉神经相关。采用梯度作为描述子的原因是，人的视觉皮层上的神经元对特定方向和空间频率的梯度相应很敏感，经过SIFT作者的一些实验验证，用梯度的方法进行匹配效果很好。

*4、为什么可以采用某些特征点的局部不变特征进行整幅图像的匹配？*

      我在一份博客上找到这样一句话：（[http://apps.hi.baidu.com/share/detail/32318290](http://apps.hi.baidu.com/share/detail/32318290)，大家可以看看这篇文章。）

从直观的人类视觉印象来看，人类视觉对物体的描述也是局部化的，基于局部不变特征的图像识别方法十分接近于人类视觉机理，通过局部化的特征组合，形成对目标物体的整体印象，这就为局部不变特征提取方法提供了生物学上的解释，因此局部不变特征也得到了广泛应用。

      还有：

      图像中的每个局部区域的重要性和影响范围并非同等重要，即特征不是同等显著的，其主要理论来源是Marr的计算机视觉理论和Treisman的特征整合理论，一般也称为“原子论”。该理论认为视觉的过程开始于对物体的特征性质和简单组成部分的分析，是从局部性质到大范围性质。

      SIFT/SURF都是对特征点的局部区域的描述，这些特征点应该是影响重要的点，对这些点的分析更加重要。所以在局部不变特征的提取和描述时也遵循与人眼视觉注意选择原理相类似的机制，所以SIFT/SURF用于匹配有效果。






- **不同点的比较：**



从博客上看到一个总结，我修改了一些内容。大家可以参看以下链接：

[http://blog.csdn.net/ijuliet/archive/2009/10/07/4640624.aspx](http://blog.csdn.net/ijuliet/archive/2009/10/07/4640624.aspx)
||SIFT|SURF|
|----|----|----|
|尺度空间|DOG与不同尺度的图片卷积|不同尺度的box filters与原图片卷积|
|特征点检测|先进行非极大抑制，再去除低对比度的点。再通过Hessian矩阵去除边缘的点|先利用Hessian矩阵确定候选点，然后进行非极大抑制|
|方向|在正方形区域内统计梯度的幅值的直方图，找max对应的方向。可以有多个方向。|在圆形区域内，计算各个扇形范围内x、y方向的haar小波响应，找模最大的扇形方向|
|特征描述子|16*16的采样点划分为4*4的区域，计算每个区域的采样点的梯度方向和幅值，统计成8bin直方图，一共4*4*8=128维*（2013.5.9 note： 不一定要是16 × 16，区域也可以不用是 4 × 4）*|20*20s的区域划分为4*4的子区域，每个子区域找5*5个采样点，计算采样点的haar小波响应，记录∑dx,∑dy,∑|dx|,∑|dy|，一共4*4*4=64维|

        SURF—金字塔仅仅是用来做特征点的检测。在计算描述子的时候，haar小波响应是计算在原图像（利用积分图）。而SIFT是计算在高斯金字塔上（注意不是高斯差分金字塔。）


- **性能的比较：**



        论文：A comparison of SIFT, PCA-SIFT and SURF 对三种方法给出了性能上的比较，源图片来源于Graffiti dataset，对原图像进行尺度、旋转、模糊、亮度变化、仿射变换等变化后，再与原图像进行匹配，统计匹配的效果。效果以可重复出现性为评价指标。

        比较的结果如下：
|**method**|**Time**|**Scale**|**Rotation**|**Blur**|**Illumination**|**Affine**|
|----|----|----|----|----|----|----|
|**Sift**|common|best|best|common|common|good|
|**Pca-sift**|good|good|good|best|good|best|
|**Surf **|best|common|common|good|best|good|

















        由此可见，SIFT在尺度和旋转变换的情况下效果最好，SURF在亮度变化下匹配效果最好，在模糊方面优于SIFT，而尺度和旋转的变化不及SIFT，旋转不变上比SIFT差很多。速度上看，SURF是SIFT速度的3倍。



-----------------------------------

jiang1st2010

原文地址：[http://blog.csdn.net/jiang1st2010/article/details/6567452](http://blog.csdn.net/jiang1st2010/article/details/6567452)







SURF[算法](http://lib.csdn.net/base/31)是SIFT算法的加速版，opencv的SURF算法在适中的条件下完成两幅图像中物体的匹配基本实现了实时处理，其快速的基础实际上只有一个——积分图像haar求导，对于它们其他方面的不同可以参考本blog的另外一篇关于SIFT的文章。

    不论科研还是应用上都希望可以和人类的视觉一样通过程序自动找出两幅图像里面相同的景物，并且建立它们之间的对应，前几年才被提出的SIFT（尺度不变特征）算法提供了一种解决方法，通过这个算法可以使得满足一定条件下两幅图像中相同景物的某些点（后面提到的关键点）可以匹配起来，为什么不是每一点都匹配呢？下面的论述将会提到。

     SIFT算法实现物体识别主要有三大工序，1、提取关键点；2、对关键点附加详细的信息（局部特征）也就是所谓的描述器；3、通过两方特征点（附带上特征向量的关键点）的两两比较找出相互匹配的若干对特征点，也就建立了景物间的对应关系。

      日常的应用中，多数情况是给出一幅包含物体的参考图像，然后在另外一幅同样含有该物体的图像中实现它们的匹配。两幅图像中的物体一般只是旋转和缩放的关系，加上图像的亮度及对比度的不同，这些就是最常见的情形。基于这些条件下要实现物体之间的匹配，SIFT算法的先驱及其发明者想到只要找到多于三对物体间的匹配点就可以通过射影几何的理论建立它们的一一对应。首先在形状上物体既有旋转又有缩小放大的变化，如何找到这样的对应点呢？于是他们的想法是首先找到图像中的一些“稳定点”，这些点是一些十分突出的点不会因光照条件的改变而消失，比如角点、边缘点、暗区域的亮点以及亮区域的暗点，既然两幅图像中有相同的景物，那么使用某种方法分别提取各自的稳定点，这些点之间会有相互对应的匹配点，正是基于这样合理的假设，SIFT算法的基础是稳定点。SIFT算法找稳定点的方法是找灰度图的局部最值，由于数字图像是离散的，想求导和求最值这些操作都是使用滤波器，而滤波器是有尺寸大小的，使用同一尺寸的滤波器对两幅包含有不同尺寸的同一物体的图像求局部最值将有可能出现一方求得最值而另一方却没有的情况，但是容易知道假如物体的尺寸都一致的话它们的局部最值将会相同。SIFT的精妙之处在于采用图像金字塔的方法解决这一问题，我们可以把两幅图像想象成是连续的，分别以它们作为底面作四棱锥，就像金字塔，那么每一个截面与原图像相似，那么两个金字塔中必然会有包含大小一致的物体的无穷个截面，但应用只能是离散的，所以我们只能构造有限层，层数越多当然越好，但处理时间会相应增加，层数太少不行，因为向下采样的截面中可能找不到尺寸大小一致的两个物体的图像。有了图像金字塔就可以对每一层求出局部最值，但是这样的稳定点数目将会十分可观，所以需要使用某种方法抑制去除一部分点，但又使得同一尺度下的稳定点得以保存。有了稳定点之后如何去让程序明白它们之间是物体的同一位置？研究者想到以该点为中心挖出一小块区域，然后找出区域内的某些特征，让这些特征附件在稳定点上，SIFT的又一个精妙之处在于稳定点附加上特征向量之后就像一个根系发达的树根一样牢牢的抓住它的“土地”，使之成为更稳固的特征点，但是问题又来了，遇到旋转的情况怎么办？发明者的解决方法是找一个“主方向”然后以它看齐，就可以知道两个物体的旋转夹角了。下面就讨论一下SIFT算法的缺陷。

      SIFT/SURT采用henssian矩阵获取图像局部最值还是十分稳定的，但是在求主方向阶段太过于依赖局部区域像素的梯度方向，有可能使得找到的主方向不准确，后面的特征向量提取以及匹配都严重依赖于主方向，即使不大偏差角度也可以造成后面特征匹配的放大误差，从而匹配不成功；另外图像金字塔的层取得不足够紧密也会使得尺度有误差，后面的特征向量提取同样依赖相应的尺度，发明者在这个问题上的折中解决方法是取适量的层然后进行插值。SIFT是一种只利用到灰度性质的算法，忽略了色彩信息，后面又出现了几种据说比SIFT更稳定的描述器其中一些利用到了色彩信息，让我们拭目以待。

      最后要提一下，我们知道同样的景物在不同的照片中可能出现不同的形状、大小、角度、亮度，甚至扭曲；计算机视觉的知识表明通过光学镜头获取的图像，对于平面形状的两个物体它们之间可以建立射影对应，对于像人脸这种曲面物体在不同角度距离不同相机参数下获取的两幅图像，它们之间不是一个线性对应关系，就是说我们即使获得两张图像中的脸上若干匹配好的点对，还是无法从中推导出其他点的对应。







﻿﻿



