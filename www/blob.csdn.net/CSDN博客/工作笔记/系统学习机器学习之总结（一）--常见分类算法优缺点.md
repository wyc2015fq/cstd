# 系统学习机器学习之总结（一）--常见分类算法优缺点 - 工作笔记 - CSDN博客





2018年09月26日 14:37:47[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：5604








主要是参考网上各种资源，做了整理。其实，这里更多的是从基础版本对比，真正使用的时候，看数据，看改进后的算法。

### 1. 五大流派

①符号主义：使用符号、规则和逻辑来表征知识和进行逻辑推理，最喜欢的算法是：规则和决策树

②贝叶斯派：获取发生的可能性来进行概率推理，最喜欢的算法是：朴素贝叶斯或马尔可夫

③联结主义：使用概率矩阵和加权神经元来动态地识别和归纳模式，最喜欢的算法是：神经网络

④进化主义：生成变化，然后为特定目标获取其中最优的，最喜欢的算法是：遗传算法

⑤Analogizer：根据约束条件来优化函数（尽可能走到更高，但同时不要离开道路），最喜欢的算法是：支持向量机

### 2. 演化的阶段

1980 年代
- 
主导流派：符号主义

- 
架构：服务器或大型机

- 
主导理论：知识工程

- 
基本决策逻辑：决策支持系统，实用性有限


1990 年代到 2000 年
- 
主导流派：贝叶斯

- 
架构：小型服务器集群

- 
主导理论：概率论

- 
分类：可扩展的比较或对比，对许多任务都足够好了


2010 年代早期到中期
- 
主导流派：联结主义

- 
架构：大型服务器农场

- 
主导理论：神经科学和概率

- 
识别：更加精准的图像和声音识别、翻译、情绪分析等


### 3. 这些流派有望合作，并将各自的方法融合到一起

2010 年代末期
- 
主导流派：联结主义+符号主义

- 
架构：许多云

- 
主导理论：记忆神经网络、大规模集成、基于知识的推理

- 
简单的问答：范围狭窄的、领域特定的知识共享


2020 年代+
- 
主导流派：联结主义+符号主义+贝叶斯+……

- 
架构：云计算和雾计算

- 
主导理论：感知的时候有网络，推理和工作的时候有规则

- 
简单感知、推理和行动：有限制的自动化或人机交互


2040 年代+
- 
主导流派：算法融合

- 
架构：无处不在的服务器

- 
主导理论：最佳组合的元学习

- 
感知和响应：基于通过多种学习方式获得的知识或经验采取行动或做出回答


你应该使用哪种机器学习算法？这在很大程度上依赖于可用数据的性质和数量以及每一个特定用例中你的训练目标。不要使用最复杂的算法，除非其结果值得付出昂贵的开销和资源。这里给出了一些最常见的算法，按使用简单程度排序。

# 决策树

##  一、  决策树优点

1、决策树易于理解和解释，可以可视化分析，容易提取出规则。

2、可以同时处理标称型和数值型数据。

3、测试数据集时，运行速度比较快。

4、决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。

5、无参数方法，无模型、数据、特征假设

6、存储方式简单

7、对新样本分类更有效，对各类问题具有普适性。

8、可以提取一系列规则

##  二、决策树缺点

1、对缺失数据处理比较困难。

2、容易出现过拟合问题。（对噪声敏感）

3、忽略数据集中属性的相互关联。

4、ID3算法计算信息增益时结果偏向数值比较多的特征。

5、非自适应，不支持增量训练。

##  三、改进措施

1、对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。

2、使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题

##  三、应用领域

企业管理实践，企业投资决策，由于决策树很好的分析能力，在决策过程应用较多。

#  KNN算法

##  一、KNN算法的优点

1、KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练

2、KNN理论简单，容易实现

3、无输入数据假定，对异常值不敏感

##  二、KNN算法的缺点

1、对于样本容量大的数据集计算量比较大。

2、样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多。

3、KNN每一次分类都会重新进行一次全局运算。

4、k值大小的选择。

5、KNN实际上相当于用一种简单的非参数密度估计方法把贝叶斯规则应用于类条件密度估计

6、没有解释性，无法体现数据内在含义

7、数据范围存在重叠时，分类精度不高

##  三、KNN算法应用领域

文本分类、模式识别、聚类分析，多分类领域

#  支持向量机（SVM）

##  一、  SVM优点

1、解决小样本下机器学习问题。

2、解决非线性问题。

3、无局部极小值问题。（相对于神经网络等算法）

4、可以很好的处理高维数据集。

5、泛化能力比较强。

##  二、SVM缺点

1、对于核函数的高维映射解释力不强，尤其是径向基函数。

2、对缺失数据敏感。

3、调参麻烦，核函数难选难调

##  三、SVM应用领域

文本分类、图像识别、主要二分类领域

#  AdaBoost算法

##  一、  AdaBoost算法优点

1、很好的利用了弱分类器进行级联。

2、可以将不同的分类算法作为弱分类器。

3、AdaBoost具有很高的精度。

4、相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重。

##  二、Adaboost算法缺点

1、AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定。

2、数据不平衡导致分类精度下降。

3、训练比较耗时，每次重新选择当前分类器最好切分点。

##  三、AdaBoost应用领域

模式识别、计算机视觉领域，用于二分类和多分类场景

#  朴素贝叶斯算法

##  一、  朴素贝叶斯算法优点

1、对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已。

2、支持增量式运算。即可以实时的对新增的样本进行训练。

3、朴素贝叶斯对结果解释容易理解。

##  二、朴素贝叶斯缺点

1、由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。

2、类条件概率密度函数，是从训练样本估计到的，问题是，实际测试的时候，训练样本很难完全代替实际数据，因此，泛化能力会受影响（生成模型的通病吧，数据漂移问题影响大）。

##  三、朴素贝叶斯应用领域

文本分类、欺诈检测中使用较多

#  Logistic回归算法

##  一、logistic回归优点

1、计算代价不高，易于理解和实现

##  二、logistic回归缺点

1、容易产生欠拟合。

2、分类精度不高。

3、这种单决策面的线性拟合分类器，很脆弱（现实大多数非线性）

##  三、logistic回归应用领域

用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。

Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。

#  人工神经网络

##  一、  神经网络优点

1、分类准确度高，学习能力极强。

2、对噪声数据鲁棒性和容错性较强。

3、有联想能力，能逼近任意非线性关系。

##  二、神经网络缺点

1、神经网络参数较多，权值和阈值。

2、黑盒过程，不能观察中间结果。

3、学习过程比较长，有可能陷入局部极小值。

##  三、人工神经网络应用领域

目前深度神经网络已经应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果。



