# 系统学习机器学习之参数方法（一） - 工作笔记 - CSDN博客





2015年12月15日 09:32:17[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：6958








**最大似然估计**

**最大似然估计法的基本思想**最大似然估计法的思想很简单：在已经得到试验结果的情况下，我们应该寻找使这个结果出现 的可能性最大的那个![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image184.gif)作为真![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image185.gif)的估计。

　　我们分两种情进行分析：
**1．离散型总体**

　　设![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image187.gif)为离散型随机变量，其概率分布的形式为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image189.gif)，则样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image191.gif)的概率分布为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image193.gif)，在![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image195.gif)固定时，上式表示![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image197.gif)取值![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image199.gif)的概率；当![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image200.gif)固定时，它是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image201.gif)的函数，我们把它记为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image203.gif)并称![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image205.gif)为似然函数。似然函数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image206.gif)的值的大小意味着该样本值出现的可能性的大小。既然已经得到了样本值![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image207.gif)，那它出现的可能性应该是大的，即似然函数的值应该是大的。因而我们选择使![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image208.gif)达到最大值的那个![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image209.gif)作为真![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image210.gif)的估计。


**2．连续型总体 **

　　设![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image211.gif)为连续型随机变量，其概率密度函数为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image213.gif)则![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image214.gif)为从该总体抽出的样本。因为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image216.gif)相互独立且同分布，于是，样本的联合概率密度函数为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image218.gif)，在![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image219.gif)是固定时，它是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image220.gif)在![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image221.gif)处的
 密度，它的大小与![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image222.gif)落在![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image223.gif)附近的概率的大小成正比，而当样本值![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image224.gif)固定时，它是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image225.gif)的函数。我们仍把它记为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image226.gif)并称![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image228.gif)为似然函数。类似于刚才的讨论，我们选择使![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image229.gif)最大的那个![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image230.gif)作为真![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image231.gif)的估计。


　　总之，在有了试验结果即样本值![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image232.gif)时，似然函数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image233.gif)反映了![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image234.gif)的各个不同值导出这个结果的可能性的大小。
 我们选择使![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image235.gif)达到最大值的那个![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image236.gif)作为真![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image237.gif)的估计。这种求点估计的方法就叫作最大似然法。  

**7.2.2　最大似然估计的求法**

　　假定现在我们已经观测到一组样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image238.gif)要去估计未知参数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image240.gif)。一种直观的想法是，哪一组能数值使现在的样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image241.gif)出现的可能性最大，哪一组参数可能就是真正的参数，我们就要用它作为参数的估计值。这
 里，假定我们有一组样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image243.gif).如果对参数的两组不同的值![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image245.gif)和![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image247.gif)，似然函数有如下关系
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image249.gif),

　　那么，从![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image251.gif)又是概率密度函数的角度来看，上式的意义就是参数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image253.gif)使![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image254.gif)出现的可能性比参数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image256.gif)使![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image257.gif)出现的可能性大，当然参数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image258.gif)比![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image259.gif)更像是真正的参数.这样的分析就导致了参数估计的一种方法，即用使似然函数
 达到最大值的点![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image261.gif),作为未知参数的估计，这就是所谓的最大似然估计。  现在我们讨论求最大似然估计的具体方法.为简单起见，以下记![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image263.gif),求θ的极大似然估计就归结为求![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image265.gif)的最大值点.由于对数函数是单调增函数，所以
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image267.gif)   　　　　　(7.2.1)


　与![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image268.gif)有相同的最大值点。而在许多情况下，求![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image270.gif)的最大值点比较简单，于是，我们就将求![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image271.gif)的最大值点改为求![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image272.gif)的最大值点.对![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image273.gif)关于![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image274.gif)求导数，并命其等于零，得到方程组
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image276.gif),     ![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image278.gif)                     
 (7.2.2)

　　称为似然方程组。解这个方程组，又能验证它是一个极大值点，则它必是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image279.gif)，也就是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image280.gif)的最大值点，即为所求的最大似然估计。大多常用的重要例子多属于这种情况。然而在一些情
 况下，问题比较复杂，似然方程组的解可能不唯一，这时就需要进一步判定哪一个是最大值点。

　　还需要指出，若函数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image282.gif)关于![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image283.gif)的导数不存在时，我们就无法得到似然方程组
 (7.2.2)，这时就必须根据最大似然估计的定义直接去![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image284.gif)的最大值点。

　　在一些情况下，我们需要估计![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image286.gif)。如果![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image288.gif)分别是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image289.gif)的最大似然估计，则称![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image291.gif)为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image293.gif)的最大似然估计。

　　下面我们举一些例子来说明求最大似然估计的方法。

**例**** 7.2.1**设 从正态总体![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image295.gif)抽出样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image296.gif)，这里未知参数为mm![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image297.gif)和![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image298.gif)（注意我们把![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image299.gif)看作一个参数）。似然函数为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image301.gif)
　　　　　 =![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image303.gif)
　　它的对数为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image305.gif)，

　　似然方程组为 
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image307.gif)

　　由第一式解得
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image309.gif)，(7.2.3)

     代入第二式得
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image311.gif).              (7.2.4)

　　似然方程组有唯一解(![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image313.gif)，![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image315.gif))，而且它一定是最大值点，这是因为当![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image317.gif)或![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image319.gif)或∞时，非负函数![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image321.gif)。于是![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image322.gif)和![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image323.gif)的最大似然估计为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image325.gif)，![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image327.gif).        
 (7.2.5)

　　这里，我们用大写字母表示所有涉及的样本，因为最大似然估计![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image328.gif)和![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image329.gif)都是统计量，离开了具体的一次试验或观测，它们都是随机的。
**例****7.2.2**设总体![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image331.gif)服从参数为的泊松分布，它的分布律为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image333.gif)，![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image335.gif)

　　有了样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image337.gif)之后，参数λ的似然函数为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image339.gif)，

　　似然方程为 
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image341.gif)，

　　解得
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image343.gif).

　　因为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image345.gif)的二阶导数总是负值，可见，似然函数在![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image347.gif)处达到最大值。所以，![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image349.gif)是λ的最大似然估计。
**例7.2.3**设总体![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image351.gif)为![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image353.gif)上的均匀分布，求![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image355.gif)的最大似然估计。
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image357.gif)的概率密度函数为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image359.gif)

　　对样本![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image360.gif)，
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image362.gif)

　　很显然，*L*(*a*，*b*)作为*a*和*b*的 二元函数是不连续的。这时我们不能用似然方程组(7.2.2)来求最大似然估计，而必须从最大似然估计的定义出发，求*L*(*a*，*b*)的 最大值。为使*L*(*a*，*b*)达到最大，*b*－*a*应
 该尽量地小，但*b*又不能小于![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image364.gif)，否则，*L*(*a*，*b*)=0。

　　类似地，*a*不能大过![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image366.gif)。因此，*a*和*b*的最 大似然估计为
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image368.gif)，
![](http://edu6.teacher.com.cn/ttg006a/chap7/jiangjie/image1/image370.gif).　

　　现在为止，我们以正态分布，泊松分布，均匀分布的参数以及事件发生的概率的估计为例子讨论了矩估计和最大似然估计。在我们所举的例子中，除了均匀分布 外，两种估计都是一致的。矩估计的优点是简单，只需知道总体的矩，总体的分布形式不必知道。而最大似然估计则必须知道总体分布形式，并且在一般情况下，似 然方程组的求解较复杂，往往需要在计算机上通过迭代运算才能计算出其近似解。

**贝叶斯估计**

贝叶斯（Bayes）统计是由T. R. Bayes于19世纪创立的数理统计的一个重要分支，20世纪50年代，以H. Robbins为代表提出了在计量经济学模型估计中将经验贝叶斯方法与经典方法相结合，引起了广泛的重视，得到了广泛的应用。**贝叶斯估计对经典计量经济学模型估计方法的扩展在于，它不仅利用样本信息，同时利用非样本信息。**

**（1）贝叶斯估计**

在经典计量经济学模型中广泛采用的最小二乘估计，以及本章讨论的最大似然函数估计和广义矩估计的一个共同特征是，在模型估计中只利用样本信息和关于总体分布的先验信息，而关于分布的先验信息仍然需要通过样本信息的检验，所以说到底还是**样本信息**。

由于模型估计依赖样本信息，这就要求样本信息足够多，因此，这些估计只有在**大样本情况下才具有一定的优良性质**。但是在许多实际应用研究中，人们无法重复大量的实验以得到大量的观测结果，只能得到少量的观测结果。在小样本情况下，最小二乘估计、最大似然估计和广义矩估计不再具有优良性质。因而，人们不得不寻求**小样本情况下的优良估计方法**。**贝叶斯估计方法**就是其中之一。

**a、贝叶斯方法的基本思路**

贝叶斯方法的基本思路是：假定**要估计的模型参数**是**服从一定分布的随机变量**，根据经验给出待估参数的先验分布（也称为主观分布），关于这些先验分布的信息被称为先验信息；然后根据这些**先验信息**，并与**样本信息**相结合，应用**贝叶斯定理**求出**待估参数**的**后验分布**；再应用**损失函数**，得出后验分布的一些特征值，并把它们作为待估参数的估计量。

**贝叶斯方法与经典估计方法的主要不同之处是：**

（a）关于参数的解释不同

**经典估计方法**认为待估参数具有确定值，它的估计量才是随机的，如果估计量是无偏的，该估计量的期望等于那个确定的参数；而**贝叶斯方法**认为待估参数是一个服从某种分布的**随机变量**。

（b）所利用的信息不同

**经典方法**只利用样本信息；**贝叶斯方法**要求事先提供一个参数的先验分布，即人们对有关参数的主观认识，被称为先验信息，是非样本信息，在参数估计过程中，这些**非样本信息与样本信息一起被利用**。

（c）对随机误差项的要求不同

**经典方法**，除了最大似然法，在参数估计过程中并不要求知道随机误差项的具体分布形式，但是在假设检验与区间估计时是需要的；**贝叶斯方法需要知道随机误差项的具体分布形式。**

（d）选择参数估计量的准则不同

**经典估计方法**或者以残差平方和最小，或者以似然函数值最大为准则，构造极值条件，求解参数估计量；**贝叶斯方法**则需要构造一个损失函数，并**以损失函数最小化为准则**求得参数估计量。

**b、贝叶斯定理**

![贝叶斯定理与贝叶斯估计 - 杰迪武士 - The Temple of JeDi](http://img2.ph.126.net/vMWohPiqORCB2Z-UKGHVzw==/683984193506949335.png)

**c、损失函数**

常用的损失函数有线性函数和二次函数，不同的损失函数，得到的参数估计值是不同的。

**（2）线性单方程计量经济学模型的贝叶斯估计**

以正态线性单方程计量经济学模型为例介绍贝叶斯估计方法。选择正态线性单方程计量经济学模型的主要原因是：（1）多元线性单方程计量经济学模型具有普遍性意义；（2）在模型设定正确的情况下，随机误差项是大量随机扰动之总和，根据中心极限定理，可以认为它是渐近正态分布；（3）计算简单，使用方便，并能完整地体现贝叶斯估计方法的主要内容。正态线性单方程计量经济学模型又分为随机误差项方差已知和方差未知两种情况。作为贝叶斯估计方法的演示，我们只讨论方差已知的情况。

**a、有先验信息的后验分布**

![贝叶斯定理与贝叶斯估计 - 杰迪武士 - The Temple of JeDi](http://img0.ph.126.net/JqhMjAHBbx1DWJe6FV5eNA==/2095581201710876781.png)

![贝叶斯定理与贝叶斯估计 - 杰迪武士 - The Temple of JeDi](http://img2.ph.126.net/j6lujSF6Co31lJSqhK0rTg==/3334634049191335175.png)

**b、无先验信息的后验分布**

![贝叶斯定理与贝叶斯估计 - 杰迪武士 - The Temple of JeDi](http://img1.ph.126.net/2Ti5IIsS7rrnl1YRkhx71w==/6597932883285958978.png)



**c、点估计**

![贝叶斯定理与贝叶斯估计 - 杰迪武士 - The Temple of JeDi](http://img0.ph.126.net/xlaZ4PNUc5cg1VxJ-oxTZg==/6597542556658099503.png)

**d、区间估计**





