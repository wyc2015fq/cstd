# 手势识别（二）--单目手势识别算法总结 - 工作笔记 - CSDN博客





2016年10月07日 13:50:34[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：20511
个人分类：[手势识别](https://blog.csdn.net/App_12062011/article/category/7337142)

所属专栏：[机器视觉](https://blog.csdn.net/column/details/33959.html)









﻿﻿本文参考：[http://blog.csdn.net/lpflying0106/article/details/22674657](http://blog.csdn.net/lpflying0106/article/details/22674657) 做修改补充（其实主要是不高兴写这多么，找了个差不多能表达意思的文章改改）

手势有三个主要特征：手型，方向，运动轨迹

一个基于视觉手势识别系统的构成应包括：图像的采集，预处理，特征提取和选择，分类器的设计，以及手势识别。其流程大致如下：

![](https://img-blog.csdn.net/20140331171337109?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHBmbHlpbmcwMTA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

上面识别过程，再分解为：

![](https://img-blog.csdn.net/20161007134949909?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


其中有三个步骤是识别系统的关键，分别是预处理时手势的分割，特征提取和选择，手势跟踪，以及手势识别采用的[算法](http://lib.csdn.net/base/datastructure)。

不管是手势检测，或者手势跟踪，识别，特征提取和选择是关键:

手势本身具有丰富的形变，运动以及纹理特征，选取合理的特征对于手势的识别至关重要。目前 常用的手势特征有:轮廓、边缘、图像矩、图像特征向量以及区域直方图特征等等。

《基于计算机视觉的手势识别研究》中提到了多尺度模型，它就是采用此模型提取手势的指尖的数量和位置，将指尖和掌心连线，采用距离公式计算各指尖到掌心的距离，再采用反余弦公式计算各指尖与掌心连线间的夹角，将距离和夹角作为选择的特征。对于静态手势识别而言，边缘信息是比较常用的特征。

《基于几何特征的手势识别算法研究》中采用的HDC提取关键点的识别算法，基于用八方向邻域搜索法提取出手势图像的边缘，把图像的边缘看成一条曲线，然后对曲线进行处理。

《基于视觉的手势识别及其在人机交互中的应用》利用方向直方图作为手势识别的特征向量。虽然方向直方图具有平移不变性，但它不具有旋转不变性。同一手势图像，经过旋转后，直方图会不同。而且方向直方图不具有唯一性，即不同的手势图像可能会有相似的方向直方图。

在进行特征选取时我们可以考虑结合多种特征，在《基于计算机视觉的手势识别研究中》提出了多尺度模型与矩描绘子相结合的算法，将指尖和重心连线，采用距离公式计算各指尖到重心的距离，再采用反余弦公式计算各指尖与重心连线间的夹角，将距离和夹角作为选择的特征，从而提高了识别正确率，并减少了识别时间。《基于几何特征的手势识别算法研究》采用几何矩和边缘检测的识别算法，手势图像经过二值化处理后，提取手势图像的几何矩特征，取出几何矩特征七个特征分量中的四个分量，形成手势的几何矩特征向量。在灰度图基础上直接检测图像的边缘，利用直方图表示图像的边界方向特征。最后，通过设定两个特征的权重来计算图像间的距离，再对手势进行识别。

可以看出适当的采用多种特征结合的算法，可以在计算的复杂度以及精确度上有所提高。总体来说：

手势检测（手势分割）：

主要受复杂背景，遮挡，直接光源的亮度变化，外部反射，

常见手部检测特征选取：

基于肤色，基于表观，基于模型三种手部检测。建议，先背景去除，在结合多特征，如肤色+纹理（类Harr）+ADABoost做手部检测，HOG+PCA（设计分类器，左手，右手，双手交叉）做左右手区分。

一般来讲，分割方法大致分为以下三类：

一是基于直方图的分割，即阈值法，通常取灰度直方图的波谷作为阈值。（《hausdorff在距离在手势识别中的运用》采用了阈值法。）

二是基于局部区域信息的分割，如基于边缘和基于区域的方法；（《基于几何特征的手势识别算法研究》采用了边缘检测方法。）

三是基于颜色等一些物理特征的分割方法。（《复杂背景下基于单目视觉的静态手势识别》采用了基于颜色空间的肤色聚类法，《基于视觉的手势识别及其在人机交互中的应用》采用了肤色滤波法。）。

每种方法都有自己的优点，但也存在一定的问题，对于简单背景的图像，采用阈值法能达到不错的效果，对于复杂的图像，单一的阈值不能得到良好的分割效果。采用边缘提取方法时，若目标物和背景灰度差别不大时，则得不到较明显的边缘。可以采用多种方法相结合的图像处理方法，例如对采集的图像先进行差影处理，然后进行灰度阈值分割，或者对图像按区域分成小块，对每一块进行设置阈值。

手势分割是手势识别系统中的关键技术之一，它直接影响系统的识别率，目前的分割技术大都需要对背景，用户以及视频采集加以约束。其受背景复杂度和光照变化的影响最大，可以在这些方面进行改进。

手势跟踪：

受快速运动，双手遮挡，非刚体，非线性，非高斯，多模态。通俗的讲，就是 手势非刚体运动，受到缩放，形变，缺少，模糊，旋转，亮度，视角等因素影响，建议，基于肤色的SIFT+肤色（ROI）+HOG,采用MeanShift

常见跟踪算法选取：

粒子滤波，MeanShift,基于Sift特征，基于EKF,基于SVM，基于模板匹配，

手势识别：

受尺度，角度，光照，同一手势每次演示的差异，分静态，动态手势：

目前基于单目视觉的静态手势识别技术主要有三大类：

第一类为模板匹配技术，这是一种最简单的识别技术。它将待识别手势的特征参数与预先存储的模板特征参数进行匹配，通过测量两者之间的相似度来完成识别任务。《Hausdorff距离在手势识别中的运用》中利用Hausdorff距离模板匹配思想来实现手势的识别。将待识别手势和模板手势的边缘图像变换到欧式距离空间，求出它们的Hausdorff距离或修正Hausdorff距离。用该距离值代表待识别手势和模板手势的相似度。识别结果取与最小距离值对应的模板手势。

第二类为统计分析技术，这是一种通过统计样本特征向量来确定分类器的基于概率统计理论的分类方法。这种技术要求人们从原始数据中提取特定的特征向量，对这些特征向量进行分类，而不是直接对原始数据进行识别。在《基于计算机视觉的手势识别研究》中虽然也采用了Hausdorff距离算法，但并未提出模板手势，而是对于每幅图像提取出指尖和重心特征，然后计算出距离和夹角，对于不同手势分别进行距离和夹角的统计，得到其分布的数字特征，根据基于

最小错误率的贝叶斯决策得到用于分割不同手势的距离和夹角的值。得到分类器以后，对于采集的手势图像进行分类识别。文中的多尺度模型和矩描绘子相结合的算法也是运用了统计分析技术。

第三类为神经网络技术，这种技术具有自组织和自学习能力，具有分布性特点，能有效的抗噪声和处理不完整模式以及具有模式推广能力。采用这种技术，在识别前都需要一对神经网络的训练(学习)阶段。

其中比较常用的是BP神经网络。BP ( Error Back Propagation Neural Network 误差反向传播神经网络)由它是一种能向着满足给定的输入输出关系方向进行自组织的神经网络，当输出层上的实际输出与给定的输入不一致时，用下降法修正各层之间旧的结合强度，直到最终满足给定的输入输出关系为止，出于误差传播的方向与信号传播的方向正好相反称为误差反向传播神经网络。BP神经网络的理论认为:只要不断给出输入和输出之间的关系，则在神经网络的学习过程中，其内部就一定会形成表示这种关系的内部构造，并且只要使关系形成的速度达到实用值，那么BP的应用就不存在任何的困难.
 《基于视觉的手势识别及其在人机交互中的应用》采用了基于方向直方图的BP（误差反向传播）神经网络方法。

   可以看出若是基于几何分类法算法简单，与神经网络的方法相比，显示出了可靠性，其允许定义一个不同手势类别特点的特征集，估计一个局部最优的线性分辨器，根据手势图像中提取的大量特征识别相应的手势类别，但其学习的效率不高，随着样本量的不断增大，算法识别率的提高不明显。但BP神经网络需要一定的学习阶段，处理过程中可能存在着中间层神经元的个数庞大，学习时间太长，结合系数范围太宽等严重缺点。在BP神经网络的实际应用中应该合理考虑网络结构。

如基于Sift 静态手势 识别，即采用基于肤色的Sift特征，用PCA降维，再用HOG特征表述手势，也做PCA降维，两种特征作为特征向量，训练分类器，生成静态特征识别库。

基于单目视觉的动态手势 识别技术：

基于神经网络，基于HMMs,基于CRFs.

传统的动态手势识别，是基于HMMs,但HMMs是与观察无关的，也就是说，所有的情况在对模型训练时就必须要知道，否则就无法对这些未经训练的样本识别。实际中，我们不可能把所有的情况都考虑清楚，也不可能把所有的训练样本都训练。其次，观察无关还导致了标注偏移。虽然MEMMS在一定程度上解决了观察无关问题，但还是存在标注偏移问题。

基于模糊的条件随机场FCRF可以避免观察无关与标注偏移问题。

由于手势序列包括内部子结构和用于区分不同手势的外部动态结构，因此，LDCRFs不但可以辨识内部结构，同时可以辨识外部结构，针对连续手势，修改隐函数为模糊函数，即FLDCRFs.

本文对针对基于视觉的手势识别算法，做一个简单总结。后续有改进再补充。




﻿﻿



