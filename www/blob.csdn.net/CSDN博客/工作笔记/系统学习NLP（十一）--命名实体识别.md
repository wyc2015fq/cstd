# 系统学习NLP（十一）--命名实体识别 - 工作笔记 - CSDN博客





2019年03月09日 20:05:29[Eason.wxd](https://me.csdn.net/App_12062011)阅读数：191








转自：[https://www.cnblogs.com/bep-feijin/articles/9650898.html](https://www.cnblogs.com/bep-feijin/articles/9650898.html)

命名实体识别(Named EntitiesRecognition, NER)是自然语言处理(Natural LanguageProcessing, NLP)的一个基础任务。其目的是识别语料中人名、地名、组织机构名等命名实体。由于这些命名实体数量不断增加，通常不可能在词典中穷尽列出，且其构成方法具有各自的一些规律性，因而,通常把对这些词的识别从词汇形态处理(如汉语切分)任务中独立处理，称为命名实体识别。命名实体识别技术是信息抽取、信息检索、机器翻译、问答系统等多种自然语言处理技术必不可少的组成部分。

    命名实体是命名实体识别的研究主体，一般包括3大类(实体类、时间类和数字类)和7小类(人名、地名、机构名、时间、日期、货币和百分比)命名实体。评判一个命名实体是否被正确识别包括两个方面：实体的边界是否正确；实体的类型是否标注正确。主要错误类型包括文本正确，类型可能错误；反之，文本边界错误,而其包含的主要实体词和词类标记可能正确。

命名实体识别的主要技术方法分为：基于规则和词典的方法、基于统计的方法、二者混合的方法等。

# 1.基于规则和词典的方法

    基于规则的方法多采用语言学专家手工构造规则模板,选用特征包括统计信息、标点符号、关键字、指示词和方向词、位置词(如尾字)、中心词等方法，以模式和字符串相匹配为主要手段，这类系统大多依赖于知识库和词典的建立。基于规则和词典的方法是命名实体识别中最早使用的方法，一般而言，当提取的规则能比较精确地反映语言现象时，基于规则的方法性能要优于基于统计的方法。但是这些规则往往依赖于具体语言、领域和文本风格，编制过程耗时且难以涵盖所有的语言现象，特别容易产生错误，系统可移植性不好，对于不同的系统需要语言学专家重新书写规则。基于规则的方法的另外一个缺点是代价太大，存在系统建设周期长、移植性差而且需要建立不同领域知识库作为辅助以提高系统识别能力等问题。

# 2.基于统计的方法

    基于统计机器学习的方法主要包括：隐马尔可夫模型(HiddenMarkovMode,HMM)、最大熵(MaxmiumEntropy,ME)、支持向量机(Support VectorMachine,SVM)、[条件随机场](https://www.baidu.com/s?wd=%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)( ConditionalRandom Fields,CRF)等。

    在这4种学习方法中，最大熵模型结构紧凑，具有较好的通用性，主要缺点是训练时间复杂性非常高，有时甚至导致训练代价难以承受，另外由于需要明确的归一化计算，导致开销比较大。而条件随机场为命名实体识别提供了一个特征灵活、全局最优的标注框架，但同时存在收敛速度慢、训练时间长的问题。一般说来，最大熵和支持向量机在正确率上要比隐马尔可夫模型高一些，但是隐马尔可夫模型在训练和识别时的速度要快一些，主要是由于在利用Viterbi算法求解命名实体类别序列的效率较高。隐马尔可夫模型更适用于一些对实时性有要求以及像信息检索这样需要处理大量文本的应用,如短文本命名实体识别。

    基于统计的方法对特征选取的要求较高，需要从文本中选择对该项任务有影响的各种特征，并将这些特征加入到特征向量中。依据特定命名实体识别所面临的主要困难和所表现出的特性，考虑选择能有效反映该类实体特性的特征集合。主要做法是通过对训练语料所包含的语言信息进行统计和分析，从训练语料中挖掘出特征。有关特征可以分为具体的单词特征、上下文特征、词典及词性特征、停用词特征、核心词特征以及语义特征等。

基于统计的方法对语料库的依赖也比较大，而可以用来建设和评估命名实体识别系统的大规模通用语料库又比较少。

# 3.混合方法

    自然语言处理并不完全是一个随机过程,单独使用基于统计的方法使状态搜索空间非常庞大，必须借助规则知识提前进行过滤修剪处理。目前几乎没有单纯使用统计模型而不使用规则知识的命名实体识别系统，在很多情况下是使用混合方法：

    3.1 统计学习方法之间或内部层叠融合。

    3.2 规则、词典和机器学习方法之间的融合，其核心是融合方法技术。

    在基于统计的学习方法中引入部分规则，将机器学习和人工知识结合起来。

    3.3 将各类模型、算法结合起来，将前一级模型的结果作为下一级的训练数据，并用这些训练数据对模型进行训练，得到下一级模型。

    这种方法在具体实现过程中需要考虑怎样高效地将两种方法结合起来，采用什么样的融合技术。由于命名实体识别在很大程度上依赖于分类技术,在分类方面可以采用的融合技术主要包括如Voting, XVoting,GradingVa,l Grading等。

目前的主流工作，是将 NER当做深度学习任务来做，所以，我们需要大量的、高质量的数据。

公开数据集

首先让我们来看看常见公开数据集

CoNLL 2003（https://www.clips.uantwerpen.be/conll2003/ner/）

这个数据集包括1393篇英语新闻文章和909篇德语新闻文章。英语语料库是免费的，德国语料库需要收钱(75美元)。英语语料实际上是RCV1(Reuters Corpus, Volume 1， https://trec.nist.gov/data/reuters/reuters.html), 路透社早些年公开的一些数据集。你需要填个使用申请表(包含组织和个人两种类型)， 然后就可以使用了。

CoNLL2003中， 实体被标注为四种类型：
- 
LOC (location, 地名)

- 
ORG (organisation， 组织机构名)

- 
PER （person， 人名）

- 
MISC (miscellaneous， 其他)


一条标注数据的组织形式如下：

> 
[word][POS tag][chunk tag][NER tag]


比如：

U.N. NNP I-NP I-ORG 

official NN I-NP O 

Ekeus NNP I-NP I-PER 

heads VBZ I-VP O 

for IN I-PP O 

Baghdad NNP I-NP I-LOC 

. . O O

更加详细的关于标注数据的介绍， 见当时官方给出的一篇文章 http://www.aclweb.org/anthology/W03-0419

OntoNotes 5.0 / CoNNLL 2012 (https://catalog.ldc.upenn.edu/ldc2013t19)

OntoNotes 5.0由 1745k 英语、900k 中文和300k 阿拉伯语文本数据组成，OntoNotes 5.0的数据来源也多种多样， 有电话对话、新闻通讯社、广播新闻、广播对话和博客。实体被标注为【PERSON】、【ORGANIZATION】和【LOCATION】等18个类别， 详情见https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf。 你只需要在这个网站注册一下https://catalog.ldc.upenn.edu/signup

还有很多其他公开数据集，包括NLPBA2014， Enron Emails 等等， 这里就不做详细介绍了， 大家可以 google 一下。

标注方法

NER 标注方法有很多种， 这里主要介绍3种最常见。

IOB 标注法

IOB 标注法， 是 CoNLL 2003 采用的标注法， I 表示 inside, O 表示 Outside, B 表示 Begin。而标注的 label是 I-XXX 的， 表示这个字符， 在 XXX类命名实体的内部(inside)。B用于标记一个命名实体的开始。

比如：

Tom B-PER

hanks I-PER

is O

my O

name O

BIOES

这是在 IOB方法上，扩展出的一个更复杂，但更完备的标注方法。其中 B表示这个词处于一个实体的开始(Begin), I 表示内部(inside), O 表示外部(outside), E 表示这个词处于一个实体的结束为止， S 表示，这个词是自己就可以组成一个实体(Single)

BIOES 是目前最通用的命名实体标注方法。

Markup

Makeup 是 OntoNotes 使用的标注方法， 思路比较简单, XML， 比如：

ENAMEX TYPE=”ORG”>DisneyENAMEX> is a global brand .

它用标签把 命名实体框出来， 然后，在 TYPE 上， 设置相应的类型。

当然， 还有很多其他的标注方法， 比如 IO, BMEWO 等等，感兴趣的读者可以 google一下。

### 模型

目前业界比较常用的模型，是 LSTM + CRF。 这类模型中， NCRF++算法, 是目前最好的 NER 算法， 发表在 COLLING 2018上，论文见 https://arxiv.org/abs/1806.04470 。NCRF++在它的文章中报告其在 CoNLL2003 上能达到91.35的 F1。

框架

NCRF++的整体框架如下：

![](http://image109.360doc.com/DownloadImg/2018/06/2813/136982061_1_20180628011106582)

它支持 BIO（注意，BIO和 IOB 有点区别）, BIOES 两种标注模式。因为 CoNLL2003 太过久远，一般将其转换到新的标注格式上来，转换方法见：https://github.com/jiesutd/NCRFpp/blob/master/utils/tagSchemeConverter.py

表现

NCRF++是目前 state-of-the-art的命名实体识别方案：
|ID|Model|Nochar|CharLSTM|CharCNN|
|----|----|----|----|----|
|1|WordLSTM|88.57|90.84|90.73|
|2|WordLSTM+CRF|89.45|**91.20**|**91.35**|
|3|WordCNN|88.56|90.46|90.30|
|4|WordCNN+CRF|88.90|90.70|90.43|

速度

NCRF++的速度表现也非常优异， 在使用全批处理的情况下， 在单个1080 显卡上， 训练速度能到到1000句话每秒，解码速度能达到2000句话每秒。

![](http://image109.360doc.com/DownloadImg/2018/06/2813/136982061_2_20180628011106863)

目前 NCRF++ 已经开源(https://github.com/jiesutd/NCRFpp)



