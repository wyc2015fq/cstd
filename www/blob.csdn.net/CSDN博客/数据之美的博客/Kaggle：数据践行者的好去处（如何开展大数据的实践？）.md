# Kaggle：数据践行者的好去处（如何开展大数据的实践？） - 数据之美的博客 - CSDN博客
2017年08月31日 04:14:13[看穿数据之美](https://me.csdn.net/oppo62258801)阅读数：300
个人分类：[深度学习/机器学习																[大数据](https://blog.csdn.net/oppo62258801/article/category/6768103)](https://blog.csdn.net/oppo62258801/article/category/6739087)
[大数据](http://lib.csdn.net/base/hadoop)的学习是需要实践的，因为学习的最有效方式之一就是通过实践（Learning
 by doing），只有把学习和实践结合起来才能达到最大的效果。那么大数据的学习如何进行实践呢？一个很好的途径就是利用目前流行的数据分析、竞赛平台。今天就来介绍一个，名字叫Kaggle。
1、Kaggle是什么？
Kaggle是一个数据建模和数据分析竞赛平台。企业和研究者可在其上发布数据，统计学者和数据挖掘专家可在其上进行竞赛以产生最好的模型。这一众包模式依赖于这一洞见：解决某一预测性问题的方法和策略有很多，究竟什么方法对某一特定问题是最为有效的呢？答案就是群众的力量。Kaggle的目标就是试图通过众包的形式来解决这一难题，进而促进数据科学的发展。
Kaggle可以分为Competitions竞赛、Datasets数据集以及Kernel内核三个子平台，配套的还有Forum论坛模块，以及供各类公司或组织招聘人才的Jobs模块等。
数据分析初学者可以在Kaggle平台上获得很多好处：
- 
真实的数据。在自己学习数据分析的过程中，很多时候是苦于没有数据，很多书或课程的数据都是演示性的，数据量小，而真实世界的数据往往都是大量，到处充满了缺失和不足，实际的数据分析工作中，很多工作都是和这些缺陷作斗争，如果能在学校里或是学习的开始阶段就被这些数据“蹂躏”一下，未来在真实工作中也会适应很多。
- 
真实的问题。在Kaggle上发布的竞赛题目，一般都是企业或政府组织中真实面临的问题。比如DVD租赁公司的推荐[算法](http://lib.csdn.net/base/datastructure)，比赛结束之后，准确率比之前提高了10%，这些算法被实际应用到了实际推荐中去；还有教育机构寻求给作文打分的算法模型，可以减少人工打分的成本，同时保持打分的稳定性，不会因为个别人的问题影响评分公正性。实际的数据分析工作都是从实际问题出发，选择解决办法的时候要考虑到各种制约，没有绝对的对与错，都是要根据实际业务，具体问题具体分析。
- 
及时的反馈。以前参加一些网上的数据分析比赛的时候，都是提交解决方案后，等到比赛截止日最终才知道结果。而在Kaggle上，只要提交了算法结果，就可以在Leader board上看到自己的排名和成绩，你可以不断改进，如果一次改进可以提高上百位的排名，对自己很有激励作用，促使你进行不断的尝试，收获也越多。
- 
线上的讨论。每给Kaggle竞赛题目都配有一个论坛，参赛者在赛中和赛后可以相互讨论，这让学习不再孤单，可以在讨论中吸取别人的思路，也可以为他人提供指导。
截止到2016年5月份，Kaggle拥有超过536,000个Kagglers，其中包括了IBM Watson以及Google Deep Mind的研究团队。Kaggle在全球范围内拥有将近20万名数据科学家，专业领域从计算机科学到统计学、经济学和数学。Kaggle的数据涉及领域涵盖了计算机科学、[计算机视觉](http://lib.csdn.net/base/computervison)、生物、医药、甚至冰川学等等。很多Kaggle的竞赛都吸引了超过1,000个队伍和个人参赛。他们中的许多人都在各类会议和同行评议的期刊上发表了与其比赛结果相关的文章。每个月Kaggle论坛有超过4,000条新帖子，每天Kaggle比赛有超过3,500次提交。
Kaggle也曾经和NASA、维基百科、德勤和好事达合作举办竞赛。例如，一项奖项高达300万美金的竞赛是Heritage Health Prize，目的是通过病人看病及吃药住院等数据预测明年病人住院的天数；另一项与微软合作的竞赛则旨在提高Kinect的手势识别精度；其他还包括艾滋病研究、棋牌评级和交通预测等。基于这些成果还能产生一系列的学术论文。产生这一结果的原因是实时积分榜促使参加者不断改进以试图超越当前的最佳实践。获胜的方法常常在Kaggle的博客No Free Hunch上展示。
2、关于比赛
Kaggle的比赛类型按照奖励内容可以分成3种，分别是提供奖金的Featured类，提供实习、面试机会的Recruitment类以及纯粹作为练手的Playground类。因此，对于初学者来说，可以从Playground类开始。
参加比赛的流程相当简单，简单来说就是分为Download → Build → Submit三个步骤。
- 
Download：Kaggle比赛的主持人（发起人）Host会准备数据和问题的描述，每个比赛都会有较详细的子页面来介绍背景、数据集、以及评价指标和提交方式等相关要求。Kaggle负责对这一过程以及竞赛的建构、数据的匿名化以及集成最终获胜的模型提供咨询服务。
- 
Build：参赛者在本地构建出一个模型之后，输入比赛提供的数据集进行训练，得到的预测结果上传回Kaggle。
- 
Submit：参赛者相互竞赛以获得最优的模型，参赛提交会根据预测精度被立即评分，并实时显示。
在截止时间过后，竞赛主持人为“全球性的，永久性的，不可撤销和免版税地使用获奖作品”支付奖金。亦即竞赛获胜者的算法、软件和相关的知识产权是非排他性的。
除了公开竞赛以外，Kaggle还向活跃参与者提供私下的比赛，以及为大学团体提供Kaggle-in-Class项目。
比赛取得优胜的方法常常在Kaggle的博客No Free Hunch上展示。
3、关于数据集
Kaggle从2016年1月开始上线了Datasets数据集服务，收集了许多公共的数据集，提供数据下载、介绍、相关脚本Scripts以及独立的论坛等服务。
利用Kaggle的数据集，通过简单的Dig in → Build → Connect的步骤，就可以自己挖掘、分析公共数据集的内容。
- 
Dig in：直接在Kaggle上使用其提供的交互式工具来进行数据分析，支持R、[Python](http://lib.csdn.net/base/python)、Julia、R
 Markdown、SQLite等语言，Kaggle通过调用相应的[Docker](http://lib.csdn.net/base/docker)容器来编译执行脚本。
- 
Build：在本地或者网页版工具上进行数据分析处理之后，可以发布自己发现的数据insights，使用Kaggle Kernels来coding，并能保存到自己的Kaggle账号仓库中。
- 
Connect：可以很方便的查看其他人公开的Kaggle Kernels，或者在论坛中咨询对应数据集的相关问题。
4、关于Kernels
Kaggle的脚本仓库以前叫做Scripts，现在改名叫Kernels了。据其官方博客所说，改名是为了更好的契合这个子项目的功能：Kernels提供了数据分析所需的环境、数据集、代码和输出样式（比如[python](http://lib.csdn.net/base/python)
 Notebook），将这些功能聚合在一起可以使得Kernels可以很方便的复现和分享。Kaggle的目的是要使得Kernels成为数据分析的核心，他们想将Kernels打造为一个能实现并分享所有数据科学工作的平台，包括与本地工具的结合（Kernels现在提供的环境库并没有办法做到包罗万象）、团队间的私有合作空间等等。
之前Datasets里面的网页版工具就是调用了Kaggle的Kernels平台，其一大好处就在于不需要将数据集加载在本地，Kernels中已经预先载入了庞大的数据集和基本的数据处理环境和库（甚至都不需要在本地配环境！）。这点很棒，毕竟庞大的数据要下载下来在网络条件不允许的情况下还是相当耗费时间，在本地配好一系列的数据处理环境也不容易，Kernels借助[docker](http://lib.csdn.net/base/docker)镜像解决了这一问题。（类似的数据上云的方式开始越来越流行）
同时，Kernels采用了类似Github的方式，有[版本控制](http://lib.csdn.net/base/git)，也可以fork他人的仓库。Kernels还支持Python Notebook的在线查看，更加直观。
5、排名系统
除此之外，Kaggle还提供了一套用户的排名等级系统Progression System，等级可以从低到高分别是Novice、Contributor、Expert、Master和Grandmaster。类似于游戏里做任务一样，在Competitions中完成指定类型的比赛、在Kernels中分享代码、在Forum中回答他人的问题都可以累计积分，达到一定要求之后就可以升级。
这个排名可能除了鼓励大家多参赛做任务升级之外，也是招聘时候的一个重要参考。很多公司举办类似比赛的目的基本上都是为了招人。
6、Kaggle的比赛可以锻炼什么能力？
首先说，绝大部分的Kaggle比赛是Data Mining（DM）比赛，但和Machine Learning（ML）关系不大。这是很多人一个误区，往往希望在Kaggle上学到很多ML的知识。Kaggle教给我们的第一件事情，就是让我们清晰领会到了这两者之间的不同：ML一般从模型或者算法出发，讲的是模型或者算法本身存在的不合理的地方，然后提出新的假设，从而去优化模型或算法，在这个过程中并不针对某一个具体的特殊的问题。而DM恰恰相反，它是从数据本身问题本身出发，希望针对问题的特性来设计最适合的方案。关键是在于对问题和数据的理解。
其次，在一个DM的比赛中，最能锻炼到的是对于数据的“嗅觉”。举一个例子，往往在比赛中会存在Data Leakage的情况，也就是说，某些和label相关的信息不小心会泄漏在feature中。有人通过这样的feature取得了很好的成绩。虽然Data Leakage不是一件好事情，但是在这背后往往隐藏的是发现leakage的人对于数据本身深刻的认识。这并不是每个人都能做到的。换句话讲，就算没有leakage，这群人还是会排名很前。在Kaggle的比赛中，能收获最大的就是这种嗅觉。可以把自己训练成了一个data
 believer：也许一次两次的巧合真的是意外，但是如果巧合总是持续发生，那么背后一定有一个原因。
7、怎样才能做好Kaggle的比赛？
第一点也是最重要的一点就是专注，专注，再专注。
第二点，永远不要放弃。希望总存在于绝望之后。每个比赛都会有一个瓶颈期。耐心地去突破它后，就是一片开阔天空。
第三点，切记只看不做。很多人只喜欢纸上谈兵，武断觉得这个问题，或者这个数据就应该是怎样。很多数据的特质都是要真正动手做进去才能发现其中的奥妙，针对这些特质设计的一些Feature或者Model，往往都能带来极大的提高。
第四点，才是多看，尤其是在比赛结束之后。很多leader会在比赛结束之后部分甚至全部地公布自己的解法。这个时候返回去看看在比赛中自己忽略掉了什么地方，才是成长最最重要的。
8、技术方面上什么最关键？
前面提到Kaggle主要是以Data Mining的比赛为主，那么这个答案就非常直接了：Feature Engineering。做Kaggle比赛如果是抱着Machine Learning的态度，沉迷于fancy的模型而忽略数据本身，注定是会失败的。
当然，基本的ML知识还是有的。在比赛中，最常用的分类器一般是Gradient Boosting Tree（GBDT）和Random Forest。一些常见的预处理技巧，比如PCA，K-Means，TF/IDF，Hashing等等都还是必须的。大家需要学习的内容还是很多的，但是有了具体的目标，这些都不是问题，在做中学是最具效率的方法。
最后，还有一个非常关键的点是Ensemble方法的重要性，从KDD Cup比赛到ImageNet，使用Ensemble方法几乎都能改善结果，只是多与少的问题。不做Ensemble就意味着你自己告别了一大块宝藏。所以这个技能必须掌握！
9、总结
总的来说，Kaggle是一个对于每个想成为所谓的Data Scientist的同学最好的练兵场所。在这里，你就会知道课上学到的那些东西和能解决一个实际问题所需要的能力的差距。而且，在学校里往往是拿不到任何大规模的数据的，绝大多数课堂上用的还是只有几百个几千个数据的小dataset，Kaggle是缩小这个Gap最好的一个地方。当然，真正的大数据还需要借助真正的大数据平台，例如前面课程中提到过的众多基于[Hadoop](http://lib.csdn.net/base/hadoop)的大系统。
同时，国内类似的学习/比赛平台也开始越来越多起来，像阿里的天池平台、DataFountain大数据竞赛平台等，上面也开始有越来越多的实际数据和问题了。还有就是像上海的SODA大赛，政府开放数据的思路还是对的，就是技术还没能很好地跟上，还是基于原始数据的下载，耗费了很多的时间和网络带宽，希望后面能提供大数据的完整分析平台和API，参赛者只用把精力集中在创意、洞察、算法、模型这样的地方就完美了。
小窍门：
Kaggle winner = feature engineering + ensemble + good machine + domain knowledge + right team
最后，希望大家都能在各种数据平台上都玩得愉快，在大数据上学得开心~
