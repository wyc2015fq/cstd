# 机器学习特征处理---离散化特征的方法 - 数据之美的博客 - CSDN博客
2018年02月06日 16:13:15[看穿数据之美](https://me.csdn.net/oppo62258801)阅读数：508
在logistic regression上，需要把一些**连续特征**进行**离散化**处理。离散化除了一些计算方面等等好处，还可以引入非线性特性，模型会更稳定
连续性变量转化成离散型变量大致有两类方法：
（1）卡方检验方法；
（2）信息增益方法；
一： **卡方检验**（X2检验）方法
1.1 分裂方法
1.2 合并方法
分裂方法，就是找到一个分裂点看，左右2个区间，**在目标值上分布是否有显著差异**，有显著差异就分裂，否则就忽略。这个点可以每次找差异最大的点。
合并类似，先划分为多个很小的单元区间，按顺序合并在目标值上分布不显著的相邻区间，直到收敛。
二：**信息增益**方法
2.1 分裂方法
2.2 合并方法
这个和决策树的学习很类似。
分裂方法，就是找到一个分裂点看，左右2个区间，看分裂前后**信息增益变化阈值**，如果差值超过阈值（正值，分列前-分裂后信息熵），则分裂。每次找差值最大的点做分裂点，直到收敛。
合并类似，先划分为多个很小的单元区间，按顺序合并信息增益小于阈值的相邻区间，直到收敛。
（1）什么是信息增益？
熵：表示随机变量的不确定性。
条件熵：在一个条件下，随机变量的不确定性。
信息增益：熵 - 条件熵
在一个条件下，信息不确定性减少的程度！
在特征选择的时候常常用信息增益，如果IG（信息增益大）的话那么这个特征对于分类来说很关键~~ 决策树就是这样来找特征的！
