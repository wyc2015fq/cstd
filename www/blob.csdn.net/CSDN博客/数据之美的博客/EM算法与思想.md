# EM算法与思想 - 数据之美的博客 - CSDN博客
2017年09月22日 17:47:43[看穿数据之美](https://me.csdn.net/oppo62258801)阅读数：137
个人分类：[深度学习/机器学习																[大数据](https://blog.csdn.net/oppo62258801/article/category/6768103)](https://blog.csdn.net/oppo62258801/article/category/6739087)
EM思想与最大似然参数估计问题密切相关。单纯的同参数(同一类别)同分布的参数估计使用最大似然估计或矩估计解决。若是混合参数(多个类别)同分布的参数估计使用的就是EM思想。EM算法就是这样，假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。             
         EM的意思是“Expectation Maximization”。其概率模型涉及无法观测的隐含变量(参数)
        最大期望算法经过两个步骤交替进行计算：
        第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；
        第二步是最大化（M），最大化在 E 步上求得的最大似然值来计算参数的值。
        M 步上找到的参数估计值被用于下一个 E 步计算中，这个过程不断交替进行。 迭代使用EM步骤，直至收敛。
        EM是一种解决存在隐含变量优化问题的有效方法。
