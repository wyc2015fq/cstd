# 高偏差、高方差、低精确率与低召回率、混淆矩阵 - 数据之美的博客 - CSDN博客
2017年09月19日 17:34:22[看穿数据之美](https://me.csdn.net/oppo62258801)阅读数：627
本文是个人理解
1.高偏差(high bias)与方差(high variance)
    偏差,可以理解为样本与模型预测结果的差距，可以使用平方差计算
    方差是样本y值与模型期望的差的平方和。
    模型对实验数据欠拟合(underfitting) 是会出现搞偏差，而过拟合(overfitting)会造成高方差
    解决方法：直接的方法是将实验数据一分为二：训练集和测试集。模型在训练集和测试集上都达到高正确率才说明偏差和方差都可以接受
                       增加体征的数量可以降低偏差；减少特征数量可以降低方差
2. 精确率(precision)与召回率(recall)
![](https://img-blog.csdn.net/20170105170755506?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center) ,  '真正' 与 '真负'总和中'真正'的比例。
![](https://img-blog.csdn.net/20170105170821475?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center) ， 即 '真正' 与'假负'总和中真正的比例
     以新闻推荐举例。
      精确率可以理解为，所有推荐了的新闻中该推荐的新闻的比例。 比如，推荐了10篇新闻，其中8篇是应该推荐的
      召回率可以理解为，所有应该推荐的新闻中实际推荐了的新闻的比例。比如应该推荐10篇感兴趣的新闻，只推荐了其中的8篇。
      要平衡精确率和召回率，可以调节区分正负类别的概率临界值。 为提高精确率，可以提高概率临界值，使得正类别的判断更加
       保守；为了提高召回率，可以降低概率临界值，以增加正类别的数量
3. 混淆矩阵
|在[机器学习](http://www.dataguru.cn/article-4063-1.html?union_site=innerlink)（[人工智能](http://www.dataguru.cn/article-10276-1.html?union_site=innerlink)领域），混淆矩阵（confusionmatrix）是可视化工具，特别用于[监督学习](http://baike.baidu.com/view/2759226.htm)，在[无监督学习](http://baike.baidu.com/view/3552442.htm)一般叫做匹配矩阵。矩阵的列表示预测类的实例，行表示实际类的实例，这样通过混淆矩阵的一些指标可以衡量[算法](http://www.dataguru.cn/article-5747-1.html?union_site=innerlink)的精度。||Predicted| | ||----|----|----|----||Negative|Positive| | ||Actual|Negative|a|b||Positive|c|d| |- - a表示伪的预测正确值- b表示伪的预测错误值- c表示真的预测错误值- d表示真的预测正确值AC（Accuracy）=(a+d)/(a+b+c+d)TP（recall or true positive rate） = d/(c+d)FP（false positive rate） = b/(a+b)TN （true negative rate）= a/(a+b)FN（false negative rate） = c/(c+d)P（precision） = d/(b+d)||Predicted|Negative|Positive|Actual|Negative|a|b|Positive|c|d|
|----|----|----|----|----|----|----|----|----|----|----|----|
||Predicted| | | | | | | | | | |
|Negative|Positive| | | | | | | | | | |
|Actual|Negative|a|b| | | | | | | | |
|Positive|c|d| | | | | | | | | |
- 
- a表示伪的预测正确值
- b表示伪的预测错误值
- c表示真的预测错误值
- d表示真的预测正确值
AC（Accuracy）=(a+d)/(a+b+c+d)
TP（recall or true
 positive rate） =
 d/(c+d)
FP（false
 positive rate） =
 b/(a+b)
TN （true
 negative rate）=
 a/(a+b)
FN（false
 negative rate） =
 c/(c+d)
P（precision） =
 d/(b+d)
