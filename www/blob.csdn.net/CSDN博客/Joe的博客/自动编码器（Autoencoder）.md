# 自动编码器（Autoencoder） - Joe的博客 - CSDN博客





2016年09月20日 22:16:52[Joe-Han](https://me.csdn.net/u010089444)阅读数：27096标签：[深度学习																[自动编码器																[神经网络](https://so.csdn.net/so/search/s.do?q=神经网络&t=blog)
个人分类：[深度学习](https://blog.csdn.net/u010089444/article/category/6419961)





# **Autoencoder**

autoencoder是一种无监督的学习算法，主要用于数据的降维或者特征的抽取，在深度学习中，autoencoder可用于在训练阶段开始前，确定权重矩阵$W$的初始值。

神经网络中的权重矩阵$W$可看作是对输入的数据进行特征转换，即先将数据编码为另一种形式，然后在此基础上进行一系列学习。然而，在对权重初始化时，我们并不知道初始的权重值在训练时会起到怎样的作用，也不知道在训练过程中权重会怎样的变化。因此一种较好的思路是，利用初始化生成的权重矩阵进行编码时，我们希望编码后的数据能够较好的保留原始数据的主要特征。那么，如何衡量码后的数据是否保留了较完整的信息呢？答案是：如果编码后的数据能够较为容易地通过解码恢复成原始数据，我们则认为$W$较好的保留了数据信息。

例如下图所示，将手写数字图片进行编码，编码后生成的 $\phi_{1}$, $\phi_{2}$, $\phi_{3}$, $\phi_{4}$, $\phi_{5}$, $\phi_{6}$ 较完整的保留了原始图像的典型特征，因此可较容易地通过解码恢复出原始图像。

![图片名称](https://img-blog.csdn.net/20160920223152660)

autoencoder通过神经网络进行预训练，从而确定$W$的初始值。其目标是让输入值等于输出值。如下图所示：首先用$W$对输入进行编码，经过激活函数后，再用$W^{\mathrm{T}}$进行解码，从而使得$h(x) \approx  x$。该过程可以看作是对输入数据的压缩编码，将高维的原始数据用低维的向量表示，使压缩后的低维向量能保留输入数据的典型特征，从而能够较为方便的恢复原始数据。**需要注意的是：**这里增加了一个约束条件，即在对数据进行编码和解码时，使用的是同一个参数矩阵$W$。该约束可看作是一种regularization，用于减少参数的个数，控制模型的复杂度。

![图片名称](https://img-blog.csdn.net/20160920230254228)

对于多层神经网络的参数初始化问题，我们可以依次对每一层进行autoencoder。如下图所示，具体做法是首先按照上述方法确定第一层的权重参数，然后固定第一层的参数，对第二层的参数进行训练，以此类推，直到得到所有权重值。

![图片名称](https://img-blog.csdn.net/20160921094159574)](https://so.csdn.net/so/search/s.do?q=自动编码器&t=blog)](https://so.csdn.net/so/search/s.do?q=深度学习&t=blog)




