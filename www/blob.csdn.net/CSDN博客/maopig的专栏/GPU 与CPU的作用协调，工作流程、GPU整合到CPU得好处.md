# GPU 与CPU的作用协调，工作流程、GPU整合到CPU得好处 - maopig的专栏 - CSDN博客
2011年09月23日 10:56:25[maopig](https://me.csdn.net/maopig)阅读数：9974

在不少人的心目中，显卡最大的用途可能就只有两点——玩游戏、看电影，除此之外，GPU并没有其他的作用了。但是随着微软IE9的正式发布，不少人突然发现，微软一直提到一个名词：GPU硬件加速，从而也让不少人开始关注GPU硬件加速。那么GPU硬件加速到底是什么？能干些什么呢？下面让我们一起走进GPU硬件加速的世界去看看吧。 GPU硬件加速就是显卡辅助CPU进行图形运算
要说起GPU硬件加速，我们首先要说说GPU这个概念。GPU是1999年，NVIDIA公司在发布GeForce256时提出的，它可以减少对CPU的依赖，并且进行部分原本属于CPU的工作，从而解放CPU（你也可以理解成抢夺CPU的工作）。也正是因为GPU的诞生，电脑中最重要的硬件开始从CPU一家独大向着CPU和GPU并存的局面转变。
下面我们来说说硬件加速，简而言之，硬件加速就是利用硬件模块来替代软件算法以充分利用硬件所固有的快速特性。那么稍加变化就可以知道，GPU硬件加速就是指利用GPU强大的硬件图形处理能力，来代替CPU原本使用的软件模拟图形处理算法，从而充分利用GPU的特长为系统服务。
小贴士：GPU硬件加速时系统如何运行呢？
现在我们有两个处理器、CPU和GPU，它们之间通过系统总线交换数据。
第一步：CPU从文件系统里读出原始数据，分离出图形数据，然后放在系统内存中，这个时候GPU在发呆。
第二步：CPU准备把图形数据交给GPU，这时系统总线上开始忙了，数据将从系统内存拷贝到GPU的显存里。
第三步：CPU要求GPU开始数据处理，现在换CPU发呆了，而GPU开始忙碌工作。当然CPU还是会定期询问一下GPU忙得怎么样了。
第四步：GPU开始用自己的工作间（GPU核心电路）处理数据，处理后的数据还是放在显存里面，CPU还在继续发呆。
第五步：图形数据处理完成后，GPU告诉CPU，我忙完了，准备输出或者已经输出。于是CPU开始接手，读出下一段数据，并告诉GPU可以歇会了，然后返回第一步。
GPU硬件加速可以让你的系统变得更快
既然GPU硬件加速是利用GPU的特长为系统服务，那么好处是什么呢？这里用时下非常流行的骑游运动做个比方，正常情况下你在骑行的时候只有腿部在进行蹬踩运动（CPU正常运算），而当你遇到诸如顺风、下坡、被人推行等情况时，速度就会加快，并且腿部感觉非常省力（GPU参与运算）。
那么换到电脑上会是什么情况呢？在以前的很多应用中，CPU是负责所有运算的，而GPU则只是负责最后的显示工作，因此一旦出现处理复杂图形数据的时候，很多使用性能较弱的CPU的电脑系统就开始缓慢无比，而使用性能较强的CPU的电脑系统也会看到CPU资源被大量的占用。
而在GPU开始参与运算之后，原本会消耗CPU大量宝贵资源的图形数据处理部分就全部交给GPU这个专业人士进行处理了，从而降低了CPU的负担，并且利用自身的特长，使得图形数据处理的效率更快，从而提升系统性能。
既然GPU硬件加速有这样的好处，那么我们就一起来看看它在日常生活中到底能为我们带来什么好处吧。
GPU 放到CPU中的好处：  就GPU而言，整合在CPU内可以加快数据传输和运算功能，提高GPU和CPU的通信效率， 不再和以往一样被系统总线的速度所牵制，可以更好
                                               的释放GPU本身的性能。
GPU的工作原理：[http://wenku.baidu.com/view/14840f6727d3240c8447eff1.html](http://wenku.baidu.com/view/14840f6727d3240c8447eff1.html)
      GPU实际上一组图形函数的集合，而这些函数由硬件实现。GPU
     从某种意义上来说就是为了在图形处理过程中充当主角而出现的。
     一块标准的GPU主要包括2D Engine、3D Engine、Video Processsing Engine、
     FSAA Engine、显存管理单元。
     显卡的显存一部分存放的是GPU处理之前的数据，另外一部分是GPU处理之后的数据。
GPU之所以称为图形处理器，最主要的原因是因为它可以进行几乎全部与计算机
  图形学有关的运算，而这些运算过去式CPU的专利。GPU的渲染速率每六个月就
  翻一番。最大的作用就是进行各种绘制计算机图形所需的运算。
内存满足不了显卡的需求，显存应运而生:
    本是同根生的状况一直持续到SDR和DDR交接的时代，其实最早用在显卡上的DDR颗粒与用在内存上的DDR颗粒仍然是一样的。后来由于GPU特殊的需要，
    显存颗粒与内存颗粒开始分道扬镳，这其中包括了几方面的因素：
    1. GPU需要比CPU更高的带宽。GPU不像CPU那样有大容量二三级缓存，GPU与显存之间的数据交换远比CPU频繁，而且大多都是突发性的数据流，因此
    GPU比CPU更加渴望得到更高的显存带宽支持。
    位宽×频率=带宽，因此提高带宽的方法就是增加位宽和提高频率，但GPU对于位宽和频率的需求还有其它的因素。
    2．显卡需要高位宽的显存。显卡PCB空间是有限的，在有限的空间内如何合理的安排显存颗粒，无论高中低端显卡都面临这个问题。
    从布线、成本、性能等多种角度来看，显存都需要达到更高的位宽。
    最早的显存是单颗16bit的芯片，后来升级到32bit，将来甚至还会有更高的规格出现。而内存则没有那么多要求，多年来内存条都是64bit，
    所以单颗内存颗粒没必要设计成高位宽，只要提高容量就行了，所以位宽一直维持在4/8bit。
    3．显卡能让显存达到更高的频率。显存颗粒与GPU配套使用时，一般都经过专门的设计和优化，而不像内存那样有太多顾忌。GPU的显存控制
    器比CPU或北桥内存控制器性能优异，而且显卡PCB可以随意的进行优化，
    因此显存一般都能达到更高的频率。而内存受到内存PCB、主板走线、北桥CPU诸多因素的限制很难冲击高频率
　　由此算来，显存与内存“分家”既是意料之外，又是情理之中的事情了。为了更好地满足显卡GPU的特殊要求，一些厂商(如三星等)推出了专门
为图形系统设计的高速DDR显存，称为“Graphics Double Data Rate DRAM”，也就是我们现在常见的GDDR。
