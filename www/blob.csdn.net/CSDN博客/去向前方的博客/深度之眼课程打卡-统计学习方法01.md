# 深度之眼课程打卡-统计学习方法01 - 去向前方的博客 - CSDN博客





2019年03月08日 18:01:56[Big_quant](https://me.csdn.net/lvsehaiyang1993)阅读数：35








# 目录




### 文章目录
- [目录](#_0)
- [前言](#_3)
- [绪论](#_5)
- [作业打卡](#_7)
- [L1和L2范式](#L1L2_8)
- [ROC曲线](#ROC_14)
- [一 roc曲线](#_roc_21)
- [二 如何画roc曲线](#_roc_57)
- [三 为什么使用Roc和Auc评价分类器](#_RocAuc_67)
- [补充 混淆矩阵](#__73)
- [参考](#_129)




# 前言

为了增加实战经验，选择了开通深度之眼vip，先试试水，效果好的话，推荐给大家。

# 绪论

统计学习方法主要是讲李航博士统计学习方法那本书，一开始主要讲解了一些基本概念。

# 作业打卡

## L1和L2范式

l1范数的数学定义是所有数绝对值之和。

在坐标平面上它是个正方形。

l2范数的数学定义是所有数的平方和。

在坐标平面上它是个圆形。

l1适合特征少而明锐的情况，l2适合特征多而平均的情况。
## ROC曲线

受试者工作特征曲线 （receiver operating characteristic curve，简称ROC曲线），又称为感受性曲线（sensitivity curve）。得此名的原因在于曲线上各点反映着相同的感受性，它们都是对同一信号刺激的反应，只不过是在两种不同的判定标准下所得的结果而已。受试者工作特征曲线就是以假阳性概率（False positive rate）为横轴，真阳性（True positive rate）为纵轴所组成的坐标图，和受试者在特定刺激条件下由于采用不同的判断标准得出的不同结果画出的曲线。

ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），以真阳性率（灵敏度）为纵坐标，假阳性率（1-特异度）为横坐标绘制的曲线。传统的诊断试验评价方法有一个共同的特点，必须将试验结果分为两类，再进行统计分析。ROC曲线的评价方法与传统的评价方法不同，无须此限制，而是根据实际情况，允许有中间状态，可以把试验结果划分为多个有序分类，如正常、大致正常、可疑、大致异常和异常五个等级再进行统计分析。因此，ROC曲线评价方法适用的范围更为广泛。

1.ROC曲线能很容易地查出任意界限值时的对疾病的识别能力。

2.选择最佳的诊断界限值。ROC曲线越靠近左上角,试验的准确性就越高。最靠近左上角的ROC曲线的点是错误最少的最好阈值，其假阳性和假阴性的总数最少。

3.两种或两种以上不同诊断试验对疾病识别能力的比较。在对同一种疾病的两种或两种以上诊断方法进行比较时，可将各试验的ROC曲线绘制到同一坐标中，以直观地鉴别优劣，靠近左上角的ROC曲线所代表的受试者工作最准确。亦可通过分别计算各个试验的ROC曲线下的面积(AUC)进行比较，哪一种试验的 AUC最大，则哪一种试验的诊断价值最佳。
### 一 roc曲线

1、roc曲线：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。

横轴：负正类率(false postive rate FPR)特异度，划分实例中所有负例占所有负例的比例；(1-Specificity)

纵轴：真正类率(true postive rate TPR)灵敏度，Sensitivity(正类覆盖率)
2针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.

(1)若一个实例是正类，并且被预测为正类，即为真正类(True Postive TP)

(2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)

(3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)

(4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)

TP:正确的肯定数目

FN:漏报，没有找到正确匹配的数目

FP:误报，没有的匹配不正确

TN:正确拒绝的非匹配数目
列联表如下，1代表正类，0代表负类：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308165937784.png)

由上表可得出横，纵轴的计算公式：
(1)真正类率(True Postive Rate)TPR: TP/(TP+FN),代表分类器预测的正类中实际正实例占所有正实例的比例。Sensitivity

(2)负正类率(False Postive Rate)FPR: FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例。1-Specificity

(3)真负类率(True Negative Rate)TNR: TN/(FP+TN),代表分类器预测的负类中实际负实例占所有负实例的比例，TNR=1-FPR。Specificity

假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR),在平面中得到对应坐标点。随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0),阈值最小时，对应坐标点(1,1)。

如下面这幅图，(a)图中实线为ROC曲线，线上每个点对应一个阈值。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308170009841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2c2VoYWl5YW5nMTk5Mw==,size_16,color_FFFFFF,t_70)横轴FPR:1-TNR,1-Specificity，FPR越大，预测正类中实际负类越多。
纵轴TPR：Sensitivity(正类覆盖率),TPR越大，预测正类中实际正类越多。

理想目标：TPR=1，FPR=0,即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。

### 二 如何画roc曲线

假设已经得出一系列样本被划分为正类的概率，然后按照大小排序，下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308170033912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2c2VoYWl5YW5nMTk5Mw==,size_16,color_FFFFFF,t_70)接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308170055718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2c2VoYWl5YW5nMTk5Mw==,size_16,color_FFFFFF,t_70)

AUC(Area under Curve)：Roc曲线下的面积，介于0.1和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。
首先AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类。

### 三 为什么使用Roc和Auc评价分类器

既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。下图是ROC曲线和Presision-Recall曲线的对比：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308170115815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x2c2VoYWl5YW5nMTk5Mw==,size_16,color_FFFFFF,t_70)在上图中，(a)和©为Roc曲线，(b)和(d)为Precision-Recall曲线。
(a)和(b)展示的是分类其在原始测试集(正负样本分布平衡)的结果，©(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果，可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线变化较大。

## 补充 混淆矩阵

混淆矩阵是除了ROC曲线和AUC之外的另一个判断分类好坏程度的方法。以下有几个概念需要先说明：

TP(True Positive): 真实为1，预测也为1

FN(False Negative): 真实为1，预测为0

FP(False Positive): 真实为0，预测为1

TN(True Negative): 真实为0，预测也为0

:分类模型总体判断的准确率(包括了所有class的总体准确率)
![在这里插入图片描述](https://img-blog.csdnimg.cn/2019030817590343.png)

: 预测为1的准确率
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308175910575.png)
: 真实为1的准确率

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308175917518.png)

: 真实为0的准确率

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019030817592425.png)

: 预测为0的准确率

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308175933346.png)

: 对于某个分类，综合了Precision和Recall的一个判断指标，F1-Score的值是从0到1的，1是最好，0是最差

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019030818000591.png)

: 另外一个综合Precision和Recall的标准，F1-Score的变形

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190308180014899.png)

因此我们知道，计算Specificity，Recall，Precision等只是计算某一分类的特性，而Accuracy和F1-Score这些是判断分类模型总体的标准。我们可以根据实际需要，得出不同的效果。

作者：remychan

链接：[https://www.jianshu.com/p/0fc8a0b784f1](https://www.jianshu.com/p/0fc8a0b784f1)

来源：简书

简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。
# 参考

百度百科
[受试者特征工作曲线](https://www.cnblogs.com/dlml/p/4403482.html)














