# 统计学2 - ls317842927的博客 - CSDN博客





2017年01月29日 21:06:32[ls317842927](https://me.csdn.net/ls317842927)阅读数：226








**随机变量**

我们熟悉的变量是比如y=2x+3,x y是变量，该变量可以变化，可以取特定值，可以求出值。而随机变量虽然也可以取很多值，但这些变量无法求解。随机变量用大写字母X Y Z表示，这和可以求解的传统变量分开。**随机变量其实是一种函数，将随机过程映射到实际数字**。假设想量化一个随机过程，比如明天是否下雨。我们则可以定义一个随机变量X，如下图。X这个变量的取值是随机的，因为这个过程是随机的。再比如骰子抛出的数值就是一个随机变量。 
![随机变量](https://img-blog.csdn.net/20170129173909000?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
随机变量有**离散随机变量**和**连续随机变量**两种类型。之前举例的是离散随机变量，这些情况的结果可以一个个枚举出来，是有穷的。而连续随机变量有无限个结果，比如X定义为明天雨量的英寸数，它可以取到无限集合中的任意一个值。将两者区分开是因为其概率的分布有一些差别。

**离散随机变量的概率分布**
![这里写图片描述](https://img-blog.csdn.net/20170129181804635?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

可以看出$p(X=6)=\frac{1}{6}$，$p(X\geq 5)=\frac{1}{6}+\frac{1}{6}$等。
**连续随机变量的概率密度函数**
![这里写图片描述](https://img-blog.csdn.net/20170129195436726?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

问明天正好下2英寸雨的概率$P\left (  Y=2 \right )$是多少，这是不对的，不多不少正正好好衡量到2英寸几乎不可能，所以只能问Y大概是2的概率是多少，即$P\left ( \left | Y-2 \right |< 0.1 \right )$，求（1.9，2.1）区间内相应曲线下方的面积，也就是概率密度函数两点间的定积分$\int_{1.9}^{2.1}f\left ( x \right )dx$。 

连续型随机变量的概率密度函数$f\left ( x \right )$下方面积为1，即$\int_{0}^{\infty }f\left ( x \right )dx=1$。离散型随机变量也一样，所有随机变量的概率加一起必然为1。
**二项分布**

假设有一枚硬币，两面均匀，往上抛5次。定义一个随机变量X=5次中正面向上的次数。 
$P(X=0)=C^{0}_{5}(\frac{1}{2})^{5}=\frac{1}{32}$
$P(X=1)=C^{1}_{5}(\frac{1}{2})^{5}=\frac{5}{32}$
$P(X=2)=C^{2}_{5}(\frac{1}{2})^{5}=\frac{10}{32}$
$P(X=3)=C^{3}_{5}(\frac{1}{2})^{5}=\frac{10}{32}$
$P(X=4)=C^{4}_{5}(\frac{1}{2})^{5}=\frac{5}{32}$
$P(X=5)=C^{5}_{5}(\frac{1}{2})^{5}=\frac{1}{32}$

X的概率分布如下图。如果将试验次数改为500万次，条形之间的距离会非常近，开始趋近于钟形曲线。因为正面向上的概率=0.5，所以图像是对称的。如果正面向上的概率>0.5，$P(X=5)>P(X=0)$图像会向右移，反之会向左移。 
![这里写图片描述](https://img-blog.csdn.net/20170129220230316?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
它对统计学的重要性还体现在，很多时候我们无法知道实际机理，只能假设很多随机事物在进行，把这些随机事件加起来，就像数正面一样，离散的情况会得到二项分布，连续的情况则得到正态分布。这很重要，因为很多时候人们都对特定事物进行这种假设，假设随机过程是符合二项或者正态分布。 
$P(X=n)=C^{n}_{5}(\frac{1}{2})^{5}=\frac{5！}{n!(5-n)!}(\frac{1}{2})^{5}$ ，其中$C^{n}_{5}$为二项式系数。称为二项分布的原因是根据二项式系数就可以确定其概率。

再举一个例子，假设投6次篮，每次命中概率为0.3，定义随机变量X=投进的次数。这比之前投硬币更有趣一些因为投硬币正反的概率是相等的，而这里投中的概率比不中的概率小。 
$P(X=0)=C^{0}_{6}(0.7)^{6}$
$P(X=1)=C^{1}_{6}(0.3)(0.7)^{5}$
$P(X=2)=C^{2}_{6}(0.3)^{2}(0.7)^{4}$
$P(X=3)=C^{3}_{6}(0.3)^{3}(0.7)^{3}$
$P(X=4)=C^{4}_{6}(0.3)^{4}(0.7)^{2}$
$P(X=5)=C^{5}_{6}(0.3)^{5}(0.7)^{1}$
$P(X=6)=C^{6}_{6}(0.3)^{6}$

可以借助Excel计算。 

1、定义命中概率0.3 
![这里写图片描述](https://img-blog.csdn.net/20170207105854932?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

2、计算一种情况的概率（F4是固定单元格快捷键） 
![这里写图片描述](https://img-blog.csdn.net/20170207105947698?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

3、计算二项系数（fact是阶乘函数） 
![这里写图片描述](https://img-blog.csdn.net/20170207110142089?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

4、计算概率 
![这里写图片描述](https://img-blog.csdn.net/20170207110257730?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

5、选中第一行，下拉得到全部6行。 
![这里写图片描述](https://img-blog.csdn.net/20170207110356653?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
可以看到二项系数对称，但是概率结果不对称，图像左移了。因为概率是0.3和0.7，不像抛硬币时的0.5和0.5。 
![这里写图片描述](https://img-blog.csdn.net/20170207110859490?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
如果改变0.3为0.7，则图像右移了。 
![这里写图片描述](https://img-blog.csdn.net/20170207111225010?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
**随机变量的期望值E(X)和方差**

假设总体是{3,3,3,4,5}，算术平均值是$\frac{3+3+3+4+5}{5}$=3.6，可以改写为概率加权平均值，$\frac{3\times3+1\times4+1\times5}{5}=\frac{3}{5}\times3+\frac{1}{5}\times4+\frac{1}{5}\times5=$60%$\times3+$20%$\times4+$20%$\times5$。但是好处是，之前我们需要知道总共有多少数，现在只需要知道数字出现的频率。 

总体可以看作随机变量的每个实例或者说每次随机试验的集合，而随机试验可以做无数次，类似抛硬币无数次。但是样本只能取有限个。**随机变量的期望值也就是总体的均值**，即总体的集中趋势。当总体是无尽的时候，不能全部求和然后除以数目的方式求均值，但我们知道数字出现的频率，参照离散变量的概率分布即可。所以$E(X)=\sum  X\times P(X)$。同理，连续随机变量$E(X)=\int_{0}^{\infty }xf\left ( x \right )dx$。
而方差是60%$\times(3-3.6)^{2}$+20%$\times(4-3.6)^{2}$+20%$\times(5-3.6)^{2}$

**二项分布的期望值E(X)和方差**

假设X=n次试验成功的次数，其中每次成功的概率是p。则E(X)=n*p。 

比如X=10次投篮的进球数，进球概率是40%。期望值是最有可能得到的那个结果，10*40%=4，因此最有可能进4次。每一次投篮有40%几率命中，可以理解为投篮总是中40%，如果投10次，那么中4次。 

二项分布的方差公式$\sigma^{2}=np(1-p)$
泊松过程

假设想知道任意时段通过街上某一点的车辆数，如某一小时内100辆车通过的概率。定义一个随机变量X=一小时内通过的车辆数，然后求出该随机变量的概率分布。假设街上此点任意时刻的情况没有差异，并且一段时间的车流量对另一段时间没有影响，即具有独立性。对于任何分布，我们首先可以求均值。我们坐在路边观察几小时的车流量，然后取平均，这就是总体均值很好的估计值了，也就是期望值。假设$E(X)=\lambda$，比如9.3辆车每小时。假设每分钟最多有一辆车通过，所以$\lambda<60$。

二项分布的期望值我们已经知道了，$E(X)=np$，n是试验的次数，p是一次试验成功的概率。如果建模成二项分布，可以分成60分钟，看每分钟是否有车辆通过，即60次试验，每分钟有车辆通过的概率是$\frac{\lambda}{60}$，$E(X)=np=60\times \frac{\lambda}{60}$，则一小时内通过k辆车的概率是$P(X=k)=C^{k}_{60}(\frac{\lambda}{60})^{k}(1-\frac{\lambda}{60})^{60-k}$。二项分布可以看每分钟内是否有车通过，但是如果一分钟内不止一辆车通过，也就是$\lambda>60$怎么办。

解决办法是分更多的区间，可以分成秒，这样得到$P(X=k)=C^{k}_{3600}(\frac{\lambda}{3600})^{k}(1-\frac{\lambda}{3600})^{3600-k}$。如果$\lambda>3600$，就继续进行区间分割，让区间越来越大（n很大，p接近0），一直下去就能得到泊松分布。

考虑让n趋近于$\infty$时的二项分布情况 
![这里写图片描述](https://img-blog.csdn.net/20170130224820662?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHMzMTc4NDI5Mjc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

假设测算出平均每小时是9辆车通过，则某小时正好有2辆车经过的概率$P(X=2)=\frac{9^{2}}{2!}e^{-9}$
大数定律

这是数学和概率论中最直观的定律之一。假设有随机变量X，随机变量的n次观测样本的平均值$\bar{X_{n}}=\frac{x_{1}+x_{2}+...+x_{n}}{n}$。大数定律是说，当n趋近于$\infty$时，样本均值趋近于随机变量的期望值，$\bar{X_{n}}\rightarrow E(X)$。

首先举一个特定的例子，假设随机变量X=抛100次硬币得到正面的次数，$E(X)=100\times \frac{1}{2}=50$。大数定律是说如果样本量足够大，那么样本均值将趋近于期望值。一次试验是指100枚硬币抛出，所以样本均值$\bar{X_{n}}=\frac{55+65+45+...+x_{n}}{n}$。当n趋近于$\infty$时，$\bar{X_{n}}\rightarrow 50$。

很多人可能会觉得，几次试验后，如果正面数高于均值，则定律会让后面的正面数更少，这是不对的。大数定律不关心前面发生的情况，比如有限次试验之后，可能得到样本均值在70，比期望值高出了很多，但是大数定律不关心这些有限次试验，后面还有无限次试验，这无限次试验的期望值是50。将有限个平均值高于期望值的数同无限个收敛于期望值的数一起求均值，最后肯定收敛回期望值。 

所以并不是开始的正面多，后面就会反面多来弥补，这是赌徒谬误。收敛于期望值只是因为后面还有无限次收敛于期望值的试验，让前面的有限次试验根本可以忽略。













