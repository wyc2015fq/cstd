# adaboost原理图解 - 战斗蜗牛的专栏 - CSDN博客





2018年10月28日 17:10:47[vbskj](https://me.csdn.net/vbskj)阅读数：55
个人分类：[Deep Learning继续学习](https://blog.csdn.net/vbskj/article/category/6337222)









### Adaboost算法及分析

　　从图1.1中，我们可以看到adaboost的一个详细的算法过程。Adaboost是一种比较有特点的算法，可以总结如下：

　　1）每次迭代改变的是样本的分布，而不是重复采样（re weight)

　　2）样本分布的改变取决于样本是否被正确分类

　　总是分类正确的样本权值低

　　总是分类错误的样本权值高（通常是边界附近的样本）

　　3）最终的结果是弱分类器的加权组合

　　权值表示该弱分类器的性能

　　简单来说，Adaboost有很多优点:

　　1)adaboost是一种有很高精度的分类器

　　2)可以使用各种方法构建子分类器，adaboost算法提供的是框架

　　3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单

　　4)简单，不用做特征筛选

　　5)不用担心overfitting！

　　总之：adaboost是简单，有效。

　　下面我们举一个简单的例子来看看adaboost的实现过程：



![](http://img1.51cto.com/attachment/201112/211325901.png)

　　图中，“+”和“-”分别表示两种类别，在这个过程中，我们使用水平或者垂直的直线作为分类器，来进行分类。

　　第一步：



![](http://img1.51cto.com/attachment/201112/211351957.png)

　　根据分类的正确率，得到一个新的样本分布D2­，一个子分类器h1

　　其中划圈的样本表示被分错的。在右边的途中，比较大的“+”表示对该样本做了加权。

　　第二步：



![](http://img1.51cto.com/attachment/201112/211418559.png)

　　根据分类的正确率，得到一个新的样本分布D3，一个子分类器h2

　　第三步：



![](http://img1.51cto.com/attachment/201112/211453424.png)

　　得到一个子分类器h3

　　整合所有子分类器：



![](http://img1.51cto.com/attachment/201112/211622365.png)

　　因此可以得到整合的结果，从结果中看，及时简单的分类器，组合起来也能获得很好的分类效果，在例子中所有的。

　　Adaboost算法的某些特性是非常好的，在我们的报告中，主要介绍adaboost的两个特性。一是训练的错误率上界，随着迭代次数的增加，会逐渐下降；二是adaboost算法即使训练次数很多，也不会出现过拟合的问题。



