# 数据相似性的度量方法总结 - guoziqing506的博客 - CSDN博客





2016年10月30日 22:34:13[guoziqing506](https://me.csdn.net/guoziqing506)阅读数：13224标签：[数据挖掘																[Lp范数																[相似度																[距离																[文档相似性](https://so.csdn.net/so/search/s.do?q=文档相似性&t=blog)
个人分类：[数据挖掘](https://blog.csdn.net/guoziqing506/article/category/6289196)





现实中，我们需要处理的数据具有着不同的形式和特征。而对数据相似性的度量又是数据挖掘分析中非常重要的环节。针对这些不同形式的数据，不可能找到一种具备普遍意义的相似性度量算法，甚至可以说，每种类型的数据都有它对应的相似度度量标准。这些标准很多，也比较杂乱，有必要作以总结。

废话不多说了，直接进入正题。

## 数据属性分类

现实世界，任何事物其实都可以描述成一个对象。这个概念其实跟面向对象编程中对象的含义是一致的。对象有很多属性，属性的类型当然也有所不同。打个比方说，如果把我看做一个对象，那我就基本拥有“姓名”、“性别”、“年龄”、“籍贯”等等，这些都是我的属性，和起来就是一条数据，也就是户籍部门拿到的关于我这个对象的数据。同理，如果把一张图片看做一个对象，那么“像素值”，“亮度”、“对比度”，“饱和度”等等就是图片的属性。处理图像数据，当然要从这些属性入手。

所以，看到这里，我们大概能总结出来2点： 

1. 一般情况下的数据挖掘工作，其实就是针对1个或多个对象及其属性做的运算，而数据一般就被表示为：object: attributes的形式。 

2. 不同对象（甚至相同对象在不同的应用场景下）的属性类型不同。需要分类讨论。
### 标称属性

属性值一般是一些符号或事物的名称。比如说，对相亲网站的注册用户，系统可会记录如下信息：性别，年龄，职业，地点，学历等等。这些数据都是通过名称来描述的。

### 二元属性

这个好理解了，所有属性都可以通过最简单的0，1描述。一般常用来表示存在性。比如说，一个感冒患者一般会用是否存在“发烧”、“流涕”、“咽痛”等症状来做记录，存在这些状况，记录为1，不存在，记录为0。当一个患者来看病时，当然就可以通过这些属性值是否为1来做出诊断的结果。

### 序数属性

属性值是由有意义的排序数决定的。例如，对一部电影评价，可以分为“剧情”、“演员”、“音乐”、“特技”等几个方面评价，而每个方面都有“好”、“中”、“差”3个选项供选择。而这些有排序意义的选择之间我们是无法说明具体差距的。也就是说，是定性，而非定量。

到此为止，上面的3种属性都是定性的，而非定量的。

### 数值属性

那么对于属性可以定量的这种属性类型，只怕也是我们生活中遇到情况最多的了，这种属性，就叫“数值属性”，有关于这些属性值的分析可以说是最多的，常见的平均数，众数、中位数等等，就是处理这些属性的。后面我们还可以看到，对于拥有数值属性的对象相似度的度量，也有着相应的方法。

## 相似性度量

我们分别就刚才所说的4种属性，看看当一个对象拥有不同类型的属性时，应该用什么方法度量。其实，我个人认为，没有人能告诉你一种对象到底该用什么样的方法度量其相似性，因为现实中，可能很多情况下你所需要测量的数据是非常复杂的，所以这里也只是给出一些常见的处理方法，具体问题还要具体分析。

另外，说一下，我本文的工作大多参考了韩家炜先生的大作《数据挖掘》，韩先生是此道大师，希望大家有空了多去看看他的文章。

### 标称属性相似度度量

很简单，拿两个对象$O_1, O_2$举例，直接看这两个对象每种属性的属性值的匹配数。

假设这一类对象一共有$n$个属性（每个对象都有这$n$个属性），两个对象$O_1, O_2$匹配的属性数为$m$，那么相似度为匹配数占总属性数的总数。



$\begin{equation}sim(O_1, O_2) = \frac{m}{n}\end{equation}$

### 二元属性相似度度量

总的来说，和标称属性是类似的，但是情况稍微复杂一点。要分成对称和非对称2种形式。

(1)对称二元属性

先看对称的情况，所谓对称，是说对象的所有属性都是一样重要的。这就和标称属性类似了，用所有具有相同属性值的属性个数除总的属性数。公式和标称属性一致：



$\begin{equation}sim(O_1, O_2) = \frac{m_1 + m_2}{n}\end{equation}$

需要注意的是，这里的$m_1$代表对象$O_1, O_2$的所有属性中，全都是1的属性数，$m_2$代表全都是0的属性数。$m_1 + m_2$就是2个对象所有属性值相同的属性的数量了。可见，基本与标称属性的度量算法是一致的。

(2)非对称二元属性

所谓非对称，是说我们只关心“正匹配”的情况，也就是只关心两个对象属性中，都是1的情况。公式如下：



$\begin{equation}sim(O_1, O_2) = \frac{m_1}{n}\end{equation}$

$m_1$的意义与上面的相同。其实，如果把2个对象看做是2个集合的话，相当于就是2个集合的交比2个集合的并。所以，这个公式不仅可以应用于二元属性，也可以应用于对2个集合相似度的度量，这个公式也被叫做Jaccard系数。比较普遍的写法是：



$\begin{equation}sim(U, V) = \frac{U \cap V}{U \cup V}\end{equation}$

$U, V$代表2个集合，不一定非要是相同元素数量的。

### 数值属性相似度度量

当然，我们还有序数属性的相似度没讲。但是序数属性的相似性测量与数值属性确是有一定联系的，所以，先看数值属性对象如何度量其相似度。

对于数值属性的相似度度量有一套完整的方法，那就是大名鼎鼎的“闵可夫斯基”距离，也叫$L_p$范数。

(1) 欧氏距离

因为数值属性一般都是以数值向量表示的。所以，当然也要从数值向量上下功夫。最常见的判断两个向量距离的方法就是我们熟知的欧氏距离，公式如下：



$\begin{equation}sim(v_1, v_2) = \sqrt{(v_{11} - v_{21})^2 + (v_{12} - v_{22})^2 + \dots + (v_{1n} - v_{2n})^2}\end{equation}$

$v_1, v_2$代表2个向量，也就是两个由数值属性描述的对象。这两个向量的维度都是$n$，代表有多少种属性。

(2) 曼哈顿距离

除了欧氏距离，还有一种方法叫曼哈顿距离，起名的由来是计量由方块形构成的曼哈顿街区的距离，因为街区不能横穿，只能按照方格走到。所以，这种距离的度量方式也就很清晰了，就是两个向量之间各个维度的差的绝对值之和，公式如下：



$\begin{equation}sim(v_1, v_2) = |v_{11} - v_{21}| + |v_{12} - v_{22}| + \dots + |v_{1n} - v_{2n}|\end{equation}$

(3) 闵可夫斯基距离

将曼哈顿距离与欧氏距离推广，可以得到闵可夫斯基距离，也叫$L_p$范数。公式如下：



$\begin{equation}sim(v_1, v_2) = \sqrt[p]{|v_{11} - v_{21}|^p + |v_{12} - v_{22}|^p + \dots + |v_{1n} - v_{2n}|^p}\end{equation}$

可见，闵可夫斯基距离就是曼哈顿距离与欧氏距离的推广，或者说曼哈顿距离与欧氏距离是闵可夫斯基距离的2种特殊情形，曼哈顿距离也可以叫做$L_1$范数，欧式距离也就是$L_2$范数。

## 序数属性相似度度量

序数属性的每个属性值都代表了一种次序，所以，不论使用数字表示的，还是用文字性的叙述，都可以表示成数字的形式。例如，一个对象的某个属性有“大”、“中”、“小”3个可能的属性值，我们当然可以用相应的1、2、3来替代这种文字性的叙述。

当转换成对应的整数之后，为了使每个属性都有相同的权重（这个很容易理解，有些属性只有“大”、“中”、“小”3中选项，有些却有“下”、“中下”、“中”、“中上”、“上”5个属性，这样，不同属性之间的权重当然没有可比性了），将通过以下公式将每个整数型的属性值映射到[0.0, 1.0]的区间上。



$\begin{equation}y = \frac{x - 1}{m - 1}\end{equation}$

其中，x为整数型的属性值，m为这个属性总共有多少种可能的属性。像我们刚才举的“大”、“中”、“小”的例子，假如现在一个对象这个属性对应的属性值为“中”，那么做归一化之后的属性值就是$\frac{2 - 1}{3 - 1} = 0.5$

## 混合类型属性相似度度量

上面说的这几种情况都是数据库中的数据相对类型比较统一，但是很多时候，实际工作中遇到的情况却并非如此。我们遇到的一组数据可能拥有多种类型的属性，也就是混合类型属性。

碰到这种情况，一种一般的处理办法是按照如下公式：



$\begin{equation}sim(O_1, O_2) = 1 - \frac{\sum_{i = 1}^m \delta_i \cdot (1 - sim(O_{1i}, O_{2i}))}{\sum_{i = 1}^m \delta_i } = \frac{\sum_{i = 1}^m \delta_i \cdot sim(O_{1i}, O_{2i})}{\sum_{i = 1}^m \delta_i}\end{equation}$

我来解释一下，这里面$ sim(O_{1i}, O_{2i})$代表的是$O_1, O_2$ 2个对象关于属性i的相似度，而参数$\delta_i$是个比较特殊的量，它这样设计：
- 假如$O_1, O_2$中有一个对象不具有属性i，则$\delta_i = 0$
- 假如$O_1, O_2$的属性i是非对称二元属性（请看上面对于二元属性部分的讲解），且对应的属性值都是0，则$\delta_i = 0$
- 除了以上2种情况，$\delta_i = 1$

## 余弦相似性

最后，介绍一种针对文档数据的，特殊的相似度测量方法：余弦相似性。

在处理文档的时候，我们一般采用文档所拥有的关键词来刻画一个文档的特征。容易想象，如果能定义一个字典，（所谓字典，就是包含了所处理的文档集的所有可能的关键词的一个有序的关键词集合。从这个角度讲，好像叫词典更为合适，但是字典的叫法已经是惯例了），那么就能通过字典为每个文档生成一个bool型的向量，这个向量与字典等长，每个位置用0、1表示字典中对应的关键词在该文档的存在性。

这么看，好像和前面说的二元属性没有什么不同。但是如果为了实现一种更准确的度量，再给这个二元向量加个权重，比如每个词的词频，那么用上面讲的任何度量方法就都不是特别合适了。例如，如果用欧氏距离判断相似度的话，因为这种向量很多位都是0，就是说很稀疏，这就导致大部分词是两个文档所不共有的，从而判断结果是2个文档很不相似。

对于这种文档-关键词的特殊情形，我们一般采用余弦相似度。



$\begin{equation}sim(x, y) = \frac{x \cdot y}{\|x\| \cdot \|y\|}\end{equation}$

其中，$x, y$是2个文档解析出来的词频向量。当然，有关于文档的相似度判断是整个信息检索领域的基础问题，也是核心问题。这里面内容相当丰富，以后再详谈，这里只是将余弦相似度做个简略的介绍。](https://so.csdn.net/so/search/s.do?q=距离&t=blog)](https://so.csdn.net/so/search/s.do?q=相似度&t=blog)](https://so.csdn.net/so/search/s.do?q=Lp范数&t=blog)](https://so.csdn.net/so/search/s.do?q=数据挖掘&t=blog)




