# Spark基础 - LC900730的博客 - CSDN博客
2017年12月10日 17:55:50[lc900730](https://me.csdn.net/LC900730)阅读数：117
### Driver与Worker
Driver与Worker是两个重要角色。Driver程序是应用逻辑执行的起点，负责作业的调度，即Task任务的分发，而多个Worker用来管理计算节点和创建Executor并行处理任务。在执行阶段，Driver会将Task和Task所依赖的file和jar序列化后传递给对方的worker机器，同时Executor将对应数据分区的任务进行处理。
Block-Manager管理RDD的物理分区，每个Block就是节点上对应的一个数据块，可以存储在内存或者磁盘中。而RDD中的partition是一个逻辑数据块，对应相应的 物理块Block。本质上一个RDD在代码中相当于是数据的一个元数据结构，存储着数据分区及其逻辑结构映射关系，存储着RDD之前的依赖转换关系。
## RDD
- 它是逻辑中实体，在集群中多台机器上进行数据分区。通过多台机器上不同RDD分区的控制，就能够减少机器之间数据重排列(data shuffling)。Spark提供了‘partitionBy‘运算符，能够通过集群中多台机器间对原始RDD进行数据再分配来创建一个新的RDD。RDD是Spark的核心数据结构，通过RDD的依赖关系形成Spark的调度顺序。通过对RDD操作形成整个Spark程序。
### 理解RDD
- 可以抽象理解为一个大数组，但是这个数组是分布在集群上。逻辑上RDD的每个分区叫一个Partition
- RDD会被划分为很多分区分布到集群上的多个节点中。分区是个逻辑概念，变化前后的新旧分区在物理上可能是同一个内存存储。这是很重要的优化，防止函数式数据的不变性(immutable)导致的内存需求无限扩张。
- 有些RDD是计算的中间结果，其分区不一定有相应的内存或磁盘数据与之对应。如果要迭代使用数据，可以调Cache()函数缓存数据。
- RDD对象实质上是一个元数据结构，存储着Block、Node等的映射关系，以及其他的元数据信息。一个RDD就是一组分区，在物理数据存储上，RDD的每个分区对应的就是一个Block，Block可以存储在内存，内存不够存储到磁盘上。
- 每个Block中存储着RDD所有数据项的一个子集，暴露给用户的就是一个Block迭代器，也就是一个数据项。
- 如果是从hdfs等外部存储作为输入数据源，数据按照HDFS中数据分布策略进行数据分区，HDFS中的一个Block对应Spark的一个分区。
## 两种创建方式
### 1.从hadoop文件系统输入创建
### 2.从父RDD转换得到新的RDD
## 两种计算操作算子
1.Transformation：从一个RDD到另一个RDD转换操作不是马上执行，而是等到有Action操作时，才会真正触发运算。 
2.Action：行动 
Action算子会触发Spark提交作业(Job),将数据输出到Spark系统。
