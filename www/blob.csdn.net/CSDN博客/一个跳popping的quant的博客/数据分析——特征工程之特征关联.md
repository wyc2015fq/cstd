# 数据分析——特征工程之特征关联 - 一个跳popping的quant的博客 - CSDN博客





2018年08月12日 12:37:59[敲代码的quant](https://me.csdn.net/FrankieHello)阅读数：2450








参考 House Price中的most voted文章 [https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-pythonhttps://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-pythonhttps://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)

以House Price数据集为例，在对特征相关性进行探究时，主要通过以下三个方面：



### 一、特征的相关矩阵
- 特征的相关矩阵
- 目标的相关矩阵
- 画出最相关的特征之间的关系

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('./data/train.csv')
corr_mat = df.corr()
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corr_mat, vmax=.8, square=True, ax=ax)
plt.show()
```

![](https://img-blog.csdn.net/20180812114536124?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5raWVIZWxsbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

通过这个热力图，可以很直观的对各个特征之间的关系一目了然。另外，从图中可以看出TotalBsmtSF和1stFlrSF变量之间的相关性很明显，**这就说明了如果同时使用这两个特征就会导致信息的冗余性，所以要尽量避免使用冗余的特征。**

其中看一下df.corr()函数的源码：

```python
def corr(self, method='pearson', min_periods=1):
        """
        Compute pairwise correlation of columns, excluding NA/null values

        Parameters
        ----------
        method : {'pearson', 'kendall', 'spearman'}
            * pearson : standard correlation coefficient
            * kendall : Kendall Tau correlation coefficient
            * spearman : Spearman rank correlation
        min_periods : int, optional
            Minimum number of observations required per pair of columns
            to have a valid result. Currently only available for pearson
            and spearman correlation

        Returns
        -------
        y : DataFrame
        """
```

默认method参数是pearson，下面介绍下这三种相关系数：

1、Pearson correlation coefficient（皮尔逊相关系数）

皮尔逊相关系数用于度量两个变量X和Y之间的相关性（线性相关），**它的值介于-1和1之间**。

两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商。

![](https://gss3.bdstatic.com/-Po3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D289/sign=90b7ce2ea064034f0bcdc50e96c27980/060828381f30e92463d59cc247086e061c95f7d4.jpg)

2、Kendall correlation coefficient（肯德尔相关性系数）

它所计算的对象是分类变量。

具体可以参考 [https://blog.csdn.net/wsywl/article/details/5889419](https://blog.csdn.net/wsywl/article/details/5889419) 和 [http://blog.sina.com.cn/s/blog_69e75efd0102wmd2.html](http://blog.sina.com.cn/s/blog_69e75efd0102wmd2.html)

3、Spearman correlation coefficient（斯皮尔曼相关性系数）

它是衡量两个变量的依赖性的非参数指标。它利用单调方程评价两个统计变量的相关性，如果数据中没有重复值，并且两个变量完全单调相关时，斯皮尔曼相关系数则为+1或者-1。

![](https://gss0.bdstatic.com/94o3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D204/sign=e9c89baf5efbb2fb302b5f127b4b2043/e850352ac65c1038e3655d30b9119313b07e892d.jpg)

### 二、目标的相关矩阵

**找到与目标值相关性最大的几个特征，而这几个特征之间的相关性要低。**

```python
k = 10
cols = corr_mat.nlargest(k, 'SalePrice')['SalePrice'].index
cm = np.corrcoef(df[cols].values.T)
sns.heatmap(cm, annot=True, square=True, yticklabels=cols.values, xticklabels=cols.values)
plt.show()
```

通过以上代码得到与目标值相关性最大的前10个值，做出热力图。

![](https://img-blog.csdn.net/20180812122655154?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5raWVIZWxsbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

从图中可以很明显地看出OverallQual、GrLivArea等特征与SalePrice目标值之间有很大的关联。

### 三、最相关的特征之间的关系图

```python
cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']
sns.pairplot(df[cols], height = 2.5)
plt.show()
```

尽管我们已经知道了这些特征之间的一些关系，但是通过这个图可以给与一个更充分的理由。

![](https://img-blog.csdn.net/20180812123445357?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5raWVIZWxsbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



