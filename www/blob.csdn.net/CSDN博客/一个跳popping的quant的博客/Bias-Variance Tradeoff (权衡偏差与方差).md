# Bias-Variance Tradeoff (权衡偏差与方差) - 一个跳popping的quant的博客 - CSDN博客





2018年05月28日 17:45:23[敲代码的quant](https://me.csdn.net/FrankieHello)阅读数：1888









**转自：**https://blog.csdn.net/qq_30490125/article/details/52401773****




对学习算法除了通过实验估计其泛化性能，我们还希望了解“为什么”具有这样的性能。“偏差－方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。

# 偏差和方差

理解偏差和方差这两个不同来源导致的误差可以帮助我们更好得拟合数据来得到更为精确的模型。

## 概念性定义
- 

- **由偏差引起的误差：**我们将模型的期望（或平均）预测和我们正在试图预测正确值之间的差定义为偏差。当然，如果你只能有一个模型，在谈论期望或平均预测值可能看起来有点怪。但是，想象一下，我们可以多次重复整个建模过程：每次收集新的数据来拟合一个新的模型。由于数据集获取中的一些随机性，我们拟合的模型将具有一定的预测范围。
- **由方差引起的误差：**我们将模型之间的多个拟合预测之间的偏离程度定义为方差。同样，想象你可以重复多次整个建模过程。 


> ![这里写图片描述](https://img-blog.csdn.net/20160901164205495)

  这是一个曲线拟合的问题，对同分布的不同的数据集进行了多次的曲线拟合，左边表示方差，右边表示偏差，绿色是真实值函数。ln λ 表示模型的复杂程度，这个值越小，表示模型的复杂程度越高。    

## 图形化定义

我们可以使用靶心图来图形化定义偏差和方差。试想一下，靶心就是我们要预测的真实值。命中的点离靶心越远，我们的预测结果越糟糕。试想一下，我们可以重复我们整个建模过程中独立得得到多个命中点的结果。每个命中都是我们模型的一次独立预测。有时，我们的预测结果会非常好，命中点靶心都集中在靶心附近；而有时，我们的命中点偏离靶心。这些不同的情况造成了对靶心的命中散布。

我们可以绘制代表高低偏差和方差的组合四种不同的组合分布图。 
![这里写图片描述](https://img-blog.csdn.net/20160901113415962)

## 数学定义：

我们定义需要预测的真实结果Y，与其对应的自变量X(训练样本)，之间有这样的关系: 
Y = f(X) + ϵ (我们认为ϵ满足正态分布ϵ∼N(0,σϵ) )’

令yD为x在测试样本中的值，y为真实的值。

> 
有可能出现噪音使得yD != y 
  为了方便讨论，这里假定E[ yD - y ] = 0


假设，fD(x)为训练集X上学得模型f在x上的预测输出，学习算法的期望预测为： 
fExpectedD(x) = E[ fD(x) ]                            

> 
统计学习中有一个重要概念叫做residual sum-of-squares： 
![这里写图片描述](https://img-blog.csdn.net/20160901161410226)
  RSS看起来是一个非常合理的统计模型优化目标。但是考虑K-NN的例子，在最近邻的情况下（K=1），RSS=0，是不是KNN就是一个完美的模型了呢，显然不是，KNN有很多明显的问题，比如对训练数据量的要求很大，很容易陷入维度灾难中。

KNN的例子说明仅仅优化RSS是不充分的，因为针对特定训练集合拟合很好的model，并不能说明这个model的泛化能力好，而泛化能力恰恰又是机器学习模型的最重要的要求。真正能说明问题的不是RSS，因为它只是一个特定训练集合，而是在多个训练结合统计得出的RSS的期望，MSE（mean squared error），即期望泛化误差。


基于假设，我们可以得到关于**测试集x**的MSE（mean squared error）:

MSE(x) = E[( fD(x) -  yD)2] 
MSE(x) = E[( fD(x) - fExpectedD(x) + fExpectedD(x) - yD)2] 
MSE(x) = E[(fD(x) - fExpectedD(x) )2] + E[(fExpectedD(x) - yD)2] + E[2×(fD(x) - fExpectedD(x) )×( fExpectedD(x) - yD )]

> 
第三项需要注意：由于训练集已知，所以这里的fExpectedD(x) - E[(fExpectedD(x) - yD)2]实际上是一个常数，可以拿到外部。 
  fD(x) - fExpectedD(x) 根据上面学习算法的期望预测的式子，可以知道其差值为０


MSE(x) = E[(fD(x) - fExpectedD(x) )2] + E[(fExpectedD(x) - yD)2] 
MSE(x) = E[(fD(x) - fExpectedD(x) )2] + E[(fExpectedD(x) - y + y -  
yD)2] 
MSE(x) = E[(fD(x) - fExpectedD(x) )2] + E[(fExpectedD(x) - y)2] + E[(y - yD)]2 + 2 × E[(fExpectedD(x) - y) × (y - yD)]

> 
噪声期望为０，因此最后一项为０


MSE(x) = E[(fD(x) - fExpectedD(x) )2] + (fExpectedD(x) - y)2 + E[(y - yD)]2

> 
使用样本数相同的不同训练集产生的方差为： 
  var(x) = E[(fD(x) - fExpectedD(x) )2]

期望输出与真实值的差别称之为偏差，即： 
  bias2(x) = (fExpectedD(x) - y)2

噪声为： 
  ϵ2 = E[(y - yD)]2


MSE(x) = var(x) + bias2(x) + ϵ2

从上面的推导我们可以看出，期望泛化误差可以分解为方差，偏差与噪音之和。

> 
最后一项，作为不可约项，是不可能从根本上进行消除。在给定任务的前提下，只需要考虑前面两项来优化模型即可。


## 小节：

偏差度量了学习算法的期望预测与真实结果的偏离程度，即**刻画了学习算法本身的拟合能力**；方差度量了同样大小的训练集的变动所导致的学习性能的变化，即**刻画了数据扰动所造成的影响**；噪声则表达了**学习问题本省的难度**。偏差－方差分解说明，泛化能力是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的，给定学习任务，为了取得好的泛化性能，需使偏差较小，即能够充分拟合数据，并使方差较小，使数据扰动产生的影响最小。 
![这里写图片描述](https://img-blog.csdn.net/20160901163918190)

在一个实际系统中，Bias与Variance往往是不能兼得的。如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。造成这种现象的根本原因是，我们总是希望试图用有限训练样本去估计无限的真实数据。当我们更加相信这些数据的真实性，而忽视对模型的先验知识，就会尽量保证模型在训练样本上的准确度，这样可以减少模型的Bias。但是，这样学习到的模型，很可能会失去一定的泛化能力，从而造成过拟合，降低模型在真实数据上的表现，增加模型的不确定性。相反，如果更加相信我们对于模型的先验知识，在学习模型的过程中对模型增加更多的限制，就可以降低模型的variance，提高模型的稳定性，但也会使模型的Bias增大。Bias与Variance两者之间的trade-off是机器学习的基本主题之一，机会可以在各种机器模型中发现它的影子。

## 权衡偏差与方差：

模型过于简单时，容易发生欠拟合（high bias）；模型过于复杂时，又容易发生过拟合（high variance）。为了达到一个合理的 bias-variance 的平衡，此时需要对模型进行认真地评估。这里简单介绍一个有用的cross-validation技术K-fold Cross Validation (K折交叉验证)， 
这个方法将帮助我们获得模型关于泛化误差（generalization error）的可信的估计，所谓的泛化误差也即模型在新数据集上的表现。在训练数据上面，我们可以进行交叉验证(Cross-Validation)。 
K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，、我们便可获得 k 个模型及其性能评价。平均K次的结果或者使用其它结合方式，最终得到一个单一估测。

当K值大的时候， 我们会有更少的Bias(偏差), 更多的Variance。 
当K值小的时候， 我们会有更多的Bias(偏差), 更少的Variance。

下图展示了 k=10 时的 k-fold 方法的工作流程。 
![这里写图片描述](https://img-blog.csdn.net/20160901171029859)

先到这里，参考博客：[http://scott.fortmann-roe.com/docs/BiasVariance.html](http://scott.fortmann-roe.com/docs/BiasVariance.html)




