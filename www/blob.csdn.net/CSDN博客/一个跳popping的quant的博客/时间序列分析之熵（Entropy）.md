# 时间序列分析之熵（Entropy） - 一个跳popping的quant的博客 - CSDN博客





2019年03月02日 12:31:25[敲代码的quant](https://me.csdn.net/FrankieHello)阅读数：209








**熵**这个概念最早是用于热力学中，毕竟这个字是火字旁，用于衡量一个系统能量的不可用程度，熵越大，能量的不可用程度就越大；越小能量的不可用程度越低。它的物理意义是体系中**混乱程度**或者**复杂程度**的度量。

关于熵的应用也在不断拓展，从热力学到生物学、物理学，以及在时间序列分析上都有应用。

### 一、近似熵（Approximate Entropy, ApEn）

#### 概念

近似熵是一种用于量化时间序列的**不规则性**或者**复杂性**的度量方式，它反映了时间序列中新的子序列产生的概率，也就是以一种**条件概率**的方式来衡量时间序列中新信息发生的可能性，因此**越复杂的时间序列对应的近似熵就越大**。

#### 近似熵求法

1、设有长度为$N$的时间序列$u(1),u(2),u(3),...,u(N)$，规定一个表示相似度比较的阈值$r$，再确定一个划分子序列长度的度量$m$。

2、通过将原序列进行重构，这样就可以得到$(N - m + 1)$个子序列$X(1),X(2),X(3),...,X(N-m+1)$。将每个子序列以$X(i)$表示，其中$X(i)=u(i),u(i+1),u(i+2),...,u(i+m-1)$。

3、计算任意两个重构向量$X(i)$和$X(j)$之间的距离 $d_{m}[X(i), X(j)]$，其中$d_{m}$表示两个重构向量$X(j)$($1\leqslant j \leqslant N-m+1$)与$X(i)$之间的距离，距离$d_{m}$由两个向量中**对应位置元素的最大差值决定**。这里包括$i=j$的距离。

4、然后统计满足以下条件的向量个数，并求出与总的统计数目之间的比值：
$$C_{i}^{m}(r) = \frac{num[d_{m}(X(i), X(j))&lt;r]}{N-m+1}$$这个过程称作$X(i)$的模版匹配过程，$C_{i}^{m}(r)$表示任意一个$X(j)$与模版之间的匹配概率。

5、定义在划分子序列个数为$m$时的平均相似率：$$\Phi_{m}(r) = \frac{ \sum_{i=1}^{N-m+1}log(C_{i}^{m}(r))}{N-m+1}$$6、按照上面1~5再计算当划分子序列个数为$m+1$时的平均相似率$\Phi_{m+1}(r)$。

7、得近似熵：$$ApEn=\Phi_{m}(r)-\Phi_{m+1}(r)$$

注：关于$m$和$r$的选取，$m$通常选择为2或者3；$r$则根据实际应用的场景选择，通常选择$r=0.2*std$，$std$是原时间序列的标准差。从信息熵的角度来看，近似熵的思想是通过判断每个子序列中元素与全局子序列中每个元素之间的差异的大小来决定信息熵的大小，如果一个子序列与其他子序列之间的差异都很大，那么它满足$d_{m}[X(i), X(j)]\leq r$的数量就会很少，相对应它的信息量就大，因而它的信息熵就会很大。
### 二、样本熵（Sample Entropy, SampEn）

#### 概念

样本熵同样也是用于衡量时间序列在单一尺度上的复杂度，与近似熵相比，具有更高的精度。样本熵是在近似熵的基础上的改进，所以求法也很类似。

#### 样本熵的求法

1、设有长度为$N$的时间序列$u(1),u(2),u(3),...,u(N)$，规定一个表示相似度比较的阈值$r$，再确定一个划分子序列长度的度量$m$。

2、通过将原序列进行重构，这样就可以得到$(N - m + 1)$个子序列$X(1),X(2),X(3),...,X(N-m+1)$。将每个子序列以$X(i)$表示，其中$X(i)=u(i),u(i+1),u(i+2),...,u(i+m-1)$。

3、计算任意两个重构向量$X(i)$和$X(j)$之间的距离 $d_{m}[X(i), X(j)]$，其中$d_{m}$表示两个重构向量$X(j)$($1\leqslant j \leqslant N-m+1$)与$X(i)$之间的距离，距离$d_{m}$由两个向量中**对应位置元素的最大差值决定**。这里的$i \neq j$。

4、然后统计满足以下条件的向量个数，并求出与总的统计数目之间的比值：
$$B_{i}^{m}(r) = \frac{num[d_{m}(X(i), X(j))&lt;r]}{N-m}$$这个过程称作$X(i)$的模版匹配过程，$B_{i}^{m}(r)$表示任意一个$X(j)$与模版之间的匹配概率。这里的$X(i) \neq X(j)$，所以总的统计数就是$N-m$。

5、求$B_{i}^{m}(r)$对于每个$i$的平均值，也就是平均相似率，记为$B^{m}(r)$：$$B^{m}(r)= \frac{ \sum_{i=1}^{N-m+1}B_{i}^{m}(r)}{N-m+1}$$注意，这里的近似平均率没有取对数，这里也是和近似熵的区别。

6、按照上面的1~5步骤计算$m+1$时的平均相似率$B^{m+1}(r)$。

7、这样就可以得到$N$取有限值时，样本熵为：$$SampEn(N,m,r) = -ln[\frac{B^{m+1}(r)}{B^{m}(r)}]$$

注：关于$m$和$r$的选取，$m$通常选择为1或者2；$r$则根据实际应用的场景选择，通常选择$r=0.1*std \sim 0.25*std$，$std$是原时间序列的标准差。近似熵是以$-ln(CP)$为模型，为了避免出现$ln(0)$的情况，所以在计算重构向量距离的时候，剔除了与自身的比较。
### 三、模糊熵（Fuzzy Entropy，FsEn）

#### 概念

模糊熵是在样本熵的基础上改进得到的，模糊熵引入了模糊隶属度函数，它是一种指数函数。它的主要特点是其参数的改变对复杂性度量的结果影响很小。

#### 模糊熵的求法

1、设有长度为$N$的时间序列$u(1),u(2),u(3),...,u(N)$，规定一个表示相似度比较的阈值$r$，再确定一个划分子序列长度的度量$m\space (m\leqslant N-2)$。

2、通过将原序列进行重构，这样就可以得到$(N - m + 1)$个子序列$X(1),X(2),X(3),...,X(N-m+1)$。将每个子序列以$X(i)$表示，其中$X(i)=[u(i),u(i+1),u(i+2),...,u(i+m-1)]-u_{0}(i)$。这里的操作有点类似去中心化。其中$$u_{0}(i) = \frac{1}{m}\sum_{j=0}^{m-1}u(i+j)$$3、计算任意两个重构向量$X(i)$和$X(j)$之间的距离 $d^{m}_{ij}[X(i), X(j)]$，其中$d^{m}_{ij}$表示两个重构向量$X(j)$($1\leqslant j \leqslant N-m+1$)与$X(i)$之间的距离，距离$d_{m}$由两个向量中**对应位置元素的最大差值决定**。这里同样$i \neq j$。

4、引入模糊隶属度函数：$$A^{m}_{ij} = exp[-(\frac{d^{m}_{ij}}{r})^{n}]$$5、计算针对于每个$i$的平均值：$$C_{i}^{m}(r) = \frac{\sum^{N-m+1}_{j=1,j \neq i}A_{ij}^{m}}{N-m}$$6、定义$$\Phi^{m}(r)= \frac{\sum^{N-m+1}_{i=1}C_{i}^{m}(r)}{N-m+1}$$7、按照1~6步骤，求$m+1$时的$\Phi^{m+1}(r)$。

8、模糊熵：$$FsEn(N,m,r)=ln\Phi^{m+1}(r)-ln\Phi^{m}(r)$$
### 四、总结

关于重构向量的大小$m$和相似度$r$的选择都是要考虑的事情，过大的相似度会导致信息丢失，太小则会增加对噪声的敏感性。

上面几种熵，都是衡量时间序列在**单一尺度上的复杂性**。后面也有多尺度熵来衡量时间序列在不同尺度因子上的**复杂性**和**自相似性**。

### REF

《基于 EEMD 和多尺度模糊熵的电机轴承故障特征提取方法研究 》
[时间序列复杂性的度量—近似熵和样本熵](https://blog.csdn.net/hdu_lazy_man/article/details/81332972)
[近似熵理论相关知识与代码实现](https://blog.csdn.net/cratial/article/details/79707169)
[样本熵理论相关知识与代码实现](https://blog.csdn.net/cratial/article/details/79742363)
[模糊熵理论相关知识与代码实现](https://blog.csdn.net/cratial/article/details/80215864#comments)






