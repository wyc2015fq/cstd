# Hadoop多用户作业调度器和安全机制的自我总结 - 专注于数据挖掘算法研究和应用 - CSDN博客





2016年12月21日 11:14:00[fjssharpsword](https://me.csdn.net/fjssharpsword)阅读数：2853
所属专栏：[Hadoop专栏](https://blog.csdn.net/column/details/16284.html)









                
在掌握Hadoop平台上，一直有两个疑问困扰着：

1）Hadoop的用户和用户组和Linux操作系统用户和用户组之间的关系；

2）多用户下，Hadoop平台如何管理以保证作业调度和文件安全；



先说下Hadoop队列管理机制：Hadoop以队列为单位管理作业、用户和资源，集群划分成若干个队列，

每个队列分配一定的资源，用户只能向对应的一个或几个队列中提交作业。

Hadoop队列管理机制由用户权限管理和系统资源管理两部分组成：

1）用户权限管理：

   hadoop的用户管理模块构建在操作系统用户管理之上，管理员可配置每个操作系统用户和用户组具有的队列权限。

   这就回答了第一个问题，hadoop用户和用户组就是Linux操作系统的用户和用户组。

2）系统资源管理：

   hadoop资源管理由调度器完成，管理员在调度器中配置各个队列的资源容量、各个用户可用资源量等信息，作业调度过程中按照所配置的相应资源约束进行。

   这就回答了第二个问题，多用户下，hadoop调度器以队列为单元来管理。


在mapred-queue-acls.xml文件中某用户配置了某队列的ACL权限管理，该用户提交作业时就是由该队列来执行；而该队列所能使用的资源是由调度器根据配置来管理。



接下来比较关心的是：Hadoop资源调度器是如何基于队列单元管理多用户使用集群资源？

回顾下hadoop多用户调度器的需求：

1）起初，Hadoop提供FIFO的调度机制，支持大数据批处理作业，所有作业统一提交到一个队列中按照提交顺序依次运行；

2）这样机制在面对不同用户提交的不同QoS应用程序的多样化需求时，无法满足，也不能充分利用集群资源；

3）基于这样一个背景，hadoop多用户多队列的调度器诞生，需求驱动技术方案前进；

多用户调度器支持集群管理员根据MR程序需求对用户分组，并根据不同的分组分配不同的资源量（队列），并设立各种约束防止单个用户或程序独占资源。

多用户调度器实现上，有两种主要思路：一是物理虚拟多个hadoop集群，如HOD调度器；二是逻辑上建立多队列多用户调度器，如Capacity Scheduler和Fair Scheduler。

多队列多用户调度器实现上的主要思想是：以队列为单元划分资源，每个队列有最低资源和上限资源值，每个队列内的每个用户也有资源上限，并支持用户间队列间资源共享。比较具体的设计框架可详细了解Capacity Scheduler和Fair Scheduler。



问题又来了，一个用户一个队列简单了点，但安全。

多用户多任务的调度器让不同需求的用户可以共享一个hadoop集群的计算资源和存储资源，降低运维成本提高资源利用率，但安全隐患来了？普通用户访问机密、杀死了其他用户的作业等。

Hadoop集群部署在内网，其安全考量主要是确保多用户安全地共享集群资源。Hadoop安全基本需求有下面三点：

1）经过授权的用户才可以访问hadoop，否则任何linux上的用户都可以访问；

2）用户只能访问那些有权限访问的文件或者目录；

3）用户只能修改或杀死自己的作业；

我们知道Hadoop集群的通信基础是基于RPC和AVRO，显然整体集群的安全机制就要考虑到RPC、MapReduce、HDFS三大模块。

1）Hadoop RPC安全机制是基于Kerberos和令牌的身份认证机制以及基于ACL的服务访问机制；

   Hadoop中RPC连接采用SASL认证机制，该机制采用第三方实现，包括Kerberos和DIGEST-MD5两种认证机制。

   ACL服务访问权限，可确保只有授权的用户才能访问对应的服务，限制只有若干用户/用户组可向Hadoop提交作业，管理员在hadoop-policy.xml中配置ACL。

2）HDFS的RPC通信连接和Block传输连接也采用Kerberos和令牌结合的身份认证；

3）MapReduce权限管理和身份认证要落实到作业的每个阶段，包括作业提交和控制、任务启动和运行等，具体可进一步扩展；

解决安全的问题，主要就是围绕身份认证和访问权限，Hadoop集群上的安全管理和机制可以去掌握具体的组件。



从hadoop集群以及其调度器和安全机制上，我们可以看出整个集群其实是一个各种组件的组合，ACL、JVM、RPC、AVRO等等，架构的价值也在于此。

这里也深刻体会到：应用需求驱动技术变现的模式，所有的知识储备是为了技术转化和落地，而要变现技术还需要市场和需求的驱动。

Hadoop集群的发展也正是体现了这点。






