# 关于在呼叫中心业务中应用语音识别技术的探讨 - 专注于数据挖掘算法研究和应用 - CSDN博客





2008年07月01日 16:10:00[fjssharpsword](https://me.csdn.net/fjssharpsword)阅读数：4333








**关于在呼叫中心业务中应用语音识别技术的探讨**



**摘要**：本文首先给出了语音技术的应用现状，接着对语音识别技术在呼叫中心中可应用可尝试的业务进行探讨，最后提出呼叫中心业务中应用语音识别技术的虚拟CSR概念。

**关键词**：SR(Speech Recognition) TTS(Text to Speech) 虚拟CSR(Virtual Customer Service Representatives)

# 前言

语音技术在呼叫中心业务中的应用已有相当程度的研究和成果；同时语音接入在如今多样化接入方式的呼叫中心依然占据重要地位，因此在具体呼叫中心业务中探讨语音技术的应用，对于提高呼叫中心运营效率与拓展业务内涵和空间具有积极意义。

一方面是语音技术的研究和应用如火如荼，另一方面在实际应用中却总是差强人意也并没有出现所预期的应用效果，这固然有语音技术方面的原因，但商业应用没有在具体业务实践中积极引入相对成熟的语音技术成果总不免起到了刹车作用。业务应用的内在需求是推动一项技术研究的动因。

本文力图在呼叫中心具体业务实践中探讨语音识别技术的应用，以求迈出小步从而推动呼叫中心向语音技术倾斜。这些探讨建立在广州电信商业呼叫中心的生产环境中，目的是在具体业务中利用语音识别技术提高效率或降低成本。探讨而非研究决定了本文的基础就是实际业务应用的试验。

# 1.语音技术应用现状

呼叫中心的核心技术是CTI（Computer Telephony Integration，计算机电话集成），CTI是计算机与通信相结合的产物。如同网络刚开始倚重于电话网实现通信，CTI属增值服务。呼叫中心利用CTI技术作为运营的核心基础，同时由IVR（Interactive Voice Response，交互式语音应答系统）、ACD（Automatic Call Distribute，自动呼叫分配）、网络设备和人工坐席等构成的网络系统呼叫中心。呼叫中心的重心已是基于CTI技术之上的业务功能软件，而业务功能软件与传统电话交换系统通过CTI技术相互间实现了透明，使呼叫中心的关注点脱离了支撑运营的技术，而专注于业务及其技术实现，即软件层面。

本文这里所探讨的语音识别技术应用是基于呼叫中心业务功能的软件层面，而对于语音技术的应用在目前主要有几点：

1）TTS（Text to Speech，文本语音转换）的应用

TTS是软件自动地把给定的文本信息转换成语音的过程。TTS技术把可视的文本信息转换为可闻的声音信息，其应用范围非常广，如文本的有声校对、语音应答系统、信息库查询系统、残疾人辅助发音系统等。TTS及最新的语音合成引擎（连接技术和合成算法的结合）在呼叫中心的IVR系统中应用已相当广泛。

2）音频分析的应用

坐席系统的录音功能保存了CSR与终端用户的通话，保存下来的语音数据可以进行数据挖掘，即音频分析。分析的目的和挖掘的方向取决于业务强调的核心，如考核CSR的语调，不需要人工监听，由音频分析系统完成。

3）SR（Speech Recognition，语音识别）的应用

SR引擎基于人工智能的自然语言理解技术生成语声抽象含义的译文。如音频分析的应用，坐席系统的录音功能保存的语音数据同样可以通过SR转化成具有一定语义的文本，综合终端用户与CSR通话的语音和文本分析终端用户对于某项产品或业务的认可或满意程度。

当前TTS和音频分析的应用相对成熟，语音识别技术的发展仍受制于自然语言处理的研究，在一些敏感性数据的业务上，其应用并不提倡。摆脱按键操作或是让眼睛休息而让耳朵和嘴巴多工作、改变键盘和鼠标的人与计算机交互方式，需要语音识别技术达到让业务软件具有同人一样的表达能力和想象能力、能够理解谈话双方的内容、可以预测不同事件的因果关系、较高的上下文关联能力。

# 2.技术环境

前文提到语音识别技术仍存在应用局限性，因此本文致力于在某些适合应用语音识别技术的业务上进行应用探讨。先就应用的技术环境进行简单说明。

1）华为ICD3.0平台：1B+1D的坐席生产环境安装有华为APC卡、华为音频二合一转换器；VP台配E1卡；

2）语音识别引擎采用微软Speech SDK51及中文语言包speechsdk51LangPack，采用VC6.0开发环境开发命令式语法模式的语音识别系统；

3）测试环境采用华为通用坐席接续控件实现在1B+1D生产环境下运行语音识别系统。

4）特别要说明：语音识别系统通过APC卡和声卡以及OS的I/O能识别响应电话来的语音，而要把语音识别系统TTS的语音传给客户则需要通过VP台的E1卡。在1B+1D的坐席环境，电话语音经过APC卡与话务员通话，同时转换成数字信号经过声卡和OS的I/O接口给语音识别系统，语音识别系统对收到的语音进行识别和响应；而语音识别系统不能把TTS的声音直接给客户，需要通过VP台进行数模转换才能给客户。建立在IP网上新一带呼叫中心，应该可以直接进行I/O操作的，目前未有相关技术或试验佐证。

5）总结：目前本文所依赖的技术环境在某些具体业务应用上推出语音识别系统在架构上无疑要发挥VP台的作用，因此需要对SR、TTS、VP台的服务器间通信和交互架构进行设计，保证客户语音可以为SR所捕获和TTS后的语音可传送到客户。该架构如图2-1语音识别技术应用架构图。



# 3.业务应用

基于前文所介绍的技术环境，本文将讨论如何在某些业务上应用语音识别技术。可通过让客户回复简单数字、字母、词汇达到交互目的业务，对于这些识别对象，语音识别率是相当高的，这些业务可以识别客户回复的词汇语义，根据识别的语义提取某些语音或TTS传回给客户。利用SR和TTS达到业务系统与客户的语音交互虽然对当前的交互方式或系统不是替代性的，但至少是可选择性的。本着提高效率或降低成本，同时也为达到语音交互的目的，探讨了下面两个业务的应用。

1）应用探讨案例——IVR上实现语音交互的数字识别

业务目标：数字交互，由键盘输入改成语音输入，如输入账号、日期的IVR流程等；

业务探讨：客户拨打电话后，直接进入TTS系统，由TTS系统开IVR流程。首先由TTS系统通过VP台给出欢迎语并提示输入日期；客户不通过电话上数字键而直接说出日期，这里说出的日期允许一定程度的模糊，如客户说出08年8月8日，客户的语音直接送到SR系统进行识别和响应；根据识别出的日期回复客户业务上需要的信息，调用TTS系统并通过VP台把回复信息的语音传送给客户。

技术探讨：客户的语音信息通过呼叫中心平台发给SR系统，TTS系统由VP台发送语音信息给客户，这是最基本的系统架构关系。SR系统采用线程池处理方式，同时处理多个IVR中客户发来的语音信息，TTS系统也是如此，线程池与呼叫中心平台中继线话路数有关。从图3-1语音交互数字识别示意图可以看出SR系统在CCS中获取语音数据并在刚启动IVR时由CCS调用TTS系统，而之后则有SR系统响应语音出发TTS系统并通过VP台传送语音给客户。

应用特点：与终端用户交互中，简单的数字可采取语音识别技术，不失为按键操作的一个选择。同时，对于特殊人群，如盲人，非人工坐席交互而纯语音呼叫中心的业务也可以考虑采用语音识别技术。引入IVR式SR系统和TTS系统不免要在华为业务支撑平台上作些改动，违背了IT不同体系分离的原则，如果语音识别技术在该方面业务有实际应用意义和推广价值，可以考虑技术革新而不采取本文所提到的技术思路。



2）应用探讨案例——问卷调查中的字母识别应用

业务目标：实现调查问卷不需要人工坐席来操作而由SR和TTS系统完成。

业务探讨：问卷调查更多的是客户选择答案，可以设计答案的回答为字母。由TTS完成问题，由SR接收来自客户的语音答案。不可避免存在个别答案需要文字说明而非字母，则需要在设计问卷时尽量采用简单词汇作为答案。

技术探讨：TTS向客户问卷，同样需要通过VP台，SR接收来自客户的语音并识别出答案，其他问卷上业务处理与一般无异，不同的是本来有CSR问卷的任务由TTS完成，由CSR选择客户给出的答案完成选择的任务由SR完成。可以在一台服务器上，通过SR和TTS对设计好的问卷和联系人发起不间断问卷，直到问卷联系人全部问卷完毕。如果要并发问卷，即同时对多个联系人问卷，则需要采用线程池实现，这点上和前一个应用案例一样。

应用特点：如同IVR外呼，实现问卷外呼不需要人工坐席干预而纯由问卷业务系统完成，问卷业务系统中增加SR和TTS处理。

上文所探讨的两个案例在业务上都要求数字、字母、简单词汇可识别。通过这些容易识别的业务中尝试语音识别技术的应用，有助于语音识别技术在呼叫中心中的推广。本文所建立的技术环境和采用的架构或技术思路均在一定条件下给出的，针对上文两个案例在本文给出的技术环境下架构具有可行性。

基于微软语音识别引擎和VC6.0开发环境，在附件中给出了命令式语法模式下语音识别测试系统的核心代码，主要是测试了SR在本文所给出的呼叫中心平台下的运行，对上文两个案例的可行性有直接参照作用。

# 4.应用方向

对于语音识别技术在呼叫中心未来的应用方向，虚拟CSR无疑是极具挑战性的课题。所谓虚拟CSR就是让语音技术完全代替人工CSR完成呼叫中心的职能，这有赖于方方面面技术的进步，但在某些业务上如上文所提到的问卷调查并非不可能的。在虚拟CSR全面替代人工CSR前，某些业务的语音识别技术应用必须考虑到虚拟CSR与人工CSR之间的无缝交接，如同目前的IVR转接到坐席处理一般，在虚拟CSR无法胜任时需要由人工CSR处理。同时对于在呼叫中心某些业务上大面积应用，必须考虑语音识别引擎的研究。虚拟CSR的目标就在于使呼叫中心的未来业务是基于虚拟CSR语声的应用和服务。

技术的展望也必须对呼叫中心未来的进行思考。呼叫中心的发展历程还未脱离人工CSR这样一个劳动密集型的产业范畴。未来人与计算机的交互方式将发生变革，键盘和鼠标可能会被语音识别、视觉以及手写输入等进行选择性的替代，尽管不会消失，但交互方式的革命也正意味着人工智能或在未来对呼叫中心的职能有根本性的影响。

# 总结

效率和成本是任何一项经营行为必须权衡的关键因素，而在呼叫中心业务中，每天产生的大量数据除了记录业务行为外就是占用硬盘空间，应该考虑挖掘这些数据背后的巨大意义。如IVR流程中，客户在交互式过程中能够快速响应，表明是熟悉该IVR的客户，判定是老客户，则可以观察其按键行为记录，从按键记录中挖掘出什么业务是老客户重视和经常要办理的。在IVR流程中把这些业务的选择或执行放在IVR流程的前面完成，老客户办理完这些业务就会挂断电话，节约话路资源和通话时间。



总结中谈到数据挖掘的重要性似乎与本文中心点并无关系，实际上，呼叫中心平台处理的就是语音和数据，如同研究语音识别技术的应用，研究数据挖掘的应用同样重要。尝试语音识别技术在呼叫中心某些业务中的应用，这就是本文从现状再到案例技术分析的出发点。

# 参考文献

# 附件

附件中的代码利用VC6.0开发环境，安装微软Speech SDK51及其语言包，同时测试环境在上文所描述的技术环境中。

1．初始化代码

开发所用的sapi.dll、sphelper.h、sapi.h应先引入。此处引用代码并没有加入代码解释语句。

::CoInitialize(NULL);

if(!OnInitSpeech())

EndDialog(0);

GetDlgItem(IDC_EDIT_Question)->SetWindowText("请问您已获得的最高学历是 A 硕士及以上 B 本科或大专 C 高中或中专或技校或职专 D 初中及以下E不知道 F拒答");

2．实现语音识别代码

BOOL CGZCC_SRDemoDlg::OnInitSpeech()

{

HRESULT hr=S_OK;

hr=cpRecoEngine.CoCreateInstance(CLSID_SpInprocRecognizer);

if( SUCCEEDED(hr) )

{

hr = cpRecoEngine->CreateRecoContext(&m_cpRecoCtxt);

}

if( SUCCEEDED(hr) )

{

hr=m_cpRecoCtxt->SetNotifyWindowMessage(m_hWnd,WM_RECOEVENT, 0, 0 );

}

if (SUCCEEDED(hr))

{

const ULONGLONG ullInterest = SPFEI(SPEI_RECOGNITION);

hr = m_cpRecoCtxt->SetInterest(ullInterest, ullInterest);

}

// create default audio object

CComPtr<ISpAudio> cpAudio;

hr = SpCreateDefaultObjectFromCategoryId(SPCAT_AUDIOIN, &cpAudio);

// set the input for the engine

hr = cpRecoEngine->SetInput(cpAudio, TRUE);

hr = cpRecoEngine->SetRecoState( SPRST_ACTIVE );

if (SUCCEEDED(hr))

{

hr = m_cpRecoCtxt->CreateGrammar( GID_CMDCTRL, &m_cpDictationGrammar);//命令式

}

if(SUCCEEDED(hr))

{

WCHARwszXMLFile[20]=L" ";//命令式

CStringXMLFileName="CmdCtrl.xml";//CmdCtrl.xml";

MultiByteToWideChar(CP_ACP, 0, (LPCSTR)XMLFileName , -1, wszXMLFile, 256);

hr = m_cpDictationGrammar->LoadCmdFromFile(wszXMLFile,SPLO_DYNAMIC); //失败，调试

}

if (SUCCEEDED(hr))

{

hr = m_cpDictationGrammar->SetRuleState( NULL,NULL,SPRS_ACTIVE );//命令式激活

}

if (FAILED(hr))

{

//Release the grammar using ISpRecoGrammar

m_cpDictationGrammar.Release();

}

return (hr == S_OK);

}

void CGZCC_SRDemoDlg::OnRecoEvent()

{

USES_CONVERSION;

CSpEvent event;

// Process all of the recognition events

while (event.GetFrom(m_cpRecoCtxt) == S_OK)

{

switch (event.eEventId)

{

case SPEI_SOUND_START:

m_bSound = TRUE;

break;

case SPEI_SOUND_END:

if (m_bSound)

{

m_bSound = FALSE;

if (!m_bReco)

{

// The sound has started and ended, 

// but the engine has not succeeded in recognizing anything

const TCHAR szNoise[] = _T("<noise>");

}

m_bReco = FALSE;

}

break;

case SPEI_RECOGNITION:

// There may be multiple recognition results, so get all of them

{

m_bReco = TRUE;

static const WCHAR wszUnrecognized[] = L"<Unrecognized>";

CSpDynamicString dstrText;

if (FAILED(event.RecoResult()->GetText(SP_GETWHOLEPHRASE, SP_GETWHOLEPHRASE, TRUE, &dstrText, NULL)))

{

dstrText = wszUnrecognized;

}

// Concatenate a space onto the end of the recognized word

dstrText.Append(L" ");

BSTR SRout; 

dstrText.CopyToBSTR(&SRout); 

CString Recstring; 

Recstring.Empty(); 

Recstring = SRout;

Recstring.TrimLeft();Recstring.TrimRight();

if (Recstring=="退出") 

::SendMessage(m_hWnd,WM_CLOSE,NULL,NULL);

else

::SendDlgItemMessage(m_hWnd, IDC_EDIT_Answer, EM_REPLACESEL, TRUE, (LPARAM) W2T(dstrText) );

}

break;

}

}

}

命令式识别的XML文本如下：

<?xmlversion="1.0"encoding="GB2312"?>

<GRAMMAR LANGID="804">

<DEFINE> 

<ID NAME="CMD" VAL="10"/> 

</DEFINE> 

<RULE NAME="COMMAND" ID="CMD" TOPLEVEL="ACTIVE"> 

<L> 

<p>A</p>

<p>B</p> 

<p>C</p>

<p>D</p>

<p>E</p>

<p>F</p>

<p>退出</p>

</L> 

</RULE> 

</GRAMMAR>

3．TTS代码

void CGZCC_SRDemoDlg::OnOK() 

{

// TODO: Add extra validation here

HRESULT hr = CoCreateInstance(CLSID_SpVoice, NULL, CLSCTX_ALL, IID_ISpVoice, (void **)&m_pVoice);

if( SUCCEEDED( hr ) )

{

IEnumSpObjectTokens *pSpEnumTokens=NULL;

hr=SpEnumTokens(SPCAT_VOICES,L"Language=804",NULL,&pSpEnumTokens);

if(SUCCEEDED(hr))

{

ISpObjectToken *pSpToken = NULL;

while(SUCCEEDED(pSpEnumTokens->Next(1, &pSpToken, NULL)) && pSpToken != NULL)

{

m_pVoice->SetVoice(pSpToken);

//pVoice->Speak(L"我们都是中国人",SPF_DEFAULT,NULL);

wchar_t* wszStr;

CString strQus;

GetDlgItem(IDC_EDIT_Question)->GetWindowText(strQus);

int len = strlen(strQus);

wszStr = new wchar_t[len + 50];

mbstowcs(wszStr,strQus,len+1);

hr = m_pVoice->Speak(wszStr, 0, NULL);

pSpToken->Release();

}

pSpEnumTokens->Release();

}

}

}



