# 霍金的遗愿清单：离开地球，警惕人工智能 - 算法与数学之美 - CSDN博客
2018年03月17日 00:00:00[算法与数学之美](https://me.csdn.net/FnqTyr45)阅读数：325
**永恒是很长的时间，特别是对尽头而言——霍金**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69SfRHvOaDJDrI7bCNLqoibJALYu0ic1xWBDFwgiauPcFBg6X9HcWzTNCRg/640?wx_fmt=jpeg)
2018年3月14日，著名理论物理学家史蒂芬·威廉·霍金去世，享年76岁。
噩耗传来，震惊世界。
在过去的二十年里，除了继续探索宇宙理论，霍金也出现在各种场合，为所有关切人类命运的主题发声。而在他去世前的这几年中，霍金最关注的话题就是：
**离开地球，和警惕人工智能。**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69zBVegZT9hjdjPnFjdy3l5Lub7p3yd4amv1eKIIPxgYT2S8ubsGmlNg/640?wx_fmt=jpeg)
现在，我们就梳理下霍金通过各种渠道谈论这两个话题的言论。
关于离开地球，早在2011年，霍金在接受美国视频共享网站BigThink访谈时就称，**地球将在两百年内毁灭，人类要想活命只能移民外星球。**
2017年11月5日，北京腾讯WE大会的现场。霍金通过视频指出了人类移民太空的原因所在：**一个原因是，对我们来说，地球变得太小了。在过去二百年中，人口增长率是指数级的，即每年人口以相同比例增长。目前这一数值约为1.9%。**
**这听起来可能不是很多，但它意味着，每四十年世界人口就会翻一番。****2022年，我将庆祝自己80岁的生日，而在我人生的这段历程中，世界人口比我出生时膨胀了四倍。****（读来恍若隔世）**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69tYZsW1FvIzGDzEhh4W1k36nbbJxaN59iabXzKXcIMS7FYGoo4Lunvaw/640?wx_fmt=jpeg)
这样的指数增长，不能持续到下个千年。
到2600年，世界将拥挤得“摩肩擦踵”，电力消耗将让地球变成“炽热”的火球。这是岌岌可危的。然而我是个乐观主义者，我相信我们可以避免这样的世界末日，**最好的方法就是移民到太空，探索人类在其他星球上生活的可能。**
2017年7月，霍金痛批美国总统特朗普退出气候问题《巴黎协定》的决定，**警告称此举或将让地球变成一个金星一样的温室星球。**霍金在接受BBC专访时表示，**我们正在接近全球变暖不可逆转的临界点，特朗普的决定可能将地球推过这个临界点，变成像金星一样的星球，温度高达250度，并且下着硫酸雨。**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69leQjv92Oaz0zL2JLqI7JCBt2CjgQYW0tcOoLmtKUAoVVCniaGkSr7Jw/640?wx_fmt=jpeg)
在2017年6月播放的纪录片《远征新地球》（Expedition New Earth）中。**霍金说，在未来一百年内，人类为生存必须离开地球，在太空寻求新家。**
离开地球，霍金是认真的。
**2016年4月12日，霍金在纽约宣布启动“突破射星”计划，将同俄罗斯商人尤里·米尔纳（Yuri Milner），以及美国社交网站面簿创始人兼总裁扎克伯格（Mark Zuckerberg）合作建造能以五分之一光速飞往比邻星的微型星际飞船。**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX697zXBfFjMVVdPTqmsictHSMWIvhzzhqPKQgwzwYuthFrqnZ98ejP594Q/640?wx_fmt=jpeg)
除了地球即将面临的各种风险，霍金更关切人类正在创造一个毁灭自己的怪物：**人工智能（AI）**。
2017年3月，霍金在接受英国《泰晤士报》采访时再次发出警告，“人类需要控制以人工智能为代表的新兴科技，以防止它们在未来可能对人类生存带来的毁灭性威胁。”
霍金解释自己的警告时说，“**他们本身也是生根于达尔文的进化论之中。因此人类需要利用逻辑和理性去控制未来可能发生的威胁。**”
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69BibibHzlz1KIamUFe57BQYtJYClPqbalI1L3x3icLfXgkNL1BlDHwpw2Q/640?wx_fmt=jpeg)
2016年10月19日，剑桥大学“莱弗休姆的未来智能中心(LCFI)”正式投入使用。霍金在庆祝典礼上发表了演讲。**霍金在演讲中，批评了人工智能的无节制发展。**
他认为，**人工智能技术，的确有希望带来巨大的福利，比如根除疾病和贫困，但是它同样也可能带来危险，比如强大的自主式武器，或者帮助少数人压迫多数人。**
早在2014年12月，霍金接受英国广播公司（BBC）采访时就明确表示：“**制造能够思考的机器，无疑是对人类自身存在的巨大威胁。当人工智能发展完全，就将是人类的末日。”**
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/cQjAXpBp6e7hmIjiazrXCOTAZdzRvDX69C4LCJ3TkcdptzaOQwbTzcMku3k72zz7zbnOaeh0UmDIAe6nsHickGxw/640?wx_fmt=jpeg)
《万物理论》剧照
**霍金对人类和科技的未来，也许是悲观的，他并不信任人类真的能控制科技这个怪物。但令人讽刺的是，一旦人类用科技毁掉了这个星球，所能仰赖的也只有科技，才能帮人类在外星球继续繁衍。**
斯人已逝，让我们别忘记霍金的预言和警告。
∑编辑 | Gemini
来源 | 澎湃新闻
![640?wx_fmt=gif](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkwJ4BpvBcQhGAbtWZZvV69s7GickZGibsKgYkTQkiaZfLYOmGS9iaaoibadibGJhT18OVZkfeJmCSUSD0zw/640?wx_fmt=gif)
算法数学之美微信公众号欢迎赐稿
稿件涉及数学、物理、算法、计算机、编程等相关领域
稿件一经采用，我们将奉上稿酬。
投稿邮箱：math_alg@163.com
