# cips2016+学习笔记︱NLP中的消岐方法总结（词典、有监督、半监督） - 素质云笔记/Recorder... - CSDN博客





2017年02月05日 19:37:45[悟乙己](https://me.csdn.net/sinat_26917383)阅读数：8586








**歧义问题方面，笔者一直比较关注利用词向量解决歧义问题：**

也许你寄希望于一个词向量能捕获所有的语义信息（例如run即是动车也是名词），但是什么样的词向量都不能很好地进行凸显。  

这篇论文有一些利用词向量的办法：[Improving Word Representations Via Global Context And Multiple Word Prototypes(Huang et al. 2012)](http://nlp.stanford.edu/pubs/HuangACL12.pdf)

解决思路：对词窗口进行聚类，并对每个单词词保留聚类标签，例如bank1, bank2等 
![这里写图片描述](https://img-blog.csdn.net/20170205192614083?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMjY5MTczODM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
来源于笔者的笔记： [NLP︱高级词向量表达（一）——GloVe（理论、相关测评结果、R&python实现、相关应用）](http://blog.csdn.net/sinat_26917383/article/details/54847240)

> 
那么在CIPS2016 中文信息处理报告《第二章 语义分析研究进展、现状及趋势》第三节 技术方法与研究现状 

  P16-P17中提到了一些词义消岐的记载。


词义消歧的研究通常需要语义词典的支持，因为词典描述了词语的义项区分。英语的词义消歧研究中使用的词典主要是ordNet，而中文使用的词典有HowNet，以及北京大学的“现代汉语语义词典”等。 

除词典外，词义标注语料库标注了词的不同义项在真实文本中的使用状况，为开展有监督的词义消歧研究提供了数据支持。常见的英文词义标注语料库包括Semcor（普林斯顿大学标注）、DSO（新加坡国立大学标注）以及用于Senseval 评测的语料库等。在中文方面，哈尔滨工业大学和北京大学分别基于HowNet 和北大“现代汉语语义词典”标注了词义消歧语料库。

词义消歧的研究是自然语言处理的一项基础关键，根据所使用的资源类型不同，可以将词义消歧方法分为以三类：

# 1、基于词典的词义消歧

基于词典的词义消歧方法研究的早期代表工作是Lesk 于1986 的工作。给定某个待消解词及其上下文，该工作的思想是计算语义词典中各个词义的定义与上下文之间的覆盖度，选择覆盖度最大的作为待消解词在其上下文下的正确词义。但由于词典中词义的定义通常比较简洁，这使得与待消解词的上下文得到的覆盖度为０，造成消歧性能不高。

# 2、有监督词义消歧

有监督的消歧方法使用词义标注语料来建立消歧模型，研究的重点在于特征的表示。常见的上下文特征可以归纳为三个类型：（1）词汇特征通常指待消解词上下窗口内出现的词及其词性； 

（2）句法特征利用待消解词在上下文中的句法关系特征，如动－宾关系、是否带主/宾语、主/宾语组块类型、主/宾语中心词等； 

（3）语义特征在句法关系的基础上添加了语义类信息，如主/宾语中心词的语义类，甚至还可以是语义角色标注类信息。
最近随着深度学习在自然语言处理领域的应用，基于深度学习方法的词义消歧成为这一领域的一大热点。深度学习算法自动的提取分类需要的低层次或者高层次特征，避免了很多特征工程方面的工作量。

# 3、无监督和半监督词义消歧

虽然有监督的消歧方法能够取得较好的消歧性能，但需要大量的人工标注语料，费时费力。为了克服对大规模语料的需要，半监督或无监督方法仅需要少量或不需要人工标注语料。 

例如Yarowsky（1995）仅需要使用少量的人工标注语料作为种子数据，Ng 等（2003）从词对齐的双语语料抽取种子数据。Resnik（1997）根据词的不同歧义往往也体现在句法搭配上的差异这一思想，通过计算“语义优选强度”和“选择关联度”在大规模语料中自动获取句法结构的语义优选，然后用之于词义消歧。 

一般说来，虽然半监督或无监督方法不需要大量的人工标注数据，但依赖于一个大规模的未标注语料，以及在该语料上的句法分析结果。另一方面，待消解词的覆盖度可能会受影响。 

例如，Resnik（1997）仅考察某部分特殊结构的句法，只能对动词、动词的主词/宾语、形容词修饰的名词等少数特定句去位置上的词进行消歧，而不能覆盖所有歧义词。
. 

.

## 延伸一：谷歌让机器更懂语言的博大精深，发布最大消歧语料库（2017-1-19）

「he will receive stock in the reorganized company」，这个句子中，我们结合上下词就能知道，「stock」在这里是股票的意思，我们可以从牛津字典中找到更为专业的解释。

但是同样在牛津字典中，stock 这个词还有超过 10 个不同的含义，比如「（商店里的）库存」或是「(鞭子、钓竿等的) 柄」。对于计算机算法而言，如何从博大精深的含义中找寻某个句子中对应的词义？这的确是一个词义消歧难题，也就是 AI-Complete 问题。 

今天谷歌研究院又发出了重磅新闻，他们发布了基于 MASC&SemCor 数据集的大规模有监督词义消歧语料。这些语料会与牛津字典上的例句做映照，广泛适用于各个社区。与此同时，本次发布也是最大的全句释义语料库之一。
- **有监督词义消歧**

人们通过对句子中词语的内容进行理解，因为我们能通过常识判断上下文的含义。比如同样一个例子，「『stock』 in a business」代表的自然是股票的意思，而「『stock』 in a bodega」更有可能是库存的意思，即使这里的 bodega 也可能指酒窖生意。我们希望为机器提供足够的背景信息，并应用于理解文本中词语的含义。

有监督词义消歧（WSD）尝试解决这一问题，也就是让机器学习使用人工标记的数据，并与字典中的词语所代表的典型含义匹配。我们希望构建这样的一个监督模型，能够不考虑复杂语境，并匹配句中单词在词典中最可能表达的含义。虽然这一点富有挑战，但监督模型在大量训练数据支持下表现良好。

通过发布数据集，我们希望社区能够提出更好的算法，让机器对自然语言产生更深刻的理解，支持以下的应用：

从文本中自动搭建数据库存，这样一来，机器可以回答问题，并将文档中的知识串联起来。举个例子，机器在经过学习后，明白「hemi engine」指的是一种自动化的机械；而「locomotive engine」则与火车有关。也能理解「Kanye West is a star」指的是名人的意思；而「Sirius is a star」则是天文学概念。

消除歧义。我们希望让文本在查询中能够呈现不同的含义，避免张冠李戴，与此同时还能返回具有相关语义的文档。

来源雷锋网，文章《谷歌让机器更懂语言的博大精深，发布最大消歧语料库》

.

## 延伸二：word2vec在消岐中的作用

来源：[第2期Talk实录 | 词向量的几何分布及其应用](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247484129&idx=1&sn=3dc530aeb3aeaef19e360a730c86b0ea&chksm=96e9dd61a19e5477bc00642a043624a449c1b2849dbf5e27da5f007fa244b9eaabb7c4fdd26d&mpshare=1&scene=1&srcid=0309aqfprK12La7gLxeubkDs#rd)
- 在消歧任务中，一个词在不同的 context 下是生成了不同的向量么？

因为 word2vec 对多义词的表述并不准确，在消歧过程中我们并没有使用多义词本身的 vector，而是使用的除去这个多义词之外其他 context words 的 vectors。
- 当歧义词出现在不同的句子中时，这些句子对应的平面一定会相交么？这种特性有没一种直观的解释？

这里“相交”的定义比较宽泛 - 由于噪声的影响，三个平面完全相交都是几乎不可能的。我们只希望存在一个 unitvector 距离所有的 subspace 都很接近。这种特性是基于最初 subspace 的假设的。假如我们考虑同义词，那么这个同义词应该在 context1 对应的 subspace 中，context2 对应的 subspace 中… 那么这个同义词的所有 subspace 都会和这个同义词的 vector 很接近，恢复 intersection 就可以近似地恢复这个同义词的 representation。同理，假设 polysemy 的每一个 sense 都有一个 representation，那么这个 sense vector 就距离它对应所有的 subspace 很近，也就是这些 subspace 近似相交了。

.

## 延伸三：利用word2vec进行消岐-华院

华院数据：[自然语言理解在金融领域的应用 | 尹相志](https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247485389&idx=2&sn=48442852c53b029bf6acb19939e1ef91&chksm=e8945d40dfe3d4567e88cdd317f756f76c27664115c7cda903818dbc492d1f0ca02b3a08c2be&mpshare=1&scene=1&srcid=0324pINSnLoNHsiVKvoNrj28#rd)

总结下来：实体词+加一个词来“辅助”正确识别语义

我们将词向量技术用于枚举出所有的币种。我们通过扫描大量的文本，可以得到每个单词的词向量，那么我们怎么把所有的货币的名称跳出来呢？答案很简单就是利用如下这个cos距离的公式，我们只要将与美元的距离＋英镑的距离和最小的那些词向量所对应的实体列举出来就可以了。  

解决方案是引入第三个词。这里有两种方法，一种是语义增强，一种是语义消岐。采用下面的两个公式分别能够做到这两点：

![这里写图片描述](http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWKHq0WuzzAeL7xgU4ayZJBuzMxRLGq7z0pIMwScMSDuDmENB18y3qLhqiaT0HEQqPicFeTjhJGvcEfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

这样就可以得到我们希望要的结果了。但是这里的冰棒和雪糕还是有点怪怪的。 
![这里写图片描述](http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWKHq0WuzzAeL7xgU4ayZJBujzMm1OOmcFpqrF1P3PFDicTawWBeJTHnwq0Th9oLNPTq0M4ANzzmXLQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)






