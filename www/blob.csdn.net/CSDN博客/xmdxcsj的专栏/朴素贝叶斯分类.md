# 朴素贝叶斯分类 - xmdxcsj的专栏 - CSDN博客





2015年04月01日 18:44:19[xmucas](https://me.csdn.net/xmdxcsj)阅读数：517
个人分类：[机器学习](https://blog.csdn.net/xmdxcsj/article/category/3074739)









一、背景知识

1.      概况

分类：根据**概率论**进行分类的方法，本质上是**有监督**的训练方式，概率值最大对应的类别即为所属的类别。

朴素：为了简化计算和公式，做出最原始和最简单的假设，即特征之间是**相互独立**的、每个特征是**同等重要**的。

2.      贝叶斯公式

![](https://img-blog.csdn.net/20150401184404118?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveG1keGNzag==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

Ci表示类别，W表示特征向量。

类比到语音识别的声学得分即为将求似然概率问题P(Ci|W)转化为求后验概率问题P(W|Ci)，P(Ci)表示先验概率，P(W)是常量。

二、实例

社区论坛屏蔽侮辱性的言论。

1.      将文本转化为词向量

生成所有词的列表w，对应于一句话，将w中该句话里面所有的词设为1，其他设为0。

2.      计算

P(W|Ci)： 对应于Ci分类的总的词数为N，Ci分类中单词Wi出现的频率为Ni，则Ni/N即为所求的概率。P(W|Ci)=P(W0|Ci)* P(W1|Ci) * P(W2|Ci)*…

3.      分类

对于输入文本，将其转化为词向量，与P(W|Ci)相乘累加，观察对应于哪个分类的概率最大。

三、参考

1.      《机器学习实战》

2.      [http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html](http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html)

3.      [http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)



