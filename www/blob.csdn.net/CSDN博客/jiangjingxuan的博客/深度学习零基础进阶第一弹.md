# 深度学习零基础进阶第一弹 - jiangjingxuan的博客 - CSDN博客





2017年02月27日 08:18:12[jiangjingxuan](https://me.csdn.net/jiangjingxuan)阅读数：873








![干货分享 | 深度学习零基础进阶大法！](http://static.leiphone.com/uploads/new/article/740_740/201610/580885768ad1b.png?imageMogr2/format/jpg/quality/90)

[pixabay](https://pixabay.com/zh/%E9%94%AE%E7%9B%98-%E5%85%B3%E9%94%AE-%E6%88%90%E5%8A%9F-%E5%9C%A8%E7%BA%BF-%E8%AE%A1%E7%AE%97%E6%9C%BA-%E4%B8%9A%E5%8A%A1-621830/)

*编者按：新手上路都会有一个疑问，如果自己没有相关基础，如何学习晦涩的专业知识？此前雷锋网(公众号：雷锋网)编译了*[*《从0到1：我是如何在一年内无师自通机器学习的？》*](http://www.leiphone.com/news/201609/SJGulTsdGcisR8Wz.html)*，这篇文章讲述了 Per Harald Borgen 的自学历程。而关于[深度学习](http://www.leiphone.com/news/201701/LqwiP7VUJO9DgBPi.html)，GitHub的 songrotek 同样有话要说。原文名为《Deep Learning Papers Reading Roadmap》，雷锋网奕欣及老吕IO整理编译，未经许可不得转载。*

**0. 深度学习的“圣经”**

提到入门级的书，就不得不提这一本 Bengio Yoshua，Ian J. Goodfellow 和 Aaron Courville共同撰写的《深度学习》（Deep Learning）。

“这本关于深度学习的教课书是一本为了帮助学生及从业者入门[机器学习](http://www.leiphone.com/news/201609/SJGulTsdGcisR8Wz.html)，并专注于深度学习领域的教材。”值得一提的是，这本 MIT 出版的“书”数年来一直在网上实时更新和完善，不断补充研究成果和新的参考文献，也向公众开放评论，接受修改意见，其火爆程度甚至被誉为深度学习的“圣经”。
 目前该书可在亚马逊预定，今年年底就会送到你手上。

《深度学习》阅读网址：[http://www.deeplearningbook.org/](http://www.deeplearningbook.org/)

**1. 调研**

 Yann LeCun , Yoshua Bengio和Geoffrey Hinton被作者誉为深度学习界三大天王，他们所发布在 Nature上的“Deep Learning”包含了大量的研究和调查，五星推荐，值得一读！

[1] [http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)

**2. 建立深度学习的知识网**

作为 AI 领袖级人物，Geoffrey Hinton 目前就职于谷歌，而其与E., Simon Osindero和Yee-Whye The的代表作《A fast learning algorithm for deep belief nets》更是被奉为圭臬，不妨看看。

[2] [http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf](http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf)

此外，他还有一篇署名第一作者的《Reducing the dimensionality of data with neural networks》，可以说是深度学习的里程碑之作。

[3] [http://www.cs.toronto.edu/~hinton/science.pdf](http://www.cs.toronto.edu/~hinton/science.pdf)

**3. ImageNet 革命**

当你读完了上面的几篇论文，相信你对深度学习也有了一个大致的了解。那么深度学习的突破点在哪呢？在 2012 年，Krizhevsky 的《Imagenet classification with deep convolutional neural networks》预示着神经网络的出现和发展有了突破性的研究进展。来不及了，赶紧上车吧，推荐指数五颗星。

[4] [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

而深度对于网络有多重要？《Very deep convolutional networks for large-scale image recognition》是牛津大学视觉几何组（VGG）Karen Simonyan 和 Andrew Zisserman 于 2014 年撰写的论文，主要探讨了深度对于网络的重要性；并建立了一个 19层的深度网络并获得了很好的结果。该论文在 ILS[VR](http://www.leiphone.com/category/arvr)C上定位第一，分类第二。

[5] [https://arxiv.org/pdf/1409.1556.pdf](https://arxiv.org/pdf/1409.1556.pdf)

如果想要了解下神经网络结构是如何改进的，那一定得读下这篇。Szegedy 和 Christian 都是当代著名的计算机科学家，他们曾在 2015 年合写了《Going deeper with convolutions》，这篇论文是为 ImageNet2014 的比赛而作，论文中的方法获得了比赛的第一名，包括 task1 分类任务和 task2 检测任务。本文主要关注针对计算机视觉的高效深度神经网络结构，通过改进神经网络的结构达到不增加计算资源需求的前提下提高网络的深度，从而达到提高效果的目的。

[6] [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)

在第六届 ImageNet 年度图像识别测试中，微软研究院的计算机图像识别系统在几个类别的测试中拔得头筹，击败了谷歌、英特尔、高通、腾讯以及一些创业公司和学术实验室的系统。微软的获胜系统名为“图像识别的深度残差学习”(Deep Residual Learning for Image Recognition)，由微软研究员何恺明、张祥雨、任少卿和孙剑组成的团队开发。因此，记录这一团队系统开发心得的《Deep Residual Learning for Image Recognition》绝对是学习必备啊，五星推荐。

[7] [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)

**4. [语音识别](http://www.leiphone.com/news/201412/SPIrQG1uFa6jWMVZ.html)大法好**


Hinton 与 Geoffrey 等技术专家合著的《Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups》是语音识别领域的巨大突破。它融合了四个小组利用深度神经网络和声学建模完成语音识别的实例。

[8] [http://cs224d.stanford.edu/papers/maas_paper.pdf](http://cs224d.stanford.edu/papers/maas_paper.pdf)

除了上面的几篇论文，Geoffrey Hinton 大神 在《Speech recognition with deep recurrent neural networks》一文中也是思如泉涌，他向我们介绍了深度循环神经网络（RNNs）在语音识别中的重要性。

[9] [https://arxiv.org/pdf/1303.5778.pdf](https://arxiv.org/pdf/1303.5778.pdf)

想必我们对语音输入并不陌生，但这是如何实现的呢？这篇名为《Towards End-To-End Speech Recognition with Recurrent Neural Networks》由 Graves、Alex 和多伦多大学教授 Navdeep Jaitly 共同撰写。它向我们描述了一个无需中继语音重构的音频转文字识别系统。

[10] [http://www.jmlr.org/proceedings/papers/v32/graves14.pdf](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)

如果你要问谷歌语音识别系统之源是什么，那我一定会向你推荐这篇名为《Fast and accurate recurrent neural network acoustic models for speech recognition》的论文由 Sak 和 Hasim 等多位专家撰写而成，它是谷歌语音识别系统的重要理论基础之一。

[11] [https://arxiv.org/pdf/1507.06947.pdf](https://arxiv.org/pdf/1507.06947.pdf)

百度近日公布了其硅谷[人工智能](http://www.leiphone.com/category/ai)实验室（SVAIL）的一项新的研究成果，被称为 Deep Speech 2。Deep Speech 通过使用一个单一的学习算法实现了准确识别英语和汉语的能力。这一成果就发表在论文《Deep speech 2: End-to-end speech recognition in english
 and mandarin》之中。

[12] [https://arxiv.org/pdf/1512.02595.pdf](https://arxiv.org/pdf/1512.02595.pdf)

本月 18 日，微软人工[智能](http://www.leiphone.com/)与研究部门的研究员和工程师发表了一篇名为《Achieving Human Parity in Conversational Speech Recognition》的论文。论文表明，微软的对话语音识别技术在产业标准 Switchboard 语音识别基准测试中实现了词错率（word error rate, 简称WER）低至
 5.9% 的好成绩，首次达成与人类专业速记员持平，并且要优于绝大多数人的表现。雷锋网此前也有提及，详情可点击[原文](http://www.leiphone.com/news/201610/iUulTnNPIyNQlJXM.html)查看。同时，也刷新了自己的一个月前创造的 6.3% 的记录。微软首席语音科学家黄学东是这一研究的参与者之一。

[13] [https://arxiv.org/pdf/1610.05256v1.pdf](https://arxiv.org/pdf/1610.05256v1.pdf)

读完了上面推荐的论文，你一定对深度学习的历史有了一个基本了解，其基本的模型架构（CNN/RNN/LSTM）与深度学习如何应用在图片和语音识别上肯定也不在话下了。下一部分，我们将通过新一批论文，让你对深度学习的方式与深度学习在不同领域的运用有个清晰的了解。由于第二部分的论文开始向细化方向延展，因此你可以根据自己的研究方向酌情进行选择。



