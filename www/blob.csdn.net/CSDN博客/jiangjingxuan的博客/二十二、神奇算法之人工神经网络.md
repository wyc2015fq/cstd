# 二十二、神奇算法之人工神经网络 - jiangjingxuan的博客 - CSDN博客





2017年01月25日 13:52:29[jiangjingxuan](https://me.csdn.net/jiangjingxuan)阅读数：386












![](http://www.shareditor.com/uploads/media/default/0001/01/thumb_254_default_big.jpeg)



深度学习是机器学习中较为流行的一种，而深度学习的基础是人工神经网络，那么人工神经网络的功能是不是像它的名字一样神奇呢？答案是肯定的，让我们一起见证一下这一神奇算法

请尊重原创，转载请注明来源网站[www.shareditor.com](http://www.shareditor.com)以及原始链接地址

## 人工神经网络

人工神经网络是借鉴了生物神经网络的工作原理形成的一种数学模型，有关人工神经网络的原理、公式推导以及训练过程请见我的文章[《机器学习教程 十二-神经网络模型的原理》](http://www.shareditor.com/blogshow/?blogId=91)



## 神奇用法之一

我们这样来设计我们的神经网络：由n个输入特征得出与输入特征几乎相同的n个结果，这样训练出的隐藏层可以得到意想不到的信息。

![](http://www.shareditor.com/uploads/media/my-context/0001/01/e71bacc31d8e066220d9d7a97fb52f07b31c0962.png)

比如，在信息检索领域，我们需要通过模型训练来得出合理的排序模型，那么输入的特征可能有：文档质量、文档点击历史、文档前链数目、文档锚文本信息……，为了能找出这些特征中隐藏的信息，我们把隐藏层的神经元数目设置的少于输入特征的数目，经过大量样本的训练出能还原原始特征的模型，这样相当于我们用少于输入特征数目的信息还原出了全部特征，表面上是一种压缩，实际上通过这种方式就可以发现某些特征之间存在隐含的相关性，或者有某种特殊的关系。

同样的，我们还可以让隐藏层中的神经元数目多余输入特征的数目，这样经过训练得出的模型还可以展示出特征之间某种细节上的关联，比如我们对图像识别做这样的模型训练，在得出的隐藏层中能展示出多种特征之间的细节信息，如鼻子一定在嘴和眼睛中间。

这种让输出和输入一致的用法就是传说中的自编码算法。



## 神奇用法之二

人工神经网络模型通过多层神经元结构建立而成，每一层可以抽象为一种思维过程，经过多层思考，最终得出结论。举一个实际的例子：识别美女图片

按照人的思维过程，识别美女图片要经过这样的判断：1）图片类别（人物、风景……）；2）图片人物性别（男、女、其他……）；3）相貌如何（美女、恐龙、5分……）

那么在人工神经网络中，这个思考过程可以抽象成多个层次的计算：第一层计算提取图片中有关类别的特征，比如是否有形如耳鼻口手的元素，是否有形如蓝天白云绿草地的元素；第二层提取是否有胡须、胸部、长发以及面部特征等来判断性别；第三层提取五官、肤质、衣着等信息来确定颜值。为了让神经网络每一层有每一层专门要做的事情，需要在每一层的神经元中添加特殊的约束条件才能做到。人类的大脑是经过上亿年进化而成的，它的功能深不可及，某些效率也极高，而计算机在某些方面效率比人脑要高很多，两种结合起来一切皆有可能。

这种通过很多层提取特定特征来做机器学习的方法就是传说中的深度学习。



## 神奇用法之三

讲述第三种用法之前我们先讲一下什么是卷积运算。卷积英文是convolution(英文含义是：盘绕、弯曲、错综复杂)，数学表达是：

![](http://www.shareditor.com/uploads/media/my-context/0001/01/a271d170d4fbe2ddedaa0863f1087db4e38e81b3.png)



数学上不好理解，我们可以通俗点来讲：卷积就相当于在一定范围内做平移并求平均值。比如说回声可以理解为原始声音的卷积结果，因为回声是原始声音经过很多物体反射回来声音揉在一起。再比如说回声可以理解为把信号分解成无穷多的冲击信号，然后再进行冲击响应的叠加。再比如说把一张图像做卷积运算，并把计算结果替换原来的像素点，可以实现一种特殊的模糊，这种模糊其实是一种新的特征提取，提取的特征就是图像的纹路。总之卷积就是先打乱，再叠加。

下面我们在看上面的积分公式，需要注意的是这里是对τ积分，不是对x积分。也就是说对于固定的x，找到x附近的所有变量，求两个函数的乘积，并求和。

下面回归正题，在神经网络里面，我们设计每个神经元计算输出的公式是卷积公式，这样相当于神经网络的每一层都会输出一种更高级的特征，比如说形状、脸部轮廓等。这种神经网络叫做卷积神经网络。

继续深入主题，在自然语言中，我们知道较近的上下文词语之间存在一定的相关性，由于标点、特殊词等的分隔使得在传统自然语言处理中会脱离词与词之间的关联，结果丢失了一部分重要信息，利用卷积神经网络完全可以做多元(n-gram)的计算，不会损失自然语言中的临近词的相关性信息。这种方法对于语义分析、语义聚类等都有非常好的效果。

这种神奇用法就是传说中的CNN



## 总结

神经网络因为其层次和扩展性的强大，有着非常多的神奇用法和非常广泛的应用，因为希望聊天机器人能够具有智能，就不得不寻找能够承载智能的方法，神经网络是其中一个，沿着这个网络，让我们继续探索。




