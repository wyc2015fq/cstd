# 三、语料与词汇资源 - jiangjingxuan的博客 - CSDN博客





2017年01月25日 12:03:41[jiangjingxuan](https://me.csdn.net/jiangjingxuan)阅读数：1185












![](http://www.shareditor.com/uploads/media/default/0001/01/thumb_172_default_big.jpeg)



当代自然语言处理都是基于统计的，统计自然需要很多样本，因此语料和词汇资源是必不可少的，本节介绍语料和词汇资源的重要性和获取方式

请尊重原创，转载请注明来源网站[www.shareditor.com](http://www.shareditor.com)以及原始链接地址

## NLTK语料库

NLTK包含多种语料库，举一个例子：Gutenberg语料库，执行：
`nltk.corpus.gutenberg.fileids()`
返回Gutenberg语料库的文件标识符

```python
[u'austen-emma.txt', u'austen-persuasion.txt', u'austen-sense.txt', u'bible-kjv.txt', u'blake-poems.txt', u'bryant-stories.txt', u'burgess-busterbrown.txt', u'carroll-alice.txt', u'chesterton-ball.txt', u'chesterton-brown.txt', u'chesterton-thursday.txt', u'edgeworth-parents.txt', u'melville-moby_dick.txt', u'milton-paradise.txt', u'shakespeare-caesar.txt', u'shakespeare-hamlet.txt', u'shakespeare-macbeth.txt', u'whitman-leaves.txt']
```



nltk.corpus.gutenberg就是gutenberg语料库的阅读器，它有很多实用的方法，比如：

nltk.corpus.gutenberg.raw('chesterton-brown.txt')：输出chesterton-brown.txt文章的原始内容

nltk.corpus.gutenberg.words('chesterton-brown.txt')：输出chesterton-brown.txt文章的单词列表

nltk.corpus.gutenberg.sents('chesterton-brown.txt')：输出chesterton-brown.txt文章的句子列表



类似的语料库还有：

from nltk.corpus import webtext：网络文本语料库，网络和聊天文本

from nltk.corpus import brown：布朗语料库，按照文本分类好的500个不同来源的文本

from nltk.corpus import reuters：路透社语料库，1万多个新闻文档

from nltk.corpus import inaugural：就职演说语料库，55个总统的演说

## 语料库的一般结构

以上各种语料库都是分别建立的，因此会稍有一些区别，但是不外乎以下几种组织结构：散养式（孤立的多篇文章）、分类式（按照类别组织，相互之间没有交集）、交叉式（一篇文章可能属于多个类）、渐变式（语法随着时间发生变化）

## 语料库的通用接口

fileids()：返回语料库中的文件

categories()：返回语料库中的分类

raw()：返回语料库的原始内容

words()：返回语料库中的词汇

sents()：返回语料库句子

abspath()：指定文件在磁盘上的位置

open()：打开语料库的文件流

## 加载自己的语料库

收集自己的语料文件（文本文件）到某路径下（比如/tmp)，然后执行：

```python
>>> from nltk.corpus import PlaintextCorpusReader
>>> corpus_root = '/tmp'
>>> wordlists = PlaintextCorpusReader(corpus_root, '.*')
>>> wordlists.fileids()
```



就可以列出自己语料库的各个文件了，也可以使用如wordlists.sents('a.txt')和wordlists.words('a.txt')等方法来获取句子和词信息

## 条件频率分布

条件分布大家都比较熟悉了，就是在一定条件下某个事件的概率分布。自然语言的条件频率分布就是指定条件下某个事件的频率分布。

比如要输出在布朗语料库中每个类别条件下每个词的概率：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import nltk
from nltk.corpus import brown

# 链表推导式，genre是brown语料库里的所有类别列表，word是这个类别中的词汇列表
# (genre, word)就是类别加词汇对
genre_word = [(genre, word)
        for genre in brown.categories()
        for word in brown.words(categories=genre)
        ]

# 创建条件频率分布
cfd = nltk.ConditionalFreqDist(genre_word)

# 指定条件和样本作图
cfd.plot(conditions=['news','adventure'], samples=[u'stock', u'sunbonnet', u'Elevated', u'narcotic', u'four', u'woods', u'railing', u'Until', u'aggression', u'marching', u'looking', u'eligible', u'electricity', u'$25-a-plate', u'consulate', u'Casey', u'all-county', u'Belgians', u'Western', u'1959-60', u'Duhagon', u'sinking', u'1,119', u'co-operation', u'Famed', u'regional', u'Charitable', u'appropriation', u'yellow', u'uncertain', u'Heights', u'bringing', u'prize', u'Loen', u'Publique', u'wooden', u'Loeb', u'963', u'specialties', u'Sands', u'succession', u'Paul', u'Phyfe'])
```

![](http://www.shareditor.com/uploads/media/my-context/0001/01/7363c8241780ee64ac755c833b7ea612e75149eb.png)

注意：这里如果把plot直接换成tabulate ，那么就是输出表格形式，和图像表达的意思相同

请尊重原创，转载请注明来源网站[www.shareditor.com](http://www.shareditor.com)以及原始链接地址

我们还可以利用条件频率分布，按照最大条件概率生成双连词，最终生成一个随机文本

这可以直接使用bigrams()函数，它的功能是生成词对链表。

创建python文件如下：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import nltk

# 循环10次，从cfdist中取当前单词最大概率的连词,并打印出来
def generate_model(cfdist, word, num=10):
    for i in range(num):
        print word,
        word = cfdist[word].max()

# 加载语料库
text = nltk.corpus.genesis.words('english-kjv.txt')

# 生成双连词
bigrams = nltk.bigrams(text)

# 生成条件频率分布
cfd = nltk.ConditionalFreqDist(bigrams)

# 以the开头，生成随机串
generate_model(cfd, 'the')
```

执行效果如下：
`the land of the land of the land of the`
the的最大概率的双连词是land，land最大概率双连词是of，of最大概率双连词是the，所以后面就循环了



## 其他词典资源

有一些仅是词或短语以及一些相关信息的集合，叫做词典资源。

词汇列表语料库：nltk.corpus.words.words()，所有英文单词，这个可以用来识别语法错误

停用词语料库：nltk.corpus.stopwords.words，用来识别那些最频繁出现的没有意义的词

发音词典：nltk.corpus.cmudict.dict()，用来输出每个英文单词的发音

比较词表：nltk.corpus.swadesh，多种语言核心200多个词的对照，可以作为语言翻译的基础

同义词集：WordNet，面向语义的英语词典，由同义词集组成，并组织成一个网络




