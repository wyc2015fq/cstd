# 十四、探究中文分词的艺术 - jiangjingxuan的博客 - CSDN博客





2017年01月25日 12:09:45[jiangjingxuan](https://me.csdn.net/jiangjingxuan)阅读数：299












![](http://www.shareditor.com/uploads/media/default/0001/01/thumb_138_default_big.jpeg)



中文是世界语言界的一朵奇葩，它天生把词连在一起，让计算机望而却步，一句#他说的确实在理#让计算机在#的确#、#实在#、#确实#里面挣扎，但是统计自然语言处理却让计算机有了智能

请尊重原创，转载请注明来源网站[www.shareditor.com](http://www.shareditor.com)以及原始链接地址

## 中文分词是怎么走到今天的

话说上个世纪，中文自动分词还处于初级阶段，每句话都要到汉语词表中查找，有没有这个词？有没有这个词？所以研究集中在：怎么查找最快、最全、最准、最狠......，所以就出现了正向最大匹配法、逆向最大匹配法、双向扫描法、助词遍历法......，用新世纪比较流行的一个词来形容就是：你太low了！

中文自动分词最难的两个问题：1）歧义消除；2）未登陆词识别。说句公道话，没有上个世纪那么low的奠定基础，也就没有这个世纪研究重点提升到这两个高级的问题

ps:未登录词就是新词，词表里没有的词

本世纪计算机软硬件发展迅猛，计算量存储量都不再是问题，因此基于统计学习的自动分词技术成为主流，所以就出现了各种新分词方法，也更适用于新世纪文本特点



## 从n元语法模型开始说起

上节讲到了n元语法模型，在前n-1个词出现的条件下，下一个词出现的概率是有统计规律的，这个规律为中文自动分词提供了统计学基础，所以出现了这么几种统计分词方法：N-最短路径分词法、基于n元语法模型的分词法

N-最短路径分词法其实就是一元语法模型，每个词成为一元，独立存在，出现的概率可以基于大量语料统计得出，比如“确实”这个词出现概率的0.001（当然这是假设，别当真），我们把一句话基于词表的各种切词结果都列出来，因为字字组合可能有很多种，所以有多个候选结果，这时我们利用每个词出现的概率相乘起来，得到的最终结果，谁最大谁就最有可能是正确的，这就是N-最短路径分词法。

这里的N的意思是说我们计算概率的时候最多只考虑前N个词，因为一个句子可能很长很长，词离得远，相关性就没有那么强了

这里的最短路径其实是传统最短路径的一种延伸，由加权延伸到了概率乘积

而基于n元语法模型的分词法就是在N-最短路径分词法基础上把一元模型扩展成n元模型，也就是统计出的概率不再是一个词的概率，而是基于前面n个词的条件概率



## 人家基于词，我来基于字

由字构词的分词方法出现可以说是一项突破，发明者也因此得到了各项第一和很多奖项，那么这个著名的分词法是怎么做的呢？

每个字在词语中都有一个构词位置：词首、词中、词尾、单独构词。根据一个字属于不同的构词位置，我们设计出来一系列特征，比如：前一个词、前两个词、前面词长度、前面词词首、前面词词尾、前面词词尾加上当前的字组成的词……

我们基于大量语料库，利用平均感知机分类器对上面特征做打分，并训练权重系数，这样得出的模型就可以用来分词了，句子右边多出来一个字，用模型计算这些特征的加权得分，得分最高的就是正确的分词方法

请尊重原创，转载请注明来源网站[www.shareditor.com](http://www.shareditor.com)以及原始链接地址



## 分词方法纵有千万种，一定有适合你的那一个

分词方法很多，效果上一定是有区别的，基于n元语法模型的方法的优势在于词表里已有的词的分词效果，基于字构词的方法的优势在于未登陆词的识别，因此各有千秋，你适合哪个就用哪个。



## 异性相吸，优势互补

既然两种分词各有优缺点，那么就把他们结合起来吧，来个插值法折中一下，用过的人都说好



## 流行分词工具都是用的什么分词方法

### jieba中文分词

官方描述：
- 基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)
- 采用了动态规划查找最大概率路径, 找出基于词频的最大切分 组合
- 对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法

前两句话是说它是基于词表的分词，最后一句是说它也用了由字构词，所以它结合了两种分词方法



### ik分词器

基于词表的最短路径切词



### ltp云平台分词

主要基于机器学习框架并部分结合词表的方法



其他分词工具判断方法类似，网上对各种分词工具好坏的判断多数是功能上比较，个人建议通过原理来判断，如果结合了基于词表和由字构词并且充分利用统计学习的方法，这样的分词工具才是最好的




