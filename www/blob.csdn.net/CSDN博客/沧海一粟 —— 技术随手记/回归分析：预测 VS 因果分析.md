# 回归分析：预测 VS 因果分析 - 沧海一粟 —— 技术随手记 - CSDN博客





2016年10月27日 09:40:47[慢游](https://me.csdn.net/eengel)阅读数：3732








在学习或者使用机器学习的方法时，回归分析可以说是最常用的一种方法了。今天朋友推荐Dr. Paul Allison的一篇[博文](http://statisticalhorizons.com/prediction-vs-causation-in-regression-analysis)，讲回归分析最常用的两种方式：预测和因果分析。觉得对医学信息学里面对回归分析的使用有很大的帮助，于是拜读了一下。下面是对于其中主要观点的总结。[Dr.
 Allison](http://statisticalhorizons.com/our-instructors/paul-allison)是统计学方面的大牛，写了很多本统计学方面的[书](http://statisticalhorizons.com/resources/books)。最厉害的是他的教学。不管面对什么样的学生，他都能很有效地教授统计学方法。



对我来说，本文的最大贡献是：**指出了回归分析的两个用途（预测和因果分析）应当分开对待。**在医学信息学领域，回归分析一般被用来做疾病风险预测模型建模，以及评估模型中的变量对最终临床结局的影响。而从本文中可以推测的是：我们并不能期望一个风险预测模型，能同时回答这两种用途所针对的问题。原因就是用途不一样，进行回归分析的很多方面的设计和考量就不一样。Dr.Allison在文中列举了5大需要区别对待的地方。


||预测|因果分析|
|----|----|----|
|遗漏的变量|遗漏变量对于预测的影响小的多。预测的目标是基于可用的变量的线性组合，得到优化的预测。因此不存在对预测来说“真正的”系数进行优化估计的说法。除非如果加入遗漏的变量，可以改进预测。|因果分析的主要目标是得到回归系数的无偏倚估计。因此遗漏的变量造成的偏倚是极具威胁的。特别是那些既影响因变量，又和自变量相关的变量。这些变量的遗漏往往会导致无效结论。|
|R2|R2反映了预测模型对数据的拟合度。最大化R2对预测建模是关键性的。|当R2 小的时候，也能做好因果分析，检验自变量对因变量效果的假设。可以通过大样本量抵消小R2的短处。|
|多重共线性|预测不管多重共线性。看的是所有自变量的组合对因变量的预测能力。因此可以不一个个地拆开对待自变量。|多重共线性是因果分析的一个主要问题。当两个或更多自变量高度相关时， 对每个自变量独立的系数估计就能难得到可靠的结论。|
|缺失数据|缺失数据对预测的影响可能有两个方面。首先，某个数据缺失了本身对预测来说是一个有用的信息。其次，不仅仅训练数据会缺失，测试数据也会有缺失。|以前对缺失数据的研究都是为了做参数估计和假设检验。|
|测量误差|测量误差对预测肯定有影响。但如何干预要看情况。很多时候做预测的数据就长成那样，也没法干预。|测量误差会对因果分析的参数估计带来误差。因此需要尽量控制。|



由于这是一篇博文，Dr. Allison并没有展开讲具体如何更好地用回归分析做预测和因果分析。对于将回归分析用于预测，目前工业界的实践也很多。比如预测建模的主要目标是提高模型的准确度。像医学信息学领域会使用AUROC去衡量一个模型。但对于因果分析，如何才算准确估计自变量对因变量的效果，本人还没有找到特别好的答案。
            


