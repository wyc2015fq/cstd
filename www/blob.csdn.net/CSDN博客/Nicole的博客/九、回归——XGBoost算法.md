# 九、回归——XGBoost算法 - Nicole的博客 - CSDN博客
2018年06月21日 10:40:36[Nicole_Liang](https://me.csdn.net/weixin_39541558)阅读数：1363

# 一、Xgboost模型参数
         Xgboost模型有３种类型的参数：通用参数、辅助参数和任务参数。通用参数确定上升过程中上升模型类型，常用树或线性模型；辅助参数取决于所选的上升模型；任务参数定义学习任务和相应的学习目标。
Xgboost模型中，常用参数说明如下：
（１）Xgboost：设置需要使用的上升模型。可选gbtree（树）或gblinear（线性函数），默认为gbtree。
（２）nthread：Xgboost运行时的并行线程数，默认为当前系统可以获得的最大可用线程数。
（３）ｅｔａ：收缩步长，即学习速率，取值范围是，默认为０．３。在更新叶子节点的时候，权重乘以ｅｔａ，以避免在更新过程中的过拟合。
（４）max_depth：每棵树的最大深度，取值范围，默认为６。树越深，越容易过拟合。
（５）subsample：训练的实例样本占整体实例样本的比例，取值范围是（０，１］，默认为１。值为０．５时意味着Xgboost随机抽取一半的数据实例来生成树模型，这样能防止过拟合。
（６）colsample_bytree :在构建每棵树时，列（特征）的子样本比，参数值的范围是（０，１］。
（７）objective:默认为ｒｅg:ｌｉｎｅａｒ；
（８）seed：随机数种子，为确保数据的可重现性，默认为０。
