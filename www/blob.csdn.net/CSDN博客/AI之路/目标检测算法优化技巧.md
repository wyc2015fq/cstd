# 目标检测算法优化技巧 - AI之路 - CSDN博客





2019年02月28日 08:52:07[AI之路](https://me.csdn.net/u014380165)阅读数：1006
个人分类：[目标检测-object detection																[计算机视觉																[深度学习](https://blog.csdn.net/u014380165/article/category/6829229)




论文：Bag of Freebies for Training Object Detection Neural Networks

论文链接：[https://arxiv.org/abs/1902.04103](https://arxiv.org/abs/1902.04103)

这篇论文介绍目标检测算法的一些优化技巧，目前已经在GluonCV中实现了，整体看下来和之前的那篇图像分类算法优化技巧的论文（Bag of Tricks for Image Classification with Convolutional Neural Networks）类似。这篇介绍的优化技巧具体而言包括mixup、label smoothing、学习率修改策略的选择、跨卡BN层计算和随机尺度训练，接下来详细介绍。

mixup是指将2张输入图像按照一定权重合并成一张图像，基于这种合成图像进行训练的模型更加鲁棒，能够有效降低对抗图像的影响。如图Figure2是在分类算法中使用mixup的例子：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228084857893.jpg)

Figure3是在目标检测算法中使用mixup的例子，合并之后的图像标签包含2张输入图像的所有标签，可以看出这种思想在实现上还是比较容易理解的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228084918216.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)

针对mixup作者做了不同参数设置下的实验效果对比，如Table1所示，这里涉及一个名词：weighted loss，在图表中也做了解释，因为模型训练用的图像来自2张原输入图像通过不同权重合并得到的（如Figure3所示），因此在计算损失函数时（损失函数是基于目标计算的），属于不同输入图像的目标的权重也是不一样的，需要和输入图像在合并时的权重对应。而Table5中第二行的0.5:0.5 evenly表示合成是按照0.5和0.5的权重进行，因此最后计算损失时目标的权重也相等。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228084936555.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)

为了证明mixup的视觉效果，作者做了前段时间比较有意思的大象贴图实验，如Figure5所示，第一行使用常规的训练方式训练YOLO v3模型，第二行则是采用mixup方式训练YOLO v3模型，可以看出后者能够有效检测到图像贴上的大象（mix-1和orig-1的对比），不过在orig-2和mix-2的对比中，二者都能检测到大象，这一点在文中没有做详细的解释。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228084952721.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)

label smoothing是分类算法中采用的优化方式，作者将其引入到目标检测算法的分类支路部分。label smoothing的思想很直接，首先来看看原来分类算法的交叉熵损失函数，公式如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085012803.jpg)

其中qi表示真实标签，pi是预测值，因为q是one-hot形式（假设分类类别数是K，那么q就是1×K的向量，且其中只有对应的真实类别位置是1，其余都为0）。pi的计算公式如下，这是常见的softmax函数，假设真实类别是i，那么模型训练过程中会不断使得zi远大于zj，这样pi就越接近1，这样公式2中的L就越接近0，虽然这是训练目标，但训练过程越趋近于这种情况，反而是越容易过拟合的。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085030518.jpg)

所以label smoothing的思想就是对真实标签q进行改造，使其不再是one-hot形式，公式如下所示，其中K表示类别数，e是一个很小的常数。举个例子，假设K=5，e=0.1，那么原来q=[0,0,1,0,0]，现在q’=[0.02,0.02,0.92,0.02,0.02]。这样在公式2中，当q‘处于非真实标签时仍然有损失值（比如0.02），就使得pi不会非常接近1，这就降低了过拟合风险。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085044375.jpg)
学习率变化采用cosine函数且增加warm-up，这部分内容可以直接看Figure6。图中(a)是常见的step修改策略和cosine修改策略+warm-up的学习率变化对比图，可以看到cosine在初始和结束阶段的变化都比较缓慢，在中间部分变化相对快一些，整体而言相比step方式变化会更加平稳一些，这种方式有利于训练过程的稳定，包括warm-up的引入，也是为了训练的起始阶段能够更加稳定地进行。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085058460.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)
跨卡BN层的计算（synchronized batch normalization），因为目标检测算法的单卡batch size一般不能设置得像分类算法那样大，但是较小的batch size对于单卡计算BN层参数而言并不是很有利，因此跨卡BN层相当于基于多卡数据计算BN层参数，这样计算得到的统计结果更加可靠。

随机尺度训练是指在模型训练阶段采用随机大小的数据进行训练，比如当前批次或epoch采用320×320大小的输入，但是在下一个批次或epoch则采用416×416。这种做法来自YOLO算法，尺寸一般在固定的几个数值中随机选择，比如{320, 352, 284, 416, 448, 480, 512, 544, 576, 608}，相邻数值相差32，表示stride。

**实验结果：**

实验部分采用的模型包括YOLO v3和Faster RCNN，数据集部分采用PASCAL VOC和COCO。Table2是优化的YOLO v3模型在VOC2007测试集上的效果提升对比。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085123197.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)

Table3是优化的Faster RCNN模型在VOC2007测试集上的效果对比。数据增强部分，因为two stage算法涉及ROI的裁剪，因此影响小一些，相比之下在one stage类型算法中影响较大。
![在这里插入图片描述](https://img-blog.csdnimg.cn/201902280851395.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=,size_16,color_FFFFFF,t_70)

Table4是在COCO数据集上的效果对比，YOLO v3的效果提升尤其明显。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190228085153624.jpg)](https://blog.csdn.net/u014380165/article/category/6829230)](https://blog.csdn.net/u014380165/article/category/6967389)





