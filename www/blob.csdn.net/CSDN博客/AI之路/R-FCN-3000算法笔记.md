# R-FCN-3000算法笔记 - AI之路 - CSDN博客





2017年12月15日 08:07:32[AI之路](https://me.csdn.net/u014380165)阅读数：4970








论文：R-FCN-3000 at 30fps: Decoupling Detection and Classification 

链接：[https://arxiv.org/abs/1712.01802](https://arxiv.org/abs/1712.01802)

**这篇是CVPR2018的文章，主要是成功将R-FCN算法（关于R-FCN算法的介绍可以看博客：[R-FCN算法及Caffe代码详解](https://blog.csdn.net/u014380165/article/details/72848254)）应用在检测类别较多的场景下。首先当初提出R-FCN算法的主要目的在于引入position-sensitive score map解决原来Faster RCNN中ROI的重复计算问题，有效提升速度。但是如果检测的类别数非常多（比如这里的3000类），那么直接用R-FCN算法的话速度是很慢的，瓶颈正是生成分类支路的position-sensitive score map时计算量非常大，因此这篇文章通过解耦分类支路的position-sensitive score map生成的过程（将原来的分类支路拆分成两条支路，而回归支路还是采用R-FCN的回归支路，这篇文章不做修改，这是因为增加检测类别数增加不影响回归支路的计算量），从而在保证速度（30FPS）的情况下将R-FCN的分类类别数延伸至3000类。**

**那么，为什么不能直接将R-FCN的检测类别扩充为3000类**？R-FCN的网络结构可以看下面的Figure1，前面基于分类网络提取到特征，然后通过一个卷积层（卷积核数量为k^2（C+1））生成k^2（C+1）维的输出（这个输出就是position-sensitive score map），其中C是类别数，k是ROI输出尺寸，图中k=3，**在实验中采用k=7，可以看R-FCN文章中Table2的实验结果：k=3时候在VOC07测试集上的mAP是75.5，k=7时候的mAP是76.6**。因此当类别数C非常大的时候（比如本文中的3000类），那么生成的position-sensitive score maps的维度就是7*7*3001=147049，也就是需要147049个卷积核的卷积层来生成这样的score map，这个计算量是很大的，速度难以达到要求。

**因此这篇R-FCN-3000通过共享卷积核计算的方式减少卷积层的卷积核数量，达到提速的目的。另外，我们知道目标检测算法的最后一般有分类和回归两条支路，这里R-FCN-3000的改进只是针对分类支路，回归支路不变。原因也非常简单，因为回归支路采用的回归和类别数无关（原先Faster RCNN的回归输出维度是和类别数相关的，比如VOC数据集，那么回归支路的输出维度就是(20+1)*4=84，后续大部分算法的回归都做成和类别数无关，比如2*4，这个2表示前景和背景两个类，4表示4个坐标信息），所以列表扩增为3000不影响回归支路的计算量（R-FCN的回归支路输出维度是7*7*4*2）**。

**附R-FCN的一些trick效果，测试集和指标分别是VOC 07测试集和mAP**。baseline是主网络为ResNet101且ROI输出尺寸k=3时，mAP是75.5，当k=7时，mAP是76.6。当训练时候加入OHEM ，mAP可以从76.6上升到79.5。当在训练中又加入multi-scale train，mAP可以从79.5上升到80.5。当再将训练数据调整为VOC07+VOC12+COCO（原来为VOC07+VOC12），mAP可以从80.5上升到83.6。 
![这里写图片描述](https://img-blog.csdn.net/20171215080349844?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
既然扩充为3000类会大大提高分类支路的计算量，那么能不能对这3000个类别做压缩呢？其实这3000个类别中很多类别之间都是很相近的，举个例子：华南虎和东北虎，其实这两个类别可以合并成一个类别进行检测的，另外比如各种品种的狗，其实特征都是非常相近的，合并成同一个类别进行检测也是可以的。基于这样的思路，就有了这篇文章的解耦做法，接下来就来详细介绍R-FCN-3000是怎么做的吧。

**Figure2是F-RCN-3000的分类支路过程，该过程包含两条支路（Figure2上面那条是生成objectness score的过程，Figure2下面那条是生成fine-grained classification score的过程），这两条支路的结果的乘积才是最终的分类结果。在Figure2中回归部分并未画出，但是需要注意的是回归部分和R-FCN的回归部分是一样的。**

**对于Figure2上面那条支路，position sensitive层的filter数量是（K+1）*P*P，K表示super-class数量。借鉴的思想就是自然界很多类别之间的差异很小，因此类型相近的一些类可以看成是一个super-class，Figure2上面这条支路就是对这样的super-class做分类，这个super-class的数量是固定的，可以通过聚类得到。因此即便每个super-class里面的子类数量增加，也不会增加这条支路的计算量。简而言之，这条支路就是将原来R-FCN中的分类支路的类别数替换成了这里的super-class数量，其他不变。**

**对于Figure2下面那条支路，是用来做fine-grained classification的，所以可以看到这条支路中有一个包含C个卷积核的卷积层，C就是所有object的类别数，C中有K个super-class。注意该部分没有用到position sensitive卷积层去得到score map，因此filter数量是C也比较大，但是相比R-FCN中（C+1）*P*P（P=7）时候的计算量，这里大约只有原来的1/49。解耦之后，即便C从20类增加为3000类，也不过是卷积层的卷积核数量从20增加到3000，这带来的计算量并不大。**

**所以这两条支路的一条输出每个ROI属于哪个super-class的概率，维度是K+1维的。参看Figure2上面支路的softmax输出，包含Pbg和Psc，这里Pbg是属于背景（back ground）的概率，Psc是属于super-class（缩写为sc）的概率，图示中有5个super-class。另一条支路输出每个ROI属于某个super-clss的哪个具体类别的概率，维度是C维的，C包含K个super-class。参看Figure2下面支路的softmax输出，Pcls的维度是C。因此将FIgure2上面支路的K+1维输出（Figure2中的Pbg+Psc）中的后面K维（Figure2中的Psc）和Figure2下面支路的C维输出（Figure2的Pcls）相乘得到最终的概率。**

![这里写图片描述](https://img-blog.csdn.net/20180821082655583?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODAxNjU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

这里有几个符号容易弄混，参考下面这个截图。**首先C表示所有的object类别数，C可以划分成K个super-class。关于super-class的获得，文中是先对主网络（ResNet-101）的最后一层输出（2048维）feature map矩阵求均值，然后采用K-means算法来做聚类，这样就能将其中类别差异较小的类归到一个super-class（比如华南虎和东北虎可以归到同一个super-class），因此每个super-class（也就是ki）就包含数个sub-class（也就是cj），可以参考Figure2中Psc和Pcls的颜色就知道这些符号的含义。**
![这里写图片描述](https://img-blog.csdn.net/20171215080538600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
**实验结果：**

Figure3中的（a）和（b）是在给定总的类别数的前提下，super-class数量对实验结果的影响，当super-class数量为1的时候，就相当于用于object detection的那部分（Figure2中上面那条支路）是用来检测一个object是background还是foreground。可以看出实验效果基本上随着super-class数量的增加而提升。（c）则是在给定super-class=1的前提下，总的类别数对最后实验结果的影响。 
![这里写图片描述](https://img-blog.csdn.net/20171215080630823?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
Table3则是在总的class数量为1000前提下，对不同的聚类数目与时间和效果的对比。 
![这里写图片描述](https://img-blog.csdn.net/20171215080644157?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
Table5是关于一些网络细节设计上的对比。 
![这里写图片描述](https://img-blog.csdn.net/20171215080700163?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
更多实验结果可以参看原文。








