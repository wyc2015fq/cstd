# CVPR2017-如何在无标签数据集上训练模型 - AI之路 - CSDN博客





2017年08月09日 08:33:48[AI之路](https://me.csdn.net/u014380165)阅读数：9266








论文：Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis： Actively and Incrementally 

论文链接:[http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Fine-Tuning_Convolutional_Neural_CVPR_2017_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Fine-Tuning_Convolutional_Neural_CVPR_2017_paper.pdf)

这是CVPR2017的文章。你可以想象一个预训练模型，在一个空的带标签的图像数据集上做分类吗？这就是这篇文章要做的事。fine-tuning在深度学习中太常见了，现在比如做图像分类或检测基本都用到，主要是因为模型的初始化对最后的结果影响太大。**传统的fine-tuning都是在一个固定的数据集上继续训练一个预训练的模型，但是本文的fine-tuning从一个空的带标签数据集开始，然后不断将部分未标注数据进行标注并填充到带标签数据集中并继续训练模型。这种算法主要就是解决带标注的医疗图像数据量少的问题，因为这个模型可以通过给未标注图像进行标注然后加入到数据集中继续训练模型。**

**先来看看文章的几个创新点：**

![这里写图片描述](https://img-blog.csdn.net/20170809082707032?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

说起来其实非常简单，**归结如下：通过不断增加标注的图像数据集来训练模型；自动处理在data augumentation过程中生成的噪音patch；定义了评价标准来评价哪些未标注的图像值得我标注。**这些创新点接下来都会详细讲解。

**文章的核心算法如下Algorithm1所示：**

![这里写图片描述](https://img-blog.csdn.net/20170809082734163?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

接下来详细讲解这个算法，先解释下几个字符的含义。

![这里写图片描述](https://img-blog.csdn.net/20170809082804992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

表示n个candidates，其实就是n张未标注的图像。

![这里写图片描述](https://img-blog.csdn.net/20170809082831301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

表示每个Ci都包含m个patch，这里为什么会有patch的概念呢？因为在CNN网络中一般会先对输入图像做预处理，比如crop，resize等等，这里的patch就是指对每个candidate做预处理（或者叫data augmentation）时，一个candidate可以生成多个patch（这里是m个），真正作为模型输入的就是这些patches。

**L表示带标签的图像集合，初始的时候是没有图像的，会在不断迭代中慢慢存进去图像。**这也是本文和其他常见的fine-tuning固定数据集不一样的地方。

M0表示预训练的模型，比如在ImageNet数据集上预训练的模型。Mt就表示当你迭代第t次时生成的模型。

介绍完一些字符的含义，接下来看Algorithm1中的repeat部分，这是一个大的循环，表示不停迭代。里面有一个小的for循环，表示遍历candidate集合U中的每个Ci，然后执行P这个函数，这个函数就是用M这个预训练模型去预测Ci集合中的patches的label（虽然你是未标注的图像，但是我可以用模型预测你是吧），得到的pi就是预测的概率结果。然后对pi求均值（**求均值是因为这里每个candidate的所有patches的标签都一样，因为最终肯定是一张图像对应一个label**），如果均值大于0.5，那么就选择Ci中概率最高的a%数量的patches放进Si‘，否者的话就选择Ci中概率最低的a%数量的patches放进Si‘（**求均值并用一个0.5阈值来判断类别应该默认是二分类，当然也很容易迁移到多分类，用softmax代替sigmoid**）。最后根据下面这个公式计算Ri：

![这里写图片描述](https://img-blog.csdn.net/20170809082920683?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

要明白公式3，就要先看看公式1和公式2，如下图。公式1说的就是交叉熵，|Y|表示所有的类别，比如你是3分类，那么|Y|就是3。pijk就是xij这个patch属于k这个类别的概率。公式1是标准的交叉熵计算公式，不再详述。公式2是计算同一个candidate（这里是i）的不同path（这里是j和l）之间的diversity。**作者认为交叉熵和diversity越大，说明这个candidate对于目前这个模型的预测更有利，也就是更值得我去标注这个图像，因此文中将这两个指标作为选择哪些未标注的candidate作为标注对象的依据，毕竟我们都希望通过算法标注的图像的可靠性越高越好。**又因为当j=l的时候，diversity=0，所以有了公式3这种区分j和l值的采用交叉熵和diversity的评价方式。参数纳姆达只是起到trade-offs的作用。

![这里写图片描述](https://img-blog.csdn.net/20170809082948465?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

当你计算完Ri，就完成了一次for循环，然后继续计算下一个Ci。因此for循环全部结束后会得到R1，R2,….,Rm，对应每个Ci，相当于对每个candidate做了一个打分，这个打分表示你这个candidate值不值得我给你标注。根据Ri值可以对n个Ci（也就是U这个集合）进行排序，然后对排在最前面的b个candidates进行标注，最后将这b个标注完的candidates放进集合Q。前面说过原来的集合L是个空集，当得到Q后，就合并Q和L，这样带标签的集合L里面就有图像了，同时U中剔除Q集合中的图像。最后用Mt-1这个预训练的模型（如果是repeat的第一步，那么此时Mt-1是M0，也就是Imagenet上预训练的模型）去训练L这个数据集，得到Mt这个预训练模型，再进行第二次repeat，直到最后的分类结果满足要求。

**因此每次repeat的时候带标签的数据集L的图像数量都是不断增加的。**

**这里还有一个疑问，那就是candidates集合U是怎么产生的？前面我们说过集合U是未标注的图像集合，文中提到这个集合是通过computer aided diagnosis（CAD）system生成的。**

Figure1的左边这个大图可以就是前面Algorithm中的一个Ci，右边的这些小图表示Ci中的多个patches。

![这里写图片描述](https://img-blog.csdn.net/20170809083017505?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

前面说过本文的一个创新点是计算交叉熵和diversity的方式可以节省计算量。因为传统的计算交叉熵和diversity的方式是对一个candidate中的所有patches进行的，而本文在此之前有一个对patch选择的过程，就是Algorithm1中的对pi就均值并选择top a%个patches的过程。这个过程是将一些noise patches过滤掉，什么是noise patches？可以看Figure1中右边patches中虽然也很清晰，但是object内容不明显的patches。因此原来你需要O（m^2）的计算量，现在只需要O（am*am）的计算量，a是小于1的（文中是1/4）。

**实验结果：**

文中的实验包括三个：Colonoscopy Frame Classification，Polyp Detection，Pulmonary Embolism Detection 
**Colonoscopy Frame Classification：**

Figure2是3张colonoscopy frames。
![这里写图片描述](https://img-blog.csdn.net/20170809083059697?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

Figure3是在Colonoscopy Frame Classification（结肠镜图像分类）上的一个对比实验。从Figure3可以看出，加上Entropy和Diversity的AIFT的效果随着数据的增加，其效果提升比较明显。将Entropy和Diversity合起来用是不是效果更好？实验证明并不是，因为二者之间的权重并不好权衡。

![这里写图片描述](https://img-blog.csdn.net/20170809083116987?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

另外两组实验结果可以参看论文，本博文主要介绍这种思想。

**总结：**

原文的这段话写得很好。**It starts with a completely empty labeled dataset, and incrementally improves the CNN’s performance through continuous fine-tuning by actively selecting the most informative and representative samples. It also can automatically handle noisy labels via majority selection and it computes entropy and diversity locally on a small number of patches within each candidate, saving computation time considerably.**




