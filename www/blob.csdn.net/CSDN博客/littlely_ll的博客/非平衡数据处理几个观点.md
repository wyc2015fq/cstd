# 非平衡数据处理几个观点 - littlely_ll的博客 - CSDN博客





2019年03月24日 15:26:50[littlely_ll](https://me.csdn.net/littlely_ll)阅读数：151








## 1.使用正确的评价准则

对于非平衡数据，准确率这种评价准则可能不能用了，比如1000个样本中，只有10个为正样本，如果全预测为负样本，则准确率为99%，但这种模型根本就没用。这种情况，可以使用其他准则：

> - Precision
- Recall
- F1 score
- MCC: 观察和预测类别之间的相关系数
- AUC


## 2.训练集重抽样

### 2.1 欠采样

### 2.2 过采样

## 3.合理使用k折交叉验证

需要注意在使用过采样处理非平衡数据时，应合理使用交叉验证。过采样基于一定的分布，使用boostrap方法从少量正样本中抽取数据，如果在过采样之后使用交叉验证，那么我们的模型会过拟合抽取的特定的数据，这就是为什么交叉验证要在过采样数据之前使用。

## 4.集成不同的抽样数据集

最简单的泛化模型就是使用更多的数据，大师很多分类器比如logistic回归和RF一般趋向于去掉噪声样本，这使得他们不能正确分类少数类别。一个简单的办法就是建立n个模型，每个模型使用所有的正样本和部分负样本，这有些类似nagtive sampling。假设你想集成10个模型，并假设有100个正样本和10000负样本，那么每个模型使用的数据都包含着100个正样本，并从10000个负样本中抽样1000个负样本，最后集成这10个模型。

## 5.对负样本进行聚类

除了对负样本进行随机抽样，也可以把负样本聚成R类（R为要采样的数量），这样对于每一类，只保留中心样本，这样模型使用的数据只包含正样本和R个负样本。[Quora](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set/answers/1144228?srid=h3G6o)

## 6.设计自己的模型

使用XGBoost等一些集成模型，设计损失函数惩罚对正样本的错误分类



