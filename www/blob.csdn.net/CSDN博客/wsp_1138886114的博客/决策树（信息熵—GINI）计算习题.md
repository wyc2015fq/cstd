# 决策树（信息熵—GINI）计算习题 - wsp_1138886114的博客 - CSDN博客





2018年07月08日 10:34:41[SongpingWang](https://me.csdn.net/wsp_1138886114)阅读数：3703











### 文章目录
- [1 有以下二分类问题训练样本](#1__1)
- [GINI计算](#GINI_24)
- [2 有以下二分类问题数据集。](#2__99)
- [信息增益计算](#_181)




### 1 有以下二分类问题训练样本
|顾客ID|性别|车型|衬衣尺码|类|
|----|----|----|----|----|
|1|男|家用|小|C0|
|2|男|运动|中|C0|
|3|男|运动|中|C0|
|4|男|运动|大|C0|
|5|男|运动|加大|C0|
|6|男|运动|加大|C0|
|7|女|运动|小|C0|
|8|女|运动|小|C0|
|9|女|运动|中|C0|
|10|女|豪华|大|C0|
|11|男|家用|大|C1|
|12|男|家用|加大|C1|
|13|男|家用|中|C1|
|14|男|豪华|加大|C1|
|15|女|豪华|小|C1|
|16|女|豪华|小|C1|
|17|女|豪华|中|C1|
|18|女|豪华|中|C1|
|19|女|豪华|中|C1|
|20|女|豪华|大|C1|

##### GINI计算
- 计算整个样本集的GINI指标值
- ID属性GINI指标值
- 性别属性GINI指标值
- 多路划分属性车型的GINI指标值
- 多路划分属性衬衣的GINI指标值
- 性别、车型、衬衣哪个属性好

以下计算 GINI 公式：
$$GINI(D) = 1-\sum_{i=1}^{n}p(i)^2$$

```
解答：
	1. 整体Gini值：1-(1/2)^2-(1/2)^2 =0.5
	2. ID 每个都不一样，与其他人没有共性，所以GINI=0
	3. 性别 ：1-(1/2)^2-(1/2)^2 =0.5 
	4. 家用： 1-(1/4)2-(3/4)2 = 0.375  
	   运动： 1-(0/8)2-(8/8)2 = 0 
	   豪华： 1-(1/8)2-(7/8)2 = 0.218
	   车型GINI=4/20*0.375+8/20*0.218 = 0.16252
```

多路划分属性统计表：
|Class|衣服种类||Class|车型| | | | |
|----|----|----|----|----|----|----|----|----|
||小|中|大|加大||家用|运动|豪华|
|C0|3|3|2|2|C0|1|8|1|
|C1|2|4|2|2|C1|3|0|7|

```
5. 三种尺码GINI系数：
   小：1-(3/5)2-(2/5)2 = 0.48
   中：1-(3/7)2-(4/7)2 = 0.4898 
   大：1-(2/4)2-(2/4)2 = 0.5 
   加大：1-(2/4)2-(2/4)2 = 0.5 
   
   衬衣GINI：5/20*0.48+7/20*0.4898+4/20*0.5+4/20*0.5 = 0.4914 
    
6.	属性比较：通过上述计算，显然车型不纯度高，更容易划分
```

### 2 有以下二分类问题数据集。

**左侧**为原数据，**右侧**上下两个表为统计数据
|A|B|类标号||统计A| |
|----|----|----|----|----|----|
|T|F|+||A=T|A=F|
|T|T|+|+|4|0|
|T|T|+|-|3|3|
|T|F|-|| | |
|T|T|+| | | |
|F|F|-| | | |
|F|F|-|统计B| | |
|F|F|-||B=T|B=F|
|T|T|-|+|3|1|
|T|F|-|-|1|5|

##### 信息增益计算
- 计算按照属性A和B划分时的信息增益。决策树归纳算法将会选择那个属性？
- 计算按照属性A和B划分时GINI指标。决策树归纳算法将会选择那个属性？
- 熵和GINI指标在区间 [0,0.5] 都是单调递增，在区间 [0,0.5] 单调递减。有没有可能信息增益和GINI指标增益支持不同的属性？解释你的理由。

**信息熵**：
$$Entropy(A) = -\sum_{i=1}^{i}p_i\log_2p_i$$

（1）**划分前**样本集的**信息熵**：$E = -0.4\log_20.4-0.6\log_20.6 = 0.9710$
$~~~~~~$$E_{A=T}:-\frac{4}{7}\log_2 \frac{4}{7}-\frac{3}{7}\log_2 \frac{3}{7}  = 0.9852$

$~~~~~~$$E_{A=F}: -\frac{0}{3}\log_2 \frac{0}{3}-\frac{3}{3}\log_2 \frac{3}{3} = 0$

$~~~~~~$按照A属性划分样本集的 **信息增益**：$\Delta_A = E-\frac{7}{10}E_{A=T}-\frac{3}{10}E_{A=F}$ = 0.2813

$~~~~~~$同理可得：（恕我偷懒了，网页编辑公式费时）
$~~~~~~$按照B属性划分样本集的 **信息增益**：$\Delta_B = E-\frac{4}{10}E_{B=T}-\frac{6}{10}E_{B=F}$ = 0.2565
$~~~~~~$因此决策树归纳算法选A属性
（2）按照属性A 、B划分样本集
$~~~~~~$解答：由原数据  （左表）和统计A 可得GINI指标：

$~~~~~~$$GINI_{类标号}：G =1-(\frac{4}{10})^2-(\frac{6}{10})^2= 0.48$

$~~~~~~$$GINI_{A=T}:1-(\frac{4}{7})^2-(\frac{3}{7})^2  = 0.4898$
$~~~~~~$$GINI_{A=F}：1-(\frac{0}{3})^2-(\frac{3}{3})^2 = 0$

GINI 增益:
$$E_A = GINI_{类标号}-\frac{7}{10}GINI_{A=T}- \frac{3}{10}GINI_{A=F} = 0.1371$$

由统计B（右下表） 可得：

$~~~~~~$$GINI_{B=T}：1-(\frac{3}{4})^2-(\frac{1}{4})^2 = 0.3750$
$~~~~~~$$GINI_{B=F}：1-(\frac{1}{6})^2-(\frac{5}{6})^2 = 0.2778$

GINI 增益:
$$E_B =  GINI_{类标号} - \frac{4}{10}GINI_{B=T}- \frac{6}{10}GINI_{B=F} = 0.1633  $$
$~~~~~~$因此决策树归纳算法选B属性
（C）：信息增益考察的是特征对整个数据贡献，没有到具体的类别上，所以一般只能用来做全局的特征选择

Gini系数是一种与信息熵类似的做特征选择的方式，用来数据的不纯度。在做特征选择的时候，我们可以取ΔGini(X)最大的那个。






