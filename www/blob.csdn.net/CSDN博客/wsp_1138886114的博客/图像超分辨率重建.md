# 图像超分辨率重建 - wsp_1138886114的博客 - CSDN博客





2018年09月14日 22:06:03[SongpingWang](https://me.csdn.net/wsp_1138886114)阅读数：2701
所属专栏：[深度学习—神经网络](https://blog.csdn.net/column/details/27368.html)












### 文章目录
- [一、前言](#_1)
- [二、网络详解](#_8)
- [2.1 FSRCNN](#21_FSRCNN_9)
- [2.2 ESPCN](#22_ESPCN_12)
- [2.3 VDSR](#23_VDSR_16)
- [2.4 EDSR](#24_EDSR_20)
- [2.5 SR-GAN](#25_SRGAN_23)




### 一、前言

写这篇文章，主要看了NTIRE 图像复原(Image Restoration)。挑战赛上超分辨率赛道上一些优胜队伍的方法。在这里跟大家分享下，如有错误的地方，还请指正，学习为主。

主要有图像超分辨率（super-resolution）、图像去雾（dehazing）、光谱重建（spectral reconstruction）三个方向。

基于深度学习的超分辨率重建 ：
- 发展历程为：**SRCNN[1]**  → **FSRCNN[2]** → **ESPCN[3]** → **VDSR[4]** → **EDSR[5]** → **SRGAN[6]**

### 二、网络详解

#### 2.1 FSRCNN

**SRCNN[1]**是最早用CNN来进行超分辨率重建的论文。**FSRCNN[2]** 是对SRCNN的改进，主要贡献在于**直接原图像进行端对端的重建，在速度上也非常快**：如下图
![这里写图片描述](https://img-blog.csdn.net/2018091421223896?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
#### 2.2 ESPCN

**ESPCN [3]** 主要提出了**subpixel convolution的方法**，这种方式在之后很多方法的上采样重建中都有被使用。
![这里写图片描述](https://img-blog.csdn.net/20180914212655237?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
#### 2.3 VDSR

**VDSR [4]** 是**第一个将全局残差引入SR的方法，使得训练速度明显加快**，在PSNR以及SSIM评价指标上有了很大的提升。VDSR之后大部分方法都采用了这种方式。当然还有很多很优秀的网络例如RED、DRRN、MemNet、LapSR这里不在过多介绍。
![这里写图片描述](https://img-blog.csdn.net/20180914212816492?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
#### 2.4 EDSR

**EDSR[5]**是首届NTIRE2017的超分辨率冠军，其**主要使用了增强的ResNet，移除了batchnorm，使用了L1 loss训练**。
![这里写图片描述](https://img-blog.csdn.net/20180914213322810?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
#### 2.5 SR-GAN

SRGAN则是 将GAN引入SR重建的。此外SRGAN与其他上述方法，不同的是重建得到的图像虽然比上述方法都要清晰，但在PSNR和SSIM上都要比上述方法甚至是bicubic上采用得到都要低很多。主要原因**SRGAN使用了style transfer里用到的感知损失**（当然也用非GAN方法使用感知损失的，例如EnhanceNet[8]），而感知损失重建的图像在人类的认知视觉上更舒服，但细节恢复上确实会和原图相差很多。
![这里写图片描述](https://img-blog.csdn.net/20180914214218374?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
超分辨率重建方向：
- 第一个方向力求恢复出真实可靠的细节部分，应用场景例如医学影像上的超分辨率重建，低分辨率摄像头人脸或者外形的恢复等对细节要求苛刻的场景。
- 另一个则追求整体视觉效果，细节部位要求不高。例如低分辨率视频电视的恢复、相机模糊图像的恢复等。

NTIRE2018这个比赛：
- 这次比赛使用的数据集为DIV2K数据集[9]，一共包含1000张2K分辨率的RGB图像，其中800张为训练集，100张为验证集，100张为测试集。
- 评价标准使用了PSNR、SSIM。这就意味着这个场景下使用感知损失重建并不会是个很好的选择。大部分队伍**以强化网络特征学习**或者**添加模糊算子先验为主**。
- 经典的bicubic 8倍放大赛道上，Toyota-TI 提出的deep back-projection networks(DBPN)[10]获得了第一名，如下图。DBPN主要思想认为以往的CNN方法中，从LR到SR是一个完全上采用的过程，这过程中没有完全处理好LR到SR的与HR之间的差异。在高倍放大下更为显著。所以DBPN提供了**一个up-down的映射单元**，希望通过迭代**上下交替采样**的纠正反馈机制，恢复更好的细节特征。本次NTIRE2018的结果可以看出DBPN在高倍放大下比LapSR、EDSR拥有更好的效果。

![这里写图片描述](https://img-blog.csdn.net/20180914215340434?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

团队在SR重建上，定位在两个优化问题：
- 
第一，个人理解上应该是与DBPN类似，如何在大尺寸放大获得更好的细节收益。

- 
第二问题则针对Mild、Difficult现实LR图像中存在的噪声，如何在放大图像的同时不放大噪声，减弱噪声对重建的影响。

- 
针对第一个问题，在bicubic上Pixel Overflow使用了**EDSR模型**，并使用了许多技巧例如RGB Layer Shuffle 、Per-Image Mean、Shift Residual Scaling Factor等.（NTIRE2018报告中介绍该团队使用了sobel滤波器提取SR和ground truth特征以强调边缘和细节的损失，但团队报告中似乎说明了这一方法并未有效）。

- 
针对第二个问题，团队使用在**EDSR前增加了一个去噪网络**，两者通过将去除输出层的去噪网络与去除输入层的EDSR串接实现端对端的模型训练。如图8，实验表明去除头尾的方式比直接串联两个网络的方式效果更好。


![这里写图片描述](https://img-blog.csdn.net/20180914220327674?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

鸣谢
- Dong C, Chen C L,He K, et al. Image Super-Resolution Using Deep Convolutional Networks[J]. IEEETransactions on Pattern Analysis & Machine Intelligence, 2016,38(2):295-307.
- Dong C, Chen C L,Tang X. Accelerating the Super-Resolution Convolutional Neural Network[J].2016:391-407.
- Shi W, CaballeroJ, Huszar F, et al. Real-Time Single Image and Video Super-Resolution Using anEfficient Sub-Pixel Convolutional Neural Network[C]// IEEE Conference onComputer Vision and Pattern Recognition. IEEE Computer Society, 2016:1874-1883.
- Kim J, Lee J K,Lee K M. Accurate Image Super-Resolution Using Very Deep ConvolutionalNetworks[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEEComputer Society, 2016:1646-1654.
- Lim B, Son S, KimH, et al. Enhanced Deep Residual Networks for Single ImageSuper-Resolution[C]// Computer Vision and Pattern Recognition Workshops. IEEE,2017:1132-1140.
- Ledig C, Theis L,Huszar F, et al. Photo-Realistic Single Image Super-Resolution Using aGenerative Adversarial Network[J]. 2016:105-114.
- Johnson J, AlahiA, Li F F. Perceptual Losses for Real-Time Style Transfer andSuper-Resolution[J]. 2016:694-711.
- Sajjadi M S M,Schölkopf B, Hirsch M. EnhanceNet: Single Image Super-Resolution ThroughAutomated Texture Synthesis[J]. 2016.
- E. Agustsson andR. Timofte. NTIRE 2017 challenge on single image super-resolution: Dataset andstudy. In The IEEE Conference on Computer Vision and Pattern Recogni[1]tion(CVPR) Workshops, July 2017. 1, 2
- Haris M,Shakhnarovich G, Ukita N. Deep Back-Projection Networks ForSuper-Resolution[J]. 2018.
- Tai Y, Yang J, LiuX, et al. MemNet: A Persistent Memory Network for Image Restoration[J].2017:4549-4557.
- Lai W S, Huang JB, Ahuja N, et al. Deep Laplacian Pyramid Networks for Fast and AccurateSuper-Resolution[C]// IEEE Conference on Computer Vision and PatternRecognition. IEEE Computer Society, 2017:5835-5843.
- Zhang K, Zuo W,Chen Y, et al. Beyond a Gaussian Denoiser: Residual Learning of Deep CNN forImage Denoising.[J]. IEEE Transactions on Image Processing, 2017,26(7):3142-3155.
- Zhang K, Zuo W,Zhang L. Learning a Single Convolutional Super-Resolution Network for MultipleDegradations[J]. 2017.
- Blau Y, MichaeliT. The Perception-Distortion Tradeoff[J]. 2017.
- NTIRE 2018Challenge on Single Image Super-Resolution: Methods and Results








