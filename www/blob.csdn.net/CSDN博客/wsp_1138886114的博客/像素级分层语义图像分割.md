# 像素级分层语义图像分割 - wsp_1138886114的博客 - CSDN博客





2018年09月15日 16:26:30[SongpingWang](https://me.csdn.net/wsp_1138886114)阅读数：816
所属专栏：[深度学习—神经网络](https://blog.csdn.net/column/details/27368.html)










- - - [前言](#前言)
- [一、像素级分层语义处理框架，实现图片对象自然修改](#一像素级分层语义处理框架实现图片对象自然修改)- [1.1 结构生成器（Structure Generator）](#11-结构生成器structure-generator)
- [1.2 图像生成器（Image Generator）](#12-图像生成器image-generator)

- [二、评估](#二评估)- [2.2 定量评估](#22-定量评估)
- [2.3 定性分析](#23-定性分析)- [语义对象处理](#语义对象处理)
- [扩展式操作](#扩展式操作)
- [交互式和数据驱动的图像编辑](#交互式和数据驱动的图像编辑)







### 前言

少废话，先看图：  
![这里写图片描述](https://img-blog.csdn.net/20180915154543642?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
你能看出‘PS’的痕迹吗？这种“毫无PS痕迹”PS，无论是色调、光线还是纹理，都与原图非常配。这多亏了密歇根大学和谷歌大脑提出了一种新的图像语义处理分层框架。 

该框架根据图像中给定对象的边界框，学习生成像素级语义标签地图（pixel-wise semantic label maps），然后根据这个地图再生成新的图像。  
![这里写图片描述](https://img-blog.csdn.net/20180915154828910?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
### 一、像素级分层语义处理框架，实现图片对象自然修改

框架的核心就是**`分层图像处理`**。当给出新的边界框B时，算法首先通过以B为中心、尺寸为S×S的裁剪平方窗口，**提取标签映射（semantic label map）**$M∈R^{S×S×C}$ 和 图像 $I∈R^{S×S×3}$的**局部观测值**。  

在$M，I和B$上，模型通过以下过程生成操纵图像：
- 给定边界框 $B$ 和语义标签映射 $M$，结构生成器通过 $\hat{M} = G^{M}(M,B)$ 预测操纵的语义标签映射；
- 给定操纵的标签映射 $M$ 和图像 $I$，图像生成器通过  $\hat{I} = G^{I}(\hat{M},I)$ 预测被操纵的图像 $I$。

而在分层图像处理过程中，有两个核心的关键步骤：
- 结构生成器（Structure Generator）
- 图像生成器（Image Generator）

#### 1.1 结构生成器（Structure Generator）

结构生成器的目标是以像素级类标签  $M∈R^{S×S×C}$ 的形式推断由 $B = \{b，c\}$ 指定的区域的潜在结构。  
![这里写图片描述](https://img-blog.csdn.net/20180915160650360?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

给定一个 masked layout M和一个binary mask B，分别用于对目标的类和位置进行编码。该模型通过来自双流解码器（ two-stream decoder）的输出产生M（该双流解码器对应于box整个区域中对象的二进制掩码和语义标签映射）。
#### 1.2 图像生成器（Image Generator）

给定一张图像I和从结构生成器中获得的可操纵 layout M，图像生成器输出区域内由B定义的、内容的像素级预测。 
![这里写图片描述](https://img-blog.csdn.net/20180915160850962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

给定一张masked图像I和语义 layout M，该模型使用单独的编码路径对对象的视觉样式和语义结构进行编码，并产生被操纵的图像。 
### 二、评估

#### 2.2 定量评估

Ablation Study。 为了分析所提方法的有效性，对该方法的几种变体进行了Ablation Study。 首先考虑图像生成器的三个基线：
- 仅限于图像上下文（SingleStream-Image）；
- 仅限于语义布局（SingleStream-Layout）；
- 对上述两个基线的结合。

结果如下表所示： 
![这里写图片描述](https://img-blog.csdn.net/20180915161113195?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

下图显示了基线的定性比较： 
![这里写图片描述](https://img-blog.csdn.net/20180915161206625?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
#### 2.3 定性分析

##### 语义对象处理

从图中可以看到，当把车的边框从一边移动到另一边的时候，模型所产生的车辆外观发生了变化。有趣的是，汽车的形状、方向和外观也会根据周围区域的场景布局和阴影而改变。  
![这里写图片描述](https://img-blog.csdn.net/20180915161716436?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

该结果表明，模型在考虑上下文的情况下生成了合适的对象结构和外观。除了生成与周围环境相匹配的对象外，还可以对框架轻松地进行扩展，允许用户直接控制对象样式。 
##### 扩展式操作

![这里写图片描述](https://img-blog.csdn.net/20180915162047435?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

结果表明，模型成功地合成了具有指定颜色的各种对象，同时保持图像的其他部分不变。 
##### 交互式和数据驱动的图像编辑

通过添加、删除和移动对象边界框来执行交互式图像处理。 结果如下图所示： 
![这里写图片描述](https://img-blog.csdn.net/20180915162234538?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
该方法生成合理的语义布局和图像，可以平滑地增加原始图像的内容。除了交互式操作之外，还可以通过以数据驱动的方式对图像中的边界框进行采样来自动化操作过程。 结果如下图所示：  
![这里写图片描述](https://img-blog.csdn.net/20180915162345299?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dzcF8xMTM4ODg2MTE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)











