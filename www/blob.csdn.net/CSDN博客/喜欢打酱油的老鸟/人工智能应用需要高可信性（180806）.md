
# 人工智能应用需要高可信性（180806） - 喜欢打酱油的老鸟 - CSDN博客


2018年08月12日 20:26:12[喜欢打酱油的老鸟](https://me.csdn.net/weixin_42137700)阅读数：96标签：[人工智能																](https://so.csdn.net/so/search/s.do?q=人工智能&t=blog)[高可信性																](https://so.csdn.net/so/search/s.do?q=高可信性&t=blog)[
							](https://so.csdn.net/so/search/s.do?q=人工智能&t=blog)个人分类：[人工智能																](https://blog.csdn.net/weixin_42137700/article/category/7820233)


[https://blog.csdn.net/cf2SudS8x8F0v/article/details/81463702](https://blog.csdn.net/cf2SudS8x8F0v/article/details/81463702)
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBVUug52kHhFbZXibUsQxDOGgnrAWxgqEkROsThRucQdqL20WTCicsAtmCJ6FNylvralzC7U8ZaOtH5g/640?wx_fmt=png)
来源：科学网
摘要：近日，“Rekognition”却闹了一个大乌龙：28名美国国会议员被它识别成了罪犯。
小编搞了大半辈子测试和容错，对这方面消息比较敏感。最近看到新闻，商业巨头亚马逊2016年推出图像识别AI系统“Rekognition”，还积极向美国警方推销以帮助其办案。不过近日，“Rekognition”却闹了一个大乌龙：28名美国国会议员被它识别成了罪犯。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVUug52kHhFbZXibUsQxDOGgDHohSukuOibOica4UHo4GyjJWzictiaMK0Y9haHu95wPsBficdU9OGDRTAQ/640?wx_fmt=jpeg)
这一错误也让发起这项测试、反对警方使用“Rekognition”的美国公民自由联盟（ACLU）抓到把柄，他们表示，测试结果引起了民众对警方使用该系统的严重担忧。7月26日，ACLU在其网站披露：该组织对“Rekognition”进行了测试，结果系统错误地将28名国会议员识别为曾因犯罪而被捕的人员。
所以，人工智能应用被吹得热热闹闹，场景令人振奋，但是，真要付诸应用，人们对这些系统信任度存在疑问，可能产生严重后果。怎么能提供这些系统的高可信性呢？这就要深入到每一个具体系统，进行科学分析。本月IEEE Spectrum 2018/8发表一篇文章，“MAKING MEDICAL AI TRUSTWORTHY”,很有参考价值。
医药工业领域是人工智能系统应用的理想之地。医学检验、医生的面谈和过程被成文为患者病历，存为电子格式。AI系统可以摘要这些数据，从而决定较好和性价比较高的治疗方案。现在许多研究都在建造这种系统，许多文章描述关于分析纪录、扫描图像、产生患者健康的诊断和预言。譬如下图所示一个低分辨率的反映心脏跳动的心动图，用AI程序分离，取出最相关的部分，然后用解剖学的理解去进行诊断。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVUug52kHhFbZXibUsQxDOGg5x2rGJj73UDl1iclZkJq8hX9k3p5fQcibcX6xIBF1Y997OMavnIjvQ9w/640?wx_fmt=jpeg)
这类文章很多，但是，这些系统很少能进入医院里实际应用。
为什么会这样？匹兹堡大学的医学研究专家和物理学家Shinjini Kundu说：问题在于信任方面，你有可行的技术，但你怎么能得到人们的信任而使用之？
许多医用AI系统是个黑盒子，输入数据，得出答案。医生们搞不懂它为什么要这么处理。所以，Kunda研究AI对医学图像的分析与解释。她从对医学图像，譬如核磁共振图像，机器学习开始，从而发现医生感兴趣的模式。
Kunda最近用AI分析膝盖核磁共振图像（MRI），分析三年内会发展为骨关节炎的可能性。她用“生长模型化”技术，用AI产生一个新图像，一个保证会发病的图像。Kunda解释说，他们开发了一个黑盒子分类器，去产生一个图像，显示支持其诊断的模式。
人眼无法根据下图的MRI图像判断患者三年内是否会得关节炎，譬如上左图不会，但上右图就会得关节炎。而AI程序进行统计分析可以得出几倍方差范围内得这种病的概率。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVUug52kHhFbZXibUsQxDOGgeIxDytgCHPuXibXzOSdHCQbN3ia1z2ricV3l934KckAsqKzy68c6heutA/640?wx_fmt=jpeg)
AI产生的图像基于MRI扫描软骨的微妙变化，这些变化可能是医生们没有注意到的。这帮助人们去理解过去治关节炎的过程为什么没注意到。
旧金山加州大学助理教授、心脏病专家Rima Arnaout训练一个神经网络去分类超声波心电图，在分辨微小而低分辨率图像方面比心脏病专家精确多了。下一步将用该图像信息去识别解剖结构和诊断心脏疾病和缺陷。
但是，Arnaout说：“我不会去做自己无法信服的诊断。”她用两个技术去搞懂她的分类器是怎么做出决定的。在封闭试验中，他考察测试图像的部分变化如何改变AI的回答；用显著图，她跟踪神经网络的最后回答返回到原图，去发现什么像素权重最高。这两技术说明图像的那些部分对AI做出结论最重要，正和专家看重的结构相重合。
微软一位骨干研究人员Rich Caruana十年来一直致力于一项研究，就是让机器学习模型不但是智能的，而且是可以理解的。他用AI拿医院的电子病历去预计患者的结果。他发现即使是高度精确的模型也隐藏着严重的缺陷。他引用他对肺癌患者的数据集，训练机器学习模型去区分该入院的高危患者和可在家恢复的低危患者。该模型发现有心脏病的人较少死于肺炎，可以安心地算作低危人群。他解释说，诊断有肺炎的心脏病患者其所以结局较好，不是因为他们低危险，而是如果他们的呼吸困难早就进了急诊，从而得到治疗。模型发现的这种关联性是正确的。但是，假如我们用这种关联性去干预卫生保健，我们可能伤害甚至杀死某些患者。由于这些麻烦的发现，他正在研究清楚显示变量相关的机器学习模型，让它判断模型不但统计意义上精确，而且医学上可用。
所以，人工智能应用需要应用领域专家的深入分析、严格的测试过程、有效的容错技术，才能保证人工智能应用系统的安全可靠，人们才能放心使用。
中国科学院,计算技术研究所,研究员 闵应骅

