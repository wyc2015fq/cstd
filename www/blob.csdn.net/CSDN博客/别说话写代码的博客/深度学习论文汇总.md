# 深度学习论文汇总 - 别说话写代码的博客 - CSDN博客





2018年07月06日 10:57:46[别说话写代码](https://me.csdn.net/qq_21997625)阅读数：170








转自：https://blog.csdn.net/qq_21190081/article/details/69564634






本博客用于记录自己平时收集的一些不错的深度学习论文，近9成的文章都是引用量3位数以上的论文，剩下少部分来自个人喜好，本博客将伴随着我的研究生涯长期更新，如有错误或者推荐文章烦请私信。

## 深度学习书籍和入门资源
- LeCun Y, Bengio Y, Hinton G. Deep learning[J]. Nature, 2015, 521(7553): 436-444.[[PDF]](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf)（深度学习最权威的综述）
- Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. Deep learning. An MIT Press book. (2015).[[PDF]](https://github.com/HFTrader/DeepLearningBook/raw/master/DeepLearningBook.pdf)（深度学习经典书籍）
- Deep Learning Tutorial[[PDF]](http://pan.baidu.com/s/1pKH3PGn)（李宏毅的深度学习综述PPT，适合入门）
- D L. LISA Lab[J]. University of Montreal, 2014.[[PDF]](http://pan.baidu.com/s/1bZ5nSa)（Theano配套的深度学习教程）
- deeplearningbook-chinese [[Github]](https://github.com/exacity/deeplearningbook-chinese)（深度学习中文书，大家一起翻译的）-

## 早期的深度学习
- Hecht-Nielsen R. Theory of the backpropagation neural network[J]. Neural Networks, 1988, 1(Supplement-1): 445-448.[[PDF]](https://pdfs.semanticscholar.org/4d3f/050801bd76ef10855ce115c31b301a83b405.pdf)（BP神经网络）
- Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets.[J]. Neural Computation, 2006, 18(7):1527-1554.[[PDF]](http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.2006.18.7.1527)（深度学习的开端DBN）
- Hinton G E, Salakhutdinov R R. Reducing the dimensionality of data with neural networks.[J]. Science, 2006, 313(5786):504-7.[[PDF]](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)（自编码器降维）
- Ng A. Sparse autoencoder[J]. CS294A Lecture notes, 2011, 72(2011): 1-19.[[PDF]](https://pdfs.semanticscholar.org/eb2f/e260af00818907fe82024203d8a5a1386777.pdf)（稀疏自编码器）
- Vincent P, Larochelle H, Lajoie I, et al. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion[J]. Journal of Machine Learning Research, 2010, 11(Dec): 3371-3408.[[PDF]](http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf)（堆叠自编码器，SAE）

## 深度学习的爆发:ImageNet挑战赛
- Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems. 2012.[[PDF]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)（AlexNet）
- Simonyan, Karen, and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).[[PDF]](https://arxiv.org/pdf/1409.1556.pdf)（VGGNet）
- Szegedy, Christian, et al. Going deeper with convolutions. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)（GoogLeNet）
- Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the Inception Architecture for Computer Vision[J]. Computer Science, 2015:2818-2826.[[PDF]](http://xueshu.baidu.com/s?wd=paperuri:%286cb3924c8d2bc09bc91ccff3f8be0f55%29&filter=sc_long_sign&tn=SE_xueshusource_2kduw22v&sc_vurl=http://arxiv.org/pdf/1512.00567v3.pdf&ie=utf-8&sc_us=6968646265670184715)（InceptionV3）
- He, Kaiming, et al. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385 (2015).[[PDF]](https://arxiv.org/pdf/1512.03385.pdf)（ResNet）
- Chollet F. Xception: Deep Learning with Depthwise Separable Convolutions[J]. arXiv preprint arXiv:1610.02357, 2016.[[PDF]](https://arxiv.org/pdf/1610.02357)（Xception）
- Huang G, Liu Z, Weinberger K Q, et al. Densely Connected Convolutional Networks[J]. 2016. [[PDF]](https://arxiv.org/pdf/1608.06993.pdf)(DenseNet, 2017 CVPR best paper)
- Squeeze-and-Excitation Networks. [[PDF]](https://arxiv.org/pdf/1709.01507.pdf)(SeNet, 2017 ImageNet 冠军)
- Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[J]. arXiv preprint arXiv:1707.01083, 2017.[[PDF]](https://arxiv.org/pdf/1707.01083)（Shufflenet）
- Sabour S, Frosst N, Hinton G E. Dynamic routing between capsules[C]//Advances in Neural Information Processing Systems. 2017: 3859-3869.[[PDF]](http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules.pdf)（Hinton, capsules）

## 炼丹技巧
- Srivastava N, Hinton G E, Krizhevsky A, et al. Dropout: a simple way to prevent neural networks from overfitting[J]. Journal of Machine Learning Research, 2014, 15(1): 1929-1958.[[PDF]](http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf)（Dropout）
- Ioffe S, Szegedy C. Batch normalization: Accelerating deep network training by reducing internal covariate shift[J]. arXiv preprint arXiv:1502.03167, 2015.[[PDF]](https://arxiv.org/pdf/1502.03167)（Batch Normalization）
- Lin M, Chen Q, Yan S. Network In Network[J]. Computer Science, 2014.[[PDF]](http://xueshu.baidu.com/s?wd=paperuri:%28b141af8f73398aaf072b958f50807e1b%29&filter=sc_long_sign&tn=SE_xueshusource_2kduw22v&sc_vurl=http://arxiv.org/pdf/1312.4400&ie=utf-8&sc_us=13783729042765531986)（Global average pooling的灵感来源）
- Goyal, Priya, Dollár, Piotr, Girshick, Ross, et al. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour[J]. 2017. [[PDF]](https://arxiv.org/abs/1706.02677)（Facebook实验室的成果，解决了工程上网络batchsize特大时性能下降的问题）

## 递归神经网络
- Mikolov T, Karafiát M, Burget L, et al. Recurrent neural network based language model[C]//Interspeech. 2010, 2: 3.[[PDF]](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)（RNN和语language model结合较经典文章）
- Kamijo K, Tanigawa T. Stock price pattern recognition-a recurrent neural network approach[C]//Neural Networks, 1990., 1990 IJCNN International Joint Conference on. IEEE, 1990: 215-221.[[PDF]](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5726532)（RNN预测股价）
- Hochreiter S, Schmidhuber J. Long short-term memory[J]. Neural computation, 1997, 9(8): 1735-1780.[[PDF]](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)（LSTM的数学原理）
- Sak H, Senior A W, Beaufays F. Long short-term memory recurrent neural network architectures for large scale acoustic modeling[C]//Interspeech. 2014: 338-342.[[PDF]](https://g.zmirrordemo.com/extdomains/http://193.6.4.39/~czap/letoltes/IS14/IS2014/PDF/AUTHOR/IS141304.PDF)（LSTM进行语音识别）
- Chung J, Gulcehre C, Cho K H, et al. Empirical evaluation of gated recurrent neural networks on sequence modeling[J]. arXiv preprint arXiv:1412.3555, 2014.[[PDF]](https://arxiv.org/pdf/1412.3555)（GRU网络）
- Ling W, Luís T, Marujo L, et al. Finding function in form: Compositional character models for open vocabulary word representation[J]. arXiv preprint arXiv:1508.02096, 2015.[[PDF]](https://arxiv.org/pdf/1508.02096)（LSTM在词向量中的应用）
- Huang Z, Xu W, Yu K. Bidirectional LSTM-CRF models for sequence tagging[J]. arXiv preprint arXiv:1508.01991, 2015.[[PDF]](https://arxiv.org/pdf/1508.01991)（Bi-LSTM在序列标注中的应用）

## 注意力模型
- Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014.[[PDF]](https://arxiv.org/pdf/1409.0473)（Attention model的提出）
- Mnih V, Heess N, Graves A. Recurrent models of visual attention[C]//Advances in neural information processing systems. 2014: 2204-2212.[[PDF]](http://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf)（Attention model和视觉结合）
- Xu K, Ba J, Kiros R, et al. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention[C]//ICML. 2015, 14: 77-81.[[PDF]](http://www.jmlr.org/proceedings/papers/v37/xuc15.pdf)（Attention model用于image caption的经典文章）
- Lee C Y, Osindero S. Recursive Recurrent Nets with Attention Modeling for OCR in the Wild[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 2231-2239.[[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lee_Recursive_Recurrent_Nets_CVPR_2016_paper.pdf)（Attention model 用于OCR）
- Gregor K, Danihelka I, Graves A, et al. DRAW: A recurrent neural network for image generation[J]. arXiv preprint arXiv:1502.04623, 2015.[[PDF]](https://arxiv.org/pdf/1502.04623)（DRAM，结合Attention model的图像生成）

## 生成对抗网络
- Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative adversarial nets[C]//Advances in neural information processing systems. 2014: 2672-2680.[[PDF]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)（GAN的提出，挖坑鼻祖）
- Mirza M, Osindero S. Conditional generative adversarial nets[J]. arXiv preprint arXiv:1411.1784, 2014.[[PDF]](https://arxiv.org/pdf/1411.1784)（CGAN）
- Radford A, Metz L, Chintala S. Unsupervised representation learning with deep convolutional generative adversarial networks[J]. arXiv preprint arXiv:1511.06434, 2015.[[PDF]](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0)（DCGAN）
- Denton E L, Chintala S, Fergus R. Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks[C]//Advances in neural information processing systems. 2015: 1486-1494.[[PDF]](http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf)（LAPGAN）
- Chen X, Duan Y, Houthooft R, et al. Infogan: Interpretable representation learning by information maximizing generative adversarial nets[C]//Advances in Neural Information Processing Systems. 2016: 2172-2180.[[PDF]](http://papers.nips.cc/paper/6398-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf)（InfoGAN）
- Arjovsky M, Chintala S, Bottou L. Wasserstein gan[J]. arXiv preprint arXiv:1701.07875, 2017.[[PDF]](https://arxiv.org/pdf/1701.07875)（WGAN）
- Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-consistent adversarial networks[J]. arXiv preprint arXiv:1703.10593, 2017.（CycleGAN）
- Yi Z, Zhang H, Gong P T. DualGAN: Unsupervised Dual Learning for Image-to-Image Translation[J]. arXiv preprint arXiv:1704.02510, 2017.[[PDF]](https://arxiv.org/pdf/1704.02510)（DualGAN）
- Isola P, Zhu J Y, Zhou T, et al. Image-to-image translation with conditional adversarial networks[J]. arXiv preprint arXiv:1611.07004, 2016.[[PDF]](https://arxiv.org/pdf/1611.07004)（pix2pix）

## 目标检测
- Szegedy C, Toshev A, Erhan D. Deep neural networks for object detection[C]//Advances in Neural Information Processing Systems. 2013: 2553-2561.[[PDF]](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf)（深度学习早期的物体检测）
- Girshick, Ross, et al. Rich feature hierarchies for accurate object detection and semantic segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.[[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf)（RCNN）
- He K, Zhang X, Ren S, et al. Spatial pyramid pooling in deep convolutional networks for visual recognition[C]//European Conference on Computer Vision. Springer International Publishing, 2014: 346-361.[[PDF]](http://arxiv.org/pdf/1406.4729)（何凯明大神的SPPNet）
- Girshick R. Fast r-cnn[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 1440-1448.[[PDF]](http://arxiv.org/pdf/1406.4729)（速度更快的Fast R-cnn）
- Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.[[PDF]](http://papers.nips.cc/paper/5638-analysis-of-variational-bayesian-latent-dirichlet-allocation-weaker-sparsity-than-map.pdf)（速度更更快的Faster r-cnn）
- Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 779-788.[[PDF]](http://homes.cs.washington.edu/~ali/papers/YOLO.pdf)（实时目标检测YOLO）
- Liu W, Anguelov D, Erhan D, et al. SSD: Single shot multibox detector[C]//European Conference on Computer Vision. Springer International Publishing, 2016: 21-37.[[PDF]](http://arxiv.org/pdf/1512.02325)（SSD）
- Li Y, He K, Sun J. R-fcn: Object detection via region-based fully convolutional networks[C]//Advances in Neural Information Processing Systems. 2016: 379-387.[[PDF]](https://arxiv.org/abs/1605.06409)（R-fcn）
- Lin T Y, Goyal P, Girshick R, et al. Focal loss for dense object detection[J]. arXiv preprint arXiv:1708.02002, 2017.[[PDF]](https://arxiv.org/pdf/1708.02002)（Focal loss）

## One/Zero shot learning
- Fei-Fei L, Fergus R, Perona P. One-shot learning of object categories[J]. IEEE transactions on pattern analysis and machine intelligence, 2006, 28(4): 594-611.[[PDF]](http://www.cs.huji.ac.il/~daphna/course/student%20lectures/cobi%20cario.pdf)（One shot learning）
- Larochelle H, Erhan D, Bengio Y. Zero-data learning of new tasks[J]. 2008:646-651.[[PDF]](http://www.aaai.org/Papers/AAAI/2008/AAAI08-103.pdf)（Zero shot learning的提出）
- Palatucci M, Pomerleau D, Hinton G E, et al. Zero-shot learning with semantic output codes[C]//Advances in neural information processing systems. 2009: 1410-1418.[[PDF]](http://papers.nips.cc/paper/3650-zero-shot-learning-with-semantic-output-codes.pdf)（Zero shot learning比较经典的应用）

## 图像分割
- Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.[[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)（有点老但是非常经典的图像语义分割论文，CVPR2015）
- Chen L C, Papandreou G, Kokkinos I, et al. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs[J]. arXiv preprint arXiv:1606.00915, 2016.[[PDF]](https://arxiv.org/pdf/1606.00915)（DeepLab）
- Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[J]. arXiv preprint arXiv:1612.01105, 2016.[[PDF]](https://arxiv.org/pdf/1612.01105)（PSPNet）
- Yu F, Koltun V, Funkhouser T. Dilated residual networks[J]. arXiv preprint arXiv:1705.09914, 2017.[[PDF]](https://arxiv.org/pdf/1705.09914)
- He K, Gkioxari G, Dollár P, et al. Mask R-CNN[J]. arXiv preprint arXiv:1703.06870, 2017.[[PDF]](https://arxiv.org/pdf/1703.06870)（何凯明大神的MASK r-cnn，膜）
- Hu R, Dollár P, He K, et al. Learning to Segment Every Thing[J]. arXiv preprint arXiv:1711.10370, 2017.[[PDF]](https://arxiv.org/pdf/1711.10370)（Mask Rcnn增强版）
- -


## Person Re-ID
- Yi D, Lei Z, Liao S, et al. Deep metric learning for person re-identification[C]//Pattern Recognition (ICPR), 2014 22nd International Conference on. IEEE, 2014: 34-39.[[PDF]](https://arxiv.org/pdf/1407.4979)（较早的一篇基于CNN的度量学习的Re-ID，现在来看网络已经很简单了）
- Ding S, Lin L, Wang G, et al. Deep feature learning with relative distance comparison for person re-identification[J]. Pattern Recognition, 2015, 48(10): 2993-3003.[[PDF]](https://arxiv.org/pdf/1512.03622.pdf)（triplet loss）
- Cheng D, Gong Y, Zhou S, et al. Person re-identification by multi-channel parts-based cnn with improved triplet loss function[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 1335-1344.[[PDF]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf)（improved triplet loss）
- Hermans A, Beyer L, Leibe B. In Defense of the Triplet Loss for Person Re-Identification[J]. arXiv preprint arXiv:1703.07737, 2017.[[PDF]](https://arxiv.org/pdf/1703.07737)（Triplet loss with hard mining sample）
- Chen W, Chen X, Zhang J, et al. Beyond triplet loss: a deep quadruplet network for person re-identification[J]. arXiv preprint arXiv:1704.01719, 2017.[[PDF]](https://arxiv.org/pdf/1704.01719.pdf)（四元组）
- Zheng Z, Zheng L, Yang Y. Unlabeled samples generated by gan improve the person re-identification baseline in vitro[J]. arXiv preprint arXiv:1701.07717, 2017.[[PDF]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zheng_Unlabeled_Samples_Generated_ICCV_2017_paper.pdf)(用GAN造图做ReID第一篇)
- Zhang X, Luo H, Fan X, et al. AlignedReID: Surpassing Human-Level Performance in Person Re-Identification[J]. arXiv preprint arXiv:1711.08184, 2017. [[PDF]](https://arxiv.org/pdf/1711.08184)（AlignedReid，首次超越人类）
- [Liang Zheng的个人主页](http://www.liangzheng.org/)（在这个领域提供了大量论文，常用的数据集和代码都可以在主页中找到）




