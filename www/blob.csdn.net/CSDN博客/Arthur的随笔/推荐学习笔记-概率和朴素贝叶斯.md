# 推荐学习笔记-概率和朴素贝叶斯 - Arthur的随笔 - CSDN博客
2012年12月16日 20:11:22[largetalk](https://me.csdn.net/largetalk)阅读数：1222
个人分类：[R&datamine																[杂七杂八](https://blog.csdn.net/largetalk/article/category/823511)](https://blog.csdn.net/largetalk/article/category/1063234)
先验概率（prior probability): 对一个假设（hypothesis)/事件 发生已知的概率，记为P(h)。如： 抛一枚硬币，证明朝上的先验概率是 P(h) = 0.5
后验概率（posterior probability): 在特定数据/情景下，某事件发生的概率， 记为P(h|d).
P(D): 某事/条件出现的概率
P(D|h): 在h发生时， 某事出现的概率。
贝叶斯公式： P(h|D)= ( P(D|h) * P(h) ) / P(D)  或 P(B|A) = P(AB)/P(A) , 在做分类时，由于P(D)都是一样的，所有可以不计算,  P(h|D)≈ P(D|h) * P(h)
Tom Mitchell的 机器学习 上举了如下例子：
P(cancer)=0.008 人群中癌症概率是0.008
P(pos|cancer)=0.98 癌症人群血液测试显阳性概率为0.98
P(pos|~cancer)=0.03 非癌症人群血液测试显阳性概率为0.03
现在一个人x来测试血液显示为阳性， 则他患癌症概率大还是没有癌症概率大， 概率多少
P(cancer|pos) ≈ P(pos|cancer) * P(cancer) = 0.98*0.008 = 0.0078
P(~cancer|pos) ≈ P(pos|~cancer) * P(~cancer) = 0.03 * (1-0.008) = 0.0298
所以x没有癌症的概率比患有癌症的概率大， 他患癌症的概率是 P(cancer|pos) = 0.0079/(0.0078+0.0298) = 0.21
**朴素贝叶斯**：
朴素贝叶斯我的理解就是在多个条件（变量）下，假设条件独立的贝叶斯公式，条件独立性质就是P(A, B) = P(A) * P(B)
以典型的朴素贝叶斯应用垃圾邮件过滤举例：
我们判断一封邮件是否是垃圾邮件是观察判断某些词是否在邮件中，由此预测垃圾邮件概率，以 sex 和 porn 两词为例：
P(sex|spam) 垃圾邮件中有sex词的概率
P(porn|spam) 垃圾邮件中有porn这个词的概率
如一封邮件同时存在这个两个词，
则是垃圾概率是P(spam|sex, porn) ≈ P(sex|spam)*P(porn|spam)*P(spam)，
不是垃圾邮件的概率是 P(~spam|sex, porn) ≈ P(sex|~spam) * P(porn|~spam) * P(~spam)
当然的真正的垃圾邮件过滤考虑的词数肯定是多的多
tips. 由于训练数据的关系，在某些情况下如P(sex|spam)为0， 为了使最后概率不为0， 可以给其设一个小概率值， 如1/N， N是邮件过滤考虑的词数。
做贝叶斯计算时，对于连续的数据（属性），如商品价格， 有两种处理方法：
1. 分组，把连续的属性分成几组不连续的
2. 高斯分布：假设属性具有高斯分布性质。 μ是期望，σs是方差， 则
![](http://pic002.cnblogs.com/images/2012/345797/2012121620073967.png)
对于连续的属性也就能通过该公式求得其条件概率。
