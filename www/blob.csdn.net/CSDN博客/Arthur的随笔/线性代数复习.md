# 线性代数复习 - Arthur的随笔 - CSDN博客
2012年12月04日 09:33:42[largetalk](https://me.csdn.net/largetalk)阅读数：831
个人分类：[杂七杂八																[R&datamine](https://blog.csdn.net/largetalk/article/category/1063234)](https://blog.csdn.net/largetalk/article/category/823511)
正交矩阵： 它的转置矩阵就是它的逆矩阵， QTQ = QQT = I
对角矩阵： 方阵M所有非主对角线元素全等于零的矩阵。 （主对角线元素： 元素两个下标相等）
svd， 奇异值分解： 矩阵M = UΣVT， U和V是正交矩阵， Σ是非负对角阵， Σ对角线上的元素即为M的奇异值。M 是m*n, U是m*m, Σ是m*n, VT是n*n
特征值与特征向量：Αξ = λξ, 在![A](http://upload.wikimedia.org/math/7/f/c/7fc56270e7a70fa81a5935b72eacbe29.png)变换的作用下，向量![\xi](http://upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png)仅仅在尺度上变为原来的![\lambda](http://upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png)倍。称![\xi](http://upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png)是*A* 的一个特征向量，![\lambda](http://upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png)是对应的特征值。所有具有相同的特征值![\lambda](http://upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png)的特征向量和零向量一起，组成了一个[向量空间](http://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4)，称为线性变换的一个**特征空间。**
**特征值分解： A是N*N方阵， 且有N个线性无关的特征向量 ![q_i \,\, (i = 1, \dots, N)](http://upload.wikimedia.org/math/8/2/a/82ad2dd7c3f65499c4956ecaa98e3132.png)， A = QΛQ-1， 其中 **Q** 是*N*×*N*方阵，且其第 *i*列为 **A** 的特征向量 ![q_i](http://upload.wikimedia.org/math/0/5/5/055c210a7797b4e842635accb13e32a7.png)。 **Λ** 是[对角矩阵](http://zh.wikipedia.org/wiki/%E5%AF%B9%E8%A7%92%E7%9F%A9%E9%98%B5)，其对角线上的元素为对应的特征值，也即 ![\Lambda_{ii}=\lambda_i](http://upload.wikimedia.org/math/d/a/1/da1afe6e5fe67eaa1e3d0d3df9ccc82f.png)**
# **酉矩阵： 复数域上的正交矩阵，正交矩阵只是在实数域上。**
**奇异值分解过程： **
首先，我们将一个矩阵A的转置 * A，将会得到一个方阵，我们用这个方阵求特征值可以得到：![image](http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226348223.png)   
 这里得到的v，就是我们上面的右奇异向量。此外我们还可以得到：
![image](http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226346304.png)   
 这里的σ就是上面说的奇异值，u就是上面说的左奇异向量。奇异值σ跟特征值类似，在矩阵Σ中也是从大到小排列，而且σ的减少特别的快，**在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了**。也就是说，我们也可以用前r大的奇异值来近似描述矩阵，这里定义一下**部分奇异值分解**：
![image](http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226358289.png)
    r是一个远小于m、n的数, 所以奇异值分解可以被用来作降维。
奇异值计算：  [Lanczos迭代](http://en.wikipedia.org/wiki/Lanczos_algorithm)就是一种解**对称方阵部分特征值**的方法
latent factory model: 将稀疏矩阵分解成两个矩阵，一个表示User的Feature， 一个表示Itme的Featur， 然后做內积得到预测评分，此外还需要考虑Biases. 求解方法 Stochastic gradient desent。
参考：
[http://somemory.com/myblog/?post=19](http://somemory.com/myblog/?post=19)
[http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html)
