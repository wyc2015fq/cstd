# 卡车图像分离车头、车厢、车轮 - 李鑫o_O - CSDN博客

置顶2016年03月07日 11:16:56[hustlx](https://me.csdn.net/HUSTLX)阅读数：2395


  要求对400张卡车图片进行处理，分割出车头、车轮、和车厢，在尝试了以上多种方法失败之后，用了2010年Varun
 Gulshan等提出的一种Geodesic Star Convexity Sequential system（简称GSCseq）算法[2]，该算法很适合于我们感兴趣的区域都在图像中央的这种情况，下图显示了原图像和处理之后保存的结果，绿色表示车头，蓝色表示车厢，红色表示车轮。用红色的圈圈起来的图像代表处理错误的图像，对所有的400张图片，有24张图片处理错误，正确率达到94%。

![clip_image002[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192502143-1513704472.jpg)![clip_image004[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192503065-1130632933.jpg)

图1 原图像和处理后的图像

## 2GSCseq算法理论

### 2.1 GSCseq算法简介

         GSCseq算法最简单的起源模型如图2所示：

![clip_image006[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192503768-1971273155.jpg)![clip_image008[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192504940-226199482.jpg)

图2 Star-convexity模型及其实验示例

该算法的核心思想是先找出目标图像的一点，然后各个方向星形地向外不断的膨胀，直到遇到明显的边缘，这个思想最早被Veksler提出[3]。该算法存在很多不足，只能处理形状凸的目标如图2右边，但是对于复杂一点的图像如图3所示则由于从任何一点出发的射线都不能足以找到目标所有区域，Varun
 Gulshan他们对这个模型进行了改进，把以前的一个核心点改为多个，甚至是连续的线（Geodesic Star Convexity Sequential），并且可以事先预分一个前景区（目标区域）和背景区。

![clip_image010[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192505690-18745540.jpg)![clip_image012[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192506409-1003034997.jpg)

图3 Geodesic Star
 Convexity Sequential模型以及Star-convexity不能处理的图像示例

图4展示了GSCseq算法处理图像的示例，如图所示，图中蓝色是预先假定的前景区域，而粉色则是预先设定的背景区域，则粉色所在区域的原图像的像素点会进行膨胀，相近的颜色会认为是背景，同样的蓝色区域的原像素也会膨胀与本身相近的颜色并进行前景标记，直到前景和背景相遇则认为是目标边缘。

![clip_image014[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192507268-1487823227.jpg)

图4 GSCseq算法处理图像

### 2.2 GSCseq算法数学证明

如图5所示，设c点是核心点，也就是预先定义的前景点，p为目标上任意一点，定义![clip_image016[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192508659-2046578325.png)作为核心点c到目标点p的最短路径，路径用欧氏距离计算，直接离散域定义。最短程

![clip_image018[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192509580-122336950.jpg)

图5 多核心点路径

路径可以弯曲并适应的图像，而不一定非是直线。在图像分割的情况下，基本图像中的梯度提供的信息来计算这样的路径。定义测地（Geodesic）距离，首先定义一个离散长度路径：

![clip_image020[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192510409-848171284.jpg)（1）

![clip_image022[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192511377-80807353.png)是一个任意的有n个u点的离散路径由![clip_image024[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192512440-638004141.png)给出，![clip_image026[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192513127-1626994083.png)是连续像素点的欧式距离，![clip_image028[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192513924-1868577789.png)是![clip_image030[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192514502-206549525.png)点之间图像梯度的有限差分近似。![clip_image032[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192515174-1424253263.png)是第一项欧式距离和第二项梯度之间的权重。由上面的定义，我们定义测地（Geodesic）距离：

![clip_image034[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192515768-1208132092.jpg)（2）

![clip_image036[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192516424-1602617767.png)表示a，b两点间的所有离散路径合集。我们比较关心的是![clip_image038[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192517362-1992516342.png)，上述的定义可以扩展到多个核心点集c，所有的量都定义在离散域。

## 1.实验过程

对于试验流程如下图所示：首先对于一副原图像，首先进行图片大小归一化，全部变成50*100的图像，我们设置一个通用的模板，红色代表背景区，白色代表我们感兴趣的目标区域，由于每幅图像的车都差不多在图像的中间，故这个模板能比较好的匹配所有的图像，GSCseq算法从每一个白色点开始向外找颜色相同的点，每一个红色的点也向周围找颜色相

![clip_image040[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192518299-568732422.jpg)![clip_image042[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192519018-707056780.jpg)

A原图像                        B前景与背景模板

![clip_image044[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192519705-1846767459.jpg)![clip_image046[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192520252-1031085600.jpg)

C分割后的图像                 D轮廓与车头车身分界线


![clip_image048[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192521112-559385353.jpg)![clip_image050[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192521768-1787364986.jpg)

E车头车身分割                  F车轮模板

![clip_image052[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192522487-1452091524.jpg)

G 最后处理的结果

图6实验过程图例

近的区域，这样得到分割后的模板图像，如图6-c所示。对于分割后的目标，我们找到其边缘，用红色线标注，此外，我们取中间的一块区域（比如20*60）进行投影，找到像素和最小的列，我们认为这是车头和车身的连接处，用绿色的线标注，如果分界线在图像左边我们则认为是车头向左，反之则认为车头向右，我们对车头进行绿色填充，车身进行蓝色填充，如图6-E所示，同理我们用车轮的模板可以得到车轮的所在区域，并且对它进行红色填充，最后处理的结果如图6-G所示，我们最后对所有图片用循环实现了批处理，把处理后的图像保存下来，图7是对所有处理后图像的截图，对于处理错误的图片我们已经用红色的圈圈出来了，可以看到一共有24张图片处理错误，对于400张图片其正确率为：

![clip_image054[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192523268-1221184518.png)

![clip_image056[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192524143-1863231113.jpg)![clip_image058[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192525002-1971517621.jpg)

![clip_image060[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192525862-900349296.jpg)![clip_image062[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192526830-2113842968.jpg)

![clip_image064[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192527846-1043025634.jpg)![clip_image066[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192528627-1411820271.jpg)![clip_image068[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192529690-1115556414.jpg)

图7  实验结果

最后我们把整个系统做成软件界面的形式，如图8所示：

![clip_image070[4]](http://images2015.cnblogs.com/blog/904258/201603/904258-20160305192530424-1126581696.jpg)

图8 软件界面

该软件见文件夹software.exe，由于编译了C++代码，所以刚开始点击之后可能会有几秒钟的响应时间，请耐心等待。

## 4实验总结

本次实验的目的是对400张图片的卡车进行车头、车身和车轮的提取，但是卡车由于清晰度较差并且有较强的环境噪声变换，因此用传统的边缘检测和图像分割方法根本行不通，在多次尝试并且查阅相关文献之后最后用了Varun
 Gulshan等在2010年CVPR会议提出的一种Geodesic
 Star Convexity Sequential system（简称GSCseq）算法，实验结果表明该算法在事先知道目标在图片相对位置时有很好的目标提取效果，我们的400张图片达到了94%的正确分割结果。总体而言实验是成功的，在查阅文献的时候看到基于深度学习的目标识别与分割，程序通过大量的带有一类目标物体的图像不断从图像中学习与认知所学习的目标，每幅图像都有相同类的目标，这样的话图像通过相关性卷积运算，目标区域由于是一类物体，相关性比较高，它的图像信息如梯度之类的会被保存下来，而背景由于每幅图像背景不同而将会被削弱，这样一层一层学习，到最顶层只剩下目标的相关信息，这便是深度学习背景目标识别与分割的主要思路，训练好的网络即可对所有包含此类物体的图像进行识别。这必将是以后主流的研究方向。

 github源码：https://github.com/HUSTLX/GSCseq

**参考文献：**

[1]胡江华. 静态图像的行人分割及其应用[D].安徽大学,2014.

[2]Gulshan V, Rother C, Criminisi A, et al. Geodesic star convexity for interactive image segmentation[C]//Computer Vision and Pattern
 Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010: 3129-3136.

[3]O. Veksler. Star shape prior for graph-cut image segmentation. In Proc. ECCV, 2008.

