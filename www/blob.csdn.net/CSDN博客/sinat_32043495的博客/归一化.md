# 归一化 - sinat_32043495的博客 - CSDN博客





2018年01月02日 21:23:04[LZXandTM](https://me.csdn.net/sinat_32043495)阅读数：1812










## **1.为什么有一些机器模型需要进行归一化**


归一化化就是要把你需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内。

1）归一化后加快了梯度下降求最优解的速度。等高线变得显得圆滑，在梯度下降进行求解时能较快的收敛。如果不做归一化，梯度下降过程容易走之字，很难收敛甚至不能收敛

2）把有量纲表达式变为无量纲表达式, 有可能提高精度。一些分类器需要计算样本之间的距离（如欧氏距离），例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）

3) 逻辑回归等模型先验假设数据服从正态分布。



## **2、归一化为什么能提高梯度下降法求解最优解的速度？**

函数z=f(x,y)在点p(x,y)的梯度的方向与过点p的等高线f(x,y)=c在这点的法线一个方向相同。梯度的方向与等高线切线方向垂直。
梯度是函数值变化最快的方向。梯度下降法找到的方向对所在的那个点来说，这个方向是下降最快的
![](https://img-blog.csdn.net/20180102212933737?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20180102214049802?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


![](https://img-blog.csdn.net/20180102213014826?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



蓝色的圈圈图代表的是两个特征的等高线。其中左图两个特征X1和X2的区间相差非常大，X1区间是[0,2000]，X2区间是[1,5]，其所形成的等高线非常尖。当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走，即沿着梯度的方向走），从而导致需要迭代很多次才能收敛；

而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。

因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。

例子：



![](https://img-blog.csdn.net/20180102215455449?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)![](https://img-blog.csdn.net/20180102215502879?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)





## 3 归一化有可能提高精度



     一些分类器需要计算样本之间的距离（如欧氏距离），例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）。

## **4 归一化的类型**

![](https://img-blog.csdn.net/20180102215727963?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

最值归一化。比如把最大值归一化成1，最小值归一化成-1；或把最大值归一化成1，最小值归一化成0。适用于本来就分布在有限范围内的数据。均值方差归一化，一般是把均值归一化成0，方差归一化成1。适用于分布没有明显边界的情况，受outlier影响也较小。

## 5.为什么树形结构不需要归一化

数值缩放，不影响分裂点位置。因为首先是按照特征值进行排序，根据特征值的概率分布选择一个让数据最能区分开的特征进行当前的分裂，归一化后排序的顺序不变，那么所属的分支以及分裂点就不会有不同。


**6.LR SVM模型为什么需要归一化**

归一化函数把来自 SVM 分类器的数据值转换到可以互相比较的同一值域区间，然后采用融合规则做出最终的决策。支持向量机 ( support vector machines， SVM) 是基于统计学习理论结构风险最小化原理和VC 维理论基础上的机器学习方法． 通过非线性方法， 把样本映射到高维的特征空间中， 使得在低维非线性空间中不可分的样本转化成高维线性可分的样本．

有些模型在各个维度进行不均匀伸缩后，最优解与原来不等价，例如SVM。对于这样的模型，除非本来各维数据的分布范围就比较接近，否则必须进行标准化，以免模型参数被分布范围较大或较小的数据dominate。




有些模型在各个维度进行不均匀伸缩后，最优解与原来等价，例如logistic regression。对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛。所以对于具有伸缩不变性的模型，**最好**也进行数据标准化。



参考：

1.http://blog.csdn.net/v_JULY_v/article/details/78121924#t3

2.https://www.zhihu.com/question/20455227

3.http://blog.csdn.net/zbc1090549839/article/details/44103801

4.https://www.zhihu.com/question/30038463/answer/50491149








