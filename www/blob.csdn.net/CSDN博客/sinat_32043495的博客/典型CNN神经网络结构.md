# 典型CNN神经网络结构 - sinat_32043495的博客 - CSDN博客





2017年12月19日 16:42:39[LZXandTM](https://me.csdn.net/sinat_32043495)阅读数：846








## LeNet-5，用来识别数字的卷积网络

![](https://img-blog.csdn.net/20171219164234319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



C1层是一个卷积层，由6个特征图Feature Map构成。特征图中每个神经元与输入为5*5的邻域相连。特征图的大小为28*28，这样能防止输入的连接掉到边界之外（32-5+1=28）。C1有156个可训练参数（每个滤波器5*5=25个unit参数和一个bias参数，一共6个滤波器，共(5*5+1)*6=156个参数），共156*(28*28)=122,304个连接。

S2层是一个下采样层，有6个14*14的特征图。特征图中的每个单元与C1中相对应特征图的2*2邻域相连接。S2层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。每个单元的2*2感受野并不重叠，因此S2中每个特征图的大小是C1中特征图大小的1/4（行和列各1/2）。S2层有12（6*（1+1）=12）个可训练参数和5880（14*14*（2*2+1）*6=5880）个连接。

 C3层也是一个卷积层，它同样通过5x5的卷积核去卷积层S2，然后得到的特征map就只有10x10个神经元，但是它有16种不同的卷积核，所以就存在16个特征map了。 C3中每个特征图由S2中所有6个或者几个特征map组合而成。为什么不把S2中的每个特征图连接到每个C3的特征图呢？原因有2点。第一，不完全的连接机制将连接的数量保持在合理的范围内。第二，也是最重要的，其破坏了网络的对称性。由于不同的特征图有不同的输入，所以迫使他们抽取不同的特征（希望是互补的）。

      例如，存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。这样C3层有1516（6*（3*25+1）+6*（4*25+1）+3*（4*25+1）+（25*6+1）=1516）个可训练参数和151600（10*10*1516=151600）个连接。

       S4层是一个下采样层，由16个5*5大小的特征图构成。特征图中的每个单元与C3中相应特征图的2*2邻域相连接，跟C1和S2之间的连接一样。S4层有32个可训练参数（每个特征图1个因子和一个偏置16*（1+1）=32）和2000（16*（2*2+1）*5*5=2000）个连接。

        C5层是一个卷积层，有120个特征图。每个单元与S4层的全部16个单元的5*5邻域相连。由于S4层特征图的大小也为5*5（同滤波器一样），故C5特征图的大小为1*1（5-5+1=1）：这构成了S4和C5之间的全连接。之所以仍将C5标示为卷积层而非全相联层，是因为如果LeNet-5的输入变大，而其他的保持不变，那么此时特征图的维数就会比1*1大。C5层有48120（120*（16*5*5+1）=48120由于与全部16个单元相连，故只加一个偏置）个可训练连接。

       F6层有84个单元（之所以选这个数字的原因来自于输出层的设计），与C5层全相连。有10164（84*(120*(1*1)+1)=10164）个可训练参数。如同经典神经网络，F6层计算输入向量和权重向量之间的点积，再加上一个偏置。然后将其传递给sigmoid函数产生单元i的一个状态。

      最后，输出层由欧式径向基函数（Euclidean Radial Basis Function）单元组成，每类一个单元，每个有84个输入。

## **VGGNet**

2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好


在卷积部分，VGG采用的是展度为3的过滤器，卷积步长为1，2*2并且步长为2的MaxPooling。之后将卷积部分的结果传到全连接部分，全连接部分则是有3个全连接层以及一个SOFTMAX层构成。




#### VGG训练方法以及参数设置细节

权重更新策略：Mini-batch gradient descent with Momentum；Batch Size为256，Momentum参数为 0.9。 

正则化：L2 norm, Dropout。L2 penalty设置为，Dropout参数为0.5。 

学习率：初始设为，并在validation
 error到达瓶颈时将学习率除以10直到validation error不能再改进为止。（在训练中，学习率总共降过3次，迭代次数有370K，共 74次对全部数据的扫描）。 

权重初始化：使用Pre-training的方式，每次初始化权重时使用正态分布，均值为0，方差为；Bias设为0

几个小滤波器卷积层的组合比一个大滤波器卷积层好：假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野。同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，也就是对输入数据体有7x7的视野。假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点。首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好的特征。其次，假设所有的数据有C个通道，那么单独的7x7卷积层将会包含7*7*C=49C2个参数，而3个3x3的卷积层的组合仅有个3*（3*3*C）=27C2个参数。直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层。前者可以表达出输入数据中更多个强力特征，使用的参数也更少。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。1*1
 filter: 作用是在不影响输入输出维数的情况下，对输入线进行线性形变，然后通过Relu进行非线性处理，增加网络的非线性表达能力。 Pooling：2*2，间隔s=2。

![](https://img-blog.csdn.net/20171219165750684?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)![](https://img-blog.csdn.net/20171219165755268?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)![](https://img-blog.csdn.net/20171219165800340?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**resnet**

可以看到56层的模型无论是训练误差还是测试误差都比26层的要大。为什么会出现这种情况？假设现在有一个稍浅的性能比较好的网络，现在在它后面加上多层网络，并且我们假设添加的多层网络拟合的是恒等函数，那么新网络的性能应该和原网络一样好才对。可是实验证明新网络的准确率降低了，这说明额外的多层网络并不能很好地拟合恒等函数。


![](https://img-blog.csdn.net/20171219173304707?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


resnet最初的想法是在训练集上，深层网络不应该比浅层网络差，因为只需要深层网络多的那些层做恒等映射就简化为了浅层网络。所以从学习恒等映射这点出发，考虑到网络要学习一个F(x)=x的映射比学习F(x)=0的映射更难，所以可以把网络结构设计成H(x) = F(x)
 + x，这样就即完成了恒等映射的学习，又降低了学习难度。这里的x是残差结构的输入，F是该层网络学习的映射，H是整个残差结构的输出。


![](https://img-blog.csdn.net/20171219171628368?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2luYXRfMzIwNDM0OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)


参考来自:


1. http://blog.csdn.net/dcxhun3/article/details/46878999

2.http://blog.csdn.net/wcy12341189/article/details/56281618










