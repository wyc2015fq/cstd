# 机器学习（二）：模型评估与模型选择、正则化与交叉验证、L0,L1,L2正则化、泛化能力 - ChihkAnchor的博客 - CSDN博客





2019年04月09日 08:42:44[Chihk-Anchor](https://me.csdn.net/weixin_40871455)阅读数：8标签：[模型评估																[模型选择																[正则化																[交叉验证																[泛化能力](https://so.csdn.net/so/search/s.do?q=泛化能力&t=blog)
个人分类：[机器学习](https://blog.csdn.net/weixin_40871455/article/category/8809411)





### 训练误差与测试误差

机器学习的目的是使学习到的模型不仅对已知数据而且对未知数据都能有很好的预测能力。不同的学习方法会给出不同的模型。当损失函数给定时， 基于损失函数的模型的`训练误差`（training error） 和模型的`测试误差`（test error） 就自然成为学习方法评估的标准。机器学习方法具体采用的损失函数未必是评估时使用的损失函数。 当然， 让两者一致是比较理想的。 

![](https://img-blog.csdnimg.cn/20190331175257223.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdnimg.cn/20190331175321533.png)

训练误差的大小， 对判断给定的问题是不是一个容易学习的问题是有意义的， 但本质上不重要。

测试误差反映了学习方法对未知的测试数据集的预测能力， 是学习中的重要概念。

显然， 给定两种学习方法， 测试误差小的方法具有更好的预测能力， 是更有效的方法。

通常将学习方法对未知数据的预测能力称为泛化能力（generalizationability）

### 过拟合与模型选择

当假设空间含有不同复杂度（例如， 不同的参数个数） 的模型时， 就要面临模型选择（model selection） 的问题。

我们希望选择或学习一个合适的模型。

如果在假设空间中存在“真”模型， 那么所选择的模型应该逼近真模型。 具体地， 所选择的模型要与真模型的参数个数相同， 所选择的模型的参数向量与真模型的参数向量相近。

如果一味追求提高对训练数据的预测能力， 所选模型的复杂度则往往会比真模型更高。 这种现象称为过拟合（over-fitting） 。

过拟合是指学习时选择的模型所包含的参数过多， 以致于出现这一模型对已知数据预测得很好， 但对未知数据预测得很差的现象。 可以说模型选择旨在避免过拟合并提高模型的预测能力。

下面， 以多项式函数拟合问题为例， 说明过拟合与模型选择。 这是一个回归问题。 
![](https://img-blog.csdnimg.cn/2019033118024929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

解决这一问题的方法可以是这样的． 首先确定模型的复杂度， 即确定多项式的次数； 然后在给定的模型复杂度下， 按照经验风险最小化的策略， 求解参数， 即多项式的系数， 具体地， 求以下经验风险最小化： 

![](https://img-blog.csdnimg.cn/20190331180728579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

![](https://img-blog.csdnimg.cn/20190331181046708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

图1.2给出了M＝0， M＝1， M＝3及M＝9时多项式函数拟合的情况。

如果M＝0， 多项式曲线是一个常数， 数据拟合效果很差。 

如果M＝1， 多项式曲线是一条直线， 数据拟合效果也很差。 

如果M＝9， 多项式曲线通过每个数据点， 训练误差为0。 从对给定训练数据拟合的角度来说， 效果是最好的。

但是， 因为训练数据本身存在噪声， 这种拟合曲线对未知数据的预测能力往往并不是最好的， 在实际学习中并不可取。 这时过拟合现象就会发生。 这就是说， 模型选择时， 不仅要考虑对已知数据的预测能力， 而且还要考虑对未知数据的预测能力。

当M＝3时， 多项式曲线对训练数据拟合效果足够好， 模型也比较简单， 是一个较好的选择．

在多项式函数拟合中可以看到， 随着多项式次数（模型复杂度）的增加， 训练误差会减小， 直至趋向于0， 但是测试误差却不如此，它会随着多项式次数（模型复杂度） 的增加先减小而后增大。 而最终的目的是使测试误差达到最小。 这样， 在多项式函数拟合中， 就要选择合适的多项式次数， 以达到这一目的。 这一结论对一般的模型选择也是成立的。


图1.3描述了训练误差和测试误差与模型的复杂度之间的关系。当模型的复杂度增大时， 训练误差会逐渐减小并趋向于0； 而测试误差会先减小， 达到最小值后又增大。当选择的模型复杂度过大时， 过拟合现象就会发生。 这样， 在学习时就要防止过拟合， 进行最优的模型选择， 即选择复杂度适当的模型， 以达到使测试误差最小的学习目的。 


![](https://img-blog.csdnimg.cn/2019033118205578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

## 正则化与交叉验证

### 正则化

模型选择的经典方法是正则化（regularization）。正规化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项。正则化一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。 正则化一般具有如下形式 

![](https://img-blog.csdnimg.cn/20190331184754691.png)

其中，第一项是经验风险，第二项是正则化项，为调整两者之间关系的系数。正则化项可以取不同的形式。例如。回归问题中，损失函数是平方损失，正则化项可以是参数向量的范数：

![](https://img-blog.csdnimg.cn/20190331184831925.png)



这里，![](https://img-blog.csdnimg.cn/20190331184901246.png)表示参数向量w的范数。 

正则化项也可以是参数向量的范数： 

![](https://img-blog.csdnimg.cn/201903311849284.png)

这里，![](https://img-blog.csdnimg.cn/20190331184947925.png)表示参数向量的范数。 

第一项的经验风险较小的模型可能较复杂（有多个非零参数），这时第二项的模型复杂度会较大。正则化的作用是选择经验风险与模型复杂度同时较小的模型。
正则化项符合奥卡姆剃刀原理。奥卡姆剃刀原理应用于模型选择时变为一下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是好模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率，可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。正则化的本质就是，给优化参数一定约束。

### L0,L1,L2正则化（重点）

L0范数：向量中非0元素的个数。如果用L0范数来规则化一个参数矩阵W的话，那么我们希望W的元素大部分都是0。让参数是稀疏的。L0范数的最小化问题在实际应用中是NP难问题,所以在实际中不会应用。

L1范数是向量中各个元素绝对值之和，有个美称“稀疏规则算子”，为什么L1会使权值稀疏？L1范数是L0范数的最优凸近似。既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。

参数稀疏的好处是什么？

　　（1）对稀疏趋之若鹜的一个关键原因就是它能实现特征的自动选择。一般来说，样本X的大部分内容（大部分特征）都是和最终的输出y无关的或者不提供任何信息。在经验风险最小化的时候，考虑这些特征，虽然可以提高训练误差，但是在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了正确的预测。稀疏规则算子就是为了完成特征自动选择的光荣使命。它会将没用的特征去掉，将这些特征对应的权重设置为0.

　　（2）模型可解释性强。

L2范数是指向量各元素的平方和然后求平方根。在回归里面，把有L2 范数的回归称为岭回归，有人也称它为权值衰减。我们让L2范数的规则项最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。实际上L2范数就是限制了权重参数的增长。

在经验风险最小化的基础上，加入了正则化项，相当于是加了约束条件，变成了有约束条件的最优化问题。

![](https://img-blog.csdnimg.cn/20190331190214724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDg3MTQ1NQ==,size_16,color_FFFFFF,t_70)

上面这幅图很好的解释了L1范数与L2范数

         L1范数：L1的输出图像如上左图所示，发现L1图像在和每个坐标轴相交的地方都有角出现，而目标函数的等值线除非摆的非常好，否则大部分的时候都会在有角的地方相交。而在有角的地方相交会产生稀疏性。

         相比之下，L2没有L1范数这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的地方可能性比较小。

         即采用L1范数正则化项等值线与经验风险等值线的交点常常出现在坐标轴上，即W1或者W2等于0，这样就相当于减少了参数的数量。采用L2范数的时候，交点一般出现在某个象限内，即W1，W2均不为0,。换言之L1范数更易于得到稀疏解。

         W取得稀疏解意味着初始的d个特征中仅仅对应的权重w不为0的特征才会出现在最终模型中，于是求解L1范数正则化的结果是得到了仅采用一部分初始特征的模型。L1范数的求解可以采用近端梯度下降PGD。

### 交叉验证

另一种常用的模型选择方法是交叉验证（cross validation） 

如果给定的样本数据充足，进行模型选择的一种简单方法是随机的降数据集分成：训练集（training set）、验证集（validation set）、测试集(test set)。训练集用来训练模型，验证集用来选择模型，测试集用于最终对学习方法的评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的。

但是在实际应用中数据时不充足的。为了选择好的模型，可以采用交叉验证方法。交叉验证的基本思想：重复的使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复的进行训练、测试及模型选择。

简单交叉验证 
- 方法：首先随机的将已给数据分为两部分，一部分作为训练集，另一部分作为测试集（例如70%作为训练，30%作为测试），然后用训练集在各种条件下（不同的参数个数）训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

S折交叉验证（ 应用最多） 
- 方法：首先随机的将已给数据切分为S个互不相交的大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均测试误差最小的模型。

留一交叉验证 
- S折交叉验证的特殊情形是S=N，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。这里，N是给定数据集的容量。

### 泛化能力

学习方法的泛化能力是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的，很有可能由此得到的评价结果是不可靠的。

泛化误差的定义。如果学到的模型是![](https://img-blog.csdnimg.cn/20190331192942658.png)，那么这个模型对未知数据预测的误差即为泛化误差：

![](https://img-blog.csdnimg.cn/20190331193042976.png)

泛化误差反映了学习方法的泛化能力。如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险。](https://so.csdn.net/so/search/s.do?q=交叉验证&t=blog)](https://so.csdn.net/so/search/s.do?q=正则化&t=blog)](https://so.csdn.net/so/search/s.do?q=模型选择&t=blog)](https://so.csdn.net/so/search/s.do?q=模型评估&t=blog)




