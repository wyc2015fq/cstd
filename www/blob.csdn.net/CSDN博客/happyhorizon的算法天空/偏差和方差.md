# 偏差和方差 - happyhorizon的算法天空 - CSDN博客
2017年09月08日 14:09:37[lxy_Alex](https://me.csdn.net/happyhorizion)阅读数：272
- 偏差度量的是函数或者参数的误差期望。对于机器学习，偏差意味着样本的输出与真实值之间的误差，即模型本身的精确程度。
- 方差度量的是数据上任意特定采样导致的估计期望的偏差。方差代表的是一次训练中一次输出结果和模型输出期望之间的误差，即模型的稳定性。
过拟合会出现高方差问题，此时模型在训练集上错误率极低，但是在测试集上表现很差，模型把训练集里面的噪声都当成了真实的数据分布特征，导致泛化性能不好。
欠拟合会出现高偏差的问题。此时，训练样本太少，导致模型不足以刻画数据分布，表现在训练集上都会出现较高的错误率。
![1240](https://upload-images.jianshu.io/upload_images/4685306-0e5febd142f24438.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
image.png
下图中用了三个模型来拟合训练集的样本。训练数据是随机生成的x，y，左图用了一个线性模型导致结果欠拟合——它无法捕捉数据中的曲率信息。中图采用了二次模型，很好反映了数据中的二次关系，且在测试集上表现良好。右图采用了9阶多项式模型，虽然得出的解可以精确地穿过每一个训练数据点，但是很显然，模型得到了一个数据集上实际并不存在的深谷，拟合曲线急剧的变化，往往意味着过拟合的产生。在测试数据集上通常不会有好的表现。
![1240](https://upload-images.jianshu.io/upload_images/4685306-31341f2a2319a767.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
image.png
提高机器学习模型泛化能力的思想可以追溯到托勒密时代的哲学思想，现在通常被简称为**奥卡姆剃刀（Occams‘s razor）**。该原则指出，在同样能够解释一直观测现象的假设中，我们应该挑选最简单的哪一个。
如何避免过拟合和欠拟合？
避免欠拟合：
1）寻找更好的特征，具有代表性；
2）用更多的特征，增大输入向量的维度
避免过拟合：
1）增大数据集合 - 使用更多的数据，噪声的比重减少
![1240](https://upload-images.jianshu.io/upload_images/4685306-9410c668c3ef9b87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
image.png
2）减少数据特征 - 减少数据维度
3）正则化方法 - 增加正则项
4）交叉验证的方法
参考文献：
1、深度学习 [https://github.com/exacity/deeplearningbook-chinese](https://github.com/exacity/deeplearningbook-chinese)
2、[http://scott.fortmann-roe.com/docs/BiasVariance.html](http://scott.fortmann-roe.com/docs/BiasVariance.html)
