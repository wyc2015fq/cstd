# AI大神Yann LeCun谈近期AI发展：最聪明的AI在常识方面还不如猫 - 人工智能学家 - CSDN博客
2018年07月19日 21:37:30[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：78
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3ia8w8mHZeUhc9pLtKWzR8K2TyOpF0ZVD6S8gblBP3cqEUgaHGHKr1ia8A/640?wx_fmt=png)
来源：网易智能
摘要：从虚拟助手到巨大的商业效益，人工智能正在重塑信息时代，作为著名的人工智能先驱者之一，Yann LeCun又是怎么看待这一领域的发展、近期的变化和潜力的呢？
从虚拟助手到巨大的商业效益，人工智能正在重塑信息时代，作为著名的人工智能先驱者之一，Yann LeCun又是怎么看待这一领域的发展、近期的变化和潜力的呢？
20世纪80年代中期，人工智能的研究陷入了完全停滞的状态。首先，计算机缺乏将事情促成的处理能力，与现代智能手机相比，软盘驱动设备在先进程度上相形见绌，直到1989年，计算机芯片才能够容纳100万个元件，相比之下，现代的高端计算机芯片则能够容纳80亿个元件。
另一个障碍也阻碍了人工智能的成形，1984年，美国人工智能协会召开了一次重大会议，行业先驱马文·明斯基(Marvin Minsky)在会上警告商界，投资者对人工智能的热情最终将会变成大失所望，果然，人工智能领域的投资开始剧降。
那时候，像Yann LeCun这样的梦想家选择了不去过多关注那些负面的东西，这是一件好事，当这位法国人加入位于新泽西的AT&T贝尔实验室适应性系统研究部门时，他还不到30岁，在那里，他对人工智能充满着热情。在贝尔实验室，LeCun开发了许多新的机器学习方法，包括模仿动物视觉皮层的卷积神经网络，LeCun的研究也促进了图像和视频识别以及自然语言处理的发展。
“整个人工智能背景下的统计学习概念在1960年代末似乎消失不见了。”LeCun回忆道，“人们或多或少抛弃了它，然后在80年代末，神经网络又重新成为人们关注的焦点。因此，当训练多层神经网络的学习算法在80年代中期出现时，它引起了人们的兴趣。”
在捕捉这场革命的过程中，LeCun一直都极其谦逊，甚至谦逊过头了，他的发现创造了历史，但他却很少提及自己的名字或成就，他不会自视非凡，事实上，他的个人网站上有一整个区域都是关于双关语的，其中有这样的自我告诫：“禁止酷刑的日内瓦公约以及禁止施加残酷和非常惩罚的美国宪法，禁止我连续写出三个以上凶残狠毒的双关语。”
LeCun也不愿满足于他在计算机科学上取得的任何应得的荣誉，如今，他担任Facebook的首席人工智能科学家，在那里他孜孜不倦地努力实现新的突破，而今天，他带领我们进行一次特权之旅——比坐在前排看明星表演还要过瘾，因为他就是这场秀的明星主角——洞悉人工智能的发展、近期的变化和潜力。
关于Yann LeCun，他在人工智能研究领域，Yann LeCun、Geoffrey Hinton 和 Yoshua Bengio一直被公认为深度学习三巨头，他是计算机科学家，被誉为“卷积网络之父”，为卷积神经网络（CNN，Convolutional Neural Networks）和图像识别领域做出了重要贡献，以手写字体识别、图像压缩和人工智能硬件等主题发表过190多份论文，研发了很多关于深度学习的项目，并且拥有14项相关的美国专利。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3iacL0hwjzuLVMR9zx5LnVgXPiaCWqJJIvtRLvX2cAA5ia4IPfWBAfN5VoQ/640?wx_fmt=jpeg)
目前，Yann LeCun是Facebook人工智能研究院院长，纽约大学的 Silver 教授，隶属于纽约大学数据科学中心、Courant 数学科学研究所、神经科学中心和电气与计算机工程系。加盟Facebook之前，Lecun已在贝尔实验室工作超过20年，期间他开发了一套能够识别手写数字的系统，叫作LeNet，用到了卷积神经网络，已开源。他在 1983 年在巴黎 ESIEE 获得电子工程学位，1987 年在 Université P&M Curie 获得计算机科学博士学位。在完成了多伦多大学的博士后研究之后，他在 1988 年加入了 AT&T 贝尔实验室（AT&T Bell Laboratories /Holmdel, NJ），在 1996 年成为 AT&T Labs-Research 的图像处理研究部门主管。2003 年，他加入纽约大学获得教授任职，并在 NEC 研究所呆过短暂一段时间。2012 年他成为纽约大学数据科学中心的创办主任。2013 年末，他成为 Facebook 的人工智能研究中心（FAIR）负责人，并仍保持在 NYU 中兼职教学。
## **“人工智能”的开端**
作为一个研究人工智能历史的学生，LeCun可以一个不漏地说出该领域的里程碑事件：始于1956年夏天在达特茅斯举行的一次头脑风暴会议，“人工智能”一词就是在那次会议上被创造出来的。仅仅一年之后，弗兰克·罗森布拉特（Frank Rosenblatt）在康奈尔航空实验室发明了感知器。第一个实现版本是Mark 1 Perceptron感知器，那是一个巨大的矩形机器，包含400个随机地连接到简单的图形检测器的光电池，以及一个可训练分类器。
“它是第一个能够学会以一种不平凡的方式识别简单模式的神经网络。”LeCun说，“你可以用它们来进行简单的图像识别，但不能识别照片中的物体，也不能进行任何推理或规划。”
十年以前，模式识别系统一直都需要人类完成大量繁重的工作才能够识别自然图像中的物体。“你需要做很多的工作来构建一个工程模块，将图像转化成一种代表性的东西——通常是一个长长的数字列表，它们能够被简单的学习算法处理。所以基本上你必须亲手完成这项工作。”他补充道，早期的语音识别和由计算机驱动的翻译也是如此：手动工程意味着付出巨大的努力，却没有得到多少回报。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3iaic2bWARnI218fvGTNyiccPFJr8hwkorzYhfGhyWia4yjpyibY3iccVwuOag/640?wx_fmt=jpeg)
那么是什么改变了计算机科学呢？“在所有的那些应用中，深度学习和神经网络已经在性能上带来了显著的改善——同时也大大减少了必要的体力劳动。”LeCun说道，“这使得人们可以将这些应用扩展到很多不同的领域。”
这就提出了这样一个问题：计算机首先是如何“学习”的。神经网络相当于对大脑的一种软件模拟；它们处理诸如视觉图像的信息，并试图得到一个正确的答案。但如果答案不是那么正确呢？输入“反向传播”(backpropagation)，这是一种促使神经网络学习的反馈流算法。
## **Yann LeCun和反向传播算法**
反向传播的突破性发现出现在1986年。当时，杰弗里·辛顿（Geoffrey Hinton）教授成为最早描述计算机通过反复执行任务来学习的方法的研究人员之一。在学习的过程中，计算机的神经网络每次都会“往减少错误的方向进行调整”。
LeCun不仅很好地利用了辛顿所打下的基础——他还帮助奠定了基础。20世纪80年代初，辛顿第一次提出了“反向”（backprop）的想法，但后来他放弃了，因为他认为这个想法行不通。
但在1985年，LeCun写了一篇论文来描述反向传播的一种形式。论文是用法语写的，基本上没有被很多人读过——但至少被一个重要的人读到了。那就是辛顿。在开始在AT&T贝尔实验室(晶体管的诞生地)工作之前，LeCun在多伦多大学在Hinton手下工作，担任博士后研究员。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3iagqzAiad8q1T4qLeCOwAgP4ic5Mfy10ibicSwafiaYwQUZ7xQAqLL9wDh96w/640?wx_fmt=jpeg)
“所有的机器学习都是关于纠错的。”LeCun解释道。想象一下，给计算机展示”成千上万张汽车和飞机的图片，每一次参数都自行调整一点，输出结果随之距离正确的参数近一点——如果你足够幸运的话，最终会达成一个让机器能够准确识别出每一辆汽车和每一架飞机的配置。”
描述最终结果的时候，他激动地说：“机器学习的神奇之处在于，即使是系统从未见过的图像，也会被正确地分类。”
不过，他还是忍不住有点爱开玩笑。“有各种各样的技巧可以让反向传播发挥作用，而且它还是有点黑色艺术——但现在我们有了一个秘方。如果你按照秘方来做，它每次都会奏效。”
## **数据、人工智能和商业：天空与极限**
人工智能时代的数据被以各种各样的方式描述：新的黄金，新的石油，新的货币，甚至新的培根。到目前为止，每个人都明白：从审计到电子商务，数据对企业来说都很有价值。但也要理解数据能做什么和不能做什么，这是众多商界人士仍必须面对的一个区别。
“数据对于把机器学习变成一门生意很重要。”LeCun坦言，“你需要数据来训练你的系统，你的数据越多，你的系统就会越精准。所以，从技术目标和商业角度来看，数据越多越好。”
但也有数据会变成油腻的培根的时候，如果你愿意的话：也就是说，它不能让使用人工智能的机器变得更智能。“在人工智能的研究方面——我们在Facebook研究的东西，还有很多在DeepMind、谷歌和其他地方的人研究的东西——我们不使用内部数据来测试它们。”LeCun说，“我们使用公共数据，原因是我们喜欢将我们的方法与学术研究领域的其他人进行比较。拥有更多的数据对于开发更好的方法并不重要。事实上，很多努力都是为了减少达到给定性能水平所需的数据量。”
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3ialWXFCckBrich17Qh7TjJ8QYff76EAQm0yKws7qnojMHvpogjYHiaNEsQ/640?wx_fmt=jpeg)
这一点在学术界尤为明显。在学术界，关键的任务不是分析处理海量的数据，而是充当LeCun所说的“新思想的先锋”。与此同时，在寻找解决方案之前，建立人工智能战略的企业需要自我评估。“这取决于人工智能对你的操作有多重要，”LeCun指出。“如果你只是想应用现有的人工智能方法，你可以使用许多公司提供的云服务。”这是相对容易的。“一些企业和出租技术可以帮助人工智能的部署；LeCun以蒙特利尔的AI元素为例。
对于企业来说，最大的挑战是建立自己的工程团队。“基本上，人工智能工程师和科学家现在需求量很大，所以你得高薪聘请他们。他们不便宜，因为他们很稀有。”
## **两种学习方式，一种光明的未来**
LeCun概述了构成当今人工智能基础的两种不同类型的学习方式：监督式学习和非监督式学习。在监督式学习中——适用于超过95%的机器学习应用——人类操作员训练机器来逐渐提升对图像或其他形式的输入的识别能力。打个比方，把它看作你可以无意识地调整的旋钮，越是调整，机器就会越接近产生你想要的那个输出结果。
非监督式学习（或者说“自我监督式学习”）拥有着巨大的潜力，尽管它在今天的机器学习中所占的比例要小得多。“它本质上是根据我们从世界上的其他事物中感知到的东西来预测一切。”LeCun说。他以“视频预测”为例：“给机器播放一小段视频，然后让它预测接下来会发生什么。”
现在的情况有点像是在预测接下来会发生什么，从而实现这种特殊的突破。但可以肯定的是，对于科学家、学者和高科技巨头来说，追求非监督式学习有着十分巨大的吸引力。非监督式学习的好处在于，能够完成我们目前无法完成的所有应用。”LeCun说道，“我们想要拥有智能的虚拟助手，你可以和它们交谈，它们可以理解你所说的一切。它们会有足够的背景知识来在日常生活中给你提供帮助。”
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWffaTJEbxvLjBz8DU0sW3iambiaMicHmsEyeibyYbsAQaze7MsBWQfTeW0wGUkbBibbWFNf6AtH8yzbSg/640?wx_fmt=jpeg)
他停顿了一下。“这有点像电影《她》（Her）。你看过那部电影吗？”简单介绍一下：在斯派克·琼斯(Spike Jonze)2013年执导的这部电影里，华金·菲尼克斯(Joaquin Phoenix)饰演一个孤独的作家，爱上了他的虚拟助手，该助手由斯嘉丽·约翰逊(Scarlett Johansson)配音。原来LeCun很喜欢这部电影。
“它对人们和变得智能的虚拟助手之间可能会发生的互动刻画得不差。”LeCun表示，“我们还远没有那样的人工智能技术能让我们制造出那样的机器。这主要是因为现在的机器不具备常识。”
常识？但机器不是很多时候都比人类更善于做决定吗？机器必须要有常识——它们有吗？LeCun解释了它们为什么没有常识：“我们没有能力让机器去学习庞大的背景知识：我们在出生以后的最初几周和几个月里所获得的关于这个世界的庞大背景知识——很多动物也获得了这种背景知识。”
正因为如此，我们对机器人的一些最简单的假设就站不住脚。“我们不可能有灵巧的机器人。”LeCun说道，“我们不可能有能够把我们的洗碗机装满然后清空的家用机器人。这超出了当今机器人技术的水平，这并不是因为我们不能制造机器人。而是因为我们不知道如何给它们制造大脑。我们不知道如何训练它们，让它们知道该如何握住东西，如何绕过障碍物，如何装载东西。”他补充说：“家猫都比最聪明的机器有常识得多。”
鉴于LeCun在将人工智能带入生活中所扮演的重要角色，这听起来或许有些轻率。但当他想到一个光明的人工智能未来在医学等领域正以闪电般的速度逼近时，他也表现出了极大的热情——甚至惊奇。
“对于医学图像分析，我们能够训练卷积神经网络来从CT扫描图或MRI（核磁共振成像）图像检测肿瘤，或者从皮肤图像检测黑色素瘤。”他称，“我认为这将会对放射学产生深远的影响。”
不管持有什么样的观点，LeCun都一直充满着乐趣，一如当初第一天到贝尔实验室工作的的那个二十来岁小伙。
7月8日是LeCun 58岁生日那天，他发布推文说：“深度神经网络既漂亮，又光亮透明。”
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
