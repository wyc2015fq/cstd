# 性价比高出英特尔45%，亚马逊的云服务器芯片如何做到？| 解读 - 人工智能学家 - CSDN博客
2018年12月23日 18:34:55[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：57
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/DT8udUick9sLaicu43u7bt6ulk1tshgEYXbibib732oaLLGN9r27aufuDmbr2sB3TluUVBS9OicUmicAcQeruvodyaOQ/640?wx_fmt=png)
来源：TheNextPlatform
编译：机器之能 张玺
摘要：到目前为止，亚马逊和其他大型云运营商几乎全部使用英特尔的 Xeon 芯片。虽然在服务器芯片市场，英特尔市场占有率非常高，但亚马逊正使用折扣策略来赢得客户。亚马逊表示，基于 Graviton 的云服务比英特尔处理器上运行的现有产品「成本低得多」，具体在某些处理任务上，能够减少 45% 的成本。
智能网卡与服务器处理器有何区别？如果你指的是亚马逊云服务（Amazon Web Services），两者大概相差三年。
在西雅图总部，公有云市场大佬亚马逊 re:Invent 2018 大会现场，亚马逊推出了基于 ARM 架构的 Graviton 服务器处理器。除去已经在 AWS 运行的 Intel Xeon 和 AMD Epyc 处理器，Annapurna Labs 表示 Graviton 还支持 EC2 虚拟计算服务。
2015 年，亚马逊以 3.5 亿美元收购 Annapurna Labs。早些时候，亚马逊从 Calxeda 挖来了几名员工，Calxeda 是一家致力于开发基于 ARM 架构服务器系统的初创公司。
过去一年的 ARM 服务器市场波谲云诡：先是高通宣布放弃 Centriq 2400；Ampere（获得私募基金 The Carlyle Group 投资）抢先收购 X-Gene，让 Applied Micro 终于获得喘息之机。
如此看来，AWS 创造了自己的服务器芯片，放弃使用目前 ARM 架构服务器市场最领先的 Marvell（前身为 Cavium）ThunderX2 芯片，就显得尤为重要。然而，这并不代表 Marvell 或者 Ampere──如果未来实现了超强浮点并行处理，拥有 A64FX 处理器（48 核且具备可伸缩矢量扩展）的富士通也将纵横 ARM 市场──ARM 芯片未来在 AWS 公有云市场一定毫无作为。
我们认为 AWS 已经在 Annapurna Labs 中研发「Alpine」系列双核及四核 ARM 芯片，为自己的服务器集群创造 SmartNIC。SmartNIC 是服务器集群不可或缺的。除了 EC2 上的 Xeon、 Epyc 和现在的 Graviton 处理器的操作系统和应用之外，服务器集几乎能卸载所有功能，使得公有云计算核心可以极大程度上运行应用。
虽然之前说过，但我们还是想再次强调：大部分 Hyperscaler 和云构建仍依赖 SmartNIC 的发展。由于 InfiniBand 网络具备搭配智能网卡 GeniusNIC（Mellanox Technology 的命名虽然有些玩笑意味，但能看得出企图心）的卸载模型，HPC 中心能够进一步提升价值。最终，Mellanox Technology 的落后也是由于相同的原因：Hyperscaler 和 HPC 中心经常采用卸载计算。核心计算十分昂贵，相对而言，卸载计算就不一样了。
2016 年 1 月，亚马逊与 Annapurna Labs 发布了 32 位 Armv7 与 64 位 Armv8 设计，两者已达到「企业级性能与特征」，如支持 DDR4 内存、2MB 二级缓存。自那以后，再没有透露好更多关于「Alpine」系列芯片的消息。
Arm Holdings 生产的基于 Cortex-A15 核心的双核及四核 32 位元件，其主频分别达到 1.4 GHz 与 1.7 GHz；基于 Cortex-A57 设计的四核元件，主频达到 1.7 GHz。上述 Arm Cortex 核心支持超标量通道及乱序执行，但并不具备超线程。
这些设备的进给量与速度并没有任何特别之处，由于 Amazon 并未公布任何细节，我们不展开讨论具体架构。但我们推测有两点非常不可思议：亚马逊如何生产这些廉价设备；亚马逊如何运用服务器卸载计算以使得服务器、网络及存储更加高效。
主流厂商的策略确定无疑：Mellanox 主推 Bluefield 多核 ARM 处理器，微软在 Azure 公有云的服务器上使用 FPGA 作为网络加速及计算引擎，Netronome 主推 Agilio 网络适配器。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/DT8udUick9sLaicu43u7bt6ulk1tshgEYXkgFHqX487GOybibUzLfuEClWS7sJOcd1MvJY3oHZywlXIws5wVIKAxA/640?wx_fmt=png)
AWS 全球基础设施及客户支持业务副总裁 Peter DeSantis 在 re:Invent 2018 大会介绍了 Graviton Arm 服务器的工艺。
虽然我们不清楚 Graviton 芯片，Graviton 看起来是一个更加实用的处理器，其与 Intel Skylake Xeon-D-2100 v2 类似，搭配 8 到 18 个核心，主频在 1.6 GHz 与 2.3 GHz 之间（通常核心数越多，时钟频率越低）。如果打开 AWS 网站，大家会发现一句申明「Gravitons 基于 64 位 Neoverse 核心」，这几乎能断定 Cosmos 核心是定制的。
Cosmos 包含 ARM Cortex-A72 与 Cortex-A75 设计的微调版本，意图达到 16 纳米芯片工艺水平，其代工厂很可能是台湾半导体制造公司（Taiwan Semiconductor Manufacturing Corp）。大家回想下，Arm 发布的 Neoverse 正是 10 月曾发布的数据中心 Arm 芯片的翻版，其每年性能提高幅度达到 30%，并将在 2021 年前完成 7 纳米到 5 纳米制造工艺的升级。
所有 AWS 的公开信息表示，通过 EC2 A1 让业界熟悉的 Graviton 处理器，最多支持 16 个虚拟 CPU、32GB 主内存，服务器适配器的网络带宽达到 10 Gb/秒，弹性块存储（EBS）带宽达到 3.5 Gb/秒。当我们想了解更多技术细节时，AWS 并未确认目前使用哪个 Cosmos 核心，亦未确认 Graviton 具备 16 个核心且无法通过同步多线程（SMT）为各个核心提供虚拟多线程。
（SMT 支持通常由 ARM 许可证持有用户添加，尚未成为 ARM 基本内核许可证部分。随着 2019 年「Ares」内核到期，情况可能会改变。）AWS 向 The Next Platform 确认，EC2 A1 具备 Graviton 芯片，主频达 2.3 GHz。单就整数计算而言，Graviton 已能与 Xeon-D 抗衡，或许达到了 Xeon SP 的下限水平。
不同 A1 的进给量和速度如下：
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/DT8udUick9sLaicu43u7bt6ulk1tshgEYXyVuJibuzuuibC8C07DE6bBQl7icgicSHO6LaxT8u5cLtI66uhQ69Kgvq7g/640?wx_fmt=png)
我们推断内存及内存带宽不多，可能只有一个内存控制器和两个内存通道，最高容量 512 GB，搭配十分昂贵的 128 GB 记忆棒，即便使用便宜的 8 GB 记忆棒也可轻松达到 32GB。Annapurna Labs 可能在芯片上放置了大量内存你控制器，我们认为其并不支持 SMT，推断芯片上具备 16 个内核。一个内存控制器搭配八个核心是很好的平衡选择，但如果大家想让计算能力和内存带宽恢复平衡，四个内存控制器的效果甚至会更好。（考虑到 AWS 并未大肆炫耀，该项可能仍未实现。）
A1 采用 Amazon Linux 2 系统（红帽 Linux 与亚马逊 CentOS 克隆版结合的自研升级系统），亦支持 RHEL 和 Ubuntu 服务器系统，未来将支持其他操作系统──如果以后 AWS Arm 服务器芯片支持 Windows Server，应该十分有趣。
基于 Arm 的 A1 EC2 目前在美国东部、西部及欧洲（爱尔兰）等区域可用，订购类型一般涵盖 On-Demand、 Reserved、Spot、Dedicated 及 Dedicated Host。AWS 特别提醒，上述 A1 实际应用于内存带宽不做特别限制的横向扩展工作负载，如 Web 服务器、开发环境、缓存服务器或容器化微服务等轻量化及无状态服务。AWS 表示与 EC2 上同等性能的 32 位服务相比，这些服务成本能降低到 45%。不过，AWS 并未说明具体的比较对象。
划重点了。
我们来看看 Arm 服务器之于基础设备的野心有多大。毫无疑问，A1 会有无数的衍生版本。对于支持极有可能成为下一代智能网卡处理器的发展来说，这是件好事。算上基于 Arm 的 A1，AWS 还在 EC2 主题上研发了一些其它基础设施变体。新一代 C5 服务在这些变体之间的以太网速率达到每秒 100Gb，适用于那些带宽依赖的 HPC 仿真建模、机器学习训练及密集数据分析工作。
如同 C5 和 C5d，C5n 基于双插槽服务器节点，搭配定制 Skylake Xeon SP 8000 Platinum 系列处理器，各芯片可能具备 18 个内核且主频达到 3 GHz。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/DT8udUick9sLaicu43u7bt6ulk1tshgEYXjgKYfLRFWg79fSXamnC218MtQA6wtYia3xFMGArDoRdva8TAehxuCUg/640?wx_fmt=png)
除了额外带宽之外，C5n 的数据队列是 C5 和 C5d 的数倍至多──32 比 8 的弹性网络接口（Elastic Network Interface，应用于 Annapurna 处理器，布置在网卡附近，使其更加智能──帮助网络适配器中数据更快的在内核中流转。无论是单个可用范围或区域内跨越多个可用范围，带宽在同一区域内都可用）。
C5n 可用于 EC2 及其他服务器集群，与 S3 对象存储或 Elastic MapReduce、Relational Database Service 及 ElastiCache 等服务连接。C5n 与 A1 的可用区域一致，业务范围还附加美国政府私有云 GovCloud。
最后，去年 10 月 AWS 推出的 P3 GPU 加速服务使得以太网达到每秒 100 Gb，服务器链路上限达到每秒 25 Gb。具有更快网络的 P3dn 将于下周推出，其配备 32 GB HBM2 内存的 Volta Tesla V100 GPU 加速器，而初代 P3 配备 16 GB HBM2 内存的初代 Volta 加速器。上述服务基于一对定制 24 核 Xeon SP 处理器，机箱中最多配备 8 个 GPU。
作为最大云计算提供商的 AWS 提供了 ARM，这对 ARM 来说是一次胜利。
在过去五年里，Calxeda、Applied Micro、英伟达、三星、博通、、Cavium、Marvell、AMD 和高通等多家先驱投身到 Arm 服务器芯片的研发。但发展到今日，这些想去几乎全军覆没。Moor Insight & Strategy 的行业分析师帕特里克·莫尔海德（Patrick Moorhead）上周五在给 CNBC 的邮件中写道：「AWS 接受 ARM 为 ARM 带来了可信度，将 ARM 的业务扩展到更多的云参与者和工作负载。」
尽管亚马逊的大部分营收仍来自商品销售，但 AWS 已成为该公司财务健康的关键。第三季度，亚马逊超过一半的营业利润来自 AWS。亚马逊在线商店的收入本季度同比增长 10%，而 AWS 服务的营收增长了 46%。AWS 现在有超过 125 种服务可供客户使用，包括核心的 EC2 计算服务。
在接下来的几年里，AWS 可以发布基于更强大 ARM 芯片的新实例。现有实例使用 ARM 于 2015 年推出的 Cortex-A72 系统。但更重要的是，其他云计算提供商将可能同样开始使用 ARM 技术发布实例。
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
