# 《自然》杂志：面对“电车难题”，不同国家的人有不同的道德选择 - 人工智能学家 - CSDN博客
2018年11月05日 20:58:52[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：51
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVNbCnGN48LSeBwXITMwicnESdxToiccX2rWYSic5I3TibLuT7SLL4Lz6U9ElGHo4u5DicORjKIIRX8ZGg/640?wx_fmt=jpeg)
来源：36Kr
电车难题原本只是一个思想实验。但是无人车的发展却绕不开这个问题。因为机器在无论如何都会撞死人的情况下必须靠预先植入的道德代码做出判断：该牺牲谁，该保谁。但是一项有全球230万人参与的调查表明：这个问题并不存在普适性的道德选择。这个问题的解决也许需要进行一场全球性的公开讨论才能达成共识——或者永远也无法达成共识。《自然》杂志的一篇文章对此进行了综述。
目前好几家主流技术公司和汽车制造商都在开发着无人车。
当一位司机猛踩刹车以避免撞上非法穿过马路的行人时，其实他正在做出一个道德决定，这个决定会把风险从行人转嫁到车内的乘客身上。无人车可能很快也要自行做出类似的道德判断——但是给汽车设定通行的道德代码也许是一项棘手的任务，这是对全球230万人进行调查后得出的结论。
这项有史以来有关机器伦理的最大型调查已经在《自然》杂志上发布。调查发现，许多知道司机做出决定的道德原则往往因国家而异。比方说，有一种场景下行人和乘客的某种组合都会因冲撞而死亡，相对繁荣、体系较为完善的国家的人对放过非法穿越马路的行人的态度会没那么友好。
Iyad Rahwan 是MIT的计算机科学家，也是本项研究的联合作者之一。他说：“说到机器伦理，有些人以为好像可以通过想出一套完美的规则指导机器人来实现，但我们的数据表明普遍规则并不存在。”
这项调查的名字叫做道德机器，里面列举了13种不可避免会有人死的场景。受访者被要求在各种情况下做出赋予谁生存权的选择，这些情况涉及到不同的变量组合：年轻或者年老，有钱或者没钱，更多人或者更少人。
大家极少会遇到如此突出的道德困境，部分批评者则质疑调查中提出的那些场景是否与无人车的道德与实际问题相关。但研究作者成这些场景代表了司机每天都要做出的微妙的道德决定。他们提出，这些发现揭示了政府和无人车制造商必须考虑的文化上的微妙之处，如果他们希望这种车能获得大众接受的话。
至少有一家攻关无人车的公司——德国汽车制造商奥迪说这项调查可以帮助他们推动有关这些问题的重要套了（其他有着无人车研发计划的公司，包括汽车制造商丰田和技术公司Waymo与Uber，拒绝对该发现置评。）耶鲁大学的社会学家Nicholas Christakis则对这些发现感到着迷。
“这是一份引人瞩目的论文，”他说。关于道德是否具有普遍性或者因文化而异的争论由来已久，Christakis说，而现在这个有关如何对无人车进行编程的“21世纪问题”让这个问题重新又被点燃。
**未选之路**
一些全世界最大型的技术公司，包括Google的母公司Alphabet、Uber和Tesla，以及汽车制造商现在都有自己的无人车计划。很多这些公司都认为这种车能够改善道路安全性，促进交通并且提高燃料效率。社会学家则称这种车会引起道德问题，而且可能会对公共安全和环境造成意外后果。
2016年，Rahwan的团队无意中发现了一个无人车的道德悖论：在调查中，大家说自己希望无人车能保护行人，哪怕这意味着要牺牲乘客——但同时他们又不想购买被按照这种规则编程好的无人车。
出于好奇无人车将来会不会引发其他的道德难题，Rahwan聚拢了一支由心理学家、人类学家以及经济学家组成的团队，发起了道德机器项目。在18个月内，这项在线调查记录了来自233个国家和地区的人做出的4000万项决定。
其发现是，无论年龄、性别或者居住过差异如何，大多数人都决定首先拯救人而不是宠物的生命，先拯救一群人而不是一个人的生命。这些回应跟也许是目前有关无人车的唯一政府性指南（2017年德国道德委员会关于自动化及联网驾驶的报告）建议的规则是一致的。
但是共识也就到此为止了。当论文作者分析了受访者至少超过100人的130个国家的人的回答之后，他们发现那些国家可以分为3个组。一个包括北美和若干欧洲国家，其共同特点是在这些地方历史上基督教曾经是统治性的宗教；另一个组说日本、印度尼西亚和巴基斯坦，有着深厚的儒教或者伊斯兰教传统。第三组是中美洲和南美洲，以及法国和前法国殖民地。不同组之间的回答差别很大，比如说第一组相对于第二组对于牺牲老人拯救年轻人表现出更强烈的倾向。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVNbCnGN48LSeBwXITMwicnEW7sCEmt7sOnMiaeubMBiab3g3pv0oz10UoTH1GkXld1t3IsuJ5fOmcoA/640?wx_fmt=jpeg)
道德罗盘：对全球230万人进行的调查发现有不同的道德原则来指导司机做出决定。受访者需要面对13种场景，在这些场景里面，行人和乘客的某种组合会因为碰撞而死亡是不可避免的。受访者需要决定应该拯救谁的生命。科学家利用这些数据对国家和地区进行分组，最后基于其道德态度分出了三组（西方、东方、南方）。
研究人员还识别出一个国家内其居民的一般观点与社会与经济因素的相关性。该团队发现，有着强有力政府体系的国家，比如芬兰和日本，相对于与政府体系较弱的国家，如尼日利亚和巴基斯坦，会更倾向于选择撞非法穿过马路的行人。
有的场景则迫使受访者在一头的无家可归者以及另一头的企业主管之间做出抉择，这方面的选择又揭示了另一个背离点。大家所做选择往往跟其所处文化的经济不平等程度相关。来自贫富差距相对较小的芬兰对于拯救谁并没有表现出明显的倾向性。但是经济差异性很大的哥伦比亚的一般受访者则选择撞死地位低的人。
温哥华英属哥伦比亚大学心理学家Azim Shariff发现这个结果很有趣，因为这说明这项调查真实反映了大家的道德偏好。“如果你假设收入不平等程度较低的地方有着偏好平等主义政策的话，这项调查表明支持这些政策的道德规范在大家玩这些游戏时就已经表现出来了。”
**前面有坑？**
尽管无人车尚未面向公众开始销售，但测试版的无人车已经在若干美国城市巡游了。到2021年，至少有5家制造商希望有无人车或者无人卡车得到广泛使用。
南卡罗来纳大学的法学教授Bryant Walker Smith对道德机器调查是否具备任何实际价值表示怀疑。他说这项研究不切实际，因为在现实生活中很少有这样的情况发生，也就是车辆要面临在碰撞两种不同类型的人的选择。Walker Smith说：“我也很想知道无人车会如何处置面临小行星撞击的情况。”
但研究作者说他们的场景代表了人类司机日常做出的不怎么重要的道德判断，而这些判断有时候会是十分致命的。在崎岖山路为了躲避骑自行车的人而打方向盘的司机会增加撞上来车的机会。如果道路上无人车的数量增加，那么它们牵涉到此类事故的可能性也会增加。
一些汽车公司正在倾听。奥迪负责领导研究无人车伦理的Barbara Wege说此类研究很有局爱之。Wege认为无人车会减少事故发生，事故率将比人类司机要低——但那些牵涉到机器人的事件会引起更多的注意。
像道德机器这样的调查可以帮助开启关于这些不可避免的事故的公共讨论，从而培养大家对无人车的信任。她说：“我们需要就我们愿意承受哪些风险达成社会共识。”
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
