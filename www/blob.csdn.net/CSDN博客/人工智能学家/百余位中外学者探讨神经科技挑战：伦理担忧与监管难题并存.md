# 百余位中外学者探讨神经科技挑战：伦理担忧与监管难题并存 - 人工智能学家 - CSDN博客
2018年09月10日 21:22:56[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：74
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBVs5YdNfKicH5WZAa8EVrYtKBEcZgJeAicpMcbQpiayvpmgicDO8mtB751AHpAdtHHxqBEXITLF5qWjTQ/640?wx_fmt=jpeg)
来源：澎湃新闻
“脑电图图纸也许会读出人的意识”、“脑机接口技术可能使个人的行为被他人操纵”、“人造大脑的发明可能取代人类的角色”……这些形形色色的言论道出了人们对于神经科学的道德和伦理担忧。澎湃新闻专访了神经伦理学领域的研究人员，就神经科学的伦理问题进行讨论。
2018年9月6日至7日，以“推动负责任创新 增进全球健康福祉”为主题的国际神经科技创新研讨会在上海举行。此次研讨会的重点是探讨神经科学独特的伦理、法律和政策挑战，为神经科学创新者提供一个交流平台。此外，部分国家分享了脑科学计划的进展情况。
这次研讨会由中国生物技术发展中心与经济合作与发展组织（OECD）共同发起，来自美国、英国、法国、德国、加拿大等13个OECD成员国的外方专家和中方专家共百余人参加了会议。
**各国分享脑计划进展**
在研讨会中，中国科学院院士裴钢分享了接下来15年中国脑计划的三个重点领域。第一是认知障碍疾病的研究，例如抑郁症和自闭症等，第二是脑的开发，可以在入学儿童方面做重点计划，第三是类脑科技，比如人工智能等。在负责任创新层面，中国会参与国际性科技伦理标准的讨论，并为残疾人士提供更多的服务。
中国科学院院士蒲慕明提出了中国非人灵长类动物研究的四个目标：用非人灵长类动物作为模型来研究高层次的大脑认知功能，生成动物模型以供人类疾病和基础神经生物学研究，为可持续的灵长类生物学研究建立培训和教育项目，在人类灵长类研究中建立起严格的伦理惯例并向社会大规模传播非人类灵长类动物的重要研究成果。
韩国的脑计划在大脑行为和活动的测量领域取得了一些进展。癌症和艾滋海默症等疾病的研究也是其关注重点。但由于市场规模较小，韩国在神经科学成果市场化的过程中遇到了一些阻碍。
日本于2015年开始脑计划，对发现早期的艾滋海默症有了一定的研究积累，但还没有转化成药物。目前，日本正在尝试与企业和机构开展合作，为帕金森症病人提出改进型的干预和恢复措施。为了应对神经科技所带来的道德问题，相关的法律正在考虑中。
**隐私权、技术滥用和身份认同**
隐私权、技术滥用和身份认知一直是与神经科技密切相关的几大伦理问题，也是此次国际神经科技创新研讨会的主要议题。
参加本次研讨会的密歇根州立大学神经伦理学副教授Laura Y. Cabrera在接受澎湃新闻（www.thepaper.cn）记者专访时谈到了神经科学所涉及的隐私问题。她发现人们会担心自己的大脑数据被他人获取。她还提到，目前有些媒体错误地报道了脑成像技术，把该技术描述成能够读取人类意识的“读心术”。事实上，神经科学还远没有发展到那一步。
技术的滥用是人们对神经科技的另一个重要关切。亚利桑那州立大学法律、科技与创新中心主任Gary Marchant对澎湃新闻（www.thepaper.cn）记者表示，大脑数据的隐私性以及侵入性设备带来的潜在心理危害是神经科学的伦理问题之一。但他最担忧神经科技对人们心理和福祉的影响。他认为，神经科学技术会发展到可以被用来控制人们的行为。其他与会人员也谈到，人们担心的不是技术，而是技术的滥用，需要有个行之有效的体制来告诉我们该如何开发和使用技术。
与基因科学类似，神经科学也引发了关于身份认同的讨论。身份认同问题在其他科学领域已经被广泛的讨论过。但在神经科学中，这一问题涉及到不同的方面。大脑影响我们的爱好，行为和举动，也在某种程度上决定了我们是谁。“一些以大脑为对象的侵入性神经科技对人的身份认同提出了新的挑战”，Cabrera说。
**文化差异与监管难题**
神经科学伦理问题的跨文化讨论也是研讨会的重点之一。Cabrera认为，神经科学的伦理问题与文化有很大的关联。她向澎湃新闻记者分享了一个关于神经科学增强技术的跨文化研究。研究显示，在欧洲，人们比较担忧神经科技的安全性，而在拉丁美洲，尽管也存在对于安全性的忧虑，人们更多考虑到人的尊严和宗教相关的问题。她还提到，由于数据收集难度大的原因，目前尚未出现关于神经科学伦理问题的中西对比研究。
由文化背景而产生的伦理差异对给出全球适用的神经科学伦理指南产生了限制。但这类问题几乎在所有科学技术的应用中都会存在。与会人员提到，有一些基本的价值观是不会因为文化、宗教和国别的不同而改变的，这些价值观可以用作各国伦理框架的原则。例如，本次论坛的主题“责任”就是一个大多数文化都认同的价值观。
把公众带到同一个讨论的场域是政府监管的另一大难题。与会嘉宾指出，“目前还有很多人没有听过说神经科技或者可能并不理解这些技术的真正影响，这种情况下很难去询问大众的意见”。
Gary Marchant认为，神经科技提出了一些更广泛的关于自主权和道德方面的问题，超出了其他生物科学技术关于环境、安全和健康的讨论。“这类更抽象的问题往往会超出监管机构的管辖范围，给监管带来挑战”。他认为，公司和其他第三方必须建立起自己的道德框架，以促进这项有前途的技术负责任地发展。在论坛上，Gary Marchant提供了一个“工具箱”，列出企业或企业组织可以采取的促进负责任创新的行动。
他指出，对于政府监管而言，最大的问题是监管系统主要针对于神经技术在临床研究中的应用。但是，神经技术已经越来越多地应用于临床之外的领域，而目前没有适当的监管结构来处理这些情况。另一个问题是，技术的发展比监管完善的速度要快得多。
OECD科学与技术政策部负责人Dominique Guellec表示，本次研讨会是一个远大旅程的起点，其中的讨论将推动OECD未来政策的制定。
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
