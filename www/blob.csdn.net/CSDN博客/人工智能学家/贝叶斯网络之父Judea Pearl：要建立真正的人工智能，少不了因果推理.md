# 贝叶斯网络之父Judea Pearl：要建立真正的人工智能，少不了因果推理 - 人工智能学家 - CSDN博客
2018年05月20日 18:28:25[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：462

来源：专知
参与 | Yingying, Xiaowen, Sanglei 
2011年图灵奖得主，贝叶斯网络之父Judea Pearl认为现在人工智能的发展进入的新的瓶颈期，各种新的成果不过本质上不过是重复简单的“曲线拟合”工作。Pearl 认为人们应该更关注人工智能中的因果（Cause and Effect）推断，这可能是实现真正智能机器的必由之路。
如今人工智能的强大力量在很多方面要归功于贝叶斯网络之父Judea Pearl。早在二十世纪八十年代，他领导的研究就能使机器能根据概率推理工作。在他的最新著作“《The Book of Why: The New Science of Cause and Effect》”中，他认为：由于人们对智能的真正含义不完全理解，人工智能的发展正受到前所未有的新的阻碍。
三十年前，人工智能研究的主要挑战是将潜在原因与一系列人们所观察到的现象联系起来。 Pearl发现贝叶斯网络可以做到这一点。贝叶斯网络可以让机器很容易的推理出，一个从非洲回来的有发烧和身体酸痛症状的患者可能是得了疟疾。凭借这项工作，在2011年，Pearl赢得了计算机科学的最高荣誉图灵奖。
但是，正如Pearl所预见，人工智能领域陷入了概率关联的困境。如今，头条新闻每天都在不停的报道机器学习和神经网络的最新突破，比如计算机可以在一些游戏中战胜人类，也可以驾驶汽车。面对这些看似喜人的成果，Pearl却高兴不起来，他认为今天人工智能领域的技术水平只不过是上一代机器已有功能的增强版，也就是在大量数据中发现隐藏的规律性。最近Pearl指出： “几乎所有的深度学习突破性成果本质上来说都只是些曲线拟合罢了”。
在他的新书中，现年81岁的Pearl详细阐述了智能机器如何真正思考的愿景。他认为，关键在于用因果推理来取代简单推理。机器不仅需要把发热和疟疾联系起来，而且需要能够推断疟疾为什么能引起发烧。一旦有了因果推理能力，机器就有可能查询某种干预而引起的因果关系如何改变 — Pearl将其视为科学思想的基石。 Pearl还提出了一种形式化的语言，这种语言使得以“全新的贝叶斯框架驱动机器能够以概率的方式思考”成为可能。
Pearl期望因果推理可以为机器提供人类智能。他解释说，他们可以更有效地与人类沟通，甚至可以实现具有自由意志和邪恶能力的道德实体的地位。Quanta 杂志采访了他。这些对话的编辑和精简版本如下。
**为什么你的新书叫做“The Book of Why”？**
它是对过去25年来我一直在做的关于因果关系，它在一个人生活中的含义，它的应用以及我们如何提出对固有因果问题的答案的工作的总结。奇怪的是，这些问题已经被科学抛弃了。所以我在这里弥补了对科学的忽视。
**这是一个戏剧性的事情，科学已经放弃了因果关系。这不正是科学的全部内容吗？**
当然，但是在科学方程式中你看不到这种高尚的愿望。代数是对称的：如果X告诉我们有关Y的信息，那么Y就会告诉我们有关X的信息。但是，没有办法用数学写出一个简单的事实 - 例如，即将到来的暴风雨导致晴雨表下降，但反过来，晴雨表下降并不会导致暴风雨。
数学还没有开发出非对称语言来捕捉我们的理解，即如果X引起Y并不意味着Y引起X。
但是科学更宽容：在我们缺乏对不对称关系的的描述语言时，科学鼓励我们创造一个。这就是用上数学的地方。对于我来说，看到简单的因果演算解决了被认为是不明确或无法解决的问题，兴奋不已。
#### **几十年前，你通过让机器用概率方法推理在AI界成名。解释当时人工智能发生了什么事。**
20世纪80年代初出现的问题具有预测性或诊断性。医生会从患者身上看到一系列症状，并提出患者患有疟疾或其他疾病的可能性。我们希望自动系统和专家系统能够替代专业人员 - 无论是医生还是矿物探险家，还是其他类型的付费专家。所以在那时我提出用概率实现这个想法。
不幸的是，标准概率计算需要指数空间和时间。我想出了一个称为贝叶斯网络的方案，它只需多项式时间，并且非常透明。
#### **然而，在你的新书中，你将自己描述为今天在AI社区中背道而驰。为什么？**
只要我们的机器能够以不确定的方式推理，我就会去追求更具挑战性的任务：推理和因果关系。我的许多AI同事在不确定性做工作。有些研究圈子继续在诊断方面做工作，而忽略因果因素。他们想要的只是预测好，诊断良好。
我可以给你一个例子。我们今天看到的所有机器学习工作都是在诊断模式下进行的 - 比如说将对象标记为“猫”或“老虎”。他们不关心干预;他们只是想识别一个对象并预测它将如何及时发展。
当我开发出用于预测和诊断的强大工具时，已经知道这只是人类智慧的小小一角。如果我们想要机器推理干预（“如果我们禁止香烟怎么办？”）和内省（“如果我读完了高中怎么办？”），我们必须引用因果模型。关联关系是不够的 - 这是一个数学事实，而不是意见。
**人们都对人工智能未来巨大的潜力异常兴奋，你有什么看法呢？**
当我深入研究深度学习所做的事情时，我发现他们都被困在了简单连接的层次上。曲线拟合（Curve fitting）这个词听起来像是一种不和谐，也就是说，深度学习取得的所有巨大成就再某种程度上都不过是对数据的曲线拟合而已。从数学层次的角度来看，不管你如何巧妙地操作数据，以及你在操作数据时读取的内容，它仍然是一个曲线拟合的训练过程，尽管它看起来比较复杂。
**你谈论曲线拟合的方式，听起来好像你对现在的机器学习并不太满意啊**
不，我对机器学习非常满意，因为没想到这么多的问题可以用纯曲线拟合的方式就能解决。但我想问的是未来——下一步呢？你能让一个机器人科学家来规划一个实验，就能为悬而未决的科学问题找到新的答案吗？我们还希望与一个有意义的机器进行一些沟通，有意义表示能够匹配我们的直觉。如果你剥夺了机器人对因果等的直觉，你就永远无法有意义地进行交流。机器人不能说“我本应该做得更好”。因此，我们失去了一个重要的沟通渠道。
**拥有和我们一样有因果判断直觉机器的前景是什么？**
我们必须使机器具备环境模型。如果机器不具备现实模型，那么你不能指望它在现实环境中有智能行为。首先，人类编程的现实概念模型可能在 10 年内出现。
下一步是机器将假设此类模型属于它们自己，并基于实验验证和修改模型。这就是科学中一直发生的事情：例如人类最初认同地心说，后来发现了日心说。
机器人也是一样，它们将彼此沟通，将这个假设的世界转换成隐喻模型（metaphorical model）。
**您是何时与当前研究 AI 的人们分享这些观点的？他们有什么反应？**
AI 目前是分裂的。首先，一部分人陶醉于机器学习、深度学习和神经网络的成功之中。他们不理解我的观点，只想继续进行曲线拟合。但是和在统计学习范畴以外研究 AI 的人们谈论这些时，他们立刻可以理解。我读了一些近两个月关于机器学习局限性的论文。
**您是说出现了一种抛弃机器学习的趋势吗？**
不是趋势，而是一个严肃的内省过程，涉及这些问题：我们去向何处？下一步是什么？
**这是我最不想问您的问题**
我很高兴你没有问我关于自由意志的问题。
**那么您怎么认为自由意志呢？**
我们将开发出具备自由意志的机器人，绝对会。我们必须理解如何编程机器人，以及我们能从中得到什么。由于某种原因，就进化方面而言这种自由意志在计算层面也将是需要的。
**以何种方式？**
 你具备自由意志，进化已经赋予我们这种感觉。很显然，它提供了一些计算功能。
**机器人具备自由意志时会有明显的迹象吗？**
我认为第一个迹象将是机器人开始反事实地彼此沟通，如「你应该做得更好」。如果一组踢足球的机器人开始用这种语言沟通，那么我们将知道它们具备了自由意志。「你应该传球给我，我刚才一直在等，但你没有把球传给我！」「你应该……」（You should have）意味着你本应该做什么，但是没做。因此第一个征兆是沟通，第二个是踢出更好的足球。
**既然您提到了自由意志，我想我应该问您关于作恶能力的问题。我们通常认为作恶的能力是选择的能力。什么是恶呢？**
人们认为恶是贪婪或不满取代了社会的所有规范。例如，某人具备一个类似会说「你饿了，因此你可以做一些事来满足自己的贪欲或发泄自己的不满。」的软件模块。但是你具备其他软件模块，可以指导自己遵循社会规范。其中一个叫做同理心（compassion）。当你抬高自己的贪欲，超过了社会通用规范，那么这就是邪恶。
**那么我们如何知道 AI 何时掌握作恶能力？**
当机器人一直忽略一些软件模块时，这对我们来说就是一个明显的迹象。还有当机器人遵循一部分软件模块的建议而不听另外模块的建议时，当机器人忽略那些维持行为规范的模块的建议时，当机器人停止遵循这些模块时。
原文链接：
https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
