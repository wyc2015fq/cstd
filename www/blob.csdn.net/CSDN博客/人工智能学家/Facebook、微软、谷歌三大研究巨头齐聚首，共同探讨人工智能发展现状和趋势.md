# Facebook、微软、谷歌三大研究巨头齐聚首，共同探讨人工智能发展现状和趋势 - 人工智能学家 - CSDN博客
2018年02月20日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：323
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBUnYSGtt2iak7v0MsPW8kx6LzdZvnlfGd5oZ0rf4giaPX2kvuL3A3JvvnvOQfFMuq8y4jGMw79riaCuA/640?wx_fmt=png)
*作**者： 思颖、李诗*
*概要：日前 AAAS 在 reddit 上组织了一场问答，Facebook 人工智能研究院 Yann LeCun，微软研究院院长 Eric Horvitz，谷歌研究总监 Peter Norvig 共同出席此次活动，回答了观众提出的一系列问题。*
日前 AAAS 在 reddit 上组织了一场问答，Facebook 人工智能研究院 Yann LeCun，微软研究院院长 Eric Horvitz，谷歌研究总监 Peter Norvig 共同出席此次活动，回答了观众提出的一系列问题，包括如何研究更通用的人工智能，如何看待深度学习热，AI 的下一个突破点，量子计算是否会对 AI 产生影响，用户的安全隐私问题等。
**Q：现在，为了让 AI 在围棋中战胜人类选手，或者使用深度学习解决特定的科学任务，我们投入了很多人力物力。取得的成就虽然很棒，但 AI 能解决的问题极其有限。能否找到一种苏格拉底式的 AI，能阐明它胜任的所有任务背后的原理。目前不将上百万种特定的 AI 组合在一起，你没法构建一个通用的 AI 系统。如何将只能解决特定问题的人工智能转为更通用的人工智能？**
**Yann LeCun**：在我看来，让机器通过观察来学习预测模型是 AGI（通用人工智能）的最大障碍。这并不是唯一方法。人类婴儿和许多动物似乎通过观察世界、与其交互得到一种常识 (与我们的 RL 系统相比，需要的交互非常少)。我的直觉是，大脑中很大一部分相当于预测机器，它训练自己去预测它所能预测的一切 (从观测中预测出未观测到的变量，例如通过过去和现在预测未来)。
可以用预测模型计划和学习新的任务，这一过程中只需与世界进行极少的交互。目前的「无模型」RL 系统，像 AlphaGo Zero，需要与「世界」进行大量的交互来学习 (尽管他们确实学得很好)。这种系统在围棋和象棋上都做得很好，因为这里的「世界」很简单，是确定的，而且可以在多个电脑上同时高速运行。与这种「世界」进行互动是可行的，成本极低。但这在现实世界中行不通，你不可能为了让系统只是学会不在悬崖边开车，而让它在悬崖边开无数次车。大脑中的模型告诉我们，在悬崖边开车是个坏主意。我们只需要一次就知道这个道理了。而如何让机器来学习这样的模型?
**Eric Horvitz**：是的，可以这样形容最近一系列取得胜利的 AI 系统——聪明而又片面的「学者」。人类智力背后存在着无数的未解之谜，我们并没有取得多大进展。包括「人工智能」，其背后也存在一系列亟待解决的问题。这些问题中，包括人们如何在开放的世界中以一种「无监督」的方式学习，人类「常识」背后的机制和原理，以及人类是如何轻松将事情进行归纳总结的。
目前有几个研究方向可以回答这些挑战，其中包括不断推动在特定领域和某些应用领域的研究，那里一定会出现突破。然而，我认为我们需要追求更通用的人工智能。
方法之一是采用综合人工智能：我们是否能将多种能力 (如语音识别、自然语言、视觉、规划和推理) 整合起来，探究整合过程中的需要解决的难题。
另一种方法是不断推动 DNNs 这种核心方法的发展，并追求更通用的解决问题的方法。我认为这一领域的突破很难实现，但将非常有价值。
下面这篇文章是关于通用 AI 框架的一些有意思的发展方向：
http://erichorvitz.com/computational_rationality.pdf
**Q：目前，很多关于机器学习的研究都转向了深度学习。**
**（1）这会减少机器学习研究的多样性吗？**
**（2）为了支持深度学习研究，其他的范式如概率图模型、支持向量机等的研究会被抛弃吗？正如 90 世纪的深度学习一样，也许现在这些表现不好的模型在未来会表现得很好。**
**Yann LeCun**：随着我们在 AI 上取得进步，我的感觉是深度学习只是解决方案的一部分。在复杂的（可能是动态的）图形中集成参数化模块并从数据中优化参数的想法并没有过时。从这个意义上说，只要我们还没有找到不需要使用梯度来优化参数的好办法，深层学习就不会消失。也就是说，正如我们今天所知道的那样，深度不足以构成「完整」的人工智能。我一直喜欢说定义动态深层结构的能力（即按照程序定义计算图，其结构随着新的输入而改变）的能力可以将深度学习推广为可微编程方法。
但事实上，我们至少遗漏了两件事：（1）可以推理的机器，而不仅仅是感知和分类，（2）机器可以通过观察世界来学习，而不需要人类策划的训练数据，不需要与世界进行太多次交互。有些人称之为无监督学习，但这个短语太模糊了。
我们需要机器学习的一种方式是学习人类的婴儿和动物：他们主要通过观察来建立世界模型，并且有非常少量的交互作用。这是下一个十年的挑战。
至于问题（2）深度学习和图形模型之间没有对立。你可以这样使用图形模型，比如因子图，其中的因子是整个神经网络。这些是正交概念。人们曾经在深度学习框架的基础上建立了概率规划框架。例如 Uber 的 Pyro，它是通过 PyTorch 建立的（概率编程可以看作图形模型的推广、类似可微编程是深度学习的泛化推广）。事实证明，在图模型中使用反向传播进行推理是非常有用的。当数据匮乏并且可以手动特征化时，SVM、核方法、树模型等更好用。
**Eric Horvitz**：人们对于深度神经网络在预测任务和分类的能力感到很兴奋。将其应用于对象识别、语音识别、翻译（结合强化学习思想）等的准确率不断提高。然而，AI 是一个宽广的领域，有着大量有前途的分支学科——并且 AI 的机器学习分支也还有着大量的分支。
我们需要继续开发有潜力的 AI 技术，包括概率图模型、决策理论分析、逻辑推理、规划、算法博弈论、元推理和控制论等已有的丰富成果。我们还需要将领域进行扩展，例如将有限理性模型推广到开放世界中研究智能体。
在微软研究室，我们在 DNNs 上付出了不少努力，投资更广泛的 AI 项目。我们也对如何结合逻辑推理、DNNs 和其他的机器学习感兴趣。例如，你可以看看我们用 DNNs+逻辑来自动编程的例子。
**Q：你认为深度深度学习只是一时的潮流，还是长期的趋势？虽然我了解到基于深层学习的模型使得计算机视觉和 NLP 方面有了巨大的改进。你认为深度学习是解决视觉和 NLP 问题的模式吗？或者，不久就会有新的范式出现？**
**Peter Norvig**：我认为「深度学习」这个品牌已经创造了很大的价值，因此不管基础技术有多大变化，它还会维持很长一段时间。即使 CNNs 和 Relus 兴起，我认为「深度学习」这个名字还将持续。
至于基本概念或方法，我认为我们在模式匹配问题上做得很好，但在关系推理和规划方面做得并不好。我们可以做一些抽象的形式，所以我们需要大量的新思想。
**Q：我想知道是否有人试图设计一种模仿情感的奖励系统。我相信人工智能系统必须与世界有某种联系，「情感」是真正把我们与环境结合在一起的粘合剂。我正在想象 AI 通过完成一项任务能达到的某种状态。例如，我们有可以打败国际象棋大师的计算机，但我们能拥有想要赢的计算机吗？一个想法可能是分割数据，如果完成了一个任务，就会打开一个分区。所有的生命形式都通过一种奖励制度进化。**
**Peter Norvig**：事实上，阿尔法狗等系统在围棋对弈以及其他游戏中取得的成果，主要来源于：一个系统的奖励，我们称之为「强化学习」。Alpha Zero 只从输掉一盘游戏或者赢得一盘游戏中获益，没有任何预先的专家知识，有的只是游戏的规则和「尝试更多能获得积极奖励的行为，更少获得消极反馈的行为」。所以，从某种意义上说，Alpha Zero 唯一「想要」的是赢。在另一个意义上说，它不想任何东西，它没有感受或好或坏的事情的感觉，它只是想从计算上获得最大的比分。
**Q：很多传统统计模型的价值在于：我们能清楚地知道模型在做什么，它们是如何得出结论的，在推断/预测时的不确定因素。深度学习的方法在预测方面也很不错，但它们往往是「黑箱子」。对于 ANNs 等模型的内部机制，我们有哪些了解？了解模型的内部机制是否重要？我认为在做重大决策（例如自动驾驶、临床决策）时，了解模型的内部机制极其重要。**
**Peter Norvig**：这是当前研究的一个重要领域。你可以从 Big Picture blog 或 Chris Olah 的博客中看到谷歌是如何来进行这一研究的。我认为理解上的困难更多的是来自于问题本身，而不是解决方案。当然，二维线性回归极易理解，但它不适用于非良好线性模型问题。同样地，随机森林或者标准的 Python/Java 代码中「if/then」规则很容易理解，但是如果这些规则真的是一目了然的话，代码中就不会有 bug 了。
我想说的不仅仅是「理解」，还有「可信度」。我们什么时候可以信任一个系统？特别是当系统做出重大决策的时候。有很多方面：
是否可以理解代码/模型；
模型是否长期在很多案例上得到过验证；
是否能确信世界没有发生变化，将我们带入模型从未见过的状态；
模型能否抵抗对抗性攻击；
模型能否抵抗 degradation 测试，即故意削弱模型的一部分，看其他部分如何工作；
过去是否有成功的相似技术；
模型是否被持续监控、验证和更新；
模型外部采取了哪些检查措施？有其他系统检查输入和输出系统吗；
采取什么语言与系统通信？能问系统正在做什么吗；
我能给它一些建议吗？如果它出错了，我只能给它成千上万个新的训练案例吗？是否可以直接对它说：「不，你得出的 X 是错误的，因为你忽略了 Y。」
……
这是一个很伟大的研究领域，希望未来看到更多的工作。
**Q：你认为 Capsule 网络怎么样？除了 MultiMNIST，你们在其他数据集上有成功应用过它吗？当输入更多数据时，CNN 和它相比如何？**
**Yann LeCun**：将胶囊网络应用于大规模的数据集是个不错的想法，Geoff Hinton 已经思考了几十年。他一直在寻找将其成功用于 MNIST 上的方法，如果想要将其成功用于 ImageNet 或其他数据集上，也需要花费很多的精力。此外，也不知道其在性能上是否存在优势。胶囊网络可以看成是一种具备特殊池化方式的卷积网络。
**Q：你们在研究 AI 时发现最吓人的事情是什么？**
**Yann LeCun**: 这项研究没有什么可怕的（与一些小报有时声称的相反）。
可怕的事情只发生在人们试图过早地部署 AI 系统时。特斯拉自动驾驶仪功能超酷，但是，作为一个司机，你必须理解它的局限性，以便安全地使用它（它使用的是卷积网！）。
**Eric Horvitz**: 对于如何在安全关键领域部署人工智能，我们有一些自己的理解——例如，当机器和人员协同工作时，我们努力实现「人工智能协作」。
我们在 AAAS 会议上有讨论这个话题：
https://aaas.confex.com/aaas/2018/meetingapp.cgi/session/17970
**Q：当人工智能机器人能够比任何一个团队更好地预测/引起市场波动，然后以闪电般的方式买卖股票、产品、土地等，会发生什么？我们能采取什么样的保障措施来防止 AI 的一些先驱者称霸世界市场？**
**Peter Norvig**：多年来，有大量交易者将先进的统计模型运用到股票市场，取得了不错的成果。无论你有多聪明，你始终不知道还有多少空间，能让你把事情做的更好。就我个人而言，我认为我们应该提前几年就采取行动，通过控制交易的速度/或在交易上施加更高的成本，来抑制定量交易的效果。比我更了解交易的人或许有更好的保障办法，但我不认为 AI 从根本上改变了规则。
**Yann LeCun**：你越能准确地预测的市场，你就使得市场越难预测。完全有效的市场是完全不可预测的。因此，如果市场完全由一系列完美的（或准完美的）自动交易系统组成，每个人都会得到完全相同的回报（这与市场指数的表现相同）。
**Q：量子计算的进步驱动了 AI 研究吗？如何看待二者在未来的融合？**
**Peter Norvig**：目前我想做的很多事情量子计算都帮不上忙。我经常想要通过一个相对简单的算法来处理海量文本，而量子计算对此并无帮助。不过，量子计算可能有助于更高效地搜索深度网络的参数空间。我不知道是否有人做出了这样的量子算法，不需要考虑如何用硬件来实现，如果在理论上可行也可能会有所帮助。
**Yann LeCun**：驱动？当然不是，量子计算对于 AI 的影响如何，说实话，我目前还不清楚。我认为，它在短期内不可能对 AI 产生影响。
**Q：许多人在使用搜索引擎和 Siri，Google Home 等语音助手时都会担心隐私泄露。当 AI 成为我们生活中密不可分的一部分时，有什么措施可以使得用户在使用 AI 的同时保护其行为数据？**
**Eric Horvitz**：我能理解这种担心，我们公司的员工对于终端用户数据采取了严格的匿名措施，数据短暂停留后就会被删除，并且为用户提供了多种方法来观察，控制和删除数据。我相信 Google 和 Facebook 也采用了同样严格的方法，对此我没有什么不满。
随着欧盟发布的「一般数据保护条例」(GDPR) 开始实施，对于用户数据的把控会越来越严格。在保护用户隐私方面的努力让人觉得很棒，例如私下训练 AI 系统和为用户提供更多选择。在几年前 IAPP 的会议上曾讨论过后者的解决方案，可以在这里查看：http://erichorvitz.com/IAPP_Eric_Horvitz.pdf
**Q：这些发展 AI 的公司（特别是 Facebook）背后的动机是什么呢？在我看来用户并不像 AI 公司那样关心 AI。一些公司借助 AI 来手机用户数据来盈利，更是激化了用户与公司之间的矛盾。如何让像我这样的用户相信这些产品不是打着 AI 的旗号，实际上是为了收集用户数据？**
**Peter Norvig**：你提到了数字助手，我认为这个技术明显是站在用户一边的，你的数字助理将是你的——你可以训练它去做你想做的事情；在某些情况下，它只会在你的设备上运行你的私人数据，没有其他人可以访问它的内部工作。它将作为你的代理人，你不用直接去一家大公司的网站，希望他们能提供给你有用的东西，而你的代理人会整理这些产品，确保你得到你想要的东西。
**Yann LeCun**：这对于我们科学家来说不成问题。真正的问题是「你信任你的数据吗？」你相信你的手机公司，你的 ISP，你的手机/操作系统制造商，你最喜欢的搜索或社交网络服务，你的信用卡公司，你的银行，你使用的每一个移动应用程序的开发者吗？看看它们的数据政策，选择你可以信任的产品，确认他们不向第三方销售（或泄露）你的数据。在数据上遵从伦理并不会带给公司利益冲突，因为从长远来看，遵从数据伦理是唯一的好政策。
**Eric Horvitz**：我同意彼得的观点。在构建个人代理方面，存在着一些有趣的可能性，这些代理只根据他们所服务的人的偏好共享数据，并且这些代理只会根据所有者的指令行事。这是一个不错的研究领域。
**Q： 我是本科新生，几年前我就想在 AI 领域工作，但是除了我的教授们我没有任何的资源。我的学校很小，要参加招聘会都得去别的城市，我如何能与 AI 领域产生更多的联系呢？**
**Peter Norvig**：我建议你自己通过课程或讨论论坛在线交友继续学习。明显地，要凭借小学校的项目，找到 AI 方面的工作很难。但是，你可以在一家大公司获得软件工程师的职位，一旦你到了那里，表达你对 AI 的兴趣，在工作中学习，密切关注你所能从事的与 AI 相关的项目，并且很有可能在更短的时间内取得博士学位，你将成为公司中一个公认的人工智能专家。
**Q：我是一名学习核工程/等离子体物理学研究生，正计划转向 AI 研究。**
**关于 AI 领域：AI 研究的下一个里程碑会是什么？目前需要攻克哪些挑战来达到这些里程碑？**
**关于专业技能：我需要具备哪些关键技能/知识？刚入门的人该如何学习？**
**Yann LeCun**：深度无监督学习、可以进行推理的深度学习系统是下一个里程碑。无监督学习需要面临的挑战：学习世界的层次化表征，以理解变化的解释因素。如何在不完全可预测的世界中进行预测，这是机器需要学习的。关键技能：良好掌握数学（线性代数、多变量微积分、概率统计、优化学等）、熟练的编程技能、科学方法论。总的来说，创造力和知觉也很重要。
**Peter Norvig**：我对能真正理解人类语言、能进行实际对话的助理很感兴趣，这将是很重要的里程碑事件。其中挑战是结合抽象推理和规划将模式匹配，目前我们只能在非常形式化的领域，如围棋中才能做的很好，而在现实世界中还远远不够。
作为物理学家是你的一大优势，你的数学背景、实验、建模和处理不确定性、误差的思维很适合学习 AI。我见到过很多物理学家在 AI 领域做得不错。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBULg0PyXjjVDR3OiaCudIgwDjRdBUkpx1Dw58Xa9VkyJUuH0piaT7Qyem2gHwfTj6ic45jwaL7y3Zdaw/640?wx_fmt=png)
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。由互联网进化论作者，计算机博士刘锋与中国科学院虚拟经济与数据科学研究中心石勇、刘颖教授创建。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
