# 深度|机器学习到底能替人干哪些工作？《科学》列出了8条评估标准 - 人工智能学家 - CSDN博客
2017年12月29日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：110
*![640?wx_fmt=png&wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBXqeMPd367XUweFJO77YDiaFrCY8kJKL7omY8UmlNdOsoStMrGHQS3FRKftvgnLONmj98ulxqU7G4A/640?wx_fmt=png&wxfrom=5&wx_lazy=1)*
*来源：机器人大讲堂*
对于AI会取代哪些人类工作的猜测，也许可以暂时停一停了。
**最近，两位来自MIT和CMU的研究者在一篇论文中提出了一种****预测那些“脆弱“工作的方式。他们认为，机器学习并不代表人类工作的终结，但它会对经济和人类工作****的方式产生极大影响。**
根据自己对于机器学习系统当下和未来能力的理解，这两位研究者列出了8条主要标准，来评估一项任务是否适合机器学习。他们的文章发表在周四的《科学》上。
*![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDMBfeyA5rbnb8kQia80VJq5B5LsRyF3MgdUPHNBB0ibn8icHdN99LE6pmn48QuAcDnImXF21NNjFsXw/640?wx_fmt=jpeg)*
###### *△ Erik Brynjolfsson*
文章的共同作者之一、MIT斯隆管理学院教授Brynjolfsson在接受CNBC采访时说，高管们可以用这些标准来对自己机构内的任何一项工作进行评估，而政策的制定者们同样可以根据这些问题来判断哪些职业最容易受到自动化影响。CMU计算机科学教授Tom Mitchell是另一位作者。
![0?wx_fmt=png](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBXqeMPd367XUweFJO77YDiaFSHxShz0wU8CyXlZA0cmM7FM4VKAw4JVJk9xOB9XeHmibrrXBvEk6HMQ/0?wx_fmt=png)
###### *△ Tom Mitchell*
“整个工作都适合或不适合机器学习的情况非常少见，但在某种工作之中，或许有几项任务是适合的。” Brynjolfsson说。论文的主要前提之一就是，我们离所谓“通用人工智能”还差得很远，机器不能把人类能干的所有事都办了。
Brynjolfsson还说，老板们将要面临的挑战是，如何将那些工作“解绑”，依据是否能被自动化将它们进行归类，然后“重新绑定”成全新的工作。
这些问题中列出的条件，包括“不需要复杂、抽象推理的任务”、“不需要与人类进行细致、广泛对话式交互的任务”、“为了完成任务不需要长期计划”等等。使用者根据这些条件来判断符合或不符合的程度，最后加在一起算总分。
**那么，究竟哪些任务最适合由机器完成？主要看这些因素：**
**标记了界定明确的输入和输出，能学习函数将其对应起来的任务**
这些任务包括分类（比如标记狗的品种或根据可能的癌症种类标记医疗记录）和预测（分析一份贷款申请来预测未来的违约可能性）。不过机器在这里学会的只是一种统计学关联，而未必是因果关系。
**存在大型数据集，或可以创建包含输入-输出对的大型数据集的任务**
**可获取的训练样本越多，学习结果就越精确。**DNN有一个值得注意的特性，在很多领域里，它的性能并不会随着训练样本数量的增加而逼近完美。能在训练数据中抓出所有相关的输入特征尤为重要。虽然原则上任何任意函数都能用DNN来表示，但电脑应付不好两样东西：一是训练数据中模拟的、持续的多余偏见，二是会忽略包含了机器观测不到变量的规律。不过，还有不少创造数据的方法，比如监测已有过程和交互行为、雇佣人类来对部分数据进行明确标注或是创建一个完整的全新数据集，或是模拟问题相关的场景。
**有着明确的目标和度量标准、提供清晰反馈的任务**
**当我们可以明确地描述目标时——即便我们未必能确定达成目标的最佳过程——机器学习能做得非常不错。**这与早期达成自动化的途径形成了鲜明对比。抓取个人输入－输出决策的能力（即便模仿这些个人的学习过程被允许）可能不会导致最佳的全系统表现，因为人类本身就会做出不完美的决策。因而，有明确界定的全系统表现（比如优化全城范围内而不是某个交叉路口的交通流量）度量标准就为机器学习系统提供了黄金准则。当训练数据是根据这种黄金准则来进行标注并以此确定目标时，机器学习的威力特别大。
**不需要依靠广泛背景知识或常识的长逻辑链或推理过程的任务**
**在学习数据中的经验性联系时，机器学习系统非常强大**；但当任务需要依赖于常识或背景知识的长推理链条或复杂计划时，它就变得不那么好使。吴恩达的“一秒钟原则”表明，机器学习在需要快速反应和提供即时反馈的电子游戏上做得非常好，但在需要依靠对于世界的背景知识、以及对于久远事件的记忆来做出最优选择的游戏上就做得没那么好。
此类事件的例外是围棋和国际象棋，因为这些智力性游戏可以以完美的准确度快速模拟，数百万完美自标注的训练样本可以被自动采集。然而，在真实世界的大多数领域，完美的模拟太少了。
**不需要对于决策过程进行细致解释的任务**
数亿数值权重与它们的人工神经元相连，大型神经网络根据它们进行细微调整来学习决策。要对人类解释这种决策的原因会十分困难，因为DNN通常不会像人类一样使用中间抽象过程。虽然对于可自主解释AI系统的研究工作正在进行中，但现在这一领域的系统在这方面做得依然比较差。
举个例子，虽然计算机在诊断癌症或肺炎种类上可以比人类专家做得更好，与人类医生相比，它们解释得出诊断结果原因的能力要差得多。而对于很多可感知的任务，人类则并不善于解释，比如，他们如何从听到的声音中识别出词语。
**能够容忍错误、不需要可证实的正确度或最优解决方案的任务**
**几乎所有的机器学习算法都是从统计学和概率上得出解决方案的。**因而，要把它们训练到百分之百的准确度几乎不可能。即使是最好的语音识别、物体识别和疾病诊断系统也会犯错误。对于错误的容忍度是一条非常重要的标准。
**不会随时间迅速变化的任务**
**一般而言，机器学习算法只会在未来的测试样本分布于训练样本分布近似时才会干得漂亮。**如果这些分布发生变化，再训练就不可避免，因而，相对于新训练数据的获取率，最终的成功更依赖于变化率（比如，垃圾邮件过滤器在过滤商业垃圾邮件上做得很好，部分是因为收到新邮件的比率要高于垃圾邮件变化的比率）。
**不需要专业的灵巧、运动技能或机动性的任务**
与人类相比，**在非结构化环境和任务中处理体力操作上，机器人仍然十分笨拙。**这其实大部分不是机器学习的问题，而是最新机器人机械化控制器的成果。
在机器学习将会如何影响劳动和工资方面，这篇论文同样考虑了其中经济因素的潜在影响。比如，在一些案例中，计算机将会取代人类。
在一些任务上，自动化的价格可能会降低，这可能会影响需求、雇佣和总投入。
作者指出机器学习的影响可能会超过一些之前已经被广泛应用的发明，比如电力和内燃机。**这些进步提高了总生产力，解放了互补性创新的浪潮。**
“进行了正确互补性投入（如技能、资源和基础设施）的个人、商业和社会最终将会繁荣起来。“作者写道，”而其他人不只失去了分一杯羹的机会，在某些情况下，他们还会过得越来越糟。“
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。由互联网进化论作者，计算机博士刘锋与中国科学院虚拟经济与数据科学研究中心石勇、刘颖教授创建。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
