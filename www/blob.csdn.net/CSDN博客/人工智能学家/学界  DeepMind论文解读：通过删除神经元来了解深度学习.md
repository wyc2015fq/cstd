# 学界 | DeepMind论文解读：通过删除神经元来了解深度学习 - 人工智能学家 - CSDN博客
2018年03月24日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：275
![640?wx_fmt=png&wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWTDDtqqAJIZpyWiaUefRMQKUwIVO36I2pdD8gjuz68hLJmLCh3XuaHAJHz6dXHibt85MtgAA57KtLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1)
作者：杨文
深度神经网络由许多单独的神经元组成，它们以复杂且违反人直觉的方式组合起来，以解决各种具有挑战性的任务。这种复杂性一方面赋予神经网络神秘力量，另一方面，也让它们变成了人类难懂的黑匣子。
了解神经网络的深层功能对于解释它们是如何做决定至关重要，并且能帮我们构建更强大的系统。就像，你不了解各个齿轮如何配合工作，你在试图做一个钟表时就很困难。
要想理解神经科学和深度学习中的神经网络，一种方法是弄清单个神经元的作用，尤其是那些易于解释的神经元。
DeepMind 最新的一篇关于神经网络学习的论文《On the Importance of Single Directions for Generalization》（https://arxiv.org/abs/1803.06959）将投稿在第六届 ICLR（国际学习表征会议）。这项研究所采用的方法是受数十年临床神经系统科学的启发，通过探索损伤神经元的影响来确定小规模神经元组对神经网络的重要性。深度神经网络中的那些越容易解释的神经元对神经网络的计算性能越重要吗？
研究人员通过删除单个神经元或神经元组来衡量它是否对网络的性能产生了影响。这项实验有了两个令人惊讶的发现：
**1.**虽然以前的许多研究集中于易理解，可解释的单个神经元（例如「猫神经元」，或深层网络的隐藏层中的神经元，它们只对猫的图像有反应），但我们发现这些可解释的神经元和那些难以理解，不可描述的神经元对神经网络的影响，并没什么不同。
**2.**在同样删除神经元的情况下，能正确分类没见过的图像的网络比仅能对看到过的图像进行分类的网络恢复的更快。换句话说，推理性好的网络比那些单纯的记忆网络更不依赖于单一方向。
**「猫神经元」可能更易解释，但它们并不重要**
在神经科学和深度学习中，广泛分析了仅对单一输入类别的图像（例如狗）作出响应的易解释神经元（「选择性」神经元）。这导致了在深度学习中对猫神经元，情绪神经元和括号神经元过度强调它们的重要性; 在神经科学中，对例如詹妮弗安妮斯顿神经元，以及一些类似的神经元的过度强调等等。然而，这些少数高选择性神经元相对于大多数具有低选择性，更令人费解且难以解释的神经元，哪个相对更重要仍然未知。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmia1n6WPqDanLLrneMd4LmfMRSzqhm0T0WjgYtowR10GiaYEQYLSNY2LjwHjfpYFNubLgfQKZupUgeg/640?)
具有明显响应模式（例如，对猫活跃，对其他所有活动不活跃）的神经元比那些随着图像随机活动或不活动的令人难理解的神经元更容易解释。
为了评估神经元的重要性，研究人员测量了当神经元被删除时，图像分类任务的网络性能是如何变化。 如果一个神经元是非常重要的，删除它应该是具有高度破坏性的并且大大降低网络性能，而删除一个不重要的神经元应该没有什么影响。 神经科学家经常进行类似的实验，尽管它们很难在人造神经网络中获得这些实验所必需的细粒度和精确度。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/vJe7ErxcLmia1n6WPqDanLLrneMd4LmfMwwmWQ0jYXjAmZiaFuDqibSn2CiaAv4awehlrdic6zsXk5AzVYU4yQOVfrg/640?)
上图是在一个简单神经网络上删除神经元产生影响的概念图，较深的神经元更活跃。  需要注意的是，删除一个或两个神经元对输出影响很小，而删除大部分神经元会产生很大的影响，并且一些神经元比其他神经元更重要。
令人惊讶的是，研究员发现神经网络的选择和重要性之间几乎没有关系。换句话说，「猫神经元」并不比令人难解的神经元更重要。这一发现与最近在神经科学方面的工作相呼应，已经证明令人难解的神经元实际上可以提供丰富的信息，并且表明今后在探索上必须超越最易于解释的神经元，以便理解深度神经网络。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/vJe7ErxcLmia1n6WPqDanLLrneMd4LmfMuUlKOXOlfzYpwqfHZJPgH2zRDDllLwyAt3Bpdf91kicXL7yUp7SMSBw/640?)
尽管可解释神经元在直觉上更容易理解（比如，「它喜欢狗」），但它们并没有比那些没有明显偏好的难解释神经元更重要。
**推理性好的网络很难打破**
我们试图构建智能系统，如果系统能够推理出新的场景，我们只能称之为系统智能。例如，一个图像分类网络只能对以前看过的特定狗图像进行分类，而不能对同一只狗的新图像进行分类，这个网络是没有价值的。只有在新样本中依然能智能分类，这些系统才能获得它们的效用。去年，Google Brain、Berkeley 和 DeepMind 合作的论文在 ICLR 2017 上获得最佳论文，表明深层网络可以简单地记住他们接受训练的每个图像，而不是以更像人类的方式在学习（例如，了解抽象的「狗」概念）。
然而，网络是否已经学会了一种能够推理到新的任务场景中的解决方案，这往往是不清楚的。通过逐渐删除越来越大的神经元组，研究员发现，相比于简单记忆在训练期间看到的图像的网络，具有良好泛化能力的网络对删除神经元组后的稳健性要强得多。换句话说，泛化好的网络很难被打破（尽管它们肯定还是会被打破的）。
通过以这种方式衡量网络的稳健性，可以评估一个网络是否在利用简单的记忆来「欺骗」人类。了解网络在记忆过程中是如何变化的将有助于建立新网络，网络记忆越少，推理性就越强。
**神经科学启发分析**
总之，这些发现证明了使用基于临床神经科学启发的技术来理解神经网络的力量是可行的。 使用这些方法，发现高选择性个体神经元并不比非选择性神经元更重要，并且那些广义的网络比单纯记忆训练数据的网络更不依赖于单个神经元。 这些结果意味着单个神经元的重要性可能看起来的那么重要。通过努力解释所有神经元的作用，而不仅仅是那些易于解释的神经元，我们希望更好地理解神经网络的内部工作，最关键的是，利用这种理解来构建更加智能和通用的系统。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBULg0PyXjjVDR3OiaCudIgwDjRdBUkpx1Dw58Xa9VkyJUuH0piaT7Qyem2gHwfTj6ic45jwaL7y3Zdaw/640?wx_fmt=png)
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
