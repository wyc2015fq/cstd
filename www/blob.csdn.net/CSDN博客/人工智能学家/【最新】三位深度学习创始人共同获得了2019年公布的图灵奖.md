# 【最新】三位深度学习创始人共同获得了2019年公布的图灵奖 - 人工智能学家 - CSDN博客
2019年03月27日 19:05:42[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：2

![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBUpRPGmNiauImXhGJPCTvjZ9JVEMFGzClqm4cUaZMvwUufLDiaGjxn3rReftec0GcVwL9bc8TQiaTcEw/640?wx_fmt=png)
来源：biendata数据实战派
2019年3月27日 ——ACM宣布，深度学习的三位创造者Yoshua Bengio, Yann LeCun, 以及Geoffrey Hinton获得了2019年的图灵奖。
今天，深度学习已经成为了人工智能技术领域最重要的技术之一。在最近数年中，计算机视觉、语音识别、自然语言处理和机器人取得的爆炸性进展都离不开深度学习。
三位科学家发明了深度学习的基本概念，在实验中发现了惊人的结果，也在工程领域做出了重要突破，帮助深度神经网络获得实际应用。
在ACM的公告中，Hinton最重要的贡献来自他1986年发明**反向传播**的论文“Learning Internal Representations by Error Propagation”，1983年发明的**玻尔兹曼机**（Boltzmann Machines），以及2012年对卷积神经网络的改进。Hinton和他的学生Alex Krizhevsky以及Ilya Sutskever 通过Rectified Linear Neurons和 Dropout Regularization改进了**卷积神经网络**，并在著名的ImageNet评测中取得了很好的成绩，在计算机视觉领域掀起一场革命。
Bengio的贡献主要在1990年代发明的**Probabilistic models of sequences**。他把神经网络和概率模型（例如隐马尔可夫模型）结合在一起，并和AT&T公司合作，用新技术识别手写的支票。现代深度学习技术中的语音识别也是这些概念的扩展。此外Bengio还于2000年还发表了划时代的论文“A Neural Probabilistic Language Model”，使用**高维词向量**来表征自然语言。他的团队还引入了**注意力机制**，让机器翻译获得突破，也成为了让深度学习处理序列的重要技术。
Yann LeCun的代表贡献之一是卷积神经网络。1980年代，LeCun发明了**卷积神经网络**，现在已经成为了机器学习领域的基础技术之一，也让深度学习效率更高。1980年代末期，Yan LeCun在多伦多大学和贝尔实验室工作期间，首次将卷积神经网络用于手写数字识别。今天，卷积神经网络已经成为了业界标准技术，广泛用于计算机视觉、语音识别、语音合成、图片合成，以及自然语言处理等学术方向，以及自动驾驶、医学图片识别、语音助手、信息过滤等工业应用方向。LeCun的第二个重要贡献是改进了**反向传播算法**。他提出了一个早期的反向传播算法backprop，也根据变分原理给出了一个简洁的推导。他的工作让反向传播算法更快，比如描述了两个简单的方法可以减少学习时间。LeCun第三个贡献是拓展了**神经网络的应用范围**。他把神经网络变成了一个可以完成大量不同任务的计算模型。他早期引进的一些工作现在已经成为了人工智能的基础概念。例如，在图片识别领域，他研究了如何让神经网络学习层次特征，这一方法现在已经用于很多日常的识别任务。他们还提出了可以操作结构数据（例如图数据）的深度学习架构。
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBUpRPGmNiauImXhGJPCTvjZ9r2rb4XW3GQamsFoEwokgeluVqq6J5AUJMO8qfzzmj38x4Cv2icicHGxQ/640?wx_fmt=jpeg)
图灵奖由ACM于1966年设置，设立目的之一是纪念著名的计算机科学先驱艾伦·图灵。图灵奖是计算机科学领域的最高奖。获奖者必须在计算机领域具有持久重大的先进性技术贡献。人工智能领域的先驱马文·明斯基（Marvin Lee Minsky）、约翰·麦卡锡（John McCarthy）、艾伦·纽厄尔（Allen Newell）和司马贺（Herbert Alexander Simon）等人都曾经获奖。华人科学家姚期智2000年因为伪随机数生成等计算领域的重要贡献获奖。
**关于深度学习：**
深度学习的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。
深度学习的概念由Hinton等人于2006年提出。基于深度置信网络(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。
深度学习是机器学习中一种基于对数据进行表征学习的方法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。
深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。
同机器学习方法一样，深度机器学习方法也有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，卷积神经网络（Convolutional neural networks，简称CNNs）就是一种深度的监督学习下的机器学习模型，而深度置信网（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
