# 这有5种来自大自然「馈赠」的AI技术及其应用，你知道多少？ - 人工智能学家 - CSDN博客
2018年01月16日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：170
![?wx_fmt=jpeg&wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTMcGrdfxYFVOV8mRbkpluYh6wdfDugw5xfLWcNwqcwrZ1lH5Qib7FQTw/?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
原文来源：Towards Data Science
作者：Luke James
「雷克世界」编译：KABUDA
对于技术领域中存在的AI相关技术，我们应心存感恩。人类不仅花费了数十年的时间来研究完善数学算法，以使这些奇妙复杂的算法发挥效用，而且在这一过程中，我们还在不断寻求突破性发展，并以此作为灵感，深入研究，从而使得下一代智能能够得以存在于我们的星球上。大自然，及其所包含的一切，都深深地根植于AI的运作中，并将在这里成长壮大。
David Attenborough拍摄的野生动物纪录片令人印象深刻。他们对地球上许多生物的行为和属性，进行了令人难以置信的详细解读，这使得我们能够了解这些生物是如何融入自然生态系统，并通过共同努力，从而使我们居住的星球蓬勃发展，最终让地球成为如今的模样。虽然我不是David Attenborough，但我还是想将你们带入到我的野生动物纪录片中来。我们要探讨的明星生物不是别的，正是那些被大自然直接启发的人工智能算法。首先，我需要想你们介绍两种算法概念，搜索/寻路（Search/Pathfinding）和预测建模（Predictive Modelling）。
**搜索（寻路）算法**
搜索算法本质上是一种程序，旨在找到一个到达目标的最佳/最短路径。例如，旅行推销员（travelling salesman）问题就是一个典型的搜索优化问题，在这一问题中，你将会得到一个城市及其之间距离的列表。旅行推销员需要对每个城市访问一次，你必须为其寻找最短路线，以最大限度地减少旅行时间和费用（确保能够返回最初城市）。这一问题的实际应用是送货卡车。假设伦敦有100人在线下单，所有的箱子都被装在同一辆货车里。快递（例如DPD）必须计算最优路线（平衡距离/时间），以便从仓库（最终返回仓库）交付这些包裹，并确保公司在交付过程中尽可能少地浪费时间和金钱。
**预测建模算法**
如今，预测建模是炒作的焦点。世界各地的数据科学家都在他们舒适的办公大楼楼顶高呼“神经网络”，而诸如谷歌这样的公司正到处奔走，试图用这些小巧而复杂的“人工大脑”及其不同变体来解决世界上的各种问题。实际上，预测建模使用统计学来预测结果。你经常会听到数据科学家试图解决两种预测建模问题，回归和分类。回归是发现两组变量之间相关性的黑魔法，分类是计算数据集属于不同组的概率的过程。
**5种生物启发学习算法**
**1.人工神经网络（ARTIFICIAL NEURAL NETWORKS）**
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTqAcoxMMTeDAibQxqB1W6tXtJHkiajiaib7UZlyEzD0Cp5OZFQ4MXozH8Xw/?wx_fmt=png)
*前馈神经网络 - 最基本的神经网络类型*
**算法类型：预测建模**
**生物学启示：认知大脑功能（神经元）**
**应用示例：情感分析、图像识别/检测、语言修正、机器人**
我们从最常见的人工智能(AI)算法开始。神经网络是人工智能领域中一个称之为机器学习的子类别的一部分。它们的设计和构建模仿了神经元层面的大脑功能（即轴突和树突相互作用，通过系统传递信息），通过一系列“层”生成预测输出。每一层都提供了一个额外的数据表示层，从而使得你能够对最复杂的问题进行建模。
神经网络可能是目前应用最广泛的机器学习算法，也是数据科学和机器学习领域的研究热点。这一概念最初是在1958年提出的，称之为“感知机”。后来Geoffrey Hinton对其进行了提炼，并被Google和Facebook等公司中进行推广。神经网络可用于解决各种类型的问题，包括自然语言处理、视觉识别等。这种监督学习算法既支持回归问题，也能用于分类问题，且其应用的实例可以在日常的消费类产品中找到，包括智能手机及联网家庭设备。
**2.遗传算法**
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTOiaHlSoXPCGwP9FTknTOrLJBgGzSYlPdP9k5bfMwyX0xQOPE45pIpvw/?wx_fmt=png)
*遗传算法中个体的繁殖*
**算法类型：搜索/寻路**
**生物学启示：适者生存/进化（细胞繁殖）**
**应用示例：数据挖掘/分析、机器人、制造/设计、过程优化**
为了解决搜索问题，遗传算法在一组连续的世代个体中采用了一种类似于“适者生存”的进化方法。每一代都含有一些字符串，标记了我们在DNA中所看到的的染色体。群体中的每个个体都代表搜索空间中的一个点，因此每个个体都是可能的候选解。为了提高解的数量，我们将个体置于进化的过程中。
- 
整体中的每个个体都会为争夺资源和配偶而竞争
- 
相较于竞争中失败的个体而言，每场竞争中胜出的个体（通常）会产生更多的子个体。
- 
更加“理想”的候选个体基因在种群中传播，会导致优秀的父母将产生更具有潜力的后代。
**3.群体/集体智能（SWARM/COLLECTIVE INTELLIGENCE）**
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTdHHw5ekc3Au6tdLRNevKzcqia9qHmsVtib0fdibjVibUAySZwEeaHndzww/?wx_fmt=png)
*蚁群优化实例， 一种集体智能算法*
**算法类型：搜索/寻路**
**生物启示：蚁群/鱼群/鸟群**
**应用示例：机器人、视频游戏AI、制造、路线规划**
蚁群优化和粒子群优化是符合“集体智慧”概念的两种最常见算法。在基本层面上，我们所讨论的算法都需要利用多个工作智能体（working agents）。每个工作智能体都表现出非常基本的行为能力，这些行为通过集体（作为一个整体）工作，以便可以触发更复杂、更紧急的行为，以解决问题。
蚁群优化（ACO）与粒子群优化（PSO）有很大不同。两者都旨在实现紧急行为，但采用了不同的方法。像真正的蚂蚁群体一样，ACO利用信息素气味引导个体智能体选择最短路径。最初，在问题空间中初始化一个随机信息素。随后，个体智能体开始遍历搜索空间，在搜索过程中释放信息素气味。在每个时间段中，信息素将以一个确定的速率衰减。单一智能体根据其前方信息素气味的强度做出决策，以遍历搜索空间。特定方向的气味越强烈，就越有可能向那个方向前进。信息素气味最强的方案就是最优解决方案。
PSO更多的是关注整体方向。一些单一智能体被初始化，随后它们从随机方向开始。每个时间段，每个智能体都需要做出决策是否要改变方向。这一决策将以最优解决方案（pbest/全局最优）的方向、最邻近的方向（局部最优）以及当前前进方向作为基础。新的前进方向通常是对所有这些值的 “妥协”。
**4.强化学习**
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTqXctEHzRKwHFsyib3A66SM9bh0s8DzqeiaZyLvVAkOLyeqf6s861YPibA/?wx_fmt=png)
*强化学习环境中的智能体行为*
**算法类型：预测建模**
**生物启示：经典条件反射**
**应用示例：视频游戏、自主车辆控制、生产线软件、金融系统**
随着心理学的发展和一个类似于经典条件反射的过程，强化学习可以对智能体所采取的有利行动做出积极的数字反应。学习强化学习的概念往往比学习经典的条件反射更容易。巴甫洛夫的狗（Pavlov’s Dogs），这是在19世纪90年代进行的一项研究，当时俄罗斯心理学家Ivan Pavlov正在研究狗的唾液对喂食的反应。这里可以找到一篇能够很好地解释这件事的文章。本质上而言，如果一个强化学习采取了一个好的行动，能够向完成任务的方向迈出了一步，那么它将得到一个数字奖励。该智能体将学习使用一个策略，从而使每一步都能获得最大奖励。将原始输入应用到算法中，可以让智能体开发自身对问题的感知，并改进该如何利用最有效的方式去解决问题。
将强化学习算法与其他机器学习技术相结合的应用是非常普遍的，例如神经网络。这通常被称为深度强化学习。神经网络常用于预测强化学习在作出特定决策时应得到的奖励。如今，Deep Mind是Google旗下的一所公司，它在这一领域取得了很大的进步，并可以采用Deep Q Learning方法来解决更为普遍的问题（例如一种算法能够玩转整个Atari游戏库，并且在游戏“GO”中，在没有任何帮助的前提下击败了世界冠军）。他们目前正在采用这种方法来处理更复杂的游戏，如“星际争霸II”。
作为参考，Q Learning是一种无模型版本的强化学习算法。它可以为任何有限的马尔可夫决策过程（Markov Decision Process）找到最优的动作选择策略。在程序初始化时，每个动作值对应的Q值由开发人员定义，并在每个时间段由强化学习算法进行更新。下图展示的是更新Q动作值对（Q action-value pair）的等式示例。
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTIn9OWpicqjgGa66OibFbC0noXHDMwkAXu91mT7niakDbELd7CPpM49ejw/?wx_fmt=png)
*Q学习值（Q Learning Value）更新方程*
**5.人工免疫系统**
![?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/waLJGrhJM0dGjR1WRhpffU74x9icgiciaqTFLtZRLGnI9JUtxKWLQSfWT6MgXDG3yheKZ7wk2kdkaI8qDpdzXiaicjA/?wx_fmt=png)
**算法类型：预测建模**
**生物学启示：免疫系统**
**用例：安全软件、自主导航系统、调度系统、故障检测软件**
免疫系统是通过产生免疫反应来保护身体免受物质和病原体侵害的系统。人工免疫系统（Artificial Immune System，AIS）是受理论免疫学和应用于解决问题的观察免疫功能启发而产生的适应性系统。AIS是生物启发计算和自然计算的子领域，与机器学习和人工智能相关。通常有多个与AIS相关联的算法:
- 
克隆选择（Clonal Selection）
- 
树突状细胞（Dendritic Cell）
- 
阴性选择（Negative Selection）
- 
人工免疫识别（Artificial Immune Recognition）
与生物免疫系统一样，AIS能够将系统内的所有细胞分为“自我”和“非我”两类。一个分布式的情报工作队被用来对所有的细胞采取行动。参与免疫活动的最重要的两类细胞是B细胞和T细胞（于你我而言是白血细胞）。T细胞分为三类，一种是用来激活B细胞，一种是用来结合并破坏外来入侵者，还有一种是用来抑制自身免疫问题。B细胞负责产生抗体，即与抗原（毒性/外来物质）相结合的特异性蛋白质。人工免疫系统通常用于通过监测入侵检测以抵御网络攻击，并且通常被集成于企业级软件中。与本文中提到的其他算法不同，关于此主题的免费在线学习资料非常有限，该技术可能是本文提及的所有技术当中最不发达的一种。
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。由互联网进化论作者，计算机博士刘锋与中国科学院虚拟经济与数据科学研究中心石勇、刘颖教授创建。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
