# 当自动驾驶汽车撞过来的时候，你希望它如何判断？ - 人工智能学家 - CSDN博客
2018年11月03日 22:14:12[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：37
![640?wx_fmt=jpegwebp](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/00yGoQJ8PHeiabedTSlTS1RzbHxOgU5Sl35Y4W2OFqRzDicNB2SuiaPHu9m4uKMCzJibm11uZChfjyYfM6lNebjnQA/640?wx_fmt=jpegwebp)
来源：网易智能 
摘要：据报道，当无人驾驶汽车在繁忙的街道上发生碰撞的时候，它该优先避免让谁受伤呢？它该杀死谁，而不杀死谁呢？麻省理工学院的一项研究表明，你的回答将取决于你来自哪里。
2016年，麻省理工学院媒体实验室的研究人员启动了一项实验。他们想了解人们希望无人驾驶汽车有怎样的行动模式，所以他们建立了一个网站，在上面任何人都可以体验到13种不同的无人驾驶汽车场景：处于撞车事故中的自动驾驶汽车是否应该优先避免让年轻人而不是老年人受伤？还是优先避免让女人而不是男人受伤？它应该优先避免让身体健康的人而不是超重的人受伤？它是否应该根本不做任何决定，而只是选择不作为呢？
两年后，研究人员已经分析了来自233个国家的230万参与者的3961万项决策。在发表在《自然》杂志上的一项新研究中，它们表明，在机器如何对待我们的问题上，我们的对错感是由我们居住的地方的经济和文化规范决定的。
他们发现，对于自动驾驶汽车该有怎样的行为模式，三大地理区域有着不同的伦理观念：西部(包括北美和欧洲基督教国家)、东部(包括远东国家和伊斯兰国家)和南部(包括南美大部分地区和与法国有渊源的国家)。这些大群体也有自己的子群，比如西方的斯堪的那维亚半岛和南方的拉丁美洲国家。正如该研究的交互式图表所显示的那样，巴西人倾向于选择保护乘客而不是行人；伊朗人更有可能优先保护行人；与平均水平相比，澳大利亚人更倾向于保护身体健康的人，而不是超重的人。
但该研究还发现，世界各地的人趋向于在三个方面达成一致：许多人希望自动驾驶汽车优先保护人类而非动物，优先保护年轻人而非老人，保护尽可能多的人。这些见解可以为机器伦理的国际准则提供基础——研究人员写道，当这些“危及生命的两难困境出现时”，必须要有相关的国际准则。那些讨论不应该局限于工程师和政策制定者，毕竟那些问题会影响到每一个人。
从这个角度来看，“道德机器”研究让我们首次能够一窥数百万人对机器伦理的看法。
**01**
**不同文化之间存在分歧**
![xmwebp](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/00yGoQJ8PHeiabedTSlTS1RzbHxOgU5SlFdp5cwYPiaCga4fjeTNPVcNehZqhqEhpdfJZLsuC4dFAgqaxMhFFmRQ/640?wx_fmt=png?x-oss-process=style/xmwebp)
虽然大多数文化有着一些普遍的趋势，但研究人员发现，在偏重个人主义文化的国家(主要在西方)和偏重集体主义文化的国家之间存在着巨大的差异。
西方国家往往更倾向于让无人驾驶汽车保护孩子而非老人，而东方国家则更重视老人的生命——例如，在优先保护儿童而非老年人的倾向度上，柬埔寨远低于世界平均水平。同样的，西方国家的人也更倾向于保护尽可能多的人，不管群体的构成如何。
研究人员认为，这种分歧可能是制定有关自动驾驶汽车应如何行动的全球指导方针的最大挑战。他们写道：“对于政策制定者来说，保护更多的人和年轻人的偏好可能是最重要的考虑因素，因此不同文化之间的差异可能会成为制定通用机器伦理的一个重要障碍。”
**02**
**一个国家经济也影响自动驾驶伦理判断**
![xmwebp](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/00yGoQJ8PHeiabedTSlTS1RzbHxOgU5SlvypoOV2YCcde0JaVn3yfsDEZdfW2LmyreVHdm1bDbU6LdPrSJs0TIA/640?wx_fmt=png?x-oss-process=style/xmwebp)
除了文化差异以外，研究还发现，经济学在该问题上也发挥着重要作用。例如，透过一个国家的经济不平等程度，可以预测人们有多愿意优先保护社会地位较高的人而不是社会地位较低的人。这意味着，来自经济不平等程度高（依据世界银行对不平等程度的衡量指标基尼系数）的国家的人更有可能希望无人驾驶汽车优先保护企业高管而不是无家可归者。
通过比较瑞典和安哥拉，你可以在‘道德机器’的交互式图表中看到这一点。基尼系数越低，国家越接近平等。相较于全球平均水平，更平等的瑞典(基尼系数非常低，为29.2)不太可能希望无人驾驶汽车优先保护地位高的人，而安哥拉(基尼系数高，为42.7)则认为地位高的人比任何其它的群体都应受到优先保护。
“在‘道德机器’研究中，那些来自经济上没那么平等的国家的人也不平等地对待富人和穷人。”研究人员写道，“这种关系或许可以解释为，人们的道德偏好经常受到不平等的影响，也许更广泛的平等主义准则影响着一个国家愿意在社会层面容忍多大程度的不平等，影响者参与者在‘道德机器’判断中支持多大程度的不平等。”
同样地，对于乱穿马路的问题，国家的人均国内生产总值和制度的力量与保护遵守交通规则的人的偏好程度相关。另一方面，来自较贫穷国家的人往往对横穿马路的行人更加宽容。
**03**
**理解文化群体之间细微的差异尤为重要**
**![xmwebp](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/00yGoQJ8PHeiabedTSlTS1RzbHxOgU5SltdxNF9tbibYVka9yN1t5nnekI1m4TEeX41pz7E9WQPiadlRUAFkvBgSA/640?wx_fmt=png?x-oss-process=style/xmwebp)**
在年龄、人口数量和人类生活上，人们对于机器伦理有着一些基本的共识，但理解文化群体之间细微的差异尤为重要——它们往往没有个体与集体的差异那么明显。例如，南部地区的国家非常偏向于保护女性而不是男性，也非常偏向于保护身体健康的人而不是不健康的人。
研究人员认为，在制定决策系统和法规时，自动驾驶汽车制造商和政治家需要考虑到所有的这些差异。这一点很重要：“尽管公众的道德偏好不一定是道德政策的主要决定因素，但人们多大程度上愿意购买自动驾驶汽车以及容忍它们上路行驶，将取决于所采用的道德规则的适合性。”研究人员写道。
尽管不同文化之间存在这些差异，但‘道德机器’团队仍然认为，我们需要进行一次全球性的、包容性的对话，讨论我们在机器决策的问题上有什么样的伦理道德——尤其是考虑到自动化机器时代正在快速逼近我们。
“在人类历史上，我们从未允许过机器在没有实时监控的情况下，在一瞬间自主决定谁该活谁该死。”研究人员写道，“我们随时都将面临这个问题，它不会发生在军事行动的遥远战场上；它将发生在我们生活中最平凡的层面：每天的交通。在我们允许我们的汽车做出道德决定之前，我们需要进行一次全球对话，向设计道德算法的公司和监管它们的政策制定者表达我们的偏好。”
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
