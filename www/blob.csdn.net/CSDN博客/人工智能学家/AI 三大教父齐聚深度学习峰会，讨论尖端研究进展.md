# AI 三大教父齐聚深度学习峰会，讨论尖端研究进展 - 人工智能学家 - CSDN博客
2017年10月15日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：1160
![640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBUtHictdibHicFDwhpQU5m0zgoK5E9HIKCpJINsSrJuhTvqicLqZ8gTEJGVH2pDicOf2gMIoibtjChVjqrQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
*来源：36氪*
*概要：近日，深度学习峰会正在加拿大蒙特利尔举行，有史以来第一次3位AI教父：Yoshua Bengio、Yann LeCun以及 Geoffrey Hinton聚在了一起出席RE•WORK举办的一个专题讨论会。*
近日，深度学习峰会正在加拿大蒙特利尔举行。
近日，深度学习峰会正在加拿大蒙特利尔举行，有史以来第一次3位AI教父：Yoshua Bengio、Yann LeCun以及 Geoffrey Hinton聚在了一起出席RE•WORK举办的一个专题讨论会。三人一起分享了AI各种尖端研究进展情况，同时讨论了AI的版图形势等。
会议由麦吉尔大学的Joelle Pineau主持，他首先让三位大牛介绍一下自己的邻居，这引起了观众的一阵哄笑。Yoshua先开头说“这位是Yann，我是在读硕士的时候碰到他的，那时候他正在读Geoff的博士后，后来Yann邀请我跟他一起工作并开始卷积神经网络的研究，这东西知道现在还很热！”Yann继续介绍Geoffrey说“我也来说点历史，我上大学的时候开始研究神经网络然后我意识到在1970年代并没有这方面的研究发表。然后我看到了一篇叫做《最优知觉推理》的论文，Geoff正是3位作者中的一位。我看了论文之后就知道我得去见Geoffrey。”
 Geoff接着开玩笑说自己也许是Bengio论文的导师，但已经想不起来了。然后继续说：“那是一篇非常好的论文，应用了神经网络来进行语音识别。我和Yoshua在加拿大做得很好，因为加拿大支持基础研究。一切都发展得太快了，我现在已经跟不上Yoshua了！每周都有几篇论文出炉，我对他的工作尤其影响深刻，我的感觉是Yoshua是最年轻的，得有些追赶的工作要做，但不幸的是我认为他已经赶上了！他现在已经在自己的领域制造出像Yann在卷积神经网络方面一样的营销。”以下是研讨会摘要。
**能否说说现在的深度学习研究和工作跟1980、1990年代有什么不同？**
Bengio：回到那时候，你可以在没有所有这些噪声的情况下专心搞研究。这是一个完全不一样的环境。我们相遇的时候神经网络还是被边缘化的东西，这跟大概5到10年前有一些有趣的相似之处。1990年代初期神经网络火过一阵子，围绕着真心想要利用这种技术的公司进行了大量炒作，所以这跟现在有点像，但不同的是现在神经网络真正管用了。
LeCun：我认为当时也是管用的！但1960年代从事知觉研究的人认为走这条道路没什么价值，于是他们开始改变东西的名字以及运作方式，这产生了巨大的实际效果。
Hinton：他们两个太年轻了，记不得那时候的事了！
LeCun：有些东西当时还出现在1990年代的AI神经网络的教科书里面，但现在已经不那么重要了，不过仍然还被用来做参考——那些东西还有用，但不是实现AI的路径。我们今天使用的很多技术极可能广泛传播也可能转入地下，这要取决于我们能否找到让这种技术保持活力的下一步，否则的话就会消亡。
Hinton:他说过了！
**在你们的论文当中有没有什么我们应该阅读但却被忽视的东西？**
Hinton：低于你的H指数（评估研究人员的学术产出数量与学术产出水平的一个指标）的那篇论文。2008/9年的时候我写过一篇论文，里面利用了对关系建模的矩阵以及对概念建模的矩阵。所以这是一个三元组，你必须从前两个做出第三个。在2000年代早期的时候我在这方面做了很多工作，这基本上就是早期的嵌入。我被告知继续这方面的研究，因为整篇论文我只有一个参考文献是非自我引用的！其想法是不用向量代表概念，矩阵代表对象，而是用矩阵表示这两个，这样就可以做关系的关系。我们教它3+2等于5，然后我们教它2和+得出+2，那么它制造出来的输出此前从来都没见过这一概念，所以它得自己学会这一点。我把论文发给认知科学，他们不喜欢这东西但说“如果我现在理解了这篇论文的话那它是令人吃惊的，但我并不认为我们的读者会感兴趣！”
Bengio：我甚至连论文都没有提交因为我知道提交了也会被拒绝的！论文的想法是为了让机器学习我们需要其他人的引导，但这是另一个故事了。
随着时间的延续，你们的意见似乎越来越一致。你们是“深度学习的三剑客”，但是有没有什么领域是你们仍然分歧很大的？
Bengio：这个问题是不是有陷阱？
Hinton：政治！不过我们对美国政治意见一致。
LeCun：我们的分歧也许在于问题的解决办法而不是实际问题本身。Geoff曾经用过概率……
Bengio：Yann对概率一点都不感兴趣，他把Geoff叫做是概率警察。
**有很多人活跃在深度学习和神经网络领域，深度学习会不会一直活跃在AI里面，或者说有没有其他领域可能会产生巨大影响？**
Bengio：在我们现有基础上我们绝对需要新想法。这些想法会受到我们现有的东西的启发，会建立在现有基础之上然后做出新的东西来。
LeCun：概念会被参数化，并且会发展下去——概念并没有消失，但我们现有的当然是不够的，所以我们会考虑新的结构——很多人都对动态结构感到兴奋，在自然语言处理方面也发生了一些有趣的事情。我们还需要对非常大型的学习系统有更多的训练手段——这未必是终极答案，过去的想法可能还会卷土重来。会有某种办法将深度学习与推理等更加离散的东西联系起来。
Bengio：我们需要通过机器学习和深度学习想办法回到目标上来，用我们的新方法训练它们，教它们，好让他们对AI做出重要贡献。
Hinton：Yann 和Yoshua也相信这个——最大的障碍是无监督学习缺少一个目标函数。1992年的时候我发表了一篇论文，里面提出了把空间相干性作为目标函数的想法。如果有了这个，我们就能够了解更多的层并且在此基础上学习更多的东西。我们还会训练自编码器。
**说到目标函数，也就是结果是找到目标——那个能够在围棋比赛中击败人类的系统。我们不知道什么时候能解决这个问题，但你认为下一个挑战以及我们会解决的下一个东西是什么？**
LeCun：在Facebook，我们有个团队正在攻关《星际争霸》（注：日前他们偷偷参加了一场AI星际争霸赛，可是输了囧）。这个游戏币围棋要困难多了，因为它采用了策略、多层以及技能——你不知道你的伙伴在做什么，这在韩国其实是一种非常职业的游戏形式，极具挑战性。有一些机器人在玩这个游戏，但水平跟人类相比不可同日而语。Facebook团队以及DeepMind的一个团队正在利用机器学习，我认为这方面我们将会看到取得一些进展，但如何训练一辆车学会驾驶才是下一个需要解决的改变生活的大问题——有没有办法彻底地安全地做到这一点呢？
Bengio：其实我最近就在做住一个项目。一个人和婴儿AI之间进行的AI游戏。人用自然语言和指示等所有你预期父母会用的方式教婴儿AI。这一切都发生在一个虚拟的环境里面。游戏的目的是让人相处最好最快捷的方式去训练婴儿AI，同时又避免提出太多的问题。这个游戏很棒，因为对于人来说会很有趣，此外还能帮助收集大量数据去了解使用强化学习如何可以识别出自然语言与环境之间的关联。
**你们有没有觉得AI有哪些问题如果要你们解决的话宁愿退休不干？**
Bengio：有一些尚待解决的问题的确非常困难，但也很有趣！我希望知道机器如何可以发现高级表征去解释这个世界。解释世界有一些一般假设，从统计学的意义来上说这些假设暂时是有效的——问题相对简单，但解决起来就不简单了。
Hinton：有一个特别的东西会对我产生影响，那就是自然语言处理和语言理解。像“将被放不进手提箱因为它太小了。”以及“奖杯放不进手提箱因为它太大了。”这样的句子——第一个句子太小的是手提箱，而在第二个句子太大的是奖杯。我们做出这样的假设和推断是因为语言的结构，但如果你把这些句子翻译成法语，就要考虑另外两个因素——机器有性别权吗？这些背景你得了解。如果机器能够把这些都翻译到位的话就可以证明自己真的理解了发生的事情，但我认为数据集要比我们现有的规模大100倍才能让机器翻译做到完美。如果我们能做到这个就意味着机器了解了常识，这个意义是非常重大的。它将能够令老派的人信服：AI不是靠运气，而是的确知道发生了什么。我认为要做到这个很可能还需要10年的时间。
Bengio：我认为我们应该让机器学习解释睡眠是干什么的，是干什么用的。我认为大家不去质疑为什么我们要把一生当中1/3的时间花在睡觉上面是很奇怪的事情，但如果你剥夺了大家的睡眠的话人是会发疯的！我们喜欢8小时睡眠但不知道为什么。我强烈认为这能够透露一些有关我们如何学习的东西。
LeCun：我们怎么才能让机器获得常识？无监督学习，表示空间里面的目标函数，我们不知道，这可能要10到20年。
Hinton：也可能只用一周！
**技术话题暂告一段落，我们接着谈谈伦理影响——哪一个伦理问题最可能让你们彻夜难眠。**
Bengio：对我来说是AI以及我们制造的产品的滥用。比方说我对AI用于智能武器尤其敏感——这可能会非常危险，我认为政府应该制订条约。此外，广告业用AI来操纵对民主也是非常危险的。AI落入到不合适的人手上的问题的确非常麻烦。
LeCun：AI如果是不怀好意的人使用那就非常糟糕。事实上机器学习方法是可能在导致伤害的情况中被恶意使用的。比方说当你用带有偏见的数据训练一台机器时这台机器就有带有偏见，当你训练一个系统时它会复制训练者的行为。这既是技术问题也是伦理问题——我们应该如何消除偏见呢？大众对AI的形象可能就会沾上污点所以我们必须主动考虑这个问题。我正在跟“The Partnership
 in AI”合作，他们给部署测试之类的事情想出了一套指南来保证安全。
**你们有什么建议要跟从事AI工作的年轻人分享的呢？**
Hinton：如果某个想法别人都说不行但你有强烈的直觉这是个好点子的话，接受者不是坏主意而其实是原创想法的暗示。然后思考，你该不该研究你的“好想法”？如果你有好的直觉就去做你思考的东西，如果你没有好的直觉你做什么都无关紧要！！
Bengio：听Geoff的话
LeCun：我们三个的直觉都非常好，我们靠直觉想出概念和想法，有时候别人会对我们说不，所以其中一些最有趣的想法并不是最复杂的，但是你实现的方式也许是，大家用了那么长的时间才意识到一些东西是好想法，这是很令人感到吃惊的！
