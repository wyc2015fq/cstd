# 业界 | 德勤预测：机器学习走向移动端成大势所趋，或将再掀行业新浪潮 - 人工智能学家 - CSDN博客
2017年10月03日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：101
![640?wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmj0WyS3ASW0B4fMd32XAdNfPfXLk6JNicBOF4t40umDg8yjicoznyFVTHr8vALic6yBqkkKC3AbicAOog/640?wxfrom=5&wx_lazy=1)
*来源：AI科技评论*
*概要：早在20世纪70、80年代，大部分企业计算都由办公大楼地下室里的大型主机和微型计算机完成，工作人员则在操作由没有机载处理能力的阴极射线管监视器（被称为“绿屏”）和键盘组成的“简易终端”。*
根据德勤全球的预测，2017 年超过3亿部智能手机——或售出的超过五分之一——将具备机载神经网络机器学习能力。这些计算机模型旨在模拟人脑结构与功能的方方面面，用各个组件来代表神经元及其互连情况。也就是说，机器学习将真正走入这一我们最常见的移动端设备，智能手机。
在总结这一趋势之外，德勤提出以下三个主要论点：
1、机器学习移动化的历史变迁趋势
2、机器学习移动化的必然性
3、移动端机器学习在中国的发展现状和未来趋势
### **从核心到边缘：分布式智能发展简史**
纵观计算机发展史，我们不难发现，它其实也是一部智能边缘化（更贴近终端用户）简史。
早在20世纪70、80年代，大部分企业计算都由办公大楼地下室里的大型主机和微型计算机完成，工作人员则在操作由没有机载处理能力的阴极射线管监视器（被称为“绿屏”）和键盘组成的“简易终端”。在计算的历史上，处理和内存不仅稀少，而且昂贵。因此，IT架构通常都高度集中，所有智能都位于核心位置，各种外围设备则相对简易。
到了20世纪80年代，处理和内存的价格大幅下降，这些功能也就被推向台式电脑。最初的应用包括会计、电子制表（比如20世纪80年代超级流行的Lotus 1-2-390）和文字处理。较之前面提到的集中式处理，这些任务可以完成得稍好一些。不过随着时间流逝，个人电脑发展出许多更有趣、更重要的用途和效能。
同样，在台式电脑之后，将智能推向笔记本电脑也开创出全新的市场。随着智能手机的出现，智能进一步向边缘靠近，早期显而易见的应用就是即便远离PC也能浏览网页和电子邮件。在上一个十年，从应用程序到更精良的摄像头再到语言翻译，我们已经见识了这些一手即可掌握的智能设备可以有多强大，多具颠覆性。
在这一趋势的基础上，我们可以预见将机器学习——智能的一种特殊形式——推向网络边缘是具有颠覆意义的。它不仅可以开创先机，甚至还可能创建我们现在都无法想象的行业。
值得注意的是，随着时间的推移，针对物联网设备的应用将更具颠覆性。便携式机器学习能力不仅限于智能手机。在以后，无人机、平板电脑、汽车、虚拟或增强现实设备、医疗器具、物联网设备以及现在还无法预测的新技术都将具备这些能力。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmj0WyS3ASW0B4fMd32XAdNfaqNbTfNMrQKC510ib7L04nFkEaZyoOIhhcr4mRYNxqtbdTLJu50C84w/640?)
### **机器学习移动化趋势有其必然性**
机器学习与传统的显式编程相比，能更好的的执行复杂的认知任务，这已经是不争的事实。拿翻译来说，传统的翻译过程是以单词为单位进行的，从存储的词典里查找一个或多个单词，然后再替换成另外一门语言中所对应的单词。这种大规模的基于统计模型的机器翻译结果往往差强人意。但如果加上神经网络机器翻译，翻译工作就不用零敲碎打地进行，而是一次可以完成好几个句子甚至一整个段落的翻译，最后的结果也更加符合语法规则、符合语言习惯，也更容易理解。
然而到2016年为止，这些机器学习的过程全部都依赖于云端而非移动设备，因此在没有蜂窝网或Wi-Fi 连接的情况下就无法执行。人们对于手机的日益依赖，以及手机功能的日益强大，使得它们的连接能力不足已经不仅仅是不便，更可能造成致命伤害。我们需要移动设备能够持续而稳定的执行机器学习任务，在断网情况下，也可以提升诸多应用的性能，包括室内导航、图像分类、增强现实、语音识别和语言翻译等。且在这一过程中，所有数据不必再连接到远程的大型数据中心，更具隐私性。
同时，在手机端执行如图像识别之类的任务可以减少必需传输的数据量。与观看或上传视频相比，这一点对消费者使用智能手机的影响并不大。但是，在潜在的物联网应用及分析领域，减少需要传输的数据量（以及延迟）则重要得多。
短期内，大多数的本机机器学习能力都是在消费类电子设备上实现的，比如智能手机和平板电脑。不过随着时间的推移，针对物联网设备的应用将更具颠覆性，譬如自动驾驶、医疗设备或者油气管道钻探等。
### **移动端机器学习在中国的发展现状和未来走势**
总的来说，在云上智能向端上转移的趋势中，硬件实现将向类脑神经元芯片方向发展，紧凑型神经网络将随之取得进展，从而为用户提供更具针对性的优化体验。
端上智能的硬件实现方向是类脑神经元芯片。德勤预测，2017 年支持硬件端自主学习的类脑神经元芯片将得到发展，并投入实际的产业化应用。
具体可分为两类：一类是专用式的辅助处理器，它们的功能是在原有主机处理器的基础上加速深度学习算法，从而获得在某些领域的突出表现。这方面巨头公司已经出产包括谷歌的TPU(Tensor Processing Unit)，英伟达的Nvidia Tesla P100芯片等，我国于今年发布的“星光智能”、“寒武纪”等亦皆属此类。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmj0WyS3ASW0B4fMd32XAdNfJoHz5gpWPwj2N4icOQmxIicmSdTx3nIzE1QicPokA8STwFEFicDdntkpZw/640?)
“星光智能”是全球首颗具备深度学习人工智能的嵌入式视频采集压缩编码系统级芯片，这款基于深度学习的芯片运用在人脸识别上，最高能达到98%的准确率，超过人眼的识别率。“寒武纪”优势集中在人脸识别、声音识别等方面。二者可广泛应用于人脸识别、语音识别、无人机、智能驾驶辅助等方面。德勤预测，2017 年或将出现装有辅助式深度学习芯片的手机、摄像头、无人机等移动端设备，以优化人工智能体验。
另一种类脑神经元芯片是可独立运行不再需要CPU 辅助的处理器，如英特尔刚刚推出的Knights Mill芯片，能充当主处理器，可以直接接入RAM系统。我国也已先行出现一批独立的类脑神经元芯片，根据神经形态工程学原理，利用电路模拟人类“神经元”形态，从而模拟人脑运行，其特点是可在无网络情况下自主学习，且相比通用处理器功耗更低、效率更高。支持离线学习的芯片已在电脑上运行试验，但目前还未嵌入更小的移动设备如手机、无人机等。德勤预测，2017 年可以期望该类芯片的进一步改进，并在未来装载于更小型的移动端。
端上智能的技术实现方向是更紧凑的神经网络算法。针对特定移动端优化的紧凑型神经网络算法将产生并活跃于2017 年，这也将成为各大厂商的新战场，比如，优化出能支持在智能手机上离线运行语言翻译、符号识别、语音识别等任务的小型神经网络算法。
端上智能的体验趋势是用户针对性优化。德勤认为，通过移动端自主学习的能力，我们可以期望产生更具针对性的优化体验，这一优化体验可延伸应用于手写符号识别、自然语言理解、图像处理等领域。自主学习的手机将成为人们工作、学习、娱乐上的助手。并且，移动端的离线机器学习在教育、医疗、智能家居、物联网等行业都可广泛应用。
![640?](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmj0WyS3ASW0B4fMd32XAdNfu5mT5AYlI4l1u1AWVHPjbtOFstyMrOWSIujGiaWefOicbchcEJT1FHaQ/640?)
**结语**
目前而言，我们现在所谈到的智能应用，大多数都是再云端上整理、计算来的模型，本地端的终端，比如说智能手机，在机器学习上扮演的角色其实并不是很重要，计算性能较弱，加上功耗预算有限，手机本身能达到的学习机制相当有限。但随着半导体技术的发展，以及手机应用的智能化以及个人化要求的强化，手机上机器学习能力的强化，也变成未来必走的方向。由此而产生的对于移动设备软硬件等方面的要求，必将在本就是群雄逐鹿的移动端市场上掀起新一轮的激烈竞争。AI科技评论认为，可以预见的是，如果厂商有足够的预算和人力，以及可见的市场空间，那么自己定规格、造芯片会是不错的方式。目前，intel、Google、苹果等巨头企业已经在此投入重本，力图先人一步。但是对于一般中小规模的终端从业者或方案设计业者，可能就很难采取上述方式，此时就必须要使用标准架构，在市场上找到最佳的现成方案，缩小和那些资金充足的厂商之间的差距。具体如何选择，则需对应用场景做出全盘考量了。
![0?wx_fmt=png](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBXbbXOqraaibSoYJ0VSAFRT2C8iasBePX8nOs83bo1QIOibwWFjuF1icEiboxIJCNJZpR8IMQpjqjfz5fQ/0?wx_fmt=png)
