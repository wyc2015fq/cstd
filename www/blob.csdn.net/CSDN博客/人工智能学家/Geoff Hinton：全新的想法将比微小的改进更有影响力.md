# Geoff Hinton：全新的想法将比微小的改进更有影响力 - 人工智能学家 - CSDN博客
2018年12月18日 22:48:34[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：81
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/vJe7ErxcLmjff0ffS4AV7OHXMLLtMb4hAAShVIJ3zd0ic39iaRTWk4iaGCSzibHfXpzQ9RHqXia6Pc7aTLMYoMzKBhA/640?wx_fmt=jpeg)
来源：AI科技评论
摘要：日前，WIRED 对 Hinton 进行了一次专访，在访谈中，WIRED 针对人工智能带来的道德挑战和面临的挑战等问题进行了提问，以下为谈话内容。
**“作为一名谷歌高管，我认为在公开场合抱怨（Pentagon 合同）并不合适，所以我私下抱怨，”Geoff Hinton 说。    **
20 世纪 70 年代初，一位名叫 Geoff Hinton 的英国研究生开始建立简单的数学模型，以说明人脑中的神经元是如何从视觉上理解世界的。人工神经网络，正如他们所说，几十年来一直是一种不切实际的技术。但是在 2012 年，Hinton 和他在多伦多大学的两个研究生用人工神经网络大大提高了计算机识别照片中物体的精度。在这之后不到六个月，谷歌就收购了这三名研究人员创办的一家初创公司。以前默默无闻的人工神经网络一时间成为了硅谷的话题。现在，所有的大型科技公司都把 Hinton 和其他一小群人煞费苦心研究的这项技术作为他们未来计划的重中之重，并将其融入我们的生活。
日前，在第一届 G7 人工智能会议上，来自世界主要发达国家的代表们讨论了如何利用人工智能的优势，同时尽量减少诸如失业和带有歧视的算法等不利因素。在这次会议上，WIRED 和 Hinton 进行了会晤，并对谈话记录进行了编辑整理。下面是访谈内容。
WIRED：加拿大总理 Justin Trudeau 在 G7 会议上说，在人工智能带来的道德挑战方面，人类还需要做更多的工作。对此，你是怎么看待的？
Geoff Hinton：我一直担心在致命的自主武器中潜在的滥用问题，我认为应该有一些像日内瓦公约一样的条例来防范这一问题。即使不是每个国家都会签名，它的存在也会起到道德标杆的作用。你会注意到谁没有签名。
WIRED：4500 多位谷歌同事签署了一封信，抗议 Pentagon 合同将机器学习应用于无人机图像。谷歌表示，这不是为了作为攻击性武器使用。你在这封信上签字了吗？
Geoff Hinton：作为一名谷歌高管，我认为在公开场合抗议不符合我的职责，所以我私下抗议。我没有在信上签名，而是和谷歌联合创始人谢尔盖·布林进行了交谈。他说他也对此感到有点担忧。所以他们决定接下来放弃这一合同。
WIRED：谷歌的领导人决定完成合同，但不会续约。他们还发布了一些关于使用人工智能的准则，其中包括保证不使用该技术制造武器。
Geoff Hinton：我认为谷歌作出了正确的决定。将会有各种各样的事情需要云计算，并且很难知道技术的边界在哪里，从某种意义上讲，这个界限很随意。我很高兴谷歌在这件事情上划清界限，这些原则对我来说很有意义。
**“你应该基于这些系统的性能来调节。你可以通过实验来查看它们是否有偏差，或者它是否可能比人杀死更少的人。”**
WIRED：人工智能在日常生活中也会引发道德问题，例如，当软件用于社会服务或医疗保健中的决策。我们应该注意什么？
Geoff Hinton：我是使技术发挥作用的专家，但不是社会政策专家。我确实拥有相关技术专长的一个地方是，监管机构是否应该坚持让你解释你的人工智能系统是如何工作的。我认为这将是一场彻底的灾难。
人们对于他们自己所做的大多数事情，都无法解释。当你决定是否雇用某人时，这个决定是基于你能量化的各种事情，然后是各种直觉。人们并不知道他们是怎么做到的。如果你要求他们解释他们的决定，你就是在强迫他们编造一个故事。
神经网络也有类似的问题。当你训练一个神经网络时，它将学习数十亿个数字，这些数字代表它从训练数据中提取的知识。如果你把图像放进去，就能检测出正确的结果，例如，检测图像中的某个物体是不是行人。但如果你问「为什么它会这么认为？」好吧，如果有任何简单的规则来判断一张图像是否包含行人，那么这个问题在很久以前就已经被解决了。
WIRED：那么我们如何知道何时可以信任这些系统呢？
Geoff Hinton：你应该基于这些系统的性能进行调节。你可以通过实验来查看它们是否有偏差，或者它是否可能比人杀死更少的人。对于自动驾驶，我认为现在人们在某种程度上已经接受了它。即使你不太清楚自动驾驶的原理，但如果自动驾驶的事故比人驾车少得多，那也是件好事。我认为我们必须像对待人一样对待它：你只要看看它们表现如何，如果它们不停地遇到困难，就说明它们不是那么好。
WIRED：你说过，思考大脑是如何工作的，会启发你对人工神经网络的研究。我们的大脑通过由突触连接的神经元网络从感觉中获取信息。人工神经网络通过数学神经元网络提供数据，这些数学神经元网络通过权重进行连接。在上周发表的一篇论文中，你和几位合著者认为我们应该做更多的工作来揭示大脑中的学习算法。这是为什么？
Geoff Hinton：大脑解决问题的方法和我们大多数神经网络有很大区别。人类有大约 100 万亿个突触，人工神经网络就权重的数量来说，通常至少要比这个数字小 10000 倍。在学习一个片段的时候，大脑会使用很多很多的突触来尽可能地学习到更多。深度学习擅长利用神经元之间较少的联系进行学习，因为神经元之间有许多事件或例子需要学习。我认为大脑并不关心如何把很多的知识连接起来，它关心的是如何利用这些连接快速获取知识。
WIRED：我们怎样才能构建出功能更完善的机器学习系统？
Geoff Hinton：我想我们需要换一种不同的计算机。幸运的是，我这里有一个。
Hinton 把手伸进他的钱包，拿出一个又大又亮的硅片。这是一个来自 Graphcore 的样品，Graphcore 是一家英国初创公司，它致力于开发一种新型的处理器来驱动机器/深度学习算法。
几乎所有我们用来运行神经网络的计算机系统，甚至是 Google 的特殊硬件，都使用 RAM 来存储正在使用的程序。从 RAM 中提取神经网络的权重，以便处理器使用，这需要花费令人难以置信的代价。一旦软件获取了权重，它就会使用很多次。这需要付出巨大的代价。
在 Graphcore 芯片上，权重存储在处理器上的高速缓存区中，而不是 RAM 中，因此不需要移动它们。正因为如此，有些事情将变得更容易探索。然后我们可能会得到一个系统，这个系统可能有一万亿个权重，但是在每个示例中只会使用到十亿个。这和大脑的规模更接近。
”从长远来看，一个全新的想法将比微小的改进更有影响力。”
WIRED：最近人们对人工智能和机器学习的兴趣和投资激增，这意味着将有更多的资金用于研究。这个领域的迅速发展是否也带来了新的挑战？
Geoff Hinton：社区面临的一个巨大挑战是，如果你现在想要发表一篇机器学习的论文，那么在这篇论文里面必须有一个表格，在表格的最上面有所有不同的数据集，在旁边还有所有不同的方法，并且你的方法必须看起来是最好的方法。如果不是这样的话，论文将很难发表。我认为这并不能鼓励人们去思考全新的理念。
现在，如果你发布一篇具有全新理念的论文，它不可能被接受，因为初级评审员并不能理解这篇论文。如果遇到一位资深评审人员，因为他会试图尽可能地读更多的论文，如果第一次就看不懂，他就会认为那篇论文肯定是胡说八道。任何人们不能理解的事情都不会被接受。我认为这真的很糟糕。
我们应该追求的是全新的理念，尤其是在基础科学会议上。从长远来看，一个全新的想法将比微小的改进更有影响力。这就是我认为的现在我们所面临的主要挑战，目前在这个领域有一部分的资深人士，还有无数年轻人。
WIRED：那这个问题会阻碍这个领域的发展吗？
Geoff Hinton：只要等上几年，这种不平衡就会得到纠正。这种状况只是暂时的。公司正忙于教育人们，大学也在教育人们，大学最终将在这个领域雇用更多的教授，而且它会进行自我调整。
WIRED：一些学者警告说，目前的炒作可能导致「人工智能的冬天」，就像上世纪 80 年代那样，因为没有达到预期的进展，当时的利息和资金枯竭了。
Geoff Hinton：不，不会有人工智能的冬天，因为 AI 技术已经用于手机。在旧人工智能的冬天，人工智能实际上不是你日常生活的一部分，但现在它是。
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
