# AI技术的天花板：图灵机无法建立“自我”意识的概念 - 人工智能学家 - CSDN博客
2017年10月09日 00:00:00[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：543
![640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBUdJ7WcPdZebaL3xHRDOFcogo0Hbd6rvUex99jUfumpudTNiao0QoCS2hIhRp4Ziclf7SVgxicDKXcpQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
*来源：财经杂志*
*概**要：AI的实现时必须依靠计算机，但基于图灵机的AI在理论上无法超越人类智能，至少不会基于这一代的计算机技术和理论。*
人工智能（AI）的基本假设是“认知即计算”。但目前对认知本质的理解不同发展出了多个学派，典型的如基于数理逻辑的符号学派、模仿生物行为特征的行为主义学派，以及模仿生物神经网络的连接学派。
60多年来，AI已多次起伏。本轮兴起的主因是硬件能力的飞跃、数据的海量增长和算法的明显改进，尤其是神经网络（更准确地说是深度学习）在计算机视觉和自然语言识别方面取得了突破。当然，云计算、开源运动和摩尔定律，也起到了至关重要的推动作用。
但目前基于深度学习的AI技术还存在诸多限制。例如，算法还是个黑盒子，无法做因果解释，调参数主要还是靠运气。另外，机器学习的训练是个吞噬算力的“算老虎”。第三，数据透明性不够，诱导性或对抗性数据容易改变学习的结果等。这些都导致目前的AI技术还无法与其他学派有机结合起来。
最关键的，所有AI的实现都要依靠各类计算机，从PC、服务器到GPU（图形处理器），它们都是 “图灵机”的具体实现。但理论上已证明，图灵机是无法建立起“自我”意识的概念。换言之，即使将来AI会超越人类智能，也至少不会基于这一代的计算机技术和理论，或许会基于量子计算。
**AI三大学派进阶**
起源于60年前的AI理论，建立在“智能的本质是计算”的基本假设上。但因为对智能本质的认知不同，基于计算机如何构造AI已形成了三大学派。
第一个叫符号主义学派。主张智能源于数理逻辑，认为人类的认知和思维的基本单元是符号，认知过程就是对符号的逻辑运算。其代表作是在电视问答竞赛中战胜人类选手的IBM Watson。
第二个叫行为主义学派。主张的基础是诺伯特·维纳的控制论，把关注的焦点从人类转向了整个生物界的智能（比如昆虫的个体和群体智能），终极形式是二进制的人工生命。其代表作是麻省理工学院的“六足机器人”。
第三个叫连接主义学派。主张将智能建立在大量简单的计算单元上，经过复杂连接后，并行运算的结果。这一学派基于神经生物学和认知科学，因为人类大脑就是由１万亿个简单的神经元细胞，错综复杂地连接起来产生的。
神经网络诞生于上世纪60年代，最初只包括输入层、隐藏层和输出层。输入层和输出层通常由应用决定，隐含层包含神经元可供训练。2006年，多伦多大学教授Geoffrey Hinton的团队在《科学》上发表了一篇文章，提出了深度学习的概念，指出可以用更多隐藏层（比如5层-10层）做算法训练，因为实验效果显著，开启了学界和产业界AI的新浪潮。
相比传统的机器学习，深度学习可以让机器自动习来特征，无需人工事先设定。针对不同的应用场景，传统机器学习算法需要把软件代码重写一遍，而深度学习只需要调整参数就能改变模型。
深度学习是用数据来做训练。一般而言，学习的深度越深和广度越大，需要的数据量就越大，需要的数据种类就越多。当然不能一概而论，也不是数据越多越好，可能会出现“过度训练”。
深度学习的训练分两种。一种是有监督的，就是人工为数据加了标签，这种方法的缺点是，现实世界中被打了标签的数据太少了。另外一种是无监督的，只有数据没有人工的标签，计算机不知道正确答案就可以训练。
**这一轮的动力**
AI的新算法和新数据，都以大幅增加对计算资源的消耗为前提。业界找到的新动力，或者说新的计算资源，就是GPU（图形处理单元）。
60多年来AI市场规模一直很小，内部帮派林立，支撑不起AI专用芯片的市场。因此早期的机器学习，只能基于廉价而广泛存在的CPU提供计算资源，或者极少数情况下用昂贵的专用芯片。
GPU诞生于上世纪90年代，设计专用于高并发计算、大量浮点计算和矩阵计算能力的视频游戏和图形渲染等应用，即计算密集型应用。深度学习正好就是计算密集型的。大约在2008年-2012年，业界逐步摸索到了，如何将深度学习与GPU有机结合起来的工程方法，直接将深度学习的速度加速了数百倍，让产业界看到了把AI实用化的希望。
当然GPU可能也还是太通用了，于是更加专用的FPGA（Field Programmable Gate Array，现场可编辑阵列）和ASIC（Application Specific Integrated Circuit，专用集成电络）纷纷登场。谷歌新近发布的TPU（Tensor Processing Unit）芯片，号称处理速度比CPU和GPU快15倍-30倍，性能功耗比高出约30倍-80倍，当然是神经网络专用场景。
摩尔定律说，同样成本每隔18个月晶体管数量会翻倍，反过来同样数量晶体管成本会减半。近年来摩尔定律虽然有所减速，但仍然是CPU、GPU和TPU等快速发展的基础。
云计算也是AI发展的坚实基础。产业界云计算“大佬”纷纷推出“GPU/FPGA/算法/数据as a Service”业务,可以通过云端直接租用资源，方便用户做深度学习。
近十年来，不仅是软件定义世界，而且是开源软件定义世界。如果说2017年AI技术最大的变化是专用硬件的设计潮，那么2016年AI技术的最大变化则是巨头们纷纷开源了深度学习框架，比如Facebook的Torch和Caffe，谷歌的Tensorflow，亚马逊的MXnet，微软的CNTK，IBM的SystemML等。十年前，谷歌开源了Android操作系统，成功打造了智能手机的Android生态。现在，谷歌等纷纷开源AI框架，希望打造“AI优先”时代的新生态，重现往日辉煌。
**技术仍有局限性**
深度学习的效果取决于网络结构的设计、训练数据的质量和训练方法的合理性等。无论是从统计学还是对智能的基本认知的角度看，这次深度学习牵引的AI产业化浪潮还存在不少局限性。
首先是在算法方面。深度学习目前仍然是黑盒子，缺乏理论指导，对神经网络内部涌现出的所谓“智能”还不能做出合理解释；二是事先无法预知学习的效果。为了提高训练的效果，除了不断增加网络深度和节点数量、喂更多数据和增加算力，然后反复调整参数，基本就没别的招数了；三是调参还像玄学。还没有总结出一套系统经验做指导，完全依赖个人经验，甚至靠碰运气；四是通用性仍有待提高。目前几乎所有的机器学习系统都是被训练执行单一任务，没有之前任务的记忆。
其次是在计算方面。目前的机器学习基本还是蛮力计算，是吞噬“算力”的巨兽。一是在线实时训练几乎不可能，还只能离线进行；二是虽然GPU等并行式计算硬件取得了巨大进步，但算力仍然是性能的巨大瓶颈；三是能够大幅提高算力的硅芯片，已逼近物理和经济成本上的极限。摩尔定律已经衰老，计算性能的增长曲线变得不可预测。
第三是在数据方面。一是数据透明度。虽然学习方法是公开透明的，但训练用的数据集往往是不透明的；二是数据攻击。输入数据的细微抖动就可能导致算法的失效，如果在利益方的诱导下发起对抗性样本攻击，系统就直接被“洗脑”了；三是监督学习。深度学习需要的海量大数据，需要打上标签做监督学习，而对实时海量的大数据人工打上标签几乎不可能。
第四是与其他学派结合。目前AI取得的进步属于连接学派，因此在对智能的认知方面，缺乏分析因果关系的逻辑推理能力，还无法理解实体的概念，无法识别关键影响因素，不会直接学习知识，不善于解决复杂数学运算，缺乏伦理道德等方面的常识。
到2017年，机器学习的神经网络已具有数千到数百万个神经元和数百万个连接。这样的复杂度还只相当于一个蠕虫的大脑，与有1000亿神经元和1万亿连接的人类大脑，差了N个数量级。但尽管如此，神经网络下围棋的能力已远高于一只蠕虫，而一只蠕虫所具有的自繁衍、捕食和躲避天敌等智能，人工智能都还望尘莫及。
现在，业界只知道深度学习在图像处理和语音识别等方面表现出色，未来在其他领域也可能有潜在的应用价值，但它究竟做不了什么，如何与逻辑推理等结合起来仍然不清楚。深度学习需要更安全、更透明和更可解释。
AI的实现时必须依靠计算机，但基于图灵机的AI在理论上无法超越人类智能，至少不会基于这一代的计算机技术和理论。
