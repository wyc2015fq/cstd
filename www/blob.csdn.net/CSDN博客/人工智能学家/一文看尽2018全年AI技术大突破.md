# 一文看尽2018全年AI技术大突破 - 人工智能学家 - CSDN博客
2018年12月21日 23:57:06[人工智能学家](https://me.csdn.net/cf2SudS8x8F0v)阅读数：95
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJIKjic9rwHtwB9qicYic7ibrzlvWAxQnupib8OLGBib1umpLad7sYpJqrF1cA/640?wx_fmt=png)
来源：量子位
摘要：2018，仍是AI领域激动人心的一年。这一年成为NLP研究的分水岭，各种突破接连不断；CV领域同样精彩纷呈，与四年前相比GAN生成的假脸逼真到让人不敢相信；新工具、新框架的出现，也让这个领域的明天特别让人期待……
近日，Analytics Vidhya发布了一份2018人工智能技术总结与2019趋势预测报告，原文作者PRANAV DAR。量子位在保留这个报告架构的基础上，对内容进行了重新编辑和补充。
这份报告总结和梳理了全年主要AI技术领域的重大进展，同时也给出了相关的资源地址，以便大家更好的使用、查询。
报告共涉及了五个主要部分：
- 
自然语言处理（NLP）
- 
计算机视觉
- 
工具和库
- 
强化学习
- 
AI道德
下面，我们就逐一来盘点和展望，嘿喂狗~
# **自然语言处理（NLP）**
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJt8RLXs5mn0BGNqjXZXv7QbenSyukx6wiblhmGS6nwQJW4wXXWc8bRiaw/640?wx_fmt=png)
2018年在NLP历史上的特殊地位，已经毋庸置疑。
这份报告认为，这一年正是NLP的分水岭。2018年里，NLP领域的突破接连不断：ULMFiT、ELMo、最近大热的BERT……
迁移学习成了NLP进展的重要推动力。从一个预训练模型开始，不断去适应新的数据，带来了无尽的潜力，甚至有“NLP领域的ImageNet时代已经到来”一说。
## **■ ULMFiT**
这个缩写，代表**“通用语言模型的微调”，**出自ACL 2018论文：Universal Language Model Fine-tuning for Text Classification。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJVkRZzUAtcHptUKE6gia6SVY6kMpm4I6XavibpUeiaxtzEjCwryzbrvCnw/640?wx_fmt=png)
正是这篇论文，打响了今年NLP迁移学习狂欢的第一枪。
论文两名作者一是Fast.ai创始人Jeremy Howard，在迁移学习上经验丰富；一是自然语言处理方向的博士生Sebastian Ruder，他的NLP博客几乎所有同行都在读。
两个人的专长综合起来，就有了ULMFiT。想要搞定一项NLP任务，不再需要从0开始训练模型，拿来ULMFiT，用少量数据微调一下，它就可以在新任务上实现更好的性能。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJmy9c4FnNMVNgBQMBMhXIKgFjriaL8UxBprOt90RK5PjzLI1Dn5TAEwA/640?wx_fmt=png)
他们的方法，在六项文本分类任务上超越了之前最先进的模型。
详细的说明可以读他们的论文：
https://arxiv.org/abs/1801.06146
Fast.ai网站上放出了训练脚本、模型等：
http://nlp.fast.ai/category/classification.html
## **■ ELMo**
## 这个名字，当然不是指《芝麻街》里那个角色，而是“语言模型的词嵌入”，出自艾伦人工智能研究院和华盛顿大学的论文Deep contextualized word representations，NLP顶会NAACL HLT 2018的优秀论文之一。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCZkVPTibibgicicDo1LmSA4j92T2aHXpMGLwIO37gSqpCnB74somfMLM1DORUWJXnDDHGYEjhTfTQChA/640?wx_fmt=png)
ELMo用语言模型（language model）来获取词嵌入，同时也把词语所处句、段的语境考虑进来。
这种语境化的词语表示，能够体现一个词在语法语义用法上的复杂特征，也能体现它在不同语境下如何变化。
当然，ELMo也在试验中展示出了强大功效。把ELMo用到已有的NLP模型上，能够带来各种任务上的性能提升。比如在机器问答数据集SQuAD上，用ELMo能让此前最厉害的模型成绩在提高4.7个百分点。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJqLF4mMDgXiajf68byzJKo8MNrppk8yPXcEtMxQ9Zz3PickkdD1AiatyMA/640?wx_fmt=png)
这里有ELMo的更多介绍和资源：
https://allennlp.org/elmo
## **■ BERT**
说BERT是2018年最火的NLP模型，一点也不为过，它甚至被称为NLP新时代的开端。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ2Haxb5G4myE54ph9oibp2DPEvXSpmvjxibarVkVjrsYtFL8v6xqcTianA/640?wx_fmt=png)
它由Google推出，全称是Bidirectional Encoder Representations from Transformers，意思是来自Transformer的双向编码器表示，也是一种预训练语言表示的方法。
从性能上来看，没有哪个模型能与BERT一战。它在11项NLP任务上都取得了最顶尖成绩，到现在，SQuAD 2.0前10名只有一个不是BERT变体：
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJIXldjRRYnOq3ojYIZleg3kvluQcjAQkr3cXLda7yVmbIuIiat0uVFng/640?wx_fmt=jpeg)
如果你还没有读过BERT的论文，真的应该在2018年结束前补完这一课：
https://arxiv.org/abs/1810.04805
另外，Google官方开源了训练代码和预训练模型：
https://github.com/google-research/bert
如果你是PyTorch党，也不怕。这里还有官方推荐的PyTorch重实现和转换脚本：
https://github.com/huggingface/pytorch-pretrained-BERT
## **■ PyText**
BERT之后，NLP圈在2018年还能收获什么惊喜？答案是，一款新工具。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJnzcpB9DSy6uW3MZQFsmp9Fmvk0iaHG4gkDibcFxDA16Lqp2p8OjTOwJg/640?wx_fmt=png)
就在上周末，Facebook开源了自家工程师们一直在用的NLP建模框架PyText。这个框架，每天要为Facebook旗下各种应用处理超过10亿次NLP任务，是一个工业级的工具包。
（Facebook开源新NLP框架：简化部署流程，大规模应用也OK）
PyText基于PyTorch，能够加速从研究到应用的进度，从模型的研究到完整实施只需要几天时间。框架里还包含了一些预训练模型，可以直接拿来处理文本分类、序列标注等任务。
想试试？开源地址在此：
https://github.com/facebookresearch/pytext
## **■ Duplex**
如果前面这些研究对你来说都太抽象的话，Duplex则是NLP进展的最生动例证。
名字有点陌生？不过这个产品你一定听说过，它就是Google在2018年I/O开发者大会上展示的“打电话AI”。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ1AsSL2wrWBuSNM1ch7dwCzpU36byIicSHWYgLUejxQwrm6oHHicnHn0Q/640?wx_fmt=png)
它能主动打电话给美发店、餐馆预约服务，全程流畅交流，简直以假乱真。Google董事长John Hennessy后来称之为“非凡的突破”，还说：“在预约领域，这个AI已经通过了图灵测试。”
Duplex在多轮对话中表现出的理解能力、合成语音的自然程度，都是NLP目前水平的体现。
如果你还没看过它的视频……
**■ 2019年展望**
NLP在2019年会怎么样？我们借用一下ULMFiT作者Sebastian Ruder的展望：
- 
预训练语言模型嵌入将无处不在：不用预训练模型，从头开始训练达到顶尖水平的模型，将十分罕见。
- 
能编码专业信息的预训练表示将会出现，这是语言模型嵌入的一种补充。到时候，我们就能根据任务需要，把不同类型的预训练表示结合起来。
- 
在多语言应用、跨语言模型上，将有更多研究。特别是在跨语言词嵌入的基础上，深度预训练跨语言表示将会出现。
# **计算机视觉**
今年，无论是图像还是视频方向都有大量新研究问世，有三大研究曾在CV圈掀起了集体波澜。
## **■ BigGAN**
今年9月，当搭载BigGAN的双盲评审中的ICLR 2019论文现身，行家们就沸腾了：简直看不出这是GAN自己生成的。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ5S8Pky0Z0mM1VeMhPXCUrFD2a2icqJCibsSEkNIP90YV59HttdqgVZaA/640?wx_fmt=png)
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJe3Qs3xjXAcXCSqzMHJAHR84LBEBMdOLPO8XgYFiaWfuoFW8eDSaKlzg/640?wx_fmt=png)
在计算机图像研究史上，BigGAN的效果比前人进步了一大截。比如在ImageNet上进行128×128分辨率的训练后，它的Inception Score（IS）得分166.3，是之前最佳得分52.52分3倍。
除了搞定128×128小图之外，BigGAN还能直接在256×256、512×512的ImageNet数据上训练，生成更让人信服的样本。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ0pyLLM0be14rL3OzMAyS6QwKV34PgPrB4chapw8qHaL6LkzsceYm0A/640?wx_fmt=png)
在论文中研究人员揭秘，BigGAN的惊人效果背后，真的付出了金钱的代价，最多要用512个TPU训练，费用可达11万美元，合人民币76万元。
不止是模型参数多，训练规模也是有GAN以来最大的。它的参数是前人的2-4倍，批次大小是前人的8倍。
相关地址
研究论文：
https://openreview.net/pdf?id=B1xsqj09Fm
## **■ Fast.ai 18分钟训练整个ImageNet**
在完整的ImageNet上训练一个模型需要多久？各大公司不断下血本刷新着记录。
不过，也有不那么烧计算资源的平民版。
今年8月，在线深度学习课程Fast.ai的创始人Jeremy Howard和自己的学生，用租来的亚马逊AWS的云计算资源，18分钟在ImageNet上将图像分类模型训练到了93%的准确率。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ16FT3ZZ6sBzrKBlsVbAVghc8LV4IaxGVEzoaQaKavsSaMx5Uokfd4A/640?wx_fmt=png)
前前后后，Fast.ai团队只用了16个AWS云实例，每个实例搭载8块英伟达V100 GPU，结果比Google用TPU Pod在斯坦福DAWNBench测试上达到的速度还要快40%。
这样拔群的成绩，成本价只需要40美元，Fast.ai在博客中将其称作人人可实现。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJhp8w3f8a4q5ypx9UQiblOcQMRYToiaLuxweeLUibrYDgEgDoFgeRtEibxg/640?wx_fmt=png)
相关地址：
Fast.ai博客介绍：
https://www.fast.ai/2018/08/10/fastai-diu-imagenet/
## **■ vid2vid技术**
今年8月，英伟达和MIT的研究团队高出一个超逼真高清视频生成AI。
只要一幅动态的语义地图，就可获得和真实世界几乎一模一样的视频。换句话说，只要把你心中的场景勾勒出来，无需实拍，电影级的视频就可以自动P出来：
![640?wx_fmt=gif](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCZkVPTibibgicicDo1LmSA4j92CHwp8HPGwgiaV953DO5FE1Wndpjg4VfJcy7sZ2Jg7j0UOJvAhnZiakpA/640?wx_fmt=gif)
除了街景，人脸也可生成：
![640?wx_fmt=gif](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCZkVPTibibgicicDo1LmSA4j92usGTeTBecLHs8ElmCZImhEojicJ7wZDDaY0gYMt4RCkAXtC5PB5NyeA/640?wx_fmt=gif)
这背后的vid2vid技术，是一种在生成对抗性学习框架下的新方法：精心设计的生成器和鉴别器架构，再加上时空对抗目标。
这种方法可以在分割蒙版、素描草图、人体姿势等多种输入格式上，实现高分辨率、逼真、时间相干的视频效果。
好消息，vid2vid现已被英伟达开源。
相关地址
研究论文：
https://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf
GitHub地址
https://github.com/NVIDIA/vid2vid
## **■ 2019趋势展望**
Analytics Vidhya预计，明年在计算机视觉领域，对现有方法的改进和增强的研究可能多于创造新方法。
在美国，政府对无人机的限令可能会稍微“松绑”，开放程度可能增加。而今年大火的自监督学习明年可能会应用到更多研究中。
Analytics Vidhya对视觉领域也有一些期待，目前来看，在CVPR和ICML等国际顶会上公布最新研究成果，在工业界的应用情况还不乐观。他希望在2019年，能看到更多的研究在实际场景中落地。
Analytics Vidhya预计，视觉问答（Visual Question Answering，VQA）技术和视觉对话系统可能会在各种实际应用中首次亮相。
![640?wx_fmt=gif](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCZkVPTibibgicicDo1LmSA4j92WmOnZtAcRbicYVU6zGoIPqjOUK5gIwypmYyfBBZFjOxnCdvTd5GlWcQ/640?wx_fmt=gif)
# **工具和框架**
哪种工具最好？哪个框架代表了未来？这都是一个个能永远争论下去的话题。
没有异议的是，不管争辩的结果是什么，我们都需要掌握和了解最新的工具，否则就有可能被行业所抛弃。
今年，机器学习领域的工具和框架仍在快速的发展，下面就是这方面的总结和展望。
## **■ PyTorch 1.0**
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJmfPMgQ7owCBtxic8R0q6XXbZbByCfXa0DTxGvZXJWNUnZMJ3PpBRONg/640?wx_fmt=png)
根据10月GitHub发布的2018年度报告，PyTorch在增长最快的开源项目排行上，名列第二。也是唯一入围的深度学习框架。
作为谷歌TensorFlow最大的“劲敌”，PyTorch其实是一个新兵，2017年1月19日才正式发布。2018年5月，PyTorch和Caffe2整合，成为新一代PyTorch 1.0，竞争力更进一步。
相较而言，PyTorch速度快而且非常灵活，在GitHub上有越来越多的开码都采用了PyTorch框架。可以预见，明年PyTorch会更加普及。
至于PyTorch和TensorFlow怎么选择？在我们之前发过的一篇报道里，不少大佬站PyTorch。
实际上，两个框架越来越像。前Google Brain深度学习研究员，Denny Britz认为，大多数情况下，选择哪一个深度学习框架，其实影响没那么大。
相关地址
PyTorch官网：
https://pytorch.org/
## **■ AutoML**
很多人将AutoML称为深度学习的新方式，认为它改变了整个系统。有了AutoML，我们就不再需要设计复杂的深度学习网络。
今年1月17日，谷歌推出Cloud AutoML服务，把自家的AutoML技术通过云平台对外发布，即便你不懂机器学习，也能训练出一个定制化的机器学习模型。
不过AutoML并不是谷歌的专利。过去几年，很多公司都在涉足这个领域，比方国外有RapidMiner、KNIME、DataRobot和H2O.ai等等。
除了这些公司的产品，还有一个开源库要介绍给大家：
Auto Keras！
这是一个用于执行AutoML任务的开源库，意在让更多人即便没有人工智能的专家背景，也能搞定机器学习这件事。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJoCEmRS1icMabpiaKqx6RQoI5QRGJDktDbp6NNLCBuv4Irrhoy8x9x4TQ/640?wx_fmt=png)
这个库的作者是美国德州农工大学（Texas A&M University）助理教授胡侠和他的两名博士生：金海峰、Qingquan Song。Auto Keras直击谷歌AutoML的三大缺陷：
- 
第一，还得付钱。
- 
第二，因为在云上，还得配置Docker容器和Kubernetes。
- 
第三，服务商(Google)保证不了你数据安全和隐私。
相关地址
官网：
https://autokeras.com/
GitHub：
https://github.com/jhfjhfj1/autokeras
## **■ TensorFlow.js**
今年3月底的TensorFlow开发者会峰会2018上，TensorFlow.js正式发布。
这是一个面向JavaScript开发者的机器学习框架，可以完全在浏览器中定义和训练模型，也能导入离线训练的TensorFlow和Keras模型进行预测，还对WebGL实现无缝支持。
在浏览器中使用TensorFlow.js可以扩展更多的应用场景，包括展开交互式的机器学习、所有数据都保存在客户端的情况等。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ9hkpfPtnZF8iaaqJJ17oXy2a417EWhR8MicYfS3Jn8ibWiashiaap9dAS0Q/640?wx_fmt=png)
实际上，这个新发布的TensorFlow.js，就是基于之前的deeplearn.js，只不过被整合进TensorFlow之中。
谷歌还给了几个TensorFlow.js的应用案例。比如借用你的摄像头，来玩经典游戏：吃豆人（Pac-Man）。
相关地址
官网：
https://js.tensorflow.org/
## **■ 2019趋势展望**
在工具这个主题中，最受关注的就是AutoML。因为这是一个真正会改变游戏规则的核心技术。在此，引用H2O.ai的大神Marios Michailidis（KazAnova）对明年AutoML领域的展望。
> - 
以智能可视化、提供洞见等方式，帮助描述和理解数据
- 
为数据集发现、构建、提取更好的特征
- 
快速构建更强大、更智能的预测模型
- 
通过机器学习可解释性，弥补黑盒建模带来的差距
- 
推动这些模型的产生
# **强化学习**
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJXcbLIuBxibd7ltoVpHkNTq8jN3rqMpFmZKKGIia85PzRPS1fXmV0lUeg/640?wx_fmt=png)
强化学习还有很长的路要走。
除了偶尔成为头条新闻之外，目前强化学习领域还缺乏真正的突破。强化学习的研究非常依赖数学，而且还没有形成真正的行业应用。
希望明年可以看到更多RL的实际用例。现在我每个月都会特别关注一下强化学习的进展，以期看到未来可能会有什么大事发生。
## **■ OpenAI的强化学习入门教程**
全无机器学习基础的人类，现在也可以迅速上手强化学习。
11月初，OpenAI发布了强化学习 (RL) 入门教程：Spinning Up。从一套重要概念，到一系列关键算法实现代码，再到热身练习，每一步都以清晰简明为上，全程站在初学者视角。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJ9VriayicoKSh2D4LN22z8jtibNSo76AibmpsY1v5eMicCzb7hYGdwiar1rqg/640?wx_fmt=png)
团队表示，目前还没有一套比较通用的强化学习教材，RL领域只有一小撮人进得去。这样的状态要改变啊，因为强化学习真的很有用。
相关地址
教程入口：
https://spinningup.openai.com/en/latest/index.html
GitHub传送门：
https://github.com/openai/spinningup
## **■ 谷歌的强化学习新框架「多巴胺」**
Dopamine（多巴胺），这是谷歌今年8月发布的强化学习开源框架，基于TensorFlow。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJK3WW8mdOicuXszpU6tZUEVyQyWp2v85hZDe8ibD62fw46Q2NGCbDic6ag/640?wx_fmt=png)
新框架在设计时就秉承着清晰简洁的理念，所以代码相对紧凑，大约是15个Python文件，基于Arcade Learning Environment (ALE)基准，整合了DQN、C51、 Rainbow agent精简版和ICML 2018上的Implicit Quantile Networks。
为了让研究人员能快速比较自己的想法和已有的方法，该框架提供了DQN、C51、 Rainbow agent精简版和Implicit Quantile Networks的玩ALE基准下的那60个雅达利游戏的完整训练数据。
另外，还有一组Dopamine的教学colab。
相关地址
Dopamine谷歌博客：
https://ai.googleblog.com/2018/08/introducing-new-framework-for-flexible.html
Dopamine github下载：
https://github.com/google/dopamine/tree/master/docs#downloads
colabs：
https://github.com/google/dopamine/blob/master/dopamine/colab/README.md
游戏训练可视化网页：
https://google.github.io/dopamine/baselines/plots.html
## **■ 2019趋势展望**
DataHack Summit 2018发言人、ArxivInsights创始人Xander Steenbrugge，也是一名强化学习专家，以下是来自他的总结和展望。
> 
1、由于辅助学习任务越来越多，增加了稀疏的外在奖励，样本的复杂性将继续提高。在非常稀疏的奖励环境中，效果非常好。
2、正因如此，直接在物理世界训练将越来越可行，替代当前大多先在虚拟环境中训练的方法。我预测2019年，会出现第一个只由深度学习训练，没有人工参与而且表现出色的机器人demo出现。
3、在DeepMind把AlphaGo的故事延续到生物领域之后（AlphaFold），我相信强化学习将逐步在学术领域外创造实际的商业价值。例如新药探索、电子芯片架构优化、车辆等等……
4、强化学习会有一个明显的转变，以前在训练数据上测试智能体的行为将不再视为“允许”。泛化指标将成为核心，就像监督学习一样。
# **AI道德**
AI被滥用事故在2018年被频频爆出：Facebook AI助特朗普当选美国总统、Goggle与美国军方联手开发AI武器、微软为移民和海关执法局（ICE）提供云计算和人脸识别服务……
每一次事故都会重新掀起一波对AI道德准则的讨论高潮，一些硅谷科技公司也再次期间制定了企业AI准则。
Analytics Vidhya认为，AI道德现在还是一个灰色地带，目前还没有所有人可以遵循的框架，2019年将有更多企业和政府制定相关条例。
AI道德规范的制定，现在才刚刚起步。
![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/f84kJBXzrBWjJ4wkCns0JA2pIeZnfZeJu3p8IhL6OHLfJjzOpPBnPOjn1Karg7DUoOgic8eSniaRRcDEm8jdwNqw/640?wx_fmt=png)
未来智能实验室是人工智能学家与科学院相关机构联合成立的人工智能，互联网和脑科学交叉研究机构。
未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）云脑研究计划，构建互联网（城市）云脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。
*如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”*
![640?wx_fmt=jpeg](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/f84kJBXzrBXtjwXLOH13nsYuQKfVHbapnHFO9iacHnzft3Q7mqEeqVf6phSiam3I17pVBMLp18riaEpPOlp4xIxzA/640?wx_fmt=jpeg)
