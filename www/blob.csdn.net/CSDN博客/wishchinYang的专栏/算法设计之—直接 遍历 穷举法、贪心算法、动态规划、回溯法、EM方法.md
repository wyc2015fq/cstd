# 算法设计之—直接 遍历/穷举法、贪心算法、动态规划、回溯法、EM方法 - wishchinYang的专栏 - CSDN博客
2014年12月01日 13:59:48[wishchin](https://me.csdn.net/wishchin)阅读数：7603
       算法是对完成特定问题的程序执行序列描述，表象为从问题初始状态到问题结束状态的所有路径之中寻找可行路径，若无先验经验，根据执行方式不同可以划分为无规则和有规则（启发式）方法。
       无规则方法为穷举，改进方法为递推和迭代；有规则方法有分治、贪心、动态规划、分支定界法等。
**穷举法**：适用于解决极小规模或者复杂度线性增长，而线性规模不会很大的状态。
** 递推法**：利用问题本身的递推关系 先求解递推关系再求解问题的一种方法。一般可解决问题都能得出通项公式或者递推公式。
**迭代法**：辗转法。不断用变量的新值来代替旧值的过程。其重要的过程为 确定迭代变量 、确定迭代关系式、并对迭代过程进行控制。
**一：直接遍历态（穷举法）**
       程序运行状态是可以遍历的，遍历算法执行每一个状态，最终会找到一个最优的可行解。
**二：分治法**
       对于输入规模很大的问题，直接求解问题非常困难，可把其N个输入划分成K个不通子集的集合，能够得到K个不通的子问题，并分别求出各个子问题。在得出子问题的解后，还可以找到合适的方法合并问题的解。  过程为 划分——求解子问题（解法一般与原问题相同）——合并。
       其算法代表有：**快速排序**、**归并排序**、**线性时间选择**、汉诺塔问题；
               多项式乘法、大整数乘法（快速傅里叶变换）、Strassen矩阵乘法、棋盘覆盖、最接近点对问题、循环赛日程表。
** 斯特拉森乘法**：对矩阵运算的改进算法。
              把大矩阵分割成小矩阵的方法，T(n)= d(n<=k) | 7t(n/2)+cn^2 (n>k)
      分治法所能解决的问题一般具有以下几个特征：
         1) 该问题的规模缩小到一定的程度就可以容易地解决
         2) 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。
         3) 利用该问题分解出的子问题的解可以合并为该问题的解；
         4) 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。
（     第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加；
**         第二条特征是应用分治法的前提**它也是大多数问题可以满足的，此特征反映了递归思想的应用；
**第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征**，如果**具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或者动态规划**。
**         第四条特征涉及到分治法的效率**，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但**一般用动态规划法较好**。）
        思路：**实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。**
**三：贪心法**
[贪心算法](http://baike.baidu.com/view/298415.htm)（又称贪婪算法）是指，在对[问题求解](http://baike.baidu.com/view/1099373.htm)时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部[最优解](http://baike.baidu.com/view/1009692.htm)。贪心算法不是对所有问题都能得到整体[最优解](http://baike.baidu.com/view/1009692.htm)，但对范围相当广泛的许多问题他能产生整体最优解或者是整体最优解的近似解。
贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。
        算法思路：
           1.建立[数学模型](http://baike.baidu.com/view/76167.htm)来描述问题
           ⒉把求解的问题分成若干个子问题。
           ⒊对每一子问题求解，得到子问题的局部最优解。
           ⒋把子问题的解局部最优解合成原来解问题的一个解。
        一般步骤：
                1.  选取一定打贪心策略，从问题的某个初始解开始；
                2.  不断循环，根据局部最优策略，得到一个当前的最优解，缩小问题的范围或者规模；
                3.  将所有的局部解综合，得到整个问题的解。
**目标函数**：在程序设计中有一类问题，它有N种可能的输入，而它的解由这种N个输入的摸个子集构成。只是这类子集应该满足某些给定的条件，我们称之为“约束条件”。满足约束条件的子集为 该问题的“可行解”。为了衡量可行解的好坏，实现确定一个标准，这些标准以函数形式给出，成为“目标函数”。那些使目标函数取极大值的可行解，称为“最优解”。
        对于这一类需求最优解的问题，根据 约束条件 和 目标函数 的数学模型的特性 或者求解方法的不同，可以将其细分为线性规划、整数规划、动态规划等问题。对于其中的某些问题，贪心法更加直接。
**        贪心策略适用的前提是：局部最优策略能导致产生全局最优解。**
**        实际上，贪心算法适用的情况很少。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。**
        贪心算法还是很常见的算法之一，这是由于它简单易行，构造贪心策略不是很困难。
        可惜的是，它需要证明后才能真正运用到题目的算法中。
        一般来说，贪心算法的证明围绕着：整个问题的最优解一定由在贪心策略中存在的子问题的最优解得来的。
         其算法代表有：
              得到全局最优的贪心法：求[最小生成树](http://baike.baidu.com/view/288214.htm)的[Prim算法](http://baike.baidu.com/view/671819.htm)和[Kruskal算法](http://baike.baidu.com/view/247951.htm)都是漂亮的贪心算法。
[Dijkstra](http://baike.baidu.com/view/809651.htm)的单源最短路径和Chvatal的贪心[集合覆盖](http://baike.baidu.com/view/2991404.htm)启发式。
        贪心算法可以与[随机化算法](http://baike.baidu.com/view/1071553.htm)一起使用，具体的例子就不再多举了。很多的智能算法（也叫启发式算法），本质上就是贪心算法和随机化算法结合——这样的算法结果虽然也是局部最优解，但是比单纯的贪心算法更靠近最优解。例如遗传算法，模拟退火算法。
**四：动态规划法**
        一个问题由多个阶段决策组成，把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的方法。
        问题的满足条件：问题的状态必须满足最优化原理；问题的状态必须满足无后效性（无后效性：在下一时刻的状态只与当前状态有关，而与当前之前的状态无关）（我去，这就是一个一阶马尔科夫链！！！）。
                 初始状态 ——>|决策1| ——>|决策2| ——>|决策3|.............. ——>结束状态
**        基本思想与策略：**
                基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。
              由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。
              与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。
**适用的情况：**能采用动态规划求解的问题的一般要具有3个性质：
            (1) 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。
            (2) 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。
            (3)有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）。
**求解的基本步骤：**
              动态规划所处理的问题是一个多阶段决策问题，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如图所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。
初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态
                      图1 动态规划决策过程示意图
    (1)**划分阶段**：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解。
    (2)**确定状态和状态变量**：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。
    (3)**确定决策并写出状态转移方程**：因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程。
    (4)**寻找边界条件**：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。
一般，只要解决问题的阶段、状态和状态转移决策确定了，就可以写出状态转移方程（包括边界条件）。
       实际应用中可以按以下几个简化的步骤进行设计：
    （1）分析最优解的性质，并刻画其结构特征。
    （2）递归的定义最优解。
    （3）以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值
    （4）根据计算最优值时得到的信息，构造问题的最优解
**算法实现的说明**
               动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。
               使用动态规划求解问题，最重要的就是确定动态规划三要素：
   （1）问题的阶段
    （2）每个阶段的状态
    （3）从前一个阶段转化到后一个阶段之间的递推关系。
      递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处。
        确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。
**f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)}**
```cpp
//动态规划
for(j=1; j<=m; j=j+1) // 第一个阶段
   xn[j] = 初始值;
   for(i=n-1; i>=1; i=i-1)// 其他n-1个阶段
      for(j=1; j>=f(i); j=j+1)//f(i)与i有关的表达式
          xi[j]=j=max（或min）{g(xi-1[j1:j2]), ......, g(xi-1[jk:jk+1])};
t = g(x1[j1:j2]); // 由子问题的最优解求解整个问题的最优解的方案
print(x1[j1]);
for(i=2; i<=n-1; i=i+1）{  
      
    t = t-xi-1[ji];
    for(j=1; j>=f(i); j=j+1)
         if(t=xi[ji])
             break;
}
```
经典算法实例：管道铺设的动态规划、矩阵连乘问题
**矩阵连乘的动态规划代码：**
```cpp
//使用最小运算代价的算法体现了动态规划的优点：在选择解时将k限制在i<=k<=j的范围内，
//并令差值j-i自小而大递增，即先解最小的子问题把解保存起来，然后利用小问题的解来求解大问题的解。
void matrixChainOrder(int r[], int** M ,int n)
{
	for (int i = 1; i < n; ++i){
		M[i][i] = 0;
	}
	int j = 0;
	for (int Level = 1; Level < n; ++Level){
		for (int i = 1; i < n - Level; ++i){
			j = i + Level;
			{
				m[i][j] = MAXINT;
				for (int k = i; k <= j - 1;++k){
					if (m[i][j] >   m[i][k] + m[k + 1][j] + r[i] * r[k + 1] * r[j + 1])
						m[i][j] >   m[i][k] + m[k + 1][j] + r[i] * r[k + 1] * r[j + 1];
				}
			}
		}
	}
	printf("M[1][n]");
}
```
**五：回朔法/分支界定法**
         回溯法（探索与回溯法）是一种选优搜索法，又称为试探法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个[状态](http://baike.baidu.com/view/705553.htm)的点称为“回溯点”。 
**一般步骤**：
（1）针对所给问题，定义问题的解空间；
（2）确定易于搜索的解空间结构；一般为解的空间树。
（3）以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。
### 基本思想：
         在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯（可联合剪枝过程）。（其实回溯法就是对隐式图的深度优先搜索算法）。 若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。 而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。
       经典算法：八皇后问题。
       分支定界法：——>转下一篇！！！
### 六、EM方法
          EM方法：[从最大似然到EM算法浅解](https://www.cnblogs.com/to-creat/p/6075322.html)。
**求最大似然函数估计值的一般步骤：**
（1）写出似然函数；（2）对似然函数取对数，并整理；（3）求导数，令导数为0，得到似然方程；（4）解似然方程，得到的参数即为所求；
**EM算法（Expectation-maximization）：**
     期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。
**EM的算法流程：**
初始化分布参数θ；
**重复以下步骤直到收敛**：
**        E步骤：**根据参数初始值或上一次迭代的模型参数来计算出隐性变量的后验概率，其实就是隐性变量的期望。作为隐藏变量的现估计值：
**        M步骤：**将似然函数最大化以获得新的参数值：
EM方法的另外一种理解：参数轮换法；
EM算法有很多的应用，最广泛的就是GMM混合高斯模型、聚类、HMM等等。具体可以参考JerryLead的cnblog中的Machine Learning专栏：[（](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html)[EM算法）](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html)The EM Algorithm [混合高斯模型（](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006924.html)Mixtures of Gaussians）和EM算法 [K-means](http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006910.html)聚类算法。
