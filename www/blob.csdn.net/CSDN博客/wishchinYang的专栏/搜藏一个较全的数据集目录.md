# 搜藏一个较全的数据集目录 - wishchinYang的专栏 - CSDN博客
2017年12月13日 10:47:56[wishchin](https://me.csdn.net/wishchin)阅读数：1499
             这个页面比较详细：[http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase](http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase).htm             
             此外cvpapers的页面一直更新：http://[www.cvpapers.com/datasets](http://www.cvpapers.com/datasets.html).html   
Long Time ago，只在意三维模式识别的数据集搜藏，在此多关注分割...
室内RGB_D场景分割：[https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2).html
[Microsoft COCO](http://mscoco.org/) - Common Objects in Context (Tsung-Yi Lin et al)
**COCO**
COCO(Common Objects in Context)是一个新的图像识别、分割和图像语义数据集，它有如下特点：
1）Object segmentation2）Recognition in Context3）Multiple objects per image4）More than 300,000 images5）More than 2 Million instances6）80 object categories7）5 captions per image8）Keypoints on 100,000 people
COCO数据集由微软赞助，其对于图像的标注信息不仅有类别、位置信息，还有对图像的语义文本描述，
COCO数据集的开源使得近两三年来图像分割语义理解取得了巨大的进展，也几乎成为了图像语义理解
算法性能评价的“标准”数据集。
## Segmentation (General)
- [: Shadow Detection/Texture Segmentation Computer Vision Dataset](http://doi.org/10.5281/zenodo.59019)- Video based sequences for shadow detection/suppression, with ground truth (Newey, C., Jones, O., & Dee, H. M.)
- [Aberystwyth Leaf Evaluation Dataset](https://doi.org/10.5281/zenodo.168158)- Timelapse plant images with hand marked up leaf-level segmentations for some time steps, and biological data from plant sacrifice. (Bell, Jonathan; Dee, Hannah M.)
- [Alpert et al. Segmentation evaluation database](http://www.wisdom.weizmann.ac.il/~vision/Seg_Evaluation_DB/index.html) (Sharon Alpert, Meirav Galun, Ronen Basri, Achi Brandt)
- [BMC (Background Model Challenge)](http://bmc.iut-auvergne.com/)- A dataset for comparing background subtraction algorithms, comp=osed of real and synthetic videos(Antoine)
- [Berkeley Segmentation Dataset and Benchmark](http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/) (David Martin and Charless Fowlkes)
- [CAD 120 affordance dataset](https://zenodo.org/record/495570#.WZGTYl2lilM) - Pixelwise affordance annotation in human context (Sawatzky, Srikantha, Gall)
- [CTU Color and Depth Image Dataset of Spread Garments](http://clopema.felk.cvut.cz/color_and_depth_dataset.html)- Images of spread garments with annotated corners.(Wagner, L., Krejov D., and Smutn V. (Czech Technical University in Prague))
- [CTU Garment Folding Photo Dataset](http://clopema.felk.cvut.cz/garment_folding_photo_dataset.html)- Color and depth images from various stages of garment folding.(Sushkov R., Melkumov I., Smutn y V. (Czech Technical University in Prague))
- [DeformIt 2.0](http://www.cs.sfu.ca/~hamarneh/software/DeformIt/index.html)- Image Data Augmentation Tool: Simulate novel images with ground truth segmentations from a single image-segmentation pair (Brian Booth and Ghassan Hamarneh)
- [GrabCut Image database](http://research.microsoft.com/en-us/um/cambridge/projects/visionimagevideoediting/segmentation/grabcut.htm) (C. Rother, V. Kolmogorov, A. Blake, M. Brown)
- [ICDAR'15 Smartphone document capture and OCR competition - challenge 1](http://smartdoc.univ-lr.fr) - videos of documents filmed by a user with a smartphone to simulate mobile document capture, and ground truth coordinates of the document corners to detect. (Burie, Chazalon, Coustaty, Eskenazi, Luqman, Mehri, Nayef, Ogier, Prum and Rusinol)
- [Intrinsic Images in the Wild (IIW)](http://opensurfaces.cs.cornell.edu/publications/intrinsic/)- Intrinsic Images in the Wild, is a large-scale, public dataset for evaluating intrinsic image decompositions of indoor scenes (Sean Bell, Kavita Bala, Noah Snavely)
- [LabelMe images database and online annotation tool](http://people.csail.mit.edu/brussell/research/LabelMe/intro.html) (Bryan Russell, Antonio Torralba, Kevin Murphy, William Freeman)
- [LITS Liver Tumor Segmentation](http://www.lits-challenge.com) - 130 3D CT scans with segmentations of the liver and liver tumor. Public benchmark with leaderboard at Codalab.org (Patrick Christ)
- [Materials in Context (MINC)](http://opensurfaces.cs.cornell.edu/publications/minc/)- The Materials in Context Database (MINC) builds on OpenSurfaces, but includes millions of point annotations of material labels. (Sean Bell, Paul Upchurch, Noah Snavely, Kavita Bala)
- [OpenSurfaces](http://opensurfaces.cs.cornell.edu/publications/opensurfaces/)- OpenSurfaces consists of tens of thousands of examples of surfaces segmented from consumer photographs of interiors, and annotated with material parameters, texture information, and contextual information . (Kavita Bala et al.)
- [Osnabrück gaze tracking data](https://ikw.uos.de/~cv/projects/mm-mkv) - 318 video sequences from several different gaze tracking data sets with polygon based object annotation (Schöning, Faion, Heidemann, Krumnack, Gert, Açik, Kietzmann, Heidemann & König)
- [PetroSurf3D](http://lrs.icg.tugraz.at/research/petroglyphsegmentation/)- 26 high resolution (sub-millimeter accuracy) 3D scans of rock art with pixelwise labeling of petroglyphs for segmentation(Poier, Seidl, Zeppelzauer, Reinbacher, Schaich, Bellandi, Marretta, Bischof)
- [SYNTHIA](http://www.synthia-dataset.net)- Large set (~half million) of virtual-world images for training autonomous cars to see. (ADAS Group at Computer Vision Center)
- [Stony Brook University Shadow Dataset (SBU-Shadow5k)](http://www3.cs.stonybrook.edu/~cvl/content/datasets/shadow_db/SBU-shadow.zip)- Large scale shadow detection dataset from a wide variety of scenes and photo types, with human annotations (Tomas F.Y. Vicente, Le Hou, Chen-Ping Yu, Minh Hoai, Dimitris Samaras)
## Urban Datasets
- [Barcelona](http://www.cs.unc.edu/~jtighe/Papers/ECCV10/) - 15,150 images, urban views of Barcelona (Tighe and Lazebnik)
- [CMP Facade Database](http://cmp.felk.cvut.cz/~tylecr1/facade/)- Includes 606 rectified images of facades from various places with 12 architectural classes annotated.(Radim Tylecek)
- [LM+SUN](http://www.cs.unc.edu/~jtighe/Papers/ECCV10/) - 45,676 images, mainly urban or human related scenes (Tighe and Lazebnik)
- [MIT CBCL StreetScenes Challenge Framework:](http://cbcl.mit.edu/software-datasets/streetscenes/) (Stan Bileschi)
- [Queen Mary Multi-Camera Distributed Traffic Scenes Dataset (QMDTS)](http://www.eecs.qmul.ac.uk/~xx302/ProjectPage/TCSVT_15/index.html)- The QMDTS is collected from urban surveillance environment for the study of surveillance behaviours in distributed scenes.(Dr. Xun Xu. Prof. Shaogang Gong and Dr. Timothy Hospedales)
- [Robust Global Translations with 1DSfM](http://www.cs.cornell.edu/projects/1dsfm/)the numerical data describing global structure from motion problems for each dataset (Kyle Wilson and Noah Snavely)
- [Sift Flow (also known as LabelMe Outdoor, LMO)](http://www.cs.unc.edu/~jtighe/Papers/ECCV10/) - 2688 images, mainly outdoor natural and urban (Tighe and Lazebnik)
- [Street-View Change Detection with Deconvolutional Networks](http://www.saistent.com/proj/RSS2016.html)- Database with aligned image pairs from street-view imagery with structural,lighting, weather and seasonal changes.(Pablo F. Alcantarilla, Simon Stent, German Ros, Roberto Arroyo and Riccardo Gherardi)
- [SydneyHouse](http://www.cs.toronto.edu/housecraft/)- Streetview house images with accurate 3D house shape, facade object label, dense point correspondence, and annotation toolbox.(Hang Chu, Shenlong Wang, Raquel Urtasun,Sanja Fidler)
- [Traffic Signs Dataset](http://www.cvl.isy.liu.se/en/research/datasets/traffic-signs-dataset/)- recording sequences from over 350 km of Swedish highways and city roads (Fredrik Larsson)
