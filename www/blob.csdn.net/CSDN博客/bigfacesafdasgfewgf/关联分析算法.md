# 关联分析算法 - bigfacesafdasgfewgf - CSDN博客





2014年10月16日 11:14:33[bigface1234fdfg](https://me.csdn.net/puqutogether)阅读数：3089








**关联分析算法**

    关联分析算法的应用非常广泛，它可以在大规模数据集中找出一组有关联的数据。例如：商品分析中，我们可以分析出哪些商品之间有购买的关联，也就是买了其中一个商品之后，顾客就很有可能买另外一个商品。

    频繁项集是指那些经常出现在一起的物品集合，那么如何评价这里的频繁程度呢？我们用支持度和可信度（置信度）来评价。一个项集的支持度指数据集中包含该项集的记录所占的比例，置信度为一个关联规则中这个关联成立的概率。举例来说：

![](https://img-blog.csdn.net/20141016100819978?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHVxdXRvZ2V0aGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


从图中可以看出：

- 项集｛豆奶｝的支持度为4/5，项集｛豆奶，尿布｝的支持度为3/5，项集｛尿布，葡萄酒｝的支持度为3/5，项集｛尿布｝的支持度为4/5, 这样看来一个项集支持度的计算方法一目了然；
- 关联规则｛尿布->葡萄酒｝的可信度等于：支持度（｛尿布，葡萄酒｝）/支持度（｛尿布｝）=3/4。





    但是，当物品的数据量增大的时候，使用上述遍历的方法是可以找到所有的可信度较高的关联规则，但是需要遍历的次数也是非常庞大的。此时出现了Apriori算法。

   需要注意的是，Apriori算法的作用只是发现一个数据集中哪些项集是频繁的。关联分析的目标处理发现频繁项集之外，还需要从它们中间获得关联规则。不过对于关联分析而言，发现频繁项集是主要的工作，之后的关联规则则计算每个规则的可信度即可。


Apriori算法的原理：如果某个项集是频繁的，那么它的所有子集也是频繁的；如果某个项集不是频繁的，那么它的所有子集也是非频繁的。利用这样的原理，我们便可以大幅度减少计算项集的个数。因为如果能推断出该项集不是频繁的，那么就没有必要计算其支持度和可信度了。《机器学习实战》中给出了一个很好的图示来解释Apriori的作用：

![](https://img-blog.csdn.net/20141016103604031?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHVxdXRvZ2V0aGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


    Apriori算法是发现频繁项集的一种方法。该算法的输入参数有两个：数据集和最小支持度。最小支持度一定要有，因为大于最小支持度的项集才能被认为是频繁项集。

     Apriori算法的过程：首先，我们会生成所有单个物品的项集列表，接着扫描交易记录来查看哪些项集满足最小支持度的要求，哪些不满足最小支持度的集合会被去掉，对剩下来的集合进行组合以生成包含两个元素的项集。接下来，再重新扫描交易记录，去掉不满足要求的项集。重复该过程直到生成了一个包含所有元素的项集。

    在找到了数据集中所有的频繁项集之后，我们需要从这些频繁项集中发现关联规则。就一个频繁项集中就可以产生好多个规则，所以如何减小需要计算规则的数量也是很重要的。这里我们可以借鉴Apriori的思想，如果某条规则不满足最小可信度的要求，那么该规则的所有子集也不会满足最小可信度的要求。

    比如，在频繁项集｛0, 1, 2, 3｝中，我们发现0,1,2->3规则不满足最小支持度的要求，那么我们就可以知道1,2->0,3, 01->23, 02->13, 0->123, 1->023, 2->013都不是关联的规则了。这样就减小了很多规则的判断。






















