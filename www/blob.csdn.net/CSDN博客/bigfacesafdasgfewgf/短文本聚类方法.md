# 短文本聚类方法 - bigfacesafdasgfewgf - CSDN博客





2014年10月15日 09:54:51[bigface1234fdfg](https://me.csdn.net/puqutogether)阅读数：11588
个人分类：[NLP](https://blog.csdn.net/puqutogether/article/category/2595129)









**短文本聚类方法**


    在拿到一个大规模数据集时，我们不可能对这么多的问题进行注意打上标记（label），因为这个是非常耗时的。而且，我们还知道文本问题是一个典型的多标记问题，这个时候打上的标记很多的时候都不会特别的精确，也就是我们通常说的弱标记weak label. 这个时候我们就需要一个聚类的方法，这样可以先把所有的文本集聚类成几个簇，每个簇的标记相似性就比较大，这样以来对打上标记的工作就减轻了许多精力。

    短文本聚类的研究在自动问答系统中有着比较重要的意义，因为交互式问答系统中的问题实际上就是一个特殊形式的短文本。

    长文本的聚类比较容易，因为长文本所包含的单词量较大，每个文本的特征多，这样有助于聚类。但是对于短文本而言，尤其是在问答系统中，每个样本（问题）的特征较少，如果使用向量空间模型中的思想，每个样本构建的特征向量会很长；其次，如果使用传统的长文本聚类方法，在计算两个问题之间的相似性时，往往要依赖于文档之间词形相似性。这种方法没有考虑到在一个问题样本中，往往会有一个或者几个关键词，这些关键词都具有很强的鉴别能力。如果没有考虑到关键词的权重，而只是匹配相同词的个数的话，那么聚类的时候往往会出错，如下所示：




![](https://img-blog.csdn.net/20141015102433714?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHVxdXRvZ2V0aGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


其实如果把每个单词的权重认为一样的话，那么S1和S2的应该聚到一起去，但是假如我们增加了Google, Yahoo!的权重，那么S2和S3就会聚到一起。

    显然，我们需要对问题样本中的每个单词都赋予一定的权重。如果当前当前ti是问题的核心词，那么权重应该高；否则，权重低。我们可以想到TF-IDF值可以用来充当特征权重的角色。具体实现如下：

   每个问题看作一个向量，使用TF-IDF方法可以提取问题中每个单词的词频，以及单词出现的文档数等信息。其中，我们可以使用单词ti在问题d中出现的次数来作为词频TF，用ti出现在不同问题的个数来计算反词频，这样TF-IDF就可以计算出来了。但是，我们发现：在自动问答系统中，每个问题包含的单词数量很少，如果出现了该单词，那么基本上出现的次数都是1，否则就是不出现，为0. 所以，我们可以简化每个单词的权重计算方式如下：

![](https://img-blog.csdn.net/20141015103208609?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcHVxdXRvZ2V0aGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


这样，我们便可以把问题特征提取出来了。而在距离度量方式方面，我们可以简单的使用两个向量点积的方式来计算。此时，有了问题样本提取出来的特征，以及距离计算方式，我们便可以运用K-means聚类的思想，实现自动问答系统中的聚类。


















