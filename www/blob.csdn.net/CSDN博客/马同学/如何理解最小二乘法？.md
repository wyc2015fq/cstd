# 如何理解最小二乘法？ - 马同学 - CSDN博客
置顶2018年07月20日 10:14:09[马同学高等数学](https://me.csdn.net/ccnt_2012)阅读数：5644
> **最小平方法是十九世纪统计学的主题曲。 从许多方面来看, 它之于统计学就相当于十八世纪的微积分之于数学。**
----乔治·斯蒂格勒的《The History of Statistics》
**1 日用而不知**
来看一个生活中的例子。比如说，有五把尺子：
![](https://img-blog.csdn.net/20180720100434770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
用它们来分别测量一线段的长度，得到的数值分别为（颜色指不同的尺子）：
![\begin{array}{c|c} \qquad\qquad&\qquad长度\qquad\\\hline \color{red}红& 10.2 \\\hline \color{blue}蓝& 10.3 \\\hline \color{orange}橙&9.8\\\hline \color{Goldenrod}黄&9.9\\\hline \color{green}绿&9.8\\\end{array}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Barray%7D%7Bc%7Cc%7D%0A%20%5Cqquad%5Cqquad%26%5Cqquad%E9%95%BF%E5%BA%A6%5Cqquad%5C%5C%5Chline%0A%20%5Ccolor%7Bred%7D%E7%BA%A2%26%2010.2%20%5C%5C%5Chline%0A%20%5Ccolor%7Bblue%7D%E8%93%9D%26%2010.3%20%5C%5C%5Chline%0A%20%5Ccolor%7Borange%7D%E6%A9%99%269.8%5C%5C%5Chline%0A%20%5Ccolor%7BGoldenrod%7D%E9%BB%84%269.9%5C%5C%5Chline%0A%20%5Ccolor%7Bgreen%7D%E7%BB%BF%269.8%5C%5C%0A%5Cend%7Barray%7D%0A)
之所以出现不同的值可能因为：
- 
不同厂家的尺子的生产精度不同
- 
尺子材质不同，热胀冷缩不一样
- 
测量的时候心情起伏不定
- 
......
总之就是有误差，这种情况下，一般取平均值来作为线段的长度：
![\overline{x}=\frac{10.2+10.3+9.8+9.9+9.8}{5}=10](https://www.zhihu.com/equation?tex=%5Coverline%7Bx%7D%3D%5Cfrac%7B10.2%2B10.3%2B9.8%2B9.9%2B9.8%7D%7B5%7D%3D10)
日常中就是这么使用的。可是作为很事'er的数学爱好者，自然要想下：
- 
这样做有道理吗？
- 
用调和平均数行不行？
- 
用中位数行不行？
- 
用几何平均数行不行？
**2 最小二乘法**
换一种思路来思考刚才的问题。
首先，把测试得到的值画在笛卡尔坐标系中，分别记作![y_i](https://www.zhihu.com/equation?tex=y_i) ：
![](https://img-blog.csdn.net/20180720100434773?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
其次，把要猜测的线段长度的真实值用平行于横轴的直线来表示（因为是猜测的，所以用虚线来画），记作![y](https://www.zhihu.com/equation?tex=y) ：
![](https://img-blog.csdn.net/20180720100434777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
每个点都向![y](https://www.zhihu.com/equation?tex=y) 做垂线，垂线的长度就是![|y-y_i|](https://www.zhihu.com/equation?tex=%7Cy-y_i%7C) ，也可以理解为测量值和真实值之间的误差：
![](https://img-blog.csdn.net/20180720100434779?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
因为误差是长度，还要取绝对值，计算起来麻烦，就干脆用平方来代表误差：
![|y-y_i|\to (y-y_i)^2](https://www.zhihu.com/equation?tex=%7Cy-y_i%7C%5Cto%20(y-y_i)%5E2)
总的误差的平方就是：
![\epsilon=\sum (y-y_i)^2](https://www.zhihu.com/equation?tex=%0A%5Cepsilon%3D%5Csum%20(y-y_i)%5E2%0A)
因为![y](https://www.zhihu.com/equation?tex=y) 是猜测的，所以可以不断变换：
![](https://img-blog.csdn.net/2018072010043558?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
自然，总的误差![\epsilon](https://www.zhihu.com/equation?tex=%5Cepsilon) 也是在不断变化的。
![](https://img-blog.csdn.net/20180720100434870?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
法国数学家，阿德里安-馬里·勒讓德（1752－1833，这个头像有点抽象）提出让总的误差的平方最小的![y](https://www.zhihu.com/equation?tex=y) 就是真值，这是基于，如果误差是随机的，应该围绕真值上下波动（关于这点可以看下“[如何理解无偏估计？](https://www.matongxue.com/madocs/808.html)”）。
这就是**最小二乘法**，即：
![\epsilon=\sum (y-y_i)^2最小\implies 真值y](https://www.zhihu.com/equation?tex=%0A%5Cepsilon%3D%5Csum%20(y-y_i)%5E2%E6%9C%80%E5%B0%8F%5Cimplies%20%E7%9C%9F%E5%80%BCy%0A)
这个猜想也蛮符合直觉的，来算一下。
这是一个二次函数，对其求导，导数为0的时候取得最小值：
![\begin{aligned}    \frac{d}{dy}\epsilon        &=\frac{d}{dy}\sum (y-y_i)^2=2\sum (y-y_i)\\        \quad\\        &=2((y-y_1)+(y-y_2)+(y-y_3)+(y-y_4)+(y-y_5))=0        \quad\\\end{aligned}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Cfrac%7Bd%7D%7Bdy%7D%5Cepsilon%0A%20%20%20%20%20%20%20%20%26%3D%5Cfrac%7Bd%7D%7Bdy%7D%5Csum%20(y-y_i)%5E2%3D2%5Csum%20(y-y_i)%5C%5C%0A%20%20%20%20%20%20%20%20%5Cquad%5C%5C%0A%20%20%20%20%20%20%20%20%26%3D2((y-y_1)%2B(y-y_2)%2B(y-y_3)%2B(y-y_4)%2B(y-y_5))%3D0%0A%20%20%20%20%20%20%20%20%5Cquad%5C%5C%0A%5Cend%7Baligned%7D%0A)
进而：
![5y=y_1+y_2+y_3+y_4+y_5\implies y=\frac{y_1+y_2+y_3+y_4+y_5}{5}](https://www.zhihu.com/equation?tex=%0A%20%20%20%205y%3Dy_1%2By_2%2By_3%2By_4%2By_5%5Cimplies%20y%3D%5Cfrac%7By_1%2By_2%2By_3%2By_4%2By_5%7D%7B5%7D%0A)
正好是算术平均数。
原来算术平均数可以让误差最小啊，这下看来选用它显得讲道理了。
以下这种方法：
![\epsilon=\sum (y-y_i)^2最小\implies 真值y](https://www.zhihu.com/equation?tex=%0A%5Cepsilon%3D%5Csum%20(y-y_i)%5E2%E6%9C%80%E5%B0%8F%5Cimplies%20%E7%9C%9F%E5%80%BCy%0A)
就是最小二乘法，所谓“二乘”就是平方的意思，台湾直接翻译为最小平方法。
**3 推广**
算术平均数只是最小二乘法的特例，适用范围比较狭窄。而最小二乘法用途就广泛。
比如温度与冰淇淋的销量：
![\begin{array}{c|c} \qquad\qquad&\qquad销量\qquad\\\hline \color{red}{25^\circ}& 110 \\\hline \color{blue}{27^\circ}& 115 \\\hline \color{orange}{31^\circ}&155\\\hline \color{Goldenrod}{33^\circ}&160\\\hline \color{green}{35^\circ}&180\\\end{array}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Barray%7D%7Bc%7Cc%7D%0A%20%5Cqquad%5Cqquad%26%5Cqquad%E9%94%80%E9%87%8F%5Cqquad%5C%5C%5Chline%0A%20%5Ccolor%7Bred%7D%7B25%5E%5Ccirc%7D%26%20110%20%5C%5C%5Chline%0A%20%5Ccolor%7Bblue%7D%7B27%5E%5Ccirc%7D%26%20115%20%5C%5C%5Chline%0A%20%5Ccolor%7Borange%7D%7B31%5E%5Ccirc%7D%26155%5C%5C%5Chline%0A%20%5Ccolor%7BGoldenrod%7D%7B33%5E%5Ccirc%7D%26160%5C%5C%5Chline%0A%20%5Ccolor%7Bgreen%7D%7B35%5E%5Ccirc%7D%26180%5C%5C%0A%5Cend%7Barray%7D%0A)
看上去像是某种线性关系：
![](https://img-blog.csdn.net/20180720100435100?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
可以假设这种线性关系为：
![f(x)=ax+b](https://www.zhihu.com/equation?tex=f(x)%3Dax%2Bb)
通过最小二乘法的思想：
![](https://img-blog.csdn.net/20180720100435141?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
上图的![i,x,y](https://www.zhihu.com/equation?tex=i%2Cx%2Cy) 分别为：
![\begin{array}{c|c|c} \qquad i\qquad&\qquad x\qquad&\qquad y\qquad\\\hline 1&25& 110 \\\hline 2&27& 115 \\\hline 3&31&155\\\hline 4&33&160\\\hline 5&35&180\\\end{array}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Barray%7D%7Bc%7Cc%7Cc%7D%0A%20%5Cqquad%20i%5Cqquad%26%5Cqquad%20x%5Cqquad%26%5Cqquad%20y%5Cqquad%5C%5C%5Chline%0A%201%2625%26%20110%20%5C%5C%5Chline%0A%202%2627%26%20115%20%5C%5C%5Chline%0A%203%2631%26155%5C%5C%5Chline%0A%204%2633%26160%5C%5C%5Chline%0A%205%2635%26180%5C%5C%0A%5Cend%7Barray%7D%0A)
总误差的平方为：
![\epsilon=\sum (f(x_i)-y_i)^2=\sum (ax_i+b-y_i)^2](https://www.zhihu.com/equation?tex=%0A%5Cepsilon%3D%5Csum%20(f(x_i)-y_i)%5E2%3D%5Csum%20(ax_i%2Bb-y_i)%5E2%0A)
不同的![a,b](https://www.zhihu.com/equation?tex=a%2Cb) 会导致不同的![\epsilon](https://www.zhihu.com/equation?tex=%5Cepsilon) ，根据多元微积分的知识，当：
![\begin{cases}    \frac{\partial}{\partial a}\epsilon=2\sum (ax_i+b-y_i)x_i=0\\    \quad\\    \frac{\partial}{\partial b}\epsilon=2\sum (ax_i+b-y_i)=0\end{cases}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Bcases%7D%0A%20%20%20%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20a%7D%5Cepsilon%3D2%5Csum%20(ax_i%2Bb-y_i)x_i%3D0%5C%5C%0A%20%20%20%20%5Cquad%5C%5C%0A%20%20%20%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20b%7D%5Cepsilon%3D2%5Csum%20(ax_i%2Bb-y_i)%3D0%0A%5Cend%7Bcases%7D%0A)
这个时候![\epsilon](https://www.zhihu.com/equation?tex=%5Cepsilon) 取最小值。
对于![a,b](https://www.zhihu.com/equation?tex=a%2Cb) 而言，上述方程组为线性方程组，用之前的数据解出来：
![\begin{cases}    a\approx 7.2\\    \quad\\    b\approx -73\end{cases}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Bcases%7D%0A%20%20%20%20a%5Capprox%207.2%5C%5C%0A%20%20%20%20%5Cquad%5C%5C%0A%20%20%20%20b%5Capprox%20-73%0A%5Cend%7Bcases%7D%0A)
也就是这根直线：
![](https://img-blog.csdn.net/20180720100435159?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
其实，还可以假设：
![f(x)=ax^2+bx+c](https://www.zhihu.com/equation?tex=f(x)%3Dax%5E2%2Bbx%2Bc)
在这个假设下，可以根据最小二乘法，算出![a,b,c](https://www.zhihu.com/equation?tex=a%2Cb%2Cc) ，得到下面这根红色的二次曲线：
![](https://img-blog.csdn.net/20180720100435257?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
同一组数据，选择不同的![f(x)](https://www.zhihu.com/equation?tex=f(x)) ，通过最小二乘法可以得到不一样的拟合曲线（[出处](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate)）：
![](https://img-blog.csdn.net/20180720100435417?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
不同的数据，更可以选择不同的![f(x)](https://www.zhihu.com/equation?tex=f(x)) ，通过最小二乘法可以得到不一样的拟合曲线：
![](https://img-blog.csdn.net/20180720100435572?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![f(x)](https://www.zhihu.com/equation?tex=f(x)) 也不能选择任意的函数，还是有一些讲究的，这里就不介绍了。
**4 最小二乘法与正态分布**
我们对勒让德的猜测，即最小二乘法，仍然抱有怀疑，万一这个猜测是错误的怎么办？
![](https://img-blog.csdn.net/20180720100435631?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
数学王子高斯（1777－1855）也像我们一样心存怀疑。
高斯换了一个思考框架，通过概率统计那一套来思考。
让我们回到最初测量线段长度的问题。高斯想，通过测量得到了这些值：
![\begin{array}{c|c} \qquad\qquad&\qquad长度\qquad\\\hline \color{red}红& 10.2 \\\hline \color{blue}蓝& 10.3 \\\hline \color{orange}橙&9.8\\\hline \color{Goldenrod}黄&9.9\\\hline \color{green}绿&9.8\\\end{array}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Barray%7D%7Bc%7Cc%7D%0A%20%5Cqquad%5Cqquad%26%5Cqquad%E9%95%BF%E5%BA%A6%5Cqquad%5C%5C%5Chline%0A%20%5Ccolor%7Bred%7D%E7%BA%A2%26%2010.2%20%5C%5C%5Chline%0A%20%5Ccolor%7Bblue%7D%E8%93%9D%26%2010.3%20%5C%5C%5Chline%0A%20%5Ccolor%7Borange%7D%E6%A9%99%269.8%5C%5C%5Chline%0A%20%5Ccolor%7BGoldenrod%7D%E9%BB%84%269.9%5C%5C%5Chline%0A%20%5Ccolor%7Bgreen%7D%E7%BB%BF%269.8%5C%5C%0A%5Cend%7Barray%7D%0A)
每次的测量值![x_i](https://www.zhihu.com/equation?tex=x_i) 都和线段长度的真值![x](https://www.zhihu.com/equation?tex=x) 之间存在一个误差：
![\epsilon_i=x-x_i](https://www.zhihu.com/equation?tex=%0A%5Cepsilon_i%3Dx-x_i%0A)
这些误差最终会形成一个概率分布，只是现在不知道误差的概率分布是什么。假设概率密度函数为：
![p(\epsilon)](https://www.zhihu.com/equation?tex=p(%5Cepsilon))
再假设一个联合概率密度函数，这样方便把所有的测量数据利用起来：
![\begin{aligned}    L(x)        &=p(\epsilon_1)p(\epsilon_2)\cdots p(\epsilon_5)\\        \quad\\        &=p(x-x_i)p(x-x_2)\cdots p(x-x_5)\end{aligned}](https://www.zhihu.com/equation?tex=%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20L(x)%0A%20%20%20%20%20%20%20%20%26%3Dp(%5Cepsilon_1)p(%5Cepsilon_2)%5Ccdots%20p(%5Cepsilon_5)%5C%5C%0A%20%20%20%20%20%20%20%20%5Cquad%5C%5C%0A%20%20%20%20%20%20%20%20%26%3Dp(x-x_i)p(x-x_2)%5Ccdots%20p(x-x_5)%0A%5Cend%7Baligned%7D%0A)
讲到这里，有些同学可能已经看出来了上面似然函数了（关于似然函数以及马上要讲到的极大似然估计，可以参考“[如何理解极大似然估计法？](https://www.matongxue.com/madocs/447.html)”）。
因为![L(x)](https://www.zhihu.com/equation?tex=L(x)) 是关于![x](https://www.zhihu.com/equation?tex=x) 的函数，并且也是一个概率密度函数（下面分布图形是随便画的）：
![](https://img-blog.csdn.net/20180720100435590?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
根据极大似然估计的思想，概率最大的最应该出现（既然都出现了，而我又不是“天选之才”，那么自然不会是发生了小概率事件），也就是应该取到下面这点：
![](https://img-blog.csdn.net/20180720100435606?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjbnRfMjAxMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
当下面这个式子成立时，取得最大值：
![\frac{d}{dx}L(x)=0](https://www.zhihu.com/equation?tex=%0A%5Cfrac%7Bd%7D%7Bdx%7DL(x)%3D0%0A)
然后高斯想，最小二乘法给出的答案是：
![x=\overline{x}=\frac{x_1+x_2+x_3+x_4+x_5}{5}](https://www.zhihu.com/equation?tex=%0Ax%3D%5Coverline%7Bx%7D%3D%5Cfrac%7Bx_1%2Bx_2%2Bx_3%2Bx_4%2Bx_5%7D%7B5%7D%0A)
如果最小二乘法是对的，那么![x=\overline{x}](https://www.zhihu.com/equation?tex=x%3D%5Coverline%7Bx%7D) 时应该取得最大值，即：
![\frac{d}{dx}L(x)|_{x=\overline{x}}=0](https://www.zhihu.com/equation?tex=%0A%5Cfrac%7Bd%7D%7Bdx%7DL(x)%7C_%7Bx%3D%5Coverline%7Bx%7D%7D%3D0%0A)
好，现在可以来解这个微分方程了。最终得到：
![p(\epsilon)={1 \over \sigma\sqrt{2\pi} }\,e^{- {{\epsilon^2 \over 2\sigma^2}}}](https://www.zhihu.com/equation?tex=%0Ap(%5Cepsilon)%3D%7B1%20%5Cover%20%5Csigma%5Csqrt%7B2%5Cpi%7D%20%7D%5C%2Ce%5E%7B-%20%7B%7B%5Cepsilon%5E2%20%5Cover%202%5Csigma%5E2%7D%7D%7D%0A)
这是什么？这就是正态分布啊。
并且这还是一个充要条件：
![x=\overline{x}\iff p(\epsilon)={1 \over \sigma\sqrt{2\pi} }\,e^{- {{\epsilon^2 \over 2\sigma^2}}}](https://www.zhihu.com/equation?tex=%0Ax%3D%5Coverline%7Bx%7D%5Ciff%20p(%5Cepsilon)%3D%7B1%20%5Cover%20%5Csigma%5Csqrt%7B2%5Cpi%7D%20%7D%5C%2Ce%5E%7B-%20%7B%7B%5Cepsilon%5E2%20%5Cover%202%5Csigma%5E2%7D%7D%7D%0A)
也就是说，如果误差的分布是正态分布，那么最小二乘法得到的就是最有可能的值。
那么误差的分布是正态分布吗？
我们相信，误差是由于随机的、无数的、独立的、多个因素造成的，比如之前提到的：
- 
不同厂家的尺子的生产精度不同
- 
尺子材质不同，热胀冷缩不一样
- 
测量的时候心情起伏不定
- 
......
那么根据中心极限定理（参考“[为什么正态分布如此常见？](https://www.matongxue.com/madocs/589.html)”），误差的分布就应该是正态分布。
因为高斯的努力，才真正奠定了最小二乘法的重要地位。
文章最新版本在（有可能会有后续更新）：[如何理解最小二乘法？](https://www.matongxue.com/madocs/818.html)
