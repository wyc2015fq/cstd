# 机器学习（一）机器学习概论 - BryantLJ学习的地方 - CSDN博客





2016年08月04日 16:57:20[遍地流金](https://me.csdn.net/u012177034)阅读数：831
个人分类：[机器学习](https://blog.csdn.net/u012177034/article/category/6357352)









机器学习通过适当的学习方法，进而能够对于新数据进行分类和预测。




**一.机器学习按学习方法分类**

监督，非监督，半监督，强化




**二.监督式统计机器学习要素**

假设：要训练和预测的同类数据有固定的统计规律，且满足独立同分布的条件。统计学习的目的就是先对输入输出数据进行一定的模型/概率假设，然后从训练数据中学习输入输出的概率分布，进而能够利用该模型对新的未知数据进行预测




1.模型：即输入与输出之间的关系模型。

有两种表示方法，不同的算法会采用不同的模型

决策函数:![](http://latex.codecogs.com/gif.latex?Y%3Df_%7B%5Ctheta%20%7D%5E%7B%20%7D%5Ctextrm%7B%7D%20%28X%29)；条件概率:![](http://latex.codecogs.com/gif.latex?P_%7B%5Ctheta%20%7D%5E%7B%20%7D%5Ctextrm%7B%7D%20%28Y%7CX%29)





2.策略：训练样本得到模型中的参数估计思想。

理想是采用期望风险函数最小化的策略。损失函数loss为模型一次预测的好坏，期望风险为对未知数据集平均意义下的预测好坏。

常用损失loss函数

（1）0-1损失

![](http://latex.codecogs.com/gif.latex?L%28Y%2Cf%28X%29%29%3D%5Cbegin%7BBmatrix%7D%201%2CY%5Cneq%20f%28X%29%5C%5C%200%2CY%3Df%28X%29%20%5Cend%7Bmatrix%7D)


（2）平方损失

![](http://latex.codecogs.com/gif.latex?L%28Y%2Cf%28X%29%29%3D%28Y-f%28X%29%29%5E%7B2%7D)


（3）绝对值损失

![](http://latex.codecogs.com/gif.latex?L%28Y%2Cf%28X%29%29%3D%7CY-f%28X%29%7C)


（4）对数损失

![](http://latex.codecogs.com/gif.latex?L%28Y%2CP%28Y%7CX%29%29%3D-log%28P%28Y%7CX%29%29)


期望风险

![](http://latex.codecogs.com/gif.latex?R_%7Bexp%7D%3DE_%7Bp%7D%5BL%28Y%2Cf%28X%29%29%5D%3D%5Cint_%7Bx*y%7D%5E%7B%20%7DL%28y%2Cf%28x%29%29P%28x%2Cy%29dxdy)


实际上没有xy的联合分布，期望风险是无法计算的，因此该期望风险最小化策略无法直接使用

实际的使用策略是结构风险最小化

经验风险![](http://latex.codecogs.com/gif.latex?R_%7Berm%7D)：为损失函数在训练数据集上的平均风险，很好计算，但是容易产生过拟合现象

结构风险![](http://latex.codecogs.com/gif.latex?R_%7Bsrm%7D)：经验风险+模型的复杂度惩罚，很好计算




3.算法：具体优化![](http://latex.codecogs.com/gif.latex?R_%7Bsrm%7D)或者![](http://latex.codecogs.com/gif.latex?R_%7Berm%7D)得到参数![](http://latex.codecogs.com/gif.latex?%5Ctheta)的算法


常用优化算法：梯度下降法，牛顿法等





**三.监督学习方法分类**

主要分为两类：

生成方法：由数据学习联合概率分布![](http://latex.codecogs.com/gif.latex?P%28X%2CY%29)，然后求出条件概率分布![](http://latex.codecogs.com/gif.latex?P%28Y%7CX%29)，以此模型作为预测的模型，即生成模型![](http://latex.codecogs.com/gif.latex?P%28Y%7CX%29%3D%5Cfrac%7BP%28X%2CY%29%7D%7BP%28X%29%7D),典型的生成方法有朴素贝叶斯，隐马尔科夫模型

判别方法：由数据直接学习决策函数![](http://latex.codecogs.com/gif.latex?Y%3Df%28X%29)或者条件概率分布![](http://latex.codecogs.com/gif.latex?P%28Y%7CX%29)，其直接关心输入与输出的关系。典型的判别方法有K近邻，感知器，决策树，逻辑回归，AdaBoost，支持向量机，条件随机场等

生成方法能够更接近数据的本真模型，判别方法更直接简单，准确率更好。目前更常用的方法一般是判别方法。




**四.模型评估与误差分析**

评估：理论上泛化误差越小，算法越优越。但是实际上泛化误差并不能求得，只能用测试误差来近似泛化误差，进而完成对模型的评估由统计检验的只是可知，此近似的准确性受评估方法的影响。理论上采用交叉验证的方法时，其平均测试误差更能够代表泛化误差的期望，**这也正是为什么要采用交叉验证来进行模型的选择和评估**（更充分的利用数据只是一方面考量）。（具体原因可参考《机器学习-周志华》2.4节“比较检验”部分）




（1）评估方法：


留出法：将数据集分为训练集和测试集，测试集上的误差即为测试误差

交叉验证：将数据及分为K个大小相似的集合，每次用k-1个训练，1个验证。最后使用k组测试误差的均值作为此方法的泛化误差估计


（2）测试误差选择与度量：

对于不同任务，所选择的误差度量种类也不一样

回归问题：均方误差

分类问题：PR曲线，ROC曲线，AUC，Accuracy等





模型：泛化误差=偏差+方差+噪声


偏差代表算法模型本身的你和能力，方差代表训练样本扰动对于学习性能的影响，噪声代表了任何学习算法在该数据集上所能达到的泛化误差下界。也即泛化性能是由学习算法的能力，训练数据的充分性（是否能够充分代表要预测数据的分布特性），学习任务本身的难度共同决定！




附：公式编辑网站：http://www.codecogs.com/latex/eqneditor.php




