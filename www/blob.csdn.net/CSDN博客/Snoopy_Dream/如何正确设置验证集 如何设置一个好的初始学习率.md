# 如何正确设置验证集  如何设置一个好的初始学习率 - Snoopy_Dream - CSDN博客





2018年12月15日 22:20:22[Snoopy_Dream](https://me.csdn.net/e01528)阅读数：161








我在一开始就犯了这个错误。**我随机分割数据集，获得了超过99.6％的惊人的良好验证准确性**。测试准确性仅为87％时，我感到很惊讶: 测试准确性和验证准确性之间的巨大差异是**验证集设计不当**或**过度拟合验证集**。

正确的方法是**找到一系列图像，并将每个系列全部放入训练或验证集中**，确保它们不会分割成两个。要了解关于创建一个好的验证集的更多信息，请阅读Rachel Thomas撰写的这篇文章。

[www.fast.ai/2017/11/13/validation-sets/](http://www.fast.ai/2017/11/13/validation-sets/)





算法搜索一个好的起始学习率。对于分类就用0.1*bn/256(bn表示batchsize)

[https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)

```
def plot_loss_change(sched, sma=1, n_skip=20, y_lim=(-0.01, 0.01)):
    """
    Plots rate of change of the loss function.
    Parameters:
        sched - learning rate scheduler, an instance of LR_Finder class.
        sma - number of batches for simple moving average to smooth out the curve.
        n_skip - number of batches to skip on the left.
        y_lim - limits for the y axis.
    """
    derivatives = [0] * (sma + 1)
    for i in range(1 + sma, len(learn.sched.lrs)):
        derivative = (learn.sched.losses[i] - learn.sched.losses[i - sma]) / sma
        derivatives.append(derivative)

    plt.ylabel("d/loss")
    plt.xlabel("learning rate (log scale)")
    plt.plot(learn.sched.lrs[n_skip:], derivatives[n_skip:])
    plt.xscale('log')
    plt.ylim(y_lim)


learn.lr_find()
```

![](https://ask.qcloudimg.com/http-save/yehe-1565119/htwcu5wh4r.png?imageView2/2/w/1620)



