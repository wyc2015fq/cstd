# 习惯性矩阵思维 - Snoopy_Dream - CSDN博客





2018年11月29日 11:13:55[Snoopy_Dream](https://me.csdn.net/e01528)阅读数：78








大体要用的函数就是squeeze/ unsequeeze /nonzero/ where /> /< /.new().fill_()/ torch.cat()/torch.sort

经常看到的变量名  keep /index  gt_max  gt_argmax

**目录**

[0. torch.nonzero返回满足条件的行列，[m,n] —> k行2列](#0.%20torch.nonzero%E8%BF%94%E5%9B%9E%E6%BB%A1%E8%B6%B3%E6%9D%A1%E4%BB%B6%E7%9A%84%E8%A1%8C%E5%88%97%EF%BC%8C%5Bm%2Cn%5D%20%E2%80%94%3E%20k%E8%A1%8C2%E5%88%97)

[1、排除anchor跑到图像外面，将all_anchors变成anchors](#1%E3%80%81%E6%8E%92%E9%99%A4anchor%E8%B7%91%E5%88%B0%E5%9B%BE%E5%83%8F%E5%A4%96%E9%9D%A2%EF%BC%8C%E5%B0%86all_anchors%E5%8F%98%E6%88%90anchors)

[2. > < np.where](#2.%20%3E%20%3C%20%20np.where)

[3. np.argmax(a,axis = none) & torch.max(a,1)](#3.%20np.argmax(a%2Caxis%20%3D%20none)%20%26%20torch.max(a%2C1))

[4. torch.stack((a,b,c),dim)](#4.%20torch.stack((a%2Cb%2Cc)%2Cdim))

[5.. expand_as(tensor) 有点想repeat之后再view](#5..%20expand_as(tensor)%20%E6%9C%89%E7%82%B9%E6%83%B3repeat%E4%B9%8B%E5%90%8E%E5%86%8Dview)

[6. torch.equal(a,b) & a.eq(b)](#6.%20torch.equal(a%2Cb)%20%26%20a.eq(b))

开始总结:

摘自faster rcnn pytorch中

需要注意><号在np和torch中的不同np直接返回true/false，torch中返回1/0/。



### 0. torch.nonzero返回满足条件的行列，[m,n] —> k行2列

>>> torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],

...                             [0.0, 0.4, 0.0, 0.0],

...                             [0.0, 0.0, 1.2, 0.0],

...                             [0.0, 0.0, 0.0,-0.4]]))

 0  0

 1  1

 2  2

 3  3

[torch.LongTensor of size 4x2]

### 1、排除anchor跑到图像外面，将all_anchors变成anchors

keep = （xmin>=0 & ymin>= & xmax<= w & ymax<=h） # 根据 keep 判断，返回所有的行，满足条件的为1，不满足的为0.

inds_inside  =torch.nonzero(keep).view(-1)   #nonzero去掉0，只返回1，也就是符合条件的行号，然后变成(m,)

all_anchors[inds_inside,:] # 按inds_inside取出符合条件的行，一般行代表一个样本

![](https://img-blog.csdnimg.cn/20181129113006742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2UwMTUyOA==,size_16,color_FFFFFF,t_70)

```python
# keep 是一个[n,1]  
        keep = ((all_anchors[:, 0] >= -self._allowed_border) &
                (all_anchors[:, 1] >= -self._allowed_border) &
                (all_anchors[:, 2] < long(im_info[0][1]) + self._allowed_border) &
                (all_anchors[:, 3] < long(im_info[0][0]) + self._allowed_border))
 
         # inds_inside 是一个[m,1]  
        inds_inside = torch.nonzero(keep).view(-1)
        anchors = all_anchors[inds_inside, :]
```

### 2. > < np.where

![](https://img-blog.csdnimg.cn/20181129113827533.png)

     np.where(condition)

返回一个行向量，一个列向量。

所以大多后面加一个[0] np.where(x>4)[0]



    a = np.array([2,4,6,8,10])

    a[np.where(a > 5)] # 等价于 a[a>5] array([ 6, 8, 10])

np.where(condition, x, y)

    满足条件(condition)，输出x，不满足输出y。image = np.where(image >= 240, 255,image)



### 3. np.argmax(a,axis = none) & torch.max(a,1)

np.argmax返回的索引 如果axis=1，二维表示在每一行里面找列最大的,只返回索引。高维度的可以这样理解：在axis轴对应的维数里寻找最大。你比如：a.shape=(2,3,4), np.argmax(a,axis=2),按4个数4个数的找最大，返回(2,3)。

torch.max(a,1)[0]  返回最大值

torch.max(a,1)[1]   返回索引

### 4. torch.stack((a,b,c),dim)

沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。

注意这个函数和concatenate是不同的，torch的concatenate函数是torch.cat，是在已有的维度上拼接，而stack是建立一个新的维度，然后再在该纬度上进行拼接。

参数:

    sqequence (Sequence) – 待连接的张量序列

    dim (int) – 插入的维度。必须介于 0 与 待连接的张量序列数之间。要看合成后的

类似的维度的操作，可以看我上面reshape的说明，必须要理解填充的顺序。从后缘维度开始填充。

你比如：a=[[1,2,3],[4,5,9],[7,8,9]] b=[[1,2,3],[4,5,9],[7,8,9]] ,c=-[[1,2,3],[4,5,9],[7,8,9]] ，

torch.stack((a,b,c),0)0是最后一个填充的，从最大层次也就是最外面的括号看

>>>【[[1,2,3],[4,5,9],[7,8,9]],[[1,2,3],[4,5,9],[7,8,9]],-[[1,2,3],[4,5,9],[7,8,9]] 】

torch.stack((a,b,c),1)从中间的括号开始看

>>> [[[1,2,3],[1,2,3],-[1,2,3]],[4,5,9],[4,5,9],-[4,5,9]...]

torch.stack((a,b,c),2)从最里面的一个元素一个元素竖着开始看

>>> [[[1,1,-1],[2,2,-2],[3,3,-3]],[....]

在比如一维度数组stack

a=([1,2,3]) b=([1,2,3])

torch.stack((a,b),0)

>>>[[1,2,3],[1,2,3]]

torch.stack((a,b),1)

>>>[[1,1][2,2],[3,3]]

### 5.. expand_as(tensor) 有点想repeat之后再view

torch版本的bbox_transform_batch有用。将tensor扩展为参数tensor的大小。类似于人为广播操作。但必须只有一个维度是不相等的。

    >>> a=torch.rand(2,1,4)

    >>> b=torch.rand(2,4,4)

    >>> a

    tensor([[[ 0.1828,  0.9803,  0.4630,  0.7553]],


            [[ 0.3949,  0.8661,  0.8884,  0.3982]]])

    >>> b

    tensor([[[ 0.5678,  0.7193,  0.6781,  0.9207],

             [ 0.4690,  0.4737,  0.2638,  0.9247],

             [ 0.9315,  0.8202,  0.5217,  0.8444],

             [ 0.5279,  0.5673,  0.6443,  0.4649]],


            [[ 0.3587,  0.8476,  0.6263,  0.1106],

             [ 0.4531,  0.0974,  0.9504,  0.6684],

             [ 0.5585,  0.9721,  0.1965,  0.3138],

             [ 0.6662,  0.2503,  0.9760,  0.0737]]])

    >>> a.expand_as(b)

    tensor([[[ 0.1828,  0.9803,  0.4630,  0.7553],

             [ 0.1828,  0.9803,  0.4630,  0.7553],

             [ 0.1828,  0.9803,  0.4630,  0.7553],

             [ 0.1828,  0.9803,  0.4630,  0.7553]],


            [[ 0.3949,  0.8661,  0.8884,  0.3982],

             [ 0.3949,  0.8661,  0.8884,  0.3982],

             [ 0.3949,  0.8661,  0.8884,  0.3982],

             [ 0.3949,  0.8661,  0.8884,  0.3982]]])

### 6. torch.equal(a,b) & a.eq(b)

![](https://img-blog.csdnimg.cn/20181129114929775.png)

a.eq(b)

torch.eq(input, other, out=None) → Tensor

比较元素相等性。第二个参数可为一个数或与第一个参数同类型形状的张量。

参数：

    input (Tensor) – 待比较张量

    other (Tensor or float) – 比较张量或数

    out (Tensor, optional) – 输出张量，须为 ByteTensor类型 or 与input同类型

返回值： 一个 torch.ByteTensor 张量，包含了每个位置的比较结果(相等为1，不等为0 )

返回类型： Tensor

例子：

    >>> torch.eq(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))

    1  0

    0  1

    [torch.ByteTensor of size 2x2]

torch.equal

torch.equal(tensor1, tensor2) → bool

如果两个张量有相同的形状和元素值，则返回True ，否则 False。

例子：

    >>> torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2]))

    True




