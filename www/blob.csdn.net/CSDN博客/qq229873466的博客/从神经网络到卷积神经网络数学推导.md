# 从神经网络到卷积神经网络数学推导 - qq229873466的博客 - CSDN博客

2016年11月11日 11:16:07[qq229873466](https://me.csdn.net/qq229873466)阅读数：1967



**NN推导：**

**A． 前向传播**
![](https://img-blog.csdn.net/20161111110104510)

![](https://img-blog.csdn.net/20161111110109682)

注： ![](https://img-blog.csdn.net/20161111110307925) 是第![](https://img-blog.csdn.net/20161111110327410) 层的输入加权和向量，输入层![](https://img-blog.csdn.net/20161111110351105) ，![](https://img-blog.csdn.net/20161111110429746)是第![](https://img-blog.csdn.net/20161111110441318)层的
 i 到第![](https://img-blog.csdn.net/20161111110327410)层的 j 的权值。

**B． 反向传播**
![](https://img-blog.csdn.net/20161111110720602)

![](https://img-blog.csdn.net/20161111110728763)

![](https://img-blog.csdn.net/20161111110736872)

![](https://img-blog.csdn.net/20161111110745884)

![](https://img-blog.csdn.net/20161111110824857)![](https://img-blog.csdn.net/20161111110837557)

![](https://img-blog.csdn.net/20161111111108905)

**CNN推导：**

**![](https://img-blog.csdn.net/20161111111155608)**

**OUT**：

![](https://img-blog.csdn.net/20161111111435078)

**S4****：**

**![](https://img-blog.csdn.net/20161111111507282)**

**C3****：**

**![](https://img-blog.csdn.net/20161111111518407)**

****S2******：**注1。

**![](https://img-blog.csdn.net/20161111111526188)**

**C1****：**

**![](https://img-blog.csdn.net/20161111112331302)**

注1：卷积的反向传播过程如下，参考神经网络的反向传播过程，l层的灵敏度等于该层神经元与l+1层有链接的神经元的权值乘以对应的l+1层的灵敏度，然后求和。例如：a只对应l+1层的Aa+Bb+Cd+De,其权值是A，所以l层的灵敏度是![](https://img-blog.csdn.net/20161112114036984)；e对应l+1层的所有，权值分别是D，C，B，A，所以l层的灵敏度是![](https://img-blog.csdn.net/20161112114051181)；总结卷积的反向传播过程可以发现，相当于将卷积核转180度再与l+1层的灵敏度做全卷积。

**![](https://img-blog.csdn.net/20161111111809320)**

**参考：**

**1.[http://blog.csdn.net/u013007900/article/details/51428186](http://blog.csdn.net/u013007900/article/details/51428186)**

****2.[http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C](http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)****

