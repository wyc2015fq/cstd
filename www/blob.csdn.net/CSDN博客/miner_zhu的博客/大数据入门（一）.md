# 大数据入门（一） - miner_zhu的博客 - CSDN博客





2018年07月19日 11:16:19[miner_zhu](https://me.csdn.net/miner_zhu)阅读数：1969








# 大数据入门
- **hadoop**
- **HDFS**
- **YARN**
- **SPARK**

## hadoop

hadoop生态圈包括以下各个组成部分： 
![这里写图片描述](https://img-blog.csdn.net/20180319125326982?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L0FHRV8wMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

HDFS：用于分布式文件存储,切分成块，多副本存于多台机器。 

YARN：用于资源管理和调度，job scheduling & cluster mangment 

Zookeeper：各个框架的管理和协调 

Hive：使系统支持SQL语句 

ooize：工作流 

pig：使用脚本scripting离线 

Flume：收集log 

sqoop：DB中数据转向别处

原生的hadoop有诸多问题，如jar包冲突，难以管理，一般不直接用于生产环境。 

所以一般使用CDH版的hadoop。 

特点：可靠性—多副本存储+作业重新调度计算 

可扩展—横向多机扩展+纵向单集群多节点 

可建设在廉价机器上，并有可靠而完整的生态圈子

## HDFS

特性： 

分块- - -每块小，可以并行；每台机器存储量差不多，存储量均衡 

冗余- - -冗余机制保障了可靠性 

分为管理节点的namenode NN和存储数据的节点DataNode DN 

NN：相应client请求，管理文件名，副本系数，block存放的DN 

DN：存储block，向NN发送心跳以及block report 

注：NN和DN可同台机器，但是不建议这样配置

副本因子决定了每个副本存放几份。 

副本的存放策略：先在本台机器上存储，再在本机架上的DN上存储，最后存放在别的机架上的DN。 

调用HDFS的方式有shell方式和调用java API接口的方式完成

HDFS读写文件流程： 
![这里写图片描述](https://img-blog.csdn.net/20180319131236634?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L0FHRV8wMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

特点总结： 

冗余容错机制，廉价机器组建，处理流的数据访问（一次写入多次读取）适合存取大文件。但是不适合存储小文件，访问慢，元数据太多存取吃力。

### YARN

Yet Another Resource Negotiator 

产生的背景在于：原来版本的hadoop架构存在问题，单点压力过大，不易扩展，不支持别的计算框架（如spark） 

效果：hadoop1.x只支持MapReduce框架 

2.x之后有了YARN，可以支持多种计算框架 

提升了资源利用率，多个集群可以化为1个共享集群使用，不用跨域。

### SPARK

MapReduce缺陷：M和R过程都要有，只能一个接一个的计算。计算结果放在磁盘落地存储，IO开销过大。进程级别消费（Map和Reduce） 

Spark的改进：程序编写简单，支持多种计算方式，计算结果放在内存，适合于迭代处理、流式处理、交互式处理。 

spark是一个分布式的计算框架，最早来源于一篇论文。快在基于线程和内存计算。支持多种语言编写（Java/Scala/Python）有交互式命令行可以随机测试。可在多种环境下运行，访问多种数据源。 

spark也有相应hadoop的BDAS生态圈 
![这里写图片描述](https://img-blog.csdn.net/20180319132700447?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L0FHRV8wMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



