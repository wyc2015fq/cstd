# 人工智能基础笔记 - miner_zhu的博客 - CSDN博客





2018年07月13日 09:06:03[miner_zhu](https://me.csdn.net/miner_zhu)阅读数：134











人工智能：机器模拟人的意识和思维。

机器学习：机器学习是一种统计学方法，计算机利用已有数据得出某种模型，再利用这个模型预测结果。

特点：随经验的增加，效果会变好。

机器学习三要素：数据，算法，算力

深度学习：深层次神经网络，源于对生物神经元结构的研究

人脑神经网络：随着人的成长，脑神经网络是在渐渐变粗变壮。

人工智能->机器学习->深度学习

庞大的神经网络是基于神经元结构的，是输入乘以权重，再求和，再过非线性函数的过程。



基于tensorflow的NN：用张量表示数据，用计算图搭建神经网络，用会话执行计算图，优化线上的权重（权重），得到模型。

张量：多维数组（列表）阶：张量的维数

计算图：搭建神经网络的计算过程，只搭建，不计算。

会话：执行计算图中的节点运算。

参数：神经元线上的权重w，用变量表示，随机给初值。

神经网络实现过程：

1:，准备数据集，提取特征，作为输入喂给神经网络；

2，（前向传播算法->计算输出）搭建神经网络结构，从输入到输出（先搭建图运算，再用会话执行）；

3，（反向传播算法->优化参数训练模型）大量特征数据喂给神经网络，迭代优化神经网络参数；

4，使用训练好模型预测和分类

变量初始化、计算图节点运算都要用会话（with结构）实现

变量初始化：在sess.run函数中用tf.globle_variable_initializer()

计算图节点运算：在sess.run函数中写入待运算节点

用tf.placeholder占位，在sess.run函数中用feed_dict喂数据

反向传播=》训练模型参数，在所有参数上用梯度下降，使NN模型在训练数据上的损失函数最小。

损失函数（loss）：预测值（y）与已知答案（y_）的差距

均方误差MSE：loss = tf.Reduce_mean(tf.square(y_-y))

反向传播训练方法：以减少loss值为优化目标

学习率：决定参数每次更新的幅度

搭建神经网络的八股：准备、前传、反传、迭代

准备：import，常量定义，生成数据集

前传：定义输入，参数和输出

反传：定义损失水函数，反向传播方法

迭代：生成会话，训练steps轮



