# NLP之贝叶斯网络 - miner_zhu的博客 - CSDN博客





2018年09月19日 19:17:44[miner_zhu](https://me.csdn.net/miner_zhu)阅读数：170








# 贝叶斯网络

贝叶斯网络又称为信度网络或信念网络（belief networks），是一种基于概率推理的数学模型，其理论基础是贝叶斯公式。贝叶斯网络的概念最初是由Judea Pearl于1985年提出来的，其目的是通过概率推理处理不确定性和不完整性问题。

形式上，一个贝叶斯网络就是一个有向无环图（directed acyclic graph, DAG），结点表示随机变量，可以是可观测量、隐含变量、未知参量或假设等；结点之间的有向边表示条件依存关系，箭头指向的结点依存于箭头发出的结点（父结点）。两个结点没有连接关系表示两个随机变量能够在某些特定情况下条件独立，而两个结点有连接关系表示两个随机变量在任何条件下都不存在条件独立。**条件独立**是贝叶斯网络所依赖的一个核心概念。每一个结点都与一个概率函数相关，概率函数的输入是该结点的父结点所表示的随机变量的一组特定值，输出为当前结点表示的随机变量的概率值。概率函数值的大小实际上表达的是结点之间依存关系的强度。假设父结点有n个布尔变量，概率函数可表示成由2^n个条目构成的二维表，每个条目是其父结点各变量可能的取值（“T”或“F”）与当前结点真值的组合。

例如，如果一篇文章是关于南海岛屿的新闻（将这一事件记作“News”），文章可能包含介绍南海岛屿历史的内容（这一事件记作“History”），但一般不会有太多介绍旅游风光的内容（将事件“有介绍旅游风光的内容”记作“Sightseeing”）。我们可以构造一个简单的贝叶斯网络，如图6-3所示。

![](https://img-blog.csdn.net/2018091816371951?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21pbmVyX3podQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

在这个例子中，“文章是关于南海岛屿的新闻”这一事件直接影响“有介绍旅游风光的内容”这一事件。如果分别用N、H、S表示这三个事件，每个变量都有两种可能的取值“T”（表示“有、是”或“包含”）和“F”（表示“没有”、“不是”或“不含”），于是可以对这三个事件之间的关系用贝叶斯网络建模。

三个事件的联合概率函数为：P（H，S，N）＝P（H|S，N）×P（S|N）×P（N）。

这个模型可以回答如下类似的问题：如果一篇文章中含有南海岛屿历史相关的内容，该文章是关于南海新闻的可能性有多大？

![](https://img-blog.csdn.net/20180918163831649?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21pbmVyX3podQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



构造贝叶斯网络是一项复杂的任务，涉及表示、推断和学习三个方面的问题。

（1）表示：在某一随机变量的集合x＝{X1，L，Xn}上给出其**联合概率分布**P。在贝叶斯网络表示中的主要问题是，即使在随机变量仅有两种取值的简单情况下，一个联合概率分布也需要对x1，L，xn的所有2n种不同取值下的概率情况进行说明，这无论从计算代价和人的认知能力方面，还是从统计方法学习如此多参数的可能性方面，几乎都是难以做到或者代价昂贵的事情。

（2）推断：由于贝叶斯网络是变量及其关系的完整模型，因此可以回答关于变量的询问，如当观察到某些变量（证据变量）时，推断另一些变量子集的变化。在已知某些证据的情况下计算变量的后验分布的过程称作**概率推理**。常用的精确推理方法包括**变量消除法（variable elimination）和团树（clique tree）法**。变量消除法的基本任务是计算条件概率p（XQ|XE＝x），其中，XQ是询问变量的集合，XE为已知证据的变量集合。其基本思想是通过分步计算不同变量的边缘分布按顺序逐个消除未观察到的非询问变量［Zhang and Poole, 1996］。团树法使用更全局化的数据结构调度各种操作，以获得更加有益的计算代价。

常用的近似推理算法有重要性抽样法（importance sampling）、随机马尔可夫链蒙特卡罗（Markov chain Monte Carlo, MCMC）模拟法、循环信念传播法（loopy belief propagation）和泛化信念传播法（generalized belief propagation）等。

3）学习：参数学习的目的是决定变量之间相互关联的量化关系，即依存强度估计。也就是说，对于每个结点X来说，需要**计算给定父结点条件下X结点的概率**，这些概率分布可以是任意形式的，通常是离散分布或高斯分布。常用的参数学习方法包括最大似然估计法、最大后验概率法、期望最大化方法（EM）和贝叶斯估计方法。在贝叶斯图模型中使用较多的是贝叶斯估计法。

除了参数学习以外，还有一项任务是寻找变量之间的图关系，即结构学习。在很简单的情况下贝叶斯网络可以由专家构造，但是在多数实用系统中人工构造一个贝叶斯网络的结构几乎是不可能的，因为这一过程过于复杂，必须从大量数据中学习网络结构和局部分布的参数。自动学习贝叶斯网络的图结构一直是机器学习领域研究的一项颇具挑战性的任务。

由于贝叶斯网络是一种不定性因果关联模型，**能够在已知有限的、不完整、不确定信息的条件下进行学习和推理**，因此广泛应用于故障诊断和维修决策等领域。在自然语言处理中已有专家将其应用于汉语自动分词和词义消歧等任务。



