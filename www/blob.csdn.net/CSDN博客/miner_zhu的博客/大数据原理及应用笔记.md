# 大数据原理及应用笔记 - miner_zhu的博客 - CSDN博客





2018年07月13日 09:03:45[miner_zhu](https://me.csdn.net/miner_zhu)阅读数：584








**分布式文件系统HDFS**

文件以多副本的方式进行存储

架构：1 master（NameNode）带n slaves（DataNode）；Name node在内存里，datanode在硬盘里。1个文件拆分为多个Block。

NameNode：1负责客户端请求的响应；2负责元数据（文件的名称，副本系数，Block存放的DN）的管理

DataNode：1存储用户的文件对应的数据块（Block）；2定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况。

建议NN和DN部署在不同节点上

常用访问语言：shell命令，java api



**资源调度框架YARN**

产生背景：MapReduce1.x存在问题：1JobTrackern TaskTracker单点故障&节点压力大不易扩展；资源利用率&运维成本；

不同计算框架可以共享同一个hdfs集群上的数据，享受整体的资源调度。按资源进行分配，提高集群资源利用率

YARN的架构：1ResourceManager:RM;

整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度；

处理客户端的请求提交/杀死一个作业

2NodeManager:NM;

整个集群有多个，负责自己自身节点资源管理和使用

定时向RM汇报本节点的资源使用情况

接受并处理来自RM的各种命令：启动Container

处理来自AM的命令

单个节点的资源管理

3ApplicationMaster:AM;

         每个应用程序对应一个：MR、Spark、负责应用程序的管理

         为应用程序向RM申请资源（core。memory），分配给内部task

         需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container

4 Container;5Client

         封装了CPU、Memory等资源的一个容器

         是一个任务运行环境的抽象

5 Client

         提交作业

         查询作业的运行进度

         杀死作业



**分布式计算框架MapReduce**

优点：海量数据离线处理&易开发&易运行

缺点：实时流式运算困难

例：wordcount

1文件内容小：shell

2文件内容很大： 

核心概念：

MapReduce执行步骤：准备map处理的输入数据；mapper处理；shufflereduce处理；结果输出

Split：交由MapReduce作业处理的数据块，是MapReduce中最小的计算单元

         HDFS：blocksize是HDFS中最小的存储单元，128M

         默认情况下：他们两是一一对应的

InputFormat：将我们的输入数据进行分片（Split）

         TextInputFormat：处理文本格式的数据

OutputFormat：输出

Combiner：可以理解为本地的reducer；减少MapTasks输出的数据量及数据网络传输量

Partitioner：决定MapTask输出的数据交由哪个ReduceTask处理；默认实现：分发的key的hash值对ReduceTask个数取模

MapReduce1.x的架构：

1）  Jobtracker：JT

作业的管理者

将作业分解为一堆的任务：Task（Maptask和Reducetask）

 将任务分配给Tasktracker运行

作业的监控、容错处理

2）  TaskTracker：TT

任务的执行者

在TT上执行我们的Task（Maptask和Reducetask）

会与JT进行交互：执行/启动/.停止作业，发送心跳信息给JT

3）  MapTask

自己开发的map任务交由该Task出来

解析每条记录的数据，交由自己的map方法处理

将map的输出结果写到本地磁盘（有些作业只有map没有reduce==>HDFS）

4)ReduceTask

         将MapTask输出的数据进行读取

         按照数据进行分组传给我们自己编写的reduce方法处理

         输出结果写到HDFs



**分布式数据库HBase**

是一个稀疏的多维度的排序的映射表。四个元素：行键，列族，列限定符，时间戳。列族支持动态扩展，旧的版本会保留。



**大数据平台Hadoop spark**

两大问题：1如何实现分布式计算2如何做到分布式并行编程

大数据处理的三大类型：1复杂的批量数据处理2基于历史数据的交互查询3基于实时数据流的数据处理

大数据处理平台hadoop：4大部分，1 common：java的一些库 2 YARN调度平台：资源分配和数据分发 3 HDFS分布式文件系统 4 map-reduce分布式编程。核心是HDFS和map-reduce。

缺点：1表达能力有限2磁盘io开销大3延迟高

Map-reduce编程方式：顺序读取大量数据，map操作：通过map运算获取关心的内容，group操作：按照键值对的形式实现聚集的运算（hadoop平台自己完成），reduce操作：进行总结、变化运算达到结果

大数据处理平台Spark：1运行速度快：基于内存运算2容易使用：支持scala、python、java、r多种语言编程3通用性4运行模式多样



**NoSql数据库**

非关系数据库。满足各种非结构数据的存储需求。常包括键值数据库，列族数据库，文档数据库，图形数据库。

特点：1灵活的可扩展性2灵活的数据模型3和云计算的紧密结合

键值数据库：一堆的键值对。键是一个字符串对象，值可以是任意类型的数据。理想的缓冲层解决方案；列族数据库：HBase根据列族进行垂直划分，根据行键进行水平划分；文档数据库：可看做键值数据库；图数据库：以图结构方式存储相关信息。

NoSQL的三大理论基石：CAP理论，BASE理论，最终一致性。CAP理论：一个分布式系统在一致性，可用性和分区容忍性中最多满足两个。



**信息检索（IR）**

文本分类、垃圾过滤、聚类分析、推荐系统、q&a

需要：数据库、信息情报领域、人工智能、自然语言处理、机器学习。

倒排索引：



推荐系统、电子商务

Web搜索引擎：信息搜索

文本单词重要性：map-reduce



索引indexes

Hash



Hadoop实战之慕课网

行为日志生成渠道：Ndinx Ajax



日志数据内容：

1）  访问的系统属性：操作系统、浏览器等

2）  访问特征：点击的url、从哪个url跳转过来的（refeer）、页面上的停留时间等

3）  访问信息：session_id、访问ip（访问城市）等



数据处理流程

1）  数据采集

Flume：web日志写入到HDFS

2）  数据清洗

脏数据

Spark、Hive、MapReduce或者其他的一些分布式计算框架

清洗完之后的数据可以存放在HDFS（Hive/Spark SQL）

3）  数据处理

按照我们的需要进行相应业务的统计和分析

Spark、Hive、MapReduce或者其他的一些分布式计算框架

4）  处理结果入库

结果可以存放在RDBMS、NoSQL

5）  数据的可视化

通过图形化的展示的方式展现出来：饼图、柱状图、地图、折线图

ECharts、HUE、Zeppelin



