# Make Your Own Neural Network（八）-----利用矩阵计算三层神经网络的输出结果 - Popeye_the_Sailor - CSDN博客
2018年05月01日 22:42:48[_Sailor_](https://me.csdn.net/lz0499)阅读数：1584

**Make Your Own Neural Network**
**构建你自己的神经网络**
[https://blog.csdn.net/lz0499](https://blog.csdn.net/lz0499)
**作者：lz0499**
**声明：**
1）**Make Your Own Neural Network**翻译自[Tariq Rashid](https://book.douban.com/search/Tariq%20Rashid)编写的神经网络入门书籍。作者的目的是尽可能的少用术语和高深的数学知识，以图文并茂的方式讲解神经网络是如何工作的。任何拥有高中数学水平的人就能够理解神经网络的工作方式。强烈推荐初学者以这本书作为神经网络入门书籍。
2）本文仅供学术交流，非商用。翻译的初衷是一边翻译一边加深对神经网络的理解。
3）由于刚刚接触神经网络这方面的知识，翻译过程中难免有些错误。若发现错误，还请各位前辈指正。谢谢！
4）由于工作原因，我将有选择的按照原文的章节不定期的进行翻译更新。
5）此属于第一版本，若有错误，还需继续修正与增删。
目录：
第一部分：神经网络是如何工作的
[一种简单的预测机](https://mp.csdn.net/postedit/80069089)
[分类即是预测](https://blog.csdn.net/lz0499/article/details/80072948)
[训练一个简单的分类器](https://blog.csdn.net/lz0499/article/details/80086402)
[单个分类器似乎远不够](https://blog.csdn.net/lz0499/article/details/80099968)
[神经元，自然界的计算机](https://blog.csdn.net/lz0499/article/details/80138584)
[通过神经网络的信号](https://blog.csdn.net/lz0499/article/details/80138955)
[矩阵很有用](https://blog.csdn.net/lz0499/article/details/80160354)
[利用矩阵计算三层神经网络的输出结果](https://blog.csdn.net/lz0499/article/details/80160449)
[从多个节点更新权重](https://blog.csdn.net/lz0499/article/details/80172534)
[从多个节点中反向传递误差](https://blog.csdn.net/lz0499/article/details/80172568)
[多层神经网络层反向传输误差](https://blog.csdn.net/lz0499/article/details/80185692)
[利用矩阵乘法计算反向传输误差](https://blog.csdn.net/lz0499/article/details/80185923)
[实际上是如何更新权重（一）](https://blog.csdn.net/lz0499/article/details/80209928)
[实际上是如何更新权重（二）](https://blog.csdn.net/lz0499/article/details/80210590)
[权重更新实例](https://blog.csdn.net/lz0499/article/details/80212695)
**利用矩阵计算三层神经网络的输出结果**
我们之前没有使用矩阵来表达神经网络中的各种计算，也没有计算超过两层的神经网络最后的结果。超过两层的神经网络确实更有意思些，我们想知道神经网络中的中间层是如何作为第三层的输入信号。
下图表示的是每一个拥有三个节点，共三层的神经网络。为了更清晰的表示出计算结果，并没有把所有权重都写出来：
**![](https://img-blog.csdn.net/20180501223202444)**
现在我们介绍一些计算过程中常用的专业术语。我们知道，第一层是输入层，最后一层为输出层。中间层我们称之为隐藏层。这个术语听起来有些神秘，当可惜的是只是一个名字而已，并没有其他太多的神秘可言。
让我们开始计算这个神经网络的输出值。如图所示，我们可以指导输入信号分辨为0.9,0.1,0.8.所以，输入矩阵**I**为：
**![](https://img-blog.csdn.net/20180501223229334)**
这个很简单。第一层的输入信号就计算完成了。
下一层是中间隐藏层的计算了。我们知道，中间隐藏层的各个节点与输入层的各个节点互相连接，所以这涉及到很多计算。我们不打算在一个一个单独计算其结果，我们想利用矩阵这个强大的工作，使用矩阵乘法计算。
就像我们之前做过的一样，输入信号的加权和经过sigmoid激活函数处理之后，得到X=WI。其中**I**是输入信号矩阵，W为权重矩阵。但是W的具体值是多少呢？上述图例中只是标出了一部分权重而不是全部权重，下图表示了余下的权重，我们依旧是使用随机值表示余下的各个权重。
我们可以从图表中可以看出，输入信号的第一个节点与隐藏层的第一个节点的权重值为W1,1=0.9.同样，输入信号的第二个节点与隐藏层的第二个节点的权重值为W2.2=0.8。上述图例中并没有标注出输入信号的第三个节点与隐藏层的第一个节点的权重值，我们设置为W3,1=0.4。
等等，**W**旁边的（input_hiden）输入_隐藏表示的是什么鬼？由于表示的是输入层和中间隐藏层之间的权重，所以我们使用输入_隐藏下标表示这两层之间的权重。我们需要另外一个矩阵表示隐藏层和输出层之间的权重值，我们使用**W**隐藏层_输出下标表示。
下图表示的是中间隐藏层和输出层之间的权重值。从图中我们可以看出，中间隐藏层的第三个节点与输出层的第三个节点的权重值为0.9.
![](https://img-blog.csdn.net/20180501223433877)
很好！我们已经用矩阵表示出了各个神经网络层之间的权重值。余下的工作就是利用矩阵的乘法进行计算了。
让我们从第一层到中间隐藏层开始计算。我们假设这一次计算出的结果用**X**隐藏表示。它仅仅表示输入到隐藏层的输入信号权重和，而不是最后一层的权重和。
![](https://img-blog.csdn.net/20180501223522656)
在这我们并不打算计算这两个矩阵的相乘结果，我们想利用计算机帮助我们计算其最后的输入结果。其结果如下：
![](https://img-blog.csdn.net/20180501223545535)
我使用计算机计算出了其最后的结果。我们后续将会学会如何使用Python编程语言计算其结果。我们现在不打算描述如何使用计算机进行矩阵运算的，这部分内容将在本书的第二部分描述。
从输入层到中间层我们有了其加权和为1.16,0.42,0.62。并且我们开始使用矩阵计算其加权和。这个是一个很大的进步了。
如下图表示的是上述的计算过程。
![](https://img-blog.csdn.net/20180501223619503)
到目前为止，一切都还不错。但是还有更多的计算还需要做。就像自然界中的实际神经网络，求出的加权和需要经过sigmoid激活函数的作用之后才最终输出其结果。故有：
![](https://img-blog.csdn.net/20180501223704236)
Sigmoid激活函数![](https://img-blog.csdn.net/20180501223737493)作用于后，输出中间隐藏层的结果为：
![](https://img-blog.csdn.net/20180501223753183)
让我们检验下是否计算得正确。Sigmoid激活函数为![](https://img-blog.csdn.net/20180501223824724)，所以，当x=1.16时，这意味着最后的输出y=1/(1+0.3135)=0.761。
从输出结果我们可以观察到，输出结果都在0到1的范围，因为sigmoid函数不会输出超过这个范围的数。
让我们停下来，想想我们刚才发做了什么。我们计算出了中间隐藏层的输出结果。也即是输入信号经过加权求和之后再经过Sigmoid激活函数之后的结果。让我们更新下最新的图表：
![](https://img-blog.csdn.net/20180501223849317)
如果这是一个两层的神经网络，那么我们就已经算出这个神经网上络的输出结果了。实际这是一个三层的神经网络，我们还得继续往下接着算。
如何计算出第三层网络的结果呢？过程其实同之前计算中间层输出结果一样。第三层的输入信号即是中间层的输出结果，我们计算其加权和之后，再经过sigmoid函数输出最后的结果。我们应该记住，无论神经网络有多少层，我们都可以按照之前那层的算法一步一步计算：求出输入信号的加权和，之后再经过sigmoid激活函数的阈值处理，输出其最后的结果。我们不必关心神经网络中是3层还是53层，甚至是103层，其计算方法都是一样的。
所以，让我们按照之前的计算方法再计算第三层神经网络的输出结果。第三层神经网络的入是第二次神经网络的输出结果![](https://img-blog.csdn.net/20180501223940835)。第二层和第三层各个节点之间的权重值为![](https://img-blog.csdn.net/20180501223951852)，而不是我们之前计算的第一层与第二次之间的权重。所以，我们有如下式子：
![](https://img-blog.csdn.net/20180501224015970)
最终计算出来的结果为;
![](https://img-blog.csdn.net/20180501224044433)
我们更新计算流程结果图：
![](https://img-blog.csdn.net/20180501224107660)
再把加权和输入给sigmoid激活函数有：
![](https://img-blog.csdn.net/20180501224154280)
这就是最后的结果。输入信号经过神经网络之后，我们计算出了其最终的结果。如下图所示;
![](https://img-blog.csdn.net/20180501224216744)
最终输出结果分别为0.726,0.708,0.778.
下一步我们该做什么处理呢?
下一步我们将计算出来的输出结果与实际的训练数据进行比较得到一个误差。我们将利用该误差值再进一步指导神经网络，使得输出更为准确的输出结果。
下一小节中，我们将慢慢道来：如何利用误差值指导神经网络得到更为准确的输出结果。



