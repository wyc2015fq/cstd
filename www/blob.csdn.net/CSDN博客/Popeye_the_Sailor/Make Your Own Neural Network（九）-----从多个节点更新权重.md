# Make Your Own Neural Network（九）-----从多个节点更新权重 - Popeye_the_Sailor - CSDN博客
2018年05月02日 21:44:22[_Sailor_](https://me.csdn.net/lz0499)阅读数：603

**Make Your Own Neural Network**
**构建你自己的神经网络**
[https://blog.csdn.net/lz0499](https://blog.csdn.net/lz0499)
**作者：lz0499**
**声明：**
1）**Make Your Own Neural Network**翻译自[Tariq Rashid](https://book.douban.com/search/Tariq%20Rashid)编写的神经网络入门书籍。作者的目的是尽可能的少用术语和高深的数学知识，以图文并茂的方式讲解神经网络是如何工作的。任何拥有高中数学水平的人就能够理解神经网络的工作方式。强烈推荐初学者以这本书作为神经网络入门书籍。
2）本文仅供学术交流，非商用。翻译的初衷是一边翻译一边加深对神经网络的理解。
3）由于刚刚接触神经网络这方面的知识，翻译过程中难免有些错误。若发现错误，还请各位前辈指正。谢谢！
4）由于工作原因，我将有选择的按照原文的章节不定期的进行翻译更新。
5）此属于第一版本，若有错误，还需继续修正与增删。
目录：
第一部分：神经网络是如何工作的
[一种简单的预测机](https://mp.csdn.net/postedit/80069089)
[分类即是预测](https://blog.csdn.net/lz0499/article/details/80072948)
[训练一个简单的分类器](https://blog.csdn.net/lz0499/article/details/80086402)
[单个分类器似乎远不够](https://blog.csdn.net/lz0499/article/details/80099968)
[神经元，自然界的计算机](https://blog.csdn.net/lz0499/article/details/80138584)
[通过神经网络的信号](https://blog.csdn.net/lz0499/article/details/80138955)
[矩阵很有用](https://blog.csdn.net/lz0499/article/details/80160354)
[利用矩阵计算三层神经网络的输出结果](https://blog.csdn.net/lz0499/article/details/80160449)
[从多个节点更新权重](https://blog.csdn.net/lz0499/article/details/80172534)
[从多个节点中反向传递误差](https://blog.csdn.net/lz0499/article/details/80172568)
[多层神经网络层反向传输误差](https://blog.csdn.net/lz0499/article/details/80185692)
[利用矩阵乘法计算反向传输误差](https://blog.csdn.net/lz0499/article/details/80185923)
[实际上是如何更新权重（一）](https://blog.csdn.net/lz0499/article/details/80209928)
[实际上是如何更新权重（二）](https://blog.csdn.net/lz0499/article/details/80210590)
[权重更新实例](https://blog.csdn.net/lz0499/article/details/80212695)
**从多个节点更新权重**
之前我们通过改变线性函数的斜率得到了一个简单的线性分类器：通过利用线性函数计算出来的值与训练样本值之间的误差，调整斜率大小，使得线性函数输出的值愈来愈接近训练样本值。实际证明误差和斜率之间存在比较简单的关系，通过误差很容易算出接近样本训练值的斜率。
当输出及其误差是受到多个节点的影响时，我们该如何更新每个节点与输出节点之间的权重值呢？下图揭示了这个问题：
![](https://img-blog.csdn.net/20180502214229613)
果输出节点的输出结果只收一个输入节点的影响，那计算很简单。但是，当输出节点的输出结果受到不止一个输入节点的影响时，我们如何利用输出结果的误差调整对应的权重呢？
用所有误差值用于更新一个权重值显然是不合适的。因为此时忽视了其他节点对输出节点的影响。输出节点的误差是由多个输入节点影响的，而不止是受一个节点的影响。
输出结果的误差只受到一个节点的影响这种情况概率很小。
一种想法是把误差平分给受那些起作用的节点。如下图所示：
![](https://img-blog.csdn.net/20180502214259942)
另一种想法是我们把误差给那些作用比较大的相连节点，而不是把误差平分给那些起作用的节点。为什么呢？因为这些节点对误差的影响更大。下图表示的这种思考方法：
![](https://img-blog.csdn.net/20180502214325932)
上图中，输出节点受到两个输入节点的影响。两个输入节点分别以3.0和1.0的权重与输出节点相连。如果我们按照相连输入节点的权重按比例分割误差，我们可以知道3/4的误差应该用于更新第一个较大的权重；1/4的误差大小应该用于更新第二个比较小的权重值。
对于众多节点的情况，我们可以延拓这种思维方式。假设我们有100个节点与输出节点相连，
那么，其误差应该使用每一个节点占100个节点权重的比例对其权重进行更新。
可以看到，我们用了两种方式使用权重。首先，我们利用权重把输出信号传输至神经网络中，我们在之前的小节中已经计算过；其次，我们利用权重把误差从输出后向传输至神经网络中。因此，这种方法也被称之为反向传输发。
如果输出层有两个节点，我们只需要对每一个节点进行相同的操作即可。输出层的第二个节点将有自己的误差，同样是按照相连节点的权重比例进行分割反向传输到神经网络中。
下一小节中，我们将详细介绍如何把误差反向传输至神经网络中。
