# 深度模型部署 - sinat_31425585的博客 - CSDN博客
2019年03月19日 00:56:56[Mirror_Yu_Chen](https://me.csdn.net/sinat_31425585)阅读数：30
**1、opencv**
    主要难点在于模型的输入输出，这个可以通过caffe model的deploy.prototxt获知，设置完输入和输出后，然后通过一个forward前向操作来得到当前输入图像对应的预测结果，这里是载入2015年性别年龄识别中年龄模型对应代码：
```cpp
cv::dnn::Net net;
// 1. load caffe model
std::string age_model_path = std::string(root_path) + "/net.caffemodel";
std::string age_txt_path = std::string(root_path) + "/deploy.prototxt";
net = cv::dnn::readNetFromCaffe(txt_path, model_path);
if (net.empty()) {
   std::cout << "error load caffe model." << std::endl;
   return -1;
}
// 2. set the data of input
cv::Mat blob = cv::dnn::blobFromImage(face, 1.0, cv::Size(227, 227), mean_file_, false);
net.setInput(blob, "data");
// 3. forward to predict
cv::Mat prob_gender = net.forward("prob");
cv::Mat prob_mat_gender = prob_gender.reshape(1, 1);
cv::Point class_num_gender;
double class_prob_gender = 0.0;
// 4.get the result
cv::minMaxLoc(prob_mat_gender, NULL, &class_prob_gender, NULL, &class_num_gender);
int class_index_gender = class_num_gender.x;
if (prob_mat_gender.at<float>(0, 0) > prob_mat_gender.at<float>(0, 1)) {
     *gender_result = "male"; 
} else { 
    *gender_result = "female"; 
}
```
**2、ncnn**
    ncnn模型结构是利用.param文件进行定义的，解析过程中，同样只需要关注输入层和输出层，及输入输出层对应维度，这里难点在于输入为单通道的图像时，如何设置输入，这里代码对应人脸关键点定位网络vanface的模型载入预测过程。
```cpp
// 1. define net
ncnn::Net net;
net.use_int8_inference = 0;
std::string param_files = std::string(root_path) + "/net.param";
std::string bin_files = std::string(root_path) + "/net.bin";
// 2. load model file
if (net.load_param(param_files.data()) == -1 ||
    net.load_model(bin_files.data() == -1) {
    std::cout << "error in load ncnn model." << std::endl;
    return -1;
}
// 3. read image data
cv::Mat src_roi = img_src(face_rect).clone();
cv::Mat img_gray;
cv::cvtColor(src_roi, img_gray, cv::COLOR_BGR2GRAY);
img_gray.convertTo(img_gray, CV_32FC1);
cv::resize(img_gray, img_gray, netSize, 0, 0);
// 4. subtract mean and divide dev
cv::Mat img_mean, img_dev;
cv::meanStdDev(img_gray, img_mean, img_dev);
img_gray = (img_gray - img_mean.at<double>(0, 0)) /
        (img_dev.at<double>(0, 0) + 0.0000001);
// 5. set the input of the network
ncnn::Mat in = ncnn::Mat(netSize.width, netSize.height, img_gray.data, 4);
ncnn::Extractor ex = vanFaceNet.create_extractor();
ex.set_light_mode(true);
ex.set_num_threads(4);
ex.input("data", in);
ncnn::Mat out;
// 6. get the result
ex.extract("Dense3", out);
cv::Point start_pt = cv::Point(face_rect.x, face_rect.y);
std::vector<cv::Point> land_mark;
for (int i = 0; i < out.total() / 2; i++) {
    cv::Point curr_pt = cv::Point(out[2 * i] * face_rect.width,
            out[2 * i + 1] * face_rect.height) + start_pt;
    cv::circle(*img_shape, curr_pt, 3, cv::Scalar(0, 255, 0), CV_FILLED);
        land_mark.push_back(curr_pt);
}
```
~~~~~未完待续~~~~~~~~
