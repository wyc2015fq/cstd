# 周志华《机器学习》 学习笔记（一）   引言与基本术语 - HJ - CSDN博客
2018年01月19日 22:15:54[FZH_SYU](https://me.csdn.net/feizaoSYUACM)阅读数：281
所属专栏：[机器学习](https://blog.csdn.net/column/details/19571.html)

**一、引言**
机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“**模型**”（model）的算法，即“**学习算法**”（learning
 algorithm）。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时（例如看到一个没剖开的西瓜），模型会给我们提供相应的判断（例如好瓜）。如果说计算机科学是研究关于“算法”的学问，那么类似的，可以说机器学习是研究关于“学习算法”的学问。
Mitchell，1997给出了一个更形式化的定义：假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T中任务获得了性能改善，则我们就说关于T和P，改程序对E进行了学习。
**二、基本术语**
要进行机器学习，先要有数据。假设我们收集了一批关于西瓜的数据，例如（色泽=青绿；根蒂=蜷缩；敲声=浊响），（色泽=乌黑；根蒂=稍蜷；敲声=沉闷），（色泽=浅白；根蒂=硬挺；敲声=清脆），……，每对括号内是一条记录，“=”意思是“**取值为**”。
这组记录的集合称为一个“**数据集**”（data set），其中每条记录是关于一个事件或对象（这里是一个西瓜）的描述，称为一个“**示例**”（instance）或“**样本**”（sample）。反映事件或对象在某方面的表现或性质的事项，例如“色泽”“根蒂”“敲声”，称为“**属性**”（attribute）或“**特征**”（feature）；属性上的取值，例如“青绿”“乌黑”，称为“**属性值**”（attribute
 value）。属性张成的空间称为“**属性空间**”（attribute space）、“**样本空间**”（sample space）或“**输入空间**”。例如我们把“色泽”“根蒂”“敲声”作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置。由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个“**特征向量**”（feature
 vector）。
一般地，令D={x1,x2,……,xm}表示包含m个示例的数据集，每个示例由d个属性描述（例如上面的西瓜数据使用了3个属性），则每个示例xi=(xi1;xi2;...;xid)是d维样本空间χ中的一个向量，xi∈χ，其中xij是xi在第j个属性上的取值（例如上述第3个西瓜在第2个属性上的值是“硬挺”），d称为样本xi的“**维数**”（dimensionality）。
从数学中学得模型的过程称为“**学习**”（learning）或“**训练**”（training），这个过程通过执行某个学习算法来完成。训练过程中使用的数据称为“**训练数据**”（training
 data），其中每个样本称为一个“**训练样本**”（training sample），训练样本组成的集合称为“**训练集**”（training set）。学得模型对应了关于数据的某种潜在规律，因此亦称“**假设**”（hypothesis）；这种潜在规律自身，则称为“**真相**”或“**真实**”（ground-truth），学习过程就是为了找出或逼近真相。有的时候将模型称为“**学习器**”（learner），可看做学习算法在给定数据和参数空间上的实例化。
如果希望学得一个能帮助我们判断没剖开的是不是“好瓜”的模型，仅有前面的示例数据显然是不够的。要建立这样的关于“**预测**”（prediction）的模型，我们需获得训练样本的“结果”信息，例如“（（色泽=青绿；根蒂=蜷缩；敲声=浊响），好瓜）”。这里关于示例结果的信息，例如“好瓜”，称为“**标记**”（label）；拥有了标记信息的示例，则称为“**样例**”（example）。一般地，用（xi,yi）表示第i个样例，其中yi∈У是示例xi的标记，У是所有标记的集合，亦称“**标记空间**”（label
 space）或“**输出空间**”。
若我们欲预测的是离散值，例如“好瓜”“坏瓜”，此类学习任务称为“**分类**”（classification）；若欲预测的是连续值，例如西瓜成熟度0.95、0.37，此类学习任务称为“**回归**”（regression）。对只涉及两个类别的“**二分类**”（binary
 classification）任务，通常称其中一个类为“**正类**”（positive class），另一个类为“**反类**”（negative class）；涉及多了个类别时，则称为“**多分类**”（multi-class
 classification）任务。一般地，预测任务是希望通过对训练集{(x1,y1),(x2,y2),...,(xm,ym)}进行学习，建立一个从输入空间χ到输出空间У的映射f:χ→У。对二分类任务，通常令У={-1,+1}或{0,1}；对多分类任务，|У|>2；对回归任务，У=R，R为实数集。
学得模型后，使用其进行预测的过程称为“**测试**”（testing），被预测的样本称为“**测试样本**”（testing sample）。例如在学得f后，对测试例x，可得到其预测标记y=f(x)。
我们还可以对西瓜做“**聚类**”（clustering），即将训练集中的西瓜分成若干组，每组称为一个“**簇**”（cluster）；这些自动形成的簇可能对应一些潜在的概念划分，例如“浅色瓜”“深色瓜”，甚至“本地瓜”“外地瓜”。这样的学习过程有助于我们了解数据内在的规律，能更为深入地分析数据建立基础。需说明的是，在聚类学习中，“浅色瓜”“本地瓜”这样的概念我们事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。
根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：“**监督学习**”（supervised learning）和“**无监督学习**”（unsupervised
 learning），分类和回归是前者的代表，而聚类则是后者的代表。
需注意的是，机器学习的目标是使学得的模型能很好地适用于“新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能使用与没在训练集中出现的样本。学得模型适用于新样本的能力，称为“**泛化**”（generalization）能力。具有强泛化能力的模型能很好地适用于整个样本空间。于是，尽管训练集通常只是样本空间的一个很小的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作得很好。通常假设样本空间中全体样本服从一个未知“**分布**”（distribution）D，我们获得的每个样本都是独立地从这个分布上采样获得的，即“**独立同分布**”（independent
 and identically distributed，简称i.i.d）。一般而言，训练样本越多，我们得到的关于D的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。
**总结归类**
模型（model）：计算机层面的认知
学习算法（learning algorithm），从数据中产生模型的方法
数据集（data set）：一组记录的合集
示例（instance）：对于某个对象的描述
样本（sample）：也叫示例
属性（attribute）：对象的某方便表现或特征
特征feature）：同属性
属性值（attribute value）：属性上的取值
属性空间（attribute space）：属性张成的空间
样本空间/输入空间（samplespace）：同属性空间
特征向量（feature vector）：在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量
维数（dimensionality）：描述样本参数的个数（也就是空间是几维的
学习（learning）/训练（training）：从数据中学得模型
训练数据（training data）：训练过程中用到的数据
训练样本（training sample）:训练用到的每个样本
训练集（training set）：训练样本组成的集合
假设（hypothesis）：学习模型对应了关于数据的某种潜在规则
真相（group-true）:真正存在的潜在规律
学习器（learner）：模型的另一种叫法，把学习算法在给定数据和参数空间的实例化
预测（prediction）：判断一个东西的属性
标记（label）：关于示例的结果信息，比如我是一个“好人”。
样例（example）：拥有标记的示例
标记空间/输出空间（label space）：所有标记的集合
分类（classification）：预测时离散值，比如把人分为好人和坏人之类的学习任务
回归（regression）：预测值时连续值，比如你的好人程度达到了0.9，0.6之类的
二分类（binary classification）：只涉及两个类别的分类任务
正类（positive class）：二分类里的一个
反类（negative class）：二分类里的另外一个
多分类（multi-class classification）：涉及多个类别的分类
测试（testing）：学习到模型之后对样本进行预测的过程
测试样本（testing sample）：被预测的样本
聚类（clustering）：把训练集中的对象分为若干组
簇（cluster）：每一个组叫簇
监督学习（supervised learning）：典范--分类和回归
无监督学习（unsupervised learning）：典范--聚类
未见示例（unseen instance）：“新样本“，没训练过的样本
泛化（generalization）能力：学得的模型适用于新样本的能力
分布（distribution）：样本空间的全体样本服从的一种规律
独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。
