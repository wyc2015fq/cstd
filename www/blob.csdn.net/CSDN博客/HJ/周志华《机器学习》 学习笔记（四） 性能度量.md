# 周志华《机器学习》 学习笔记（四） 性能度量 - HJ - CSDN博客
2018年02月07日 01:37:40[FZH_SYU](https://me.csdn.net/feizaoSYUACM)阅读数：1042
个人分类：[机器学习](https://blog.csdn.net/feizaoSYUACM/article/category/7412520)
所属专栏：[机器学习](https://blog.csdn.net/column/details/19571.html)
**性能度量**
对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量（performance measure）。
在预测任务中，给定样例集![](https://img-blog.csdn.net/20180207011141423?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)，其中yi是示例xi的真实标记，要评估学习器f的性能，就要把学习器预测结果f(x)与真实标记y进行比较。
回归任务最常用的性能度量是“均方误差”（mean squared error）
![](https://img-blog.csdn.net/20180207011215596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
更一般的，对于数据分布D和概率密度函数p(·)，均方误差可描述为
![](https://img-blog.csdn.net/20180207011234951?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
下面主要介绍分类任务中常用的性能度量
1.**错误率与精度**
这是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务。
错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。对样例集D，分类错误率定义为
![](https://img-blog.csdn.net/20180207011308955?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
精度则定义为
![](https://img-blog.csdn.net/20180207011407020?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
更一般地，对于数据分布D和概率密度函数p(·)，错误率与精度可分别描述为
![](https://img-blog.csdn.net/20180207011445863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
![](https://img-blog.csdn.net/20180207011505461?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
2.**查准率、查全率与F1**
错误率和精度虽常用，但并不能满足所有任务需求。例如在信息检索中，我们经常会关心“检索出的信息有多少比例是用户感兴趣的”“用户感兴趣的信息中有多少被检索出来了”。“查准率”与“查全率”是更为适用于此类需求的性能度量。
对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例、假正例、真反例、假反例四种情形，令TP、FP、TN、FN分别表示其对应的样例数，则显然有TP+FP+TN+FN=样例总数。分类结果的“混淆矩阵”如下所示
![](https://img-blog.csdn.net/20180207011603399?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
查准率P定义为
![](https://img-blog.csdn.net/20180207011631552?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
查全率R定义为
![](https://img-blog.csdn.net/20180207011650173?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
查准率和查全率是一对矛盾的变量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。通常只有在一些简单任务中，才可能使查准率和查全率都很高。
在很多情况下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在后面的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称“P-R曲线”，显示该曲线的图称为“P-R图”，如下图所示
![](https://img-blog.csdn.net/20180207011718649?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
（注意：为绘图方便和美观，示意图显示出单调平滑曲线。但现实任务中的P-R曲线常是非单调、不平滑的，在很多局部有上下波动）
P-R图直观地显示出学习器在样本总体上的查全率、查准率。在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；如果两个学习器的P-R曲线发生了交叉，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较。
然而，在很多情形下，人们往往希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。
但是这个值不太容易估算，因此人们就设计出了“平衡点”（简称BEP），它是综合考查准率、查全率的性能度量，它是“查准率=查全率”时的取值。但是BEP还是过于简化了些，更常用的是F1度量
![](https://img-blog.csdn.net/20180207011810783?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
在一些应用中，对查准率和查全率的重视程度有所不同。F1度量的一般形式![](https://img-blog.csdn.net/20180207011831332?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)，能让我们表达出对查准率/查全率的不同偏好，它定义为
![](https://img-blog.csdn.net/20180207011856226?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
其中β>0度量了查全率对查准率的相对重要性。
①β=1  退化为标准的F1
②β>1  查全率有更大影响
③β<1  查准率有更大影响
很多时候我们有多个二分类混淆矩阵，当我们希望在n个二分类混淆矩阵上综合考察查准率和查全率的时候，一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，记为![](https://img-blog.csdn.net/20180207011925801?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)，再计算平均值，这样就得到“宏查准率”、“宏查全率”，以及相对应的“宏F1”：
![](https://img-blog.csdn.net/20180207011949606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
也可以先将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、FN的平均值，分别记为![](https://img-blog.csdn.net/20180207012044069?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)，再基于这些平均值计算出“微查准率”、“微查全率”、“微F1”：
![](https://img-blog.csdn.net/20180207012021758?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
3.**ROC与AUC**
很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值进行比较，若大于阈值则分为正类，否则为反类。实际上，根据这个实值或预测结果，我们可将测试样本进行排序，“最可能”是正例的排在最前面，“最不可能”是正例的排在最后面，这样，分类过程就相当于在这个排序中以某个“截断点”将样本分为两部分，前一部分判作正例，后一部分则判为反例。
在不同的应用任务中，我们可根据任务需求来采用不同的截断点。例如若我们更重视“查准率”，则可选择排序中靠前的位置进行截断；若更重视“查全率”，则可选择靠后的位置进行截断。
因此，排序本身的质量好坏，体现了综合考虑学习器在不同任务下的“期望泛化性能”的好坏，或者说，“一般情况下”泛化性能的好坏。
ROC全称是“受试者工作特征”，其ROC曲线则是从这个角度出发来研究学习器泛化性能的有力工具。
与上一点介绍的P-R曲线相似，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了“ROC曲线”。与P-R曲线使用查准率、查全率为纵、横轴不同，ROC曲线的纵轴是“真正例率”（简称TPR），横轴是“假正例率”（FPR），两者分别定义为：
![](https://img-blog.csdn.net/20180207012118497?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
下面给出了一个示意图
![](https://img-blog.csdn.net/20180207012153981?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
显然，对角线对应于“随机猜测”模型，而点(0,1)则对应于将所有正例排在所有反例之前的“理想模型”现实任务中通常是利用有限个测试样例来绘制ROC图，此时仅能获得有限个（真正例率，假正例率）坐标对，无法产生(a)中的光滑ROC曲线，只能绘制出如图(b)所示的近似ROC曲线。
进行学习器的比较时，与P-R图相似，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据就是比较ROC曲线下的面积，即AUC（Area Under ROC Curve）。如图2.4所示。
假定ROC曲线是由坐标为![](https://img-blog.csdn.net/20180207012232968?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)的点按序连接而形成![](https://img-blog.csdn.net/20180207012250965?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)，参见图2.4(b)，则AUC可估算为：
![](https://img-blog.csdn.net/20180207012310640?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
AUC考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定个![](https://img-blog.csdn.net/20180207012340440?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)正例和![](https://img-blog.csdn.net/20180207012414759?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)个反例，令![](https://img-blog.csdn.net/20180207012435205?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)和![](https://img-blog.csdn.net/20180207012453861?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)分别表示正、反例集合，则排序“损失”定义为：
![](https://img-blog.csdn.net/20180207012513202?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
即考虑每一对正、反例，若正例的预测值小于反例，则记一个“罚分”，若相等，则记0.5个罚分。容易看出，![](https://img-blog.csdn.net/20180207012739091?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)对应的是ROC曲线之上的面积：若一个正例在ROC曲线上对应标记点的坐标为（x,y），则x恰是排序在其之前的反例所占的比例，即假正例率。因此有：
![](https://img-blog.csdn.net/20180207012753950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
4.**代价敏感错误率与代价曲线**
在现实任务中，不同类型的错误所造成的后果不同。为权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”。
以二分类任务为例，我们可根据任务的领域知识设定一个“代价矩阵”，如表2.2所示，其中![](https://img-blog.csdn.net/20180207012840106?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)表示将第i类样本预测为第j类样本的代价。一般来说![](https://img-blog.csdn.net/20180207012901401?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)=0；若将第0类别为第1类所造成的损失更大，则![](https://img-blog.csdn.net/20180207012919069?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)>![](https://img-blog.csdn.net/20180207012943094?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)；损失程度相差越大，![](https://img-blog.csdn.net/20180207012919069?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)与![](https://img-blog.csdn.net/20180207012943094?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)值的差别越大。不过在一般情况下，重要的是代价比值而非绝对值，例如![](https://img-blog.csdn.net/20180207012919069?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)：![](https://img-blog.csdn.net/20180207012943094?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)=5:1与50:10所起效果相当。
![](https://img-blog.csdn.net/20180207013145345?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”，若将表2.2中的第0类作为正类，第1类作为反类，令![](https://img-blog.csdn.net/20180207013247337?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)与![](https://img-blog.csdn.net/20180207013302169?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)分别代表样例集D的正例子集和反例子集，则“代价敏感”错误率为：
![](https://img-blog.csdn.net/20180207013340835?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量如精度的代价敏感版本。
在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而“代价曲线”则可达到该目的。代价曲线图的横轴是取值为[0,1]的正例概率代价
![](https://img-blog.csdn.net/20180207013416479?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
其中p是样例为正例的概率；纵轴是取值为[0,1]的归一化代价
![](https://img-blog.csdn.net/20180207013447841?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
代价曲线的绘制：ROC曲线上每一点对应了代价平面上的一条线段，设ROC曲线上点的坐标为（TPR，FPR），则可相应计算出FNR，然后在代价平面上绘制一条从（0，FPR）到（1，FNR）的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC曲线上的每一个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为所在条件下学习器的期望总体代价，如图2.5所示：
![](https://img-blog.csdn.net/20180207013507888?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZmVpemFvU1lVQUNN/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
